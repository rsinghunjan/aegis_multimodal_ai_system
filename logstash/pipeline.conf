  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
# Logstash pipeline to ingest audit objects from S3 and index into OpenSearch/Elasticsearch
# Requires logstash-input-s3 plugin installed and logstash-output-elasticsearch

input {
  s3 {
    bucket => "YOUR_AEGIS_AUDIT_BUCKET"
    region => "YOUR_REGION"
    prefix => "aegis/audit/"
    temporary_directory => "/tmp/logstash_s3_tmp"
    sincedb_path => "/var/lib/logstash/s3_sincedb"
    codec => "plain"
    interval => 60
    # credentials can be provided via environment (AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY) or IAM role
  }
}

filter {
  # Each object is newline-delimited json; split into events
  json {
    source => "message"
    target => "audit_event"
    skip_on_invalid_json => true
  }
  # Flatten fields from audit_event to top-level for indexing
  ruby {
    code => '
      if event.get("audit_event")
        audit = event.get("audit_event")
        audit.each { |k,v| event.set(k, v) }
        event.remove("message")
        event.remove("audit_event")
      end
    '
  }
}

output {
  elasticsearch {
    hosts => ["https://your-opensearch:9200"]
    index => "aegis-audit-%{+YYYY.MM.dd}"
    ssl => true
    ssl_certificate_validation => false
    # credentials via environment or keystore
  }
  # optional: stdout { codec => rubydebug }
}
