  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
name: Model validation (promotion gate)

on:
  workflow_dispatch:
  workflow_call:
  # Optionally, wire this to runs that produce model artifacts, e.g. on tag or on model registration events

jobs:
  validate:
    runs-on: ubuntu-latest
    env:
      # point to MLflow / registry endpoints if needed; adapt for your infra
      MLFLOW_TRACKING_URI: http://localhost:5000
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install scikit-learn joblib mlflow boto3 pandas requests

      - name: Download MLflow stack for local CI (optional)
        # If your CI uses a shared MLflow, skip this step and set MLFLOW_TRACKING_URI accordingly
        run: |
          if [ -f docker/docker-compose-mlflow.yml ]; then
            sudo apt-get update
            sudo apt-get install -y docker-compose-plugin docker.io
            docker compose -f docker/docker-compose-mlflow.yml up -d --build
            # wait for MLflow
            until curl -sSf http://localhost:5000/health || true; do sleep 2; done
            echo "MLflow ready"
          else
            echo "No local docker compose found; assuming external MLflow"
          fi

      - name: Run validation
        id: validate
        run: |
          # Example usage: adapt inputs via workflow_call inputs or environment variables
          python scripts/evaluate_model.py \
            --mlflow-run-id "${{ github.event.inputs.run_id || '' }}" \
            --mlflow-artifact-path "${{ github.event.inputs.artifact_path || 'model/model.joblib' }}" \
            --mode sklearn \
            --metric accuracy \
            --baseline "${{ github.event.inputs.baseline || '0.85' }}" \
            --tolerance "${{ github.event.inputs.tolerance || '0.02' }}" \
            --emit-json validation_result.json || true

          cat validation_result.json
        # If the script returns non-zero, job will fail; the '|| true' above lets us print JSON first.
      - name: Gate outcome
        run: |
          jq -r '.status' validation_result.json | grep -q "passed"
