diff --git a/scripts/deepspeed_vllm_harness.sh b/scripts/deepspeed_vllm_harness.sh
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/scripts/deepspeed_vllm_harness.sh
@@ -0,0 +1,260 @@
+#!/usr/bin/env bash
+#
+# DeepSpeed + vLLM Staged Test Harness
+# - Scales DeepSpeed StatefulSet to requested node counts
+# - Runs a short training job (module mode) to create network & NCCL activity
+# - Runs vLLM load benchmark against the inference gateway
+# - Collects NCCL/GPU diagnostics and load-test artifacts
+# - Optionally uploads artifacts to S3 or writes them to a local artifacts dir
+#
+# Usage:
+#   ./scripts/deepspeed_vllm_harness.sh --nodes 2 --rounds 3 --gateway http://gateway:8080/generate --artifact-dir ./artifacts --s3-bucket my-bucket --s3-prefix artifacts/deepspeed
+
+set -euo pipefail
+
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+DS_STATEFULSET="${DS_STATEFULSET:-deepspeed-trainer}"
+NODES="${NODES:-2}"
+ROUNDS="${ROUNDS:-2}"
+GATEWAY="${GATEWAY:-http://aegis-inference-gateway.aegis-ml.svc.cluster.local/generate}"
+ARTIFACT_DIR="${ARTIFACT_DIR:-./artifacts}"
+S3_BUCKET="${S3_BUCKET:-}"
+S3_PREFIX="${S3_PREFIX:-}"
+VLLM_CONCURRENCY="${VLLM_CONCURRENCY:-8}"
+VLLM_REQUESTS="${VLLM_REQUESTS:-100}"
+TEST_SLEEP="${TEST_SLEEP:-30}"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --nodes) NODES="$2"; shift 2;;
+    --rounds) ROUNDS="$2"; shift 2;;
+    --gateway) GATEWAY="$2"; shift 2;;
+    --artifact-dir) ARTIFACT_DIR="$2"; shift 2;;
+    --s3-bucket) S3_BUCKET="$2"; shift 2;;
+    --s3-prefix) S3_PREFIX="$2"; shift 2;;
+    --concurrency) VLLM_CONCURRENCY="$2"; shift 2;;
+    --requests) VLLM_REQUESTS="$2"; shift 2;;
+    --namespace) NAMESPACE="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+mkdir -p "$ARTIFACT_DIR"
+
+echo "[harness] Running $ROUNDS rounds with $NODES DeepSpeed nodes"
+for r in $(seq 1 "$ROUNDS"); do
+  echo "[harness] Round $r: scaling to $NODES nodes"
+  kubectl -n "$NAMESPACE" scale statefulset "$DS_STATEFULSET" --replicas="$NODES"
+  kubectl -n "$NAMESPACE" rollout status statefulset/"$DS_STATEFULSET" --timeout=15m || true
+
+  echo "[harness] Triggering short activity on head pod"
+  HEAD_POD="${DS_STATEFULSET}-0"
+  kubectl -n "$NAMESPACE" exec "$HEAD_POD" -- bash -lc "touch /workspace/perf_marker && sleep ${TEST_SLEEP}" &>/dev/null || true
+
+  echo "[harness] Collecting NCCL/GPU diagnostics from DeepSpeed pods"
+  pods=$(kubectl -n "$NAMESPACE" get pods -l app=deepspeed-trainer -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}')
+  for p in $pods; do
+    echo "[harness] collect diagnostics for $p"
+    mkdir -p "$ARTIFACT_DIR/$r/$p"
+    kubectl -n "$NAMESPACE" logs "$p" --tail=500 > "$ARTIFACT_DIR/$r/$p/logs.txt" || true
+    # Attempt to collect nvidia-smi and dmesg
+    kubectl -n "$NAMESPACE" exec "$p" -- nvidia-smi -q -x > "$ARTIFACT_DIR/$r/$p/nvidia_smi.xml" 2>/dev/null || true
+    kubectl -n "$NAMESPACE" exec "$p" -- dmesg | tail -n 200 > "$ARTIFACT_DIR/$r/$p/dmesg.txt" 2>/dev/null || true
+  done
+
+  echo "[harness] Running vLLM load benchmark (concurrency=$VLLM_CONCURRENCY requests=$VLLM_REQUESTS)"
+  python3 scripts/vllm_perf_benchmark.py --gateway "$GATEWAY" --concurrency "$VLLM_CONCURRENCY" --requests "$VLLM_REQUESTS" --out-csv "$ARTIFACT_DIR/vllm_round_${r}.csv" || true
+
+  echo "[harness] Sleeping 10s between iterations"
+  sleep 10
+done
+
+echo "[harness] Completed rounds. Preparing artifact bundle"
+BUNDLE_NAME="$(date +%Y%m%d%H%M%S)-deepspeed-vllm-artifacts.tar.gz"
+tar -czf "$BUNDLE_NAME" -C "$ARTIFACT_DIR" .
+echo "[harness] Wrote $BUNDLE_NAME"
+
+if [ -n "${S3_BUCKET}" ]; then
+  if command -v aws >/dev/null 2>&1; then
+    KEY="${S3_PREFIX%/}/${BUNDLE_NAME}"
+    echo "[harness] Uploading $BUNDLE_NAME to s3://${S3_BUCKET}/${KEY}"
+    aws s3 cp "$BUNDLE_NAME" "s3://${S3_BUCKET}/${KEY}"
+  else
+    echo "[harness] aws CLI not found; skipping upload"
+  fi
+fi
+
+echo "[harness] Done"
+exit 0
+
diff --git a/.github/workflows/deepspeed_vllm_harness.yml b/.github/workflows/deepspeed_vllm_harness.yml
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/.github/workflows/deepspeed_vllm_harness.yml
@@ -0,0 +1,220 @@
+name: DeepSpeed + vLLM Harness (dispatchable)
+
+on:
+  workflow_dispatch:
+    inputs:
+      nodes:
+        description: 'Number of DeepSpeed nodes'
+        required: false
+        default: '2'
+      rounds:
+        description: 'Benchmark rounds'
+        required: false
+        default: '2'
+
+jobs:
+  run-harness:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Prepare
+        run: |
+          python -V
+      - name: Run harness (requires KUBECONFIG in secrets to actually run against cluster)
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG_STAGING || '' }}
+          S3_BUCKET: ${{ secrets.ARTIFACT_S3_BUCKET || '' }}
+          S3_PREFIX: "aegis/bench"
+        run: |
+          if [ -z "$KUBECONFIG" ]; then
+            echo "KUBECONFIG not present in secrets; skipping real harness. This workflow can be run on self-hosted runner with cluster access."
+            exit 0
+          fi
+          mkdir -p artifacts
+          ./scripts/deepspeed_vllm_harness.sh --nodes ${{ github.event.inputs.nodes }} --rounds ${{ github.event.inputs.rounds }} --artifact-dir ./artifacts --s3-bucket "$S3_BUCKET" --s3-prefix "$S3_PREFIX"
+      - name: Upload artifacts (if any)
+        if: always()
+        uses: actions/upload-artifact@v4
+        with:
+          name: deepspeed-vllm-artifacts
+          path: artifacts || .
+
diff --git a/scripts/vault_rotate_and_raise_pr.py b/scripts/vault_rotate_and_raise_pr.py
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/scripts/vault_rotate_and_raise_pr.py
@@ -0,0 +1,360 @@
+#!/usr/bin/env python3
+"""
+Vault rotation automation that:
+ - Generates a new keypair (or requests from KMS/CA if configured)
+ - Writes new secret to Vault KV v2
+ - Notifies services via webhook or Kubernetes annotation rollout
+ - Verifies /vault/secrets injection in pods
+ - Deletes plaintext k8s secret after verification (with dry-run safeguard)
+ - Generates a report and can open a GitHub PR describing the rotation (optional)
+
+Usage:
+  VAULT_ADDR=... VAULT_TOKEN=... GITHUB_TOKEN=... python3 scripts/vault_rotate_and_raise_pr.py --vault-path secret/data/aegis/github_app --k8s-namespace aegis-ml --k8s-secret aegis-github-secret --notify-url http://orchestrator/... --dry-run
+
+Notes:
+ - If KMS_URL is provided, script will call it to obtain key material; otherwise it will generate locally via openssl.
+ - PR requires gh CLI or GitHub token and will create a branch in the repository and open a PR with the rotation report attached.
+"""
+import os
+import argparse
+import requests
+import subprocess
+import tempfile
+import json
+import time
+import sys
+
+VAULT_ADDR = os.environ.get("VAULT_ADDR")
+VAULT_TOKEN = os.environ.get("VAULT_TOKEN")
+KMS_URL = os.environ.get("KMS_URL")  # optional key-management CA URL to request keys
+GITHUB_REPO = os.environ.get("GITHUB_REPO")  # owner/repo for PR
+
+def get_key_from_kms(kms_url):
+    try:
+        r = requests.post(kms_url + "/generate_keypair", timeout=10)
+        r.raise_for_status()
+        return r.json().get("private_key"), r.json().get("public_key")
+    except Exception:
+        return None, None
+
+def generate_local_keypair(bits=2048):
+    fd, priv = tempfile.mkstemp()
+    os.close(fd)
+    pub = priv + ".pub"
+    subprocess.check_call(["openssl", "genrsa", "-out", priv, str(bits)])
+    subprocess.check_call(["openssl", "rsa", "-in", priv, "-pubout", "-out", pub])
+    with open(priv, "r") as fh:
+        p = fh.read()
+    with open(pub, "r") as fh:
+        q = fh.read()
+    os.unlink(priv); os.unlink(pub)
+    return p, q
+
+def vault_write_kv_v2(path, data):
+    url = f"{VAULT_ADDR}/v1/{path}"
+    headers = {"X-Vault-Token": VAULT_TOKEN}
+    resp = requests.post(url, headers=headers, json={"data": data}, timeout=10)
+    resp.raise_for_status()
+    return resp.json()
+
+def verify_injection(namespace, expected_files, timeout=60):
+    end = time.time() + timeout
+    while time.time() < end:
+        pods = subprocess.check_output(["kubectl","-n",namespace,"get","pods","-o","jsonpath={.items[*].metadata.name}"]).decode().strip().split()
+        all_ok = True
+        for p in pods:
+            try:
+                phase = subprocess.check_output(["kubectl","-n",namespace,"get","pod",p,"-o","jsonpath={.status.phase}"]).decode().strip()
+                if phase != "Running":
+                    all_ok = False; break
+                if subprocess.call(["kubectl","-n",namespace,"exec",p,"--","test","-d","/vault/secrets"]) != 0:
+                    all_ok = False; break
+                for f in expected_files:
+                    if subprocess.call(["kubectl","-n",namespace,"exec",p,"--","test","-f",f"/vault/secrets/{f}"]) != 0:
+                        all_ok = False; break
+            except Exception:
+                all_ok = False; break
+        if all_ok:
+            return True
+        time.sleep(5)
+    return False
+
+def delete_k8s_secret(namespace, name, dry_run=True):
+    if dry_run:
+        return "[dry-run] deletion skipped"
+    try:
+        subprocess.check_call(["kubectl","-n",namespace,"delete","secret",name])
+        return "deleted"
+    except Exception as e:
+        return f"failed: {e}"
+
+def create_pr_with_report(repo, branch, title, body, files):
+    # Create branch, commit report file(s) and open PR using gh CLI (requires authentication)
+    report_branch = branch
+    try:
+        subprocess.check_call(["git","checkout","-b",report_branch])
+        for fname, content in files.items():
+            with open(fname, "w") as fh:
+                fh.write(content)
+            subprocess.check_call(["git","add",fname])
+        subprocess.check_call(["git","commit","-m", title])
+        subprocess.check_call(["git","push","--set-upstream","origin",report_branch])
+        subprocess.check_call(["gh","pr","create","--title",title,"--body",body,"--base","main"])
+        # checkout back
+        subprocess.check_call(["git","checkout","-"])
+        return True
+    except Exception as e:
+        print("PR creation failed:", e)
+        return False
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--vault-path", required=True)
+    p.add_argument("--k8s-namespace", required=True)
+    p.add_argument("--k8s-secret", required=True)
+    p.add_argument("--verify-files", required=True, help="comma-separated filenames expected in /vault/secrets")
+    p.add_argument("--notify-url", help="webhook to notify services after rotate")
+    p.add_argument("--dry-run", action="store_true")
+    p.add_argument("--open-pr", action="store_true", help="open PR with report (requires GITHUB_REPO and gh auth)")
+    args = p.parse_args()
+
+    if not VAULT_ADDR or not VAULT_TOKEN:
+        print("Set VAULT_ADDR and VAULT_TOKEN in env"); sys.exit(2)
+
+    # get key via KMS if configured; else generate locally
+    if KMS_URL:
+        priv, pub = get_key_from_kms(KMS_URL)
+    else:
+        priv, pub = None, None
+    if not priv:
+        priv, pub = generate_local_keypair()
+
+    payload = {"private_key": priv, "public_key": pub, "rotated_at": int(time.time())}
+    print(f"[rotate] Writing to Vault {args.vault_path} (dry-run={args.dry_run})")
+    if not args.dry_run:
+        vault_write_kv_v2(args.vault_path, payload)
+
+    if args.notify_url and not args.dry_run:
+        try:
+            requests.post(args.notify_url, json={"path": args.vault_path, "rotated_at": payload["rotated_at"]}, timeout=5)
+        except Exception as e:
+            print("notify failed:", e)
+
+    files = [f.strip() for f in args.verify_files.split(",")]
+    print("[rotate] Verifying injector propagation (timeout 120s)")
+    ok = verify_injection(args.k8s_namespace, files, timeout=120)
+    report = {"vault_path": args.vault_path, "verify_ok": ok, "timestamp": int(time.time())}
+    print("[rotate] verify result:", ok)
+
+    deletion_result = None
+    if ok:
+        deletion_result = delete_k8s_secret(args.k8s_namespace, args.k8s_secret, dry_run=args.dry_run)
+        print("[rotate] deletion:", deletion_result)
+        report["deletion"] = deletion_result
+    else:
+        report["deletion"] = "skipped - verification failed"
+
+    # Write report file
+    report_file = f"vault-rotate-report-{int(time.time())}.json"
+    with open(report_file, "w") as fh:
+        json.dump(report, fh, indent=2)
+    print("[rotate] wrote report:", report_file)
+
+    if args.open_pr and GITHUB_REPO:
+        branch = f"aegis/rotate-{int(time.time())}"
+        title = f"Vault rotation report for {args.vault_path}"
+        body = f"Automated rotation report (dry-run={args.dry_run}). See {report_file}"
+        # Create PR (repo must be checked out and gh auth set)
+        create_pr_with_report(GITHUB_REPO, branch, title, body, {report_file: json.dumps(report, indent=2)})
+
+    print("[rotate] done")
+    return 0
+
+if __name__ == "__main__":
+    sys.exit(main())
+
diff --git a/.github/workflows/vault_rotate_dispatch.yml b/.github/workflows/vault_rotate_dispatch.yml
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/.github/workflows/vault_rotate_dispatch.yml
@@ -0,0 +1,220 @@
+name: Vault Rotate Dispatch (dry-run)
+
+on:
+  workflow_dispatch:
+    inputs:
+      vault_path:
+        description: 'Vault KV v2 path (secret/data/...)'
+        required: true
+      k8s_namespace:
+        description: 'Kubernetes namespace'
+        required: true
+      k8s_secret:
+        description: 'Plaintext k8s secret to delete'
+        required: true
+
+jobs:
+  rotate:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run rotate (dry-run)
+        env:
+          VAULT_ADDR: ${{ secrets.VAULT_ADDR }}
+          VAULT_TOKEN: ${{ secrets.VAULT_TOKEN }}
+          KMS_URL: ${{ secrets.KMS_URL || '' }}
+        run: |
+          python3 scripts/vault_rotate_and_raise_pr.py --vault-path "${{ github.event.inputs.vault_path }}" --k8s-namespace "${{ github.event.inputs.k8s_namespace }}" --k8s-secret "${{ github.event.inputs.k8s_secret }}" --verify-files "github_app.pem" --dry-run
+
diff --git a/scripts/set_branch_protection.sh b/scripts/set_branch_protection.sh
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/scripts/set_branch_protection.sh
@@ -0,0 +1,180 @@
+#!/usr/bin/env bash
+#
+# Use GitHub API (gh CLI) to enforce branch protection requirements for policy CI checks.
+# Requires GH_TOKEN or gh CLI logged in.
+#
+# Usage:
+#   ./scripts/set_branch_protection.sh --repo owner/repo --branch main --required-check policy-blocking-ci
+
+set -euo pipefail
+
+REPO=""
+BRANCH="main"
+REQUIRED_CHECK=""
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --repo) REPO="$2"; shift 2;;
+    --branch) BRANCH="$2"; shift 2;;
+    --required-check) REQUIRED_CHECK="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+if [ -z "$REPO" ] || [ -z "$REQUIRED_CHECK" ]; then
+  echo "--repo and --required-check are required"
+  exit 2
+fi
+
+echo "Applying branch protection on $REPO:$BRANCH requiring check $REQUIRED_CHECK"
+gh api -X PUT "repos/$REPO/branches/$BRANCH/protection" -f required_status_checks='{"strict":true,"contexts":["'"$REQUIRED_CHECK"'"]}' || true
+echo "Done (check via GitHub settings)."
+
diff --git a/policy/opa/budget_guard.rego b/policy/opa/budget_guard.rego
new file mode 100644
index 0000000..6666666
--- /dev/null
+++ b/policy/opa/budget_guard.rego
@@ -0,0 +1,220 @@
+package aegis.policies.budget_guard
+
+import data.models
+
+default allow = true
+
+# Input:
+# {
+#   "action":"generate"|"promote"|...,
+#   "model":"name",
+#   "params": {"estimated_cost_usd": float, ...},
+#   "env":"production"|"staging"
+# }
+
+# Global budget per model (could be overridden via data.models)
+budget_for_model[m] = b {
+  bm := data.models.models[m]
+  # use configured budget_usd_per_month if present, else default 1000
+  b := bm.budget_usd_per_month
+}
+budget_for_model[m] = 1000 {
+  not data.models.models[m]
+}
+
+deny_budget_exceeded {
+  input.env == "production"
+  estimated := input.params.estimated_cost_usd
+  estimated != null
+  b := budget_for_model[input.model]
+  estimated > b
+}
+
+allow {
+  not deny_budget_exceeded
+}
+
+result = {"allow": allow, "deny_budget_exceeded": deny_budget_exceeded}
+
diff --git a/k8s/manifests/keda_gpu_slo_scaledobject.yaml b/k8s/manifests/keda_gpu_slo_scaledobject.yaml
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/k8s/manifests/keda_gpu_slo_scaledobject.yaml
@@ -0,0 +1,220 @@
+apiVersion: keda.sh/v1alpha1
+kind: ScaledObject
+metadata:
+  name: aegis-vllm-gpu-scaledobject-slo
+  namespace: aegis-ml
+spec:
+  scaleTargetRef:
+    name: aegis-vllm
+  minReplicaCount: 1
+  maxReplicaCount: 12
+  pollingInterval: 15
+  cooldownPeriod: 120
+  triggers:
+    - type: prometheus
+      metadata:
+        serverAddress: http://prometheus-operated.monitoring.svc.cluster.local
+        metricName: aegis_gpu_utilization_percent
+        threshold: "70"
+        query: avg_over_time(aegis_gpu_utilization_percent[2m])
+
+---
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: aegis-budget-guard-alerts
+  namespace: aegis-ml
+spec:
+  groups:
+    - name: aegis.budget.alerts
+      rules:
+        - alert: ModelBudgetExceeded
+          expr: increase(aegis_inference_cost_usd_total[1h]) > 100
+          for: 30m
+          labels:
+            severity: warning
+          annotations:
+            summary: "Model inference cost exceeded threshold in last hour"
+
diff --git a/scripts/metabase_provision_advanced.py b/scripts/metabase_provision_advanced.py
new file mode 100644
index 0000000..8888888
--- /dev/null
+++ b/scripts/metabase_provision_advanced.py
@@ -0,0 +1,320 @@
+#!/usr/bin/env python3
+"""
+Provision Metabase with datasources, saved questions and dashboards for auditors.
+Also create a service-account-like user (if Metabase supports provisioning) -- otherwise document admin steps.
+
+Environment:
+ - METABASE_URL, METABASE_ADMIN_USER, METABASE_ADMIN_PASS
+ - MB_PG_HOST/PORT/DB/USER/PASS
+
+This script:
+ - Logs into Metabase
+ - Adds a Postgres datasource pointing to decision_log
+ - Creates saved questions for auditors (recent decision_log, promotion approvals)
+ - Creates a dashboard and adds panels referencing saved questions
+"""
+import os
+import requests
+import json
+import time
+
+MB_URL = os.environ.get("METABASE_URL")
+MB_USER = os.environ.get("METABASE_ADMIN_USER")
+MB_PASS = os.environ.get("METABASE_ADMIN_PASS")
+PG_HOST = os.environ.get("MB_PG_HOST")
+PG_PORT = os.environ.get("MB_PG_PORT", "5432")
+PG_DB = os.environ.get("MB_PG_DB")
+PG_USER = os.environ.get("MB_PG_USER")
+PG_PASS = os.environ.get("MB_PG_PASS")
+
+if not MB_URL:
+    print("Set METABASE_URL and admin credentials")
+    raise SystemExit(2)
+
+def login():
+    resp = requests.post(f"{MB_URL}/api/session", json={"username": MB_USER, "password": MB_PASS})
+    resp.raise_for_status()
+    return resp.json()["id"]
+
+def create_datasource(session_token):
+    headers = {"X-Metabase-Session": session_token}
+    payload = {
+        "name": "decision_log_postgres",
+        "engine": "postgres",
+        "details": {
+            "host": PG_HOST,
+            "port": int(PG_PORT),
+            "dbname": PG_DB,
+            "user": PG_USER,
+            "password": PG_PASS
+        }
+    }
+    r = requests.post(f"{MB_URL}/api/databases", headers=headers, json=payload)
+    if r.status_code in (200,201):
+        print("Datasource created")
+    else:
+        print("Datasource response:", r.status_code, r.text)
+
+def create_saved_question(session_token, db_id=1):
+    headers = {"X-Metabase-Session": session_token}
+    question = {
+        "name": "Auditor Recent decision_log",
+        "dataset_query": {
+            "database": db_id,
+            "type": "native",
+            "native": {
+                "query": "SELECT id, created_at, agent, payload->>'action' as action, payload->>'model' as model, evidence->>'pr_url' as pr_url FROM decision_log ORDER BY created_at DESC LIMIT 200"
+            }
+        },
+        "display": "table"
+    }
+    resp = requests.post(f"{MB_URL}/api/card", headers=headers, json=question)
+    print("Saved question response:", resp.status_code, resp.text)
+
+def create_dashboard(session_token):
+    headers = {"X-Metabase-Session": session_token}
+    dash = {
+        "name": "Aegis Auditor Dashboard",
+        "collection_id": None,
+        "description": "Important auditor views",
+        "ordered_cards": []
+    }
+    resp = requests.post(f"{MB_URL}/api/dashboard", headers=headers, json=dash)
+    print("Dashboard create:", resp.status_code, resp.text)
+
+def main():
+    token = login()
+    print("Logged in to Metabase")
+    create_datasource(token)
+    time.sleep(2)
+    create_saved_question(token)
+    create_dashboard(token)
+    print("Metabase provisioning attempted. Adjust datasource id and queries as needed.")
+
+if __name__ == "__main__":
+    main()
+
diff --git a/k8s/manifests/metabase_auditor_rbac.yaml b/k8s/manifests/metabase_auditor_rbac.yaml
new file mode 100644
index 0000000..9999999
--- /dev/null
+++ b/k8s/manifests/metabase_auditor_rbac.yaml
@@ -0,0 +1,220 @@
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: metabase-auditor-access
+  namespace: aegis-ml
+rules:
+  - apiGroups: [""]
+    resources: ["pods","services","secrets"]
+    verbs: ["get","list"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: metabase-auditor-binding
+  namespace: aegis-ml
+subjects:
+  - kind: ServiceAccount
+    name: aegis-metabase
+    namespace: aegis-ml
+roleRef:
+  kind: Role
+  name: metabase-auditor-access
+  apiGroup: rbac.authorization.k8s.io
+
diff --git a/scripts/simulate_canary_failure.sh b/scripts/simulate_canary_failure.sh
new file mode 100644
index 0000000..aaaaaaaa
--- /dev/null
+++ b/scripts/simulate_canary_failure.sh
@@ -0,0 +1,200 @@
+#!/usr/bin/env bash
+#
+# Simulate canary failures by temporarily injecting a fault into the canary deployment.
+# Example approaches:
+#  - scale canary to 0 to simulate outage (not ideal)
+#  - patch deployment to use an image that returns 500 for all requests (safer in staging)
+#
+# Usage:
+#   ./scripts/simulate_canary_failure.sh --namespace aegis-ml --canary-deploy aegis-canary --duration 60
+
+set -euo pipefail
+
+NS="aegis-ml"
+CANARY_DEPLOY="aegis-canary"
+DURATION=60
+FAULT_IMAGE="hashicorp/http-echo:0.2.3"  # simple image that echoes; we will use args to return 500 by writing a small server is better; here we simulate via readiness failure
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --namespace) NS="$2"; shift 2;;
+    --canary-deploy) CANARY_DEPLOY="$2"; shift 2;;
+    --duration) DURATION="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+echo "[canary] Creating a backup of current deployment"
+kubectl -n "$NS" get deploy "$CANARY_DEPLOY" -o yaml > "/tmp/${CANARY_DEPLOY}.bak.yaml"
+
+echo "[canary] Simulating failure: patching deployment to zero-ready or failing pod"
+# Option A: scale to 0 (simulate outage)
+kubectl -n "$NS" scale deployment "$CANARY_DEPLOY" --replicas=0
+echo "[canary] Sleeping for ${DURATION}s to let monitoring detect outage"
+sleep "$DURATION"
+
+echo "[canary] Restoring deployment"
+kubectl -n "$NS" apply -f "/tmp/${CANARY_DEPLOY}.bak.yaml"
+kubectl -n "$NS" rollout status deploy/"$CANARY_DEPLOY" --timeout=2m || true
+echo "[canary] Canary failure simulation complete"
+
diff --git a/.github/workflows/canary_rollback_test.yml b/.github/workflows/canary_rollback_test.yml
new file mode 100644
index 0000000..bbbbbbbb
--- /dev/null
+++ b/.github/workflows/canary_rollback_test.yml
@@ -0,0 +1,220 @@
+name: Canary rollback simulation (dispatch)
+
+on:
+  workflow_dispatch:
+    inputs:
+      canary_deploy:
+        required: true
+        default: aegis-canary
+      duration:
+        required: false
+        default: '60'
+
+jobs:
+  simulate-and-check:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Simulate canary failure (requires KUBECONFIG secret)
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG_STAGING || '' }}
+        run: |
+          if [ -z "$KUBECONFIG" ]; then
+            echo "KUBECONFIG not set - cannot simulate in cluster. Run on self-hosted runner with cluster access."
+            exit 0
+          fi
+          ./scripts/simulate_canary_failure.sh --namespace aegis-ml --canary-deploy "${{ github.event.inputs.canary_deploy }}" --duration "${{ github.event.inputs.duration }}"
+      - name: (Optional) Trigger promote workflow or check rollback logic
+        run: echo "Check Argo workflow history or run promote workflow manually in staging"
+
diff --git a/README_PROD_FEATURES.md b/README_PROD_FEATURES.md
new file mode 100644
index 0000000..cccccccc
--- /dev/null
+++ b/README_PROD_FEATURES.md
@@ -0,0 +1,220 @@
+# Aegis Production Feature Patch â€” DeepSpeed/vLLM harness, Vault rotation, OPA budget guard, KEDA SLO, Auditor UX, Canary tests
+
+This patch adds end-to-end tooling to validate and operate production features:
+
+- DeepSpeed + vLLM staged harness with artifact collection and optional S3 upload (.github workflow)
+- Vault rotation automation integrating KMS fallback and PR/report creation
+- Scripts to set branch protection to enforce policy CI
+- OPA budget guard rego to deny overly expensive operations
+- KEDA GPU-based ScaledObjects tuned to SLOs & Prometheus SLO alerts
+- Metabase provisioning and RBAC for auditors
+- Canary failure simulation script and CI dispatchable workflow
+
+Quick commands:
+ - Run harness locally (with cluster access): ./scripts/deepspeed_vllm_harness.sh --nodes 2 --rounds 2 --artifact-dir ./artifacts --s3-bucket my-bucket
+ - Dry-run vault rotate: python3 scripts/vault_rotate_and_raise_pr.py --vault-path secret/data/aegis/github_app --k8s-namespace aegis-ml --k8s-secret aegis-github-secret --verify-files github_app.pem --dry-run
+ - Create branch protection: ./scripts/set_branch_protection.sh --repo owner/repo --branch main --required-check policy-blocking-ci
+ - Toggle vLLM quant & benchmark: python3 scripts/vllm_perf_benchmark.py --gateway http://... --concurrency 16 --requests 200 --quant --toggle-quant-api http://vllm-admin/quant
+ - Simulate canary failure (requires KUBECONFIG): ./scripts/simulate_canary_failure.sh --canary-deploy aegis-canary --duration 60
+
+Operator notes:
+ - Many operations require cluster-level access and secrets (KUBECONFIG, VAULT_TOKEN, GITHUB_TOKEN). Test in staging with limited blast radius.
+ - Always run vault rotation in dry-run first and get sign-off.
+ - Enforce policy_blocking_ci in GitHub branch protection to prevent merges of policy changes that fail tests.
+
+End of README.
