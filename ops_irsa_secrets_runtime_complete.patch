*** Begin Patch
*** Add File:ops/apply_irsa_and_annotate.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Apply Terraform IRSA module and annotate Kubernetes ServiceAccounts with IAM role ARNs.
+# Operator MUST create terraform/irsa/my.tfvars locally (do NOT commit).
+#
+# Usage:
+#   cp terraform/irsa/my.tfvars.example terraform/irsa/my.tfvars
+#   # edit terraform/irsa/my.tfvars locally (do NOT commit)
+#   ./ops/apply_irsa_and_annotate.sh terraform/irsa/my.tfvars
+
+TFVARS=${1:-terraform/irsa/my.tfvars}
+TFDIR="terraform/irsa"
+
+if [ ! -f "${TFVARS}" ]; then
+  echo "ERROR: tfvars not found at ${TFVARS}"
+  exit 2
+fi
+
+echo "[IRSA] Running Terraform (init/plan/apply) in ${TFDIR} with ${TFVARS}"
+pushd "${TFDIR}" >/dev/null
+terraform init -input=false
+terraform plan -input=false -var-file="${TFVARS}" -out=tfplan
+terraform apply -input=false -auto-approve tfplan
+terraform output -json > /tmp/irsa_outputs.json
+popd >/dev/null
+
+echo "[IRSA] Terraform outputs written to /tmp/irsa_outputs.json"
+
+if [ -f /tmp/irsa_outputs.json ]; then
+  if [ -x "./terraform/irsa/irsa_annotate_sa.sh" ]; then
+    echo "[IRSA] Annotating ServiceAccounts via terraform/irsa/irsa_annotate_sa.sh"
+    bash terraform/irsa/irsa_annotate_sa.sh /tmp/irsa_outputs.json
+  else
+    echo "[IRSA] Annotation helper terraform/irsa/irsa_annotate_sa.sh missing or not executable."
+    echo "[IRSA] Please annotate SAs manually using values in /tmp/irsa_outputs.json"
+  fi
+else
+  echo "[IRSA] No terraform outputs found at /tmp/irsa_outputs.json — cannot annotate SAs"
+fi
+
+echo "[IRSA] Complete."
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/terraform_irsa_apply.yml
+name: Terraform IRSA Plan & Apply (OIDC)
+
+on:
+  workflow_dispatch:
+    inputs:
+      auto_approve:
+        description: "Set to true to auto-apply (use with caution)"
+        required: false
+        default: "false"
+
+jobs:
+  plan:
+    runs-on: ubuntu-latest
+    permissions:
+      id-token: write
+      contents: read
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Terraform
+        uses: hashicorp/setup-terraform@v2
+        with:
+          terraform_version: 1.5.0
+      - name: Configure AWS via OIDC
+        uses: aws-actions/configure-aws-credentials@v2
+        with:
+          role-to-assume: ${{ secrets.TERRAFORM_OIDC_ROLE }}
+          aws-region: REPLACE_AWS_REGION
+      - name: Terraform init & plan
+        working-directory: terraform/irsa
+        run: |
+          terraform init -input=false
+          terraform plan -input=false -var-file=my.tfvars -out=tfplan
+      - name: Upload tfplan
+        uses: actions/upload-artifact@v4
+        with:
+          name: irsa-tfplan
+          path: terraform/irsa/tfplan
+
+  apply:
+    needs: plan
+    if: ${{ github.event.inputs.auto_approve == 'true' }}
+    runs-on: ubuntu-latest
+    permissions:
+      id-token: write
+    steps:
+      - uses: actions/checkout@v4
+      - name: Configure AWS via OIDC
+        uses: aws-actions/configure-aws-credentials@v2
+        with:
+          role-to-assume: ${{ secrets.TERRAFORM_OIDC_ROLE }}
+          aws-region: REPLACE_AWS_REGION
+      - name: Download tfplan
+        uses: actions/download-artifact@v4
+        with:
+          name: irsa-tfplan
+          path: terraform/irsa/tfplan
+      - name: Terraform apply
+        working-directory: terraform/irsa
+        run: terraform apply -input=false -auto-approve tfplan
+
*** End Patch
*** Begin Patch
*** Add File:ops/provision_github_secrets_and_externalsecrets.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Provision GitHub repository secrets and apply ExternalSecrets manifests.
+# Required env vars before running:
+#   REPO, COSIGN_KMS_ARN, REKOR_URL, EVIDENCE_BUCKET, MLFLOW_TRACKING_URI
+# Optional:
+#   AWS_ROLE_TO_ASSUME, PROVIDER_API_KEYS_JSON, GITHUB_TOKEN, NAMESPACE (default: aegis)
+#
+REPO=${REPO:-REPLACE_GITHUB_REPOSITORY}
+NAMESPACE=${NAMESPACE:-aegis}
+
+required=(COSIGN_KMS_ARN REKOR_URL EVIDENCE_BUCKET MLFLOW_TRACKING_URI)
+for v in "${required[@]}"; do
+  if [ -z "${!v:-}" ]; then
+    echo "ERROR: env var ${v} must be set"
+    exit 2
+  fi
+done
+
+echo "[SECRETS] Creating GitHub secrets in ${REPO}..."
+gh secret set COSIGN_KMS_ARN --repo "${REPO}" --body "${COSIGN_KMS_ARN}"
+gh secret set REKOR_URL --repo "${REPO}" --body "${REKOR_URL}"
+gh secret set EVIDENCE_BUCKET --repo "${REPO}" --body "${EVIDENCE_BUCKET}"
+gh secret set MLFLOW_TRACKING_URI --repo "${REPO}" --body "${MLFLOW_TRACKING_URI}"
+if [ -n "${AWS_ROLE_TO_ASSUME:-}" ]; then
+  gh secret set AWS_ROLE_TO_ASSUME --repo "${REPO}" --body "${AWS_ROLE_TO_ASSUME}"
+fi
+if [ -n "${PROVIDER_API_KEYS_JSON:-}" ]; then
+  gh secret set PROVIDER_API_KEYS_JSON --repo "${REPO}" --body "${PROVIDER_API_KEYS_JSON}"
+fi
+
+echo "[SECRETS] Applying ExternalSecrets manifests (ExternalSecrets operator required)"
+kubectl create namespace "${NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -
+kubectl apply -n "${NAMESPACE}" -f k8s/external-secrets/secretstore.aws.yaml || true
+kubectl apply -n "${NAMESPACE}" -f k8s/external-secrets/externalsecret_runtime.yaml || true
+
+echo "[SECRETS] Provisioning finished. Verify GitHub secrets and ExternalSecrets in k8s."
+
*** End Patch
*** Begin Patch
*** Add File:k8s/external-secrets/secretstore.aws.yaml
+apiVersion: external-secrets.io/v1beta1
+kind: SecretStore
+metadata:
+  name: aws-secrets-manager
+  namespace: aegis
+spec:
+  provider:
+    aws:
+      service: SecretsManager
+      region: REPLACE_AWS_REGION
+      auth:
+        jwt:
+          serviceAccountRef:
+            name: externalsecrets-sa
+            namespace: aegis
+
+# Note: create IAM role and annotate externalsecrets-sa for IRSA permissions to read Secrets Manager.
+
*** End Patch
*** Begin Patch
*** Add File:k8s/external-secrets/externalsecret_runtime.yaml
+apiVersion: external-secrets.io/v1beta1
+kind: ExternalSecret
+metadata:
+  name: aegis-runtime-values
+  namespace: aegis
+spec:
+  refreshInterval: "1h"
+  secretStoreRef:
+    name: aws-secrets-manager
+    kind: SecretStore
+  target:
+    name: aegis-runtime-secrets
+    creationPolicy: Owner
+  data:
+    - secretKey: COSIGN_KMS_ARN
+      remoteRef:
+        key: "aegis/cosign"
+        property: "kms_arn"
+    - secretKey: REKOR_URL
+      remoteRef:
+        key: "aegis/rekor"
+        property: "rekor_url"
+    - secretKey: MLFLOW_TRACKING_URI
+      remoteRef:
+        key: "aegis/mlflow"
+        property: "tracking_uri"
+    - secretKey: GITHUB_TOKEN
+      remoteRef:
+        key: "gitops/github"
+        property: "token"
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/ci_registry_kms_check.yml
+name: CI — Registry & KMS Permissions Validation
+
+on:
+  workflow_dispatch:
+    inputs:
+      ecr_registry:
+        description: "ECR registry (optional)"
+        required: false
+
+jobs:
+  validate:
+    runs-on: ubuntu-latest
+    permissions:
+      id-token: write
+      contents: read
+    steps:
+      - name: Configure AWS via OIDC
+        uses: aws-actions/configure-aws-credentials@v2
+        with:
+          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
+          aws-region: REPLACE_AWS_REGION
+      - name: Validate KMS & ECR access
+        run: |
+          if [ -z "${{ secrets.COSIGN_KMS_ARN }}" ]; then
+            echo "COSIGN_KMS_ARN secret not set; fail"
+            exit 1
+          fi
+          aws kms describe-key --key-id "${{ secrets.COSIGN_KMS_ARN }}"
+          if [ -n "${{ github.event.inputs.ecr_registry }}" ]; then
+            aws ecr get-authorization-token --registry-ids "$(echo ${{ github.event.inputs.ecr_registry }} | cut -d. -f1)"
+            echo "ECR auth OK"
+          fi
+
*** End Patch
*** Begin Patch
*** Add File:ops/install_runtime_services.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Install runtime services:
+#  - Argo Workflows
+#  - ArgoCD (Helm)
+#  - Prometheus (kube-prometheus-stack)
+#  - ExternalSecrets operator
+#  - Istio (demo profile) and Knative (optional)
+#
+echo "[RUNTIME] Installing Argo Workflows..."
+kubectl create namespace argo --dry-run=client -o yaml | kubectl apply -f -
+kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/stable/manifests/install.yaml
+
+echo "[RUNTIME] Installing ArgoCD via Helm..."
+bash ops/install_argocd_helm.sh
+
+echo "[RUNTIME] Installing Prometheus (kube-prometheus-stack)..."
+helm repo add prometheus-community https://prometheus-community.github.io/helm-charts || true
+helm repo update
+kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
+helm upgrade --install kube-prom prometheus-community/kube-prometheus-stack -n monitoring --wait
+
+echo "[RUNTIME] Installing ExternalSecrets operator..."
+helm repo add external-secrets https://external-secrets.github.io/kubernetes-external-secrets/ || true
+helm repo update
+kubectl create namespace external-secrets --dry-run=client -o yaml | kubectl apply -f -
+helm upgrade --install external-secrets external-secrets/kubernetes-external-secrets -n external-secrets --wait
+
+echo "[RUNTIME] Installing Istio (demo profile)..."
+bash istio/install_istio.sh || true
+echo "[RUNTIME] Installing Knative (optional)..."
+bash knative/install_knative.sh || true
+
+echo "[RUNTIME] Runtime stack installed. Confirm pods in argo, argocd, monitoring, external-secrets namespaces."
+
*** End Patch
*** Begin Patch
*** Add File:argocd/application-gitops-staging.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Application
+metadata:
+  name: aegis-staging
+  namespace: argocd
+spec:
+  project: default
+  source:
+    repoURL: 'https://github.com/REPLACE_GITOPS_OWNER/REPLACE_GITOPS_REPO.git'
+    targetRevision: HEAD
+    path: 'overlays/staging'
+  destination:
+    server: 'https://kubernetes.default.svc'
+    namespace: aegis
+  syncPolicy:
+    automated:
+      prune: true
+      selfHeal: true
+    syncOptions:
+      - CreateNamespace=true
+      - ApplyOutOfSyncOnly=true
+
*** End Patch
*** Begin Patch
*** Add File:ops/deploy_promoter_and_metricproxy.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Deploy metric-proxy and gitops-promoter and create in-cluster promoter secret.
+# Provide GITHUB_TOKEN env var for promoter secret (token must have minimal scope).
+#
+NAMESPACE=${NAMESPACE:-aegis}
+PROM_URL=${PROM_URL:-"REPLACE_PROMETHEUS_INTERNAL_URL"}
+
+kubectl create namespace "${NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -
+
+echo "[DEPLOY] Applying metric-proxy manifests..."
+kubectl apply -n "${NAMESPACE}" -f ops/metric-proxy-configmap.yaml
+kubectl apply -n "${NAMESPACE}" -f ops/metric-proxy-deployment.yaml
+kubectl -n "${NAMESPACE}" patch deployment metric-proxy --patch "{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"proxy\",\"env\":[{\"name\":\"PROMETHEUS_URL\",\"value\":\"${PROM_URL}\"}]}]}}}}"
+
+echo "[DEPLOY] Applying promoter manifests and RBAC..."
+kubectl apply -n "${NAMESPACE}" -f ops/gitops-promoter-configmap.yaml
+kubectl apply -n "${NAMESPACE}" -f ops/gitops-promoter-deployment.yaml
+kubectl apply -n "${NAMESPACE}" -f ops/promoter_rbac.yaml || true
+
+if [ -n "${GITHUB_TOKEN:-}" ]; then
+  kubectl -n "${NAMESPACE}" create secret generic gitops-promoter-secret --from-literal=github_token="${GITHUB_TOKEN}" --dry-run=client -o yaml | kubectl apply -f -
+  echo "[DEPLOY] gitops-promoter-secret created."
+else
+  echo "[DEPLOY] GITHUB_TOKEN not supplied; please create gitops-promoter-secret in ${NAMESPACE} to enable PR creation."
+fi
+
+echo "[DEPLOY] Metric-proxy & promoter deployment finished."
+
*** End Patch
*** Begin Patch
*** Add File:ops/promoter_rbac.yaml
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: gitops-promoter
+  namespace: aegis
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: gitops-promoter
+  namespace: aegis
+rules:
+  - apiGroups: [""]
+    resources: ["configmaps"]
+    verbs: ["get", "list", "watch"]
+  - apiGroups: [""]
+    resources: ["secrets"]
+    verbs: ["get"]
+  - apiGroups: ["apps"]
+    resources: ["deployments"]
+    verbs: ["get", "list"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: gitops-promoter-binding
+  namespace: aegis
+roleRef:
+  apiGroup: rbac.authorization.k8s.io
+  kind: Role
+  name: gitops-promoter
+subjects:
+  - kind: ServiceAccount
+    name: gitops-promoter
+    namespace: aegis
+
+# Keep promoter RBAC minimal and rotate token periodically.
+
*** End Patch
*** Begin Patch
*** Add File:ops/install_gatekeeper_and_protect.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Install Gatekeeper and apply constraints; configure GitHub branch protection requiring sanitizer + CI checks and PR approvals.
+# Requires GITHUB_TOKEN to set branch protection using gh.
+#
+REPO=${REPO:-REPLACE_GITHUB_REPOSITORY}
+BRANCH=${BRANCH:-main}
+
+echo "[GOV] Installing Gatekeeper..."
+kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml
+sleep 5
+kubectl apply -f k8s/gatekeeper/constraint_qpu_approved.yaml || true
+
+if [ -z "${GITHUB_TOKEN:-}" ]; then
+  echo "[GOV] GITHUB_TOKEN not set; skipping GitHub branch protection configuration. Set and re-run to enforce protection."
+  exit 0
+fi
+
+echo "[GOV] Configuring branch protection for ${REPO}:${BRANCH}"
+required_contexts='["sanitizer","ci_train_validate_register","image_build_cosign"]'
+gh api --method PUT /repos/${REPO}/branches/${BRANCH}/protection -f required_status_checks.strict=true -f "required_status_checks.contexts=${required_contexts}" -f enforce_admins=true -f required_pull_request_reviews.required_approving_review_count=1
+
+echo "[GOV] Gatekeeper installed and branch protection configured."
+
*** End Patch
*** Begin Patch
*** Add File:ops/upload_legal_signoff_and_require_checks.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Upload legal signoff to S3 and enforce sanitizer + CI checks before real-data/QPU runs.
+# Usage:
+#   export EVIDENCE_BUCKET, REPO, BRANCH, GITHUB_TOKEN
+#   ./ops/upload_legal_signoff_and_require_checks.sh path/to/legal_signoff.md
+#
+FILE=${1:-ops/legal_signoff.md}
+EVIDENCE_BUCKET=${EVIDENCE_BUCKET:-REPLACE_EVIDENCE_BUCKET}
+REPO=${REPO:-REPLACE_GITHUB_REPOSITORY}
+BRANCH=${BRANCH:-main}
+
+if [ ! -f "${FILE}" ]; then
+  echo "ERROR: Legal signoff file not found: ${FILE}"
+  exit 2
+fi
+
+echo "[GOV] Uploading legal signoff to s3://${EVIDENCE_BUCKET}/legal_signoff/"
+aws s3 cp "${FILE}" "s3://${EVIDENCE_BUCKET}/legal_signoff/$(basename "${FILE}")"
+
+if [ -z "${GITHUB_TOKEN:-}" ]; then
+  echo "[GOV] GITHUB_TOKEN not set; skipping branch protection update. Set and re-run to enforce sanitizer/CI checks."
+  exit 0
+fi
+
+echo "[GOV] Enforcing sanitizer + CI checks on ${REPO}:${BRANCH}"
+required_contexts='["sanitizer","ci_train_validate_register","secret-and-deploy-preflight"]'
+gh api --method PUT /repos/${REPO}/branches/${BRANCH}/protection -f required_status_checks.strict=true -f "required_status_checks.contexts=${required_contexts}" -f enforce_admins=true -f required_pull_request_reviews.required_approving_review_count=1
+
+echo "[GOV] Legal signoff uploaded and checks enforced."
+
*** End Patch
*** Begin Patch
*** Add File:ops/qpu_cost_gate.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Example wrapper to call a QPU cost estimator and gate execution when cost > budget.
+# This is a placeholder; replace with your actual estimator invocation.
+#
+# Usage:
+# # Example environment:
+# export BUDGET_USD=100
+# ./ops/qpu_cost_gate.sh path/to/job_spec.json
+
+JOB_SPEC=${1:?job spec JSON required}
+BUDGET_USD=${BUDGET_USD:-100}
+
+echo "[COST] Running cost estimator for job: ${JOB_SPEC}"
+if [ -x ./ops/qpu_cost_estimator_braket_integration.py ]; then
+  ESTIMATE=$(python3 ./ops/qpu_cost_estimator_braket_integration.py --estimate --job "${JOB_SPEC}")
+  echo "[COST] Estimated cost: ${ESTIMATE} USD"
+  awk -v e="${ESTIMATE}" -v b="${BUDGET_USD}" 'BEGIN { if (e > b) exit 2; else exit 0 }'
+  if [ $? -eq 2 ]; then
+    echo "[COST] Estimate ${ESTIMATE} exceeds budget ${BUDGET_USD}. Gate triggered."
+    exit 2
+  else
+    echo "[COST] Estimate is within budget (${BUDGET_USD}). Proceed."
+    exit 0
+  fi
+else
+  echo "[COST] No cost estimator script found at ./ops/qpu_cost_estimator_braket_integration.py - cannot estimate; require human approval."
+  exit 1
+fi
+
*** End Patch
*** Begin Patch
*** Add File:ops/tune_and_validate.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Set SLO thresholds (ConfigMap), run sample Prometheus queries via metric-proxy, and validate cost estimator output.
+#
+P95=${1:-0.5}
+ERROR_RATE=${2:-0.02}
+WINDOW=${3:-60}
+METRIC_PROXY=${METRIC_PROXY:-http://metric-proxy.aegis.svc.cluster.local:8080}
+
+echo "[TUNE] Updating aegis-slo-config: p95=${P95}, error_rate=${ERROR_RATE}, window=${WINDOW}m"
+kubectl -n aegis create configmap aegis-slo-config --from-literal=p95_latency_threshold_seconds="${P95}" --from-literal=canary_error_rate_threshold="${ERROR_RATE}" --from-literal=canary_success_window_minutes="${WINDOW}" -o yaml --dry-run=client | kubectl apply -f -
+
+echo "[TUNE] Querying metric-proxy for sample p95 latency..."
+QUERY='histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="kserve",env="prod"}[5m])) by (le))'
+ENCODED=$(python3 - <<PY
+import urllib.parse
+print(urllib.parse.quote('''${QUERY}'''))
+PY
+)
+curl -s "${METRIC_PROXY}/api/v1/query?query=${ENCODED}" | jq .
+
+echo "[TUNE] Validating cost estimator (if present)..."
+if [ -x ./ops/qpu_cost_estimator_braket_integration.py ]; then
+  python3 ./ops/qpu_cost_estimator_braket_integration.py --dry-run || echo "[TUNE] Cost estimator run returned non-zero (or placeholder)"
+else
+  echo "[TUNE] No cost estimator present locally; validate budgets manually or add estimator."
+fi
+
+echo "[TUNE] Tune & validation complete."
+
*** End Patch
*** Begin Patch
*** Add File:k8s/monitoring/promotion_alerts.yaml
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: aegis-promotion-alerts
+  namespace: monitoring
+spec:
+  groups:
+    - name: aegis-promotion.rules
+      rules:
+        - alert: PromotionFailure
+          expr: increase(argo_workflow_status_failed_total{workflow_template=~"rollout-promote.*"}[5m]) > 0
+          for: 2m
+          labels:
+            severity: critical
+          annotations:
+            summary: "Promotion workflow failures detected"
+            description: "rollout-promote workflow has failed in the last 5m. Investigate."
+        - alert: CanaryErrorRateHigh
+          expr: sum(rate(http_requests_total{job="kserve",env="prod",status!~"2.."}[5m])) / sum(rate(http_requests_total{job="kserve",env="prod"}[5m])) > 0.05
+          for: 5m
+          labels:
+            severity: warning
+          annotations:
+            summary: "High error rate for canary"
+            description: "Error rate > 5% for prod job; consider rollback."
+
*** End Patch
*** Begin Patch
*** Add File:docs/operational_hardening.md
+# Operational hardening checklist for Aegis
+
+This file lists recommended production hardening actions.
+
+1) Least-privilege IAM
+  - Grant Actions OIDC role only ECR push and KMS Sign permissions required.
+  - Scope IRSA roles to minimal API surface per SA.
+
+2) Secret rotation & ExternalSecrets
+  - Use ExternalSecrets backed by AWS Secrets Manager or Vault and automate rotation.
+  - Test rotation handling in staging.
+
+3) Monitoring & alerting
+  - Apply PrometheusRule alerts (k8s/monitoring/promotion_alerts.yaml) and integrate with on-call.
+
+4) Automated testing & rollback
+  - Add CI integration tests that exercise canary and rollback paths.
+  - Validate ArgoCD self-heal behavior.
+
+5) Cost & budget guard rails
+  - Integrate cost estimator and use ops/qpu_cost_gate.sh in workflows to block/require approval if cost > budget.
+
+6) Governance & legal
+  - Gatekeeper constraints and branch protection requiring sanitizer + CI checks.
+  - Store legal signoff in evidence S3 and enforce as prerequisite for real-data/QPU runs.
+
+7) Disaster recovery
+  - Backup GitOps repo, S3 evidence bucket, and critical manifests.
+
*** End Patch
*** End Patch
