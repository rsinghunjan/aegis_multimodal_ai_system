*** Begin Patch
*** Add File:rl/collector/collector.py
+#!/usr/bin/env python3
+"""
+RL Collector
+ - Runs episodes of a Gym environment (default CartPole-v1)
+ - Saves episodes (observations, actions, rewards) as JSON/npz files
+ - Uploads files to S3 under prefix: s3://{EVIDENCE_BUCKET}/rl/collect/{run_id}/
+
+Usage:
+  EVIDENCE_BUCKET=my-bucket python3 rl/collector/collector.py --run-id run1 --episodes 10
+"""
+import argparse, os, time, json, uuid
+import gym
+import numpy as np
+import boto3
+
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+
+def upload_file(local_path, s3_key):
+    if not EVIDENCE_BUCKET:
+        print("EVIDENCE_BUCKET not set, skipping upload for", local_path)
+        return
+    s3 = boto3.client("s3")
+    s3.upload_file(local_path, EVIDENCE_BUCKET, s3_key)
+    print("Uploaded", local_path, "-> s3://{}/{}".format(EVIDENCE_BUCKET, s3_key))
+
+def collect(env_name, episodes, run_id, out_dir="/tmp/rl_collect"):
+    env = gym.make(env_name)
+    os.makedirs(out_dir, exist_ok=True)
+    for ep in range(episodes):
+        obs = []
+        acts = []
+        rews = []
+        done = False
+        o = env.reset()
+        while not done:
+            a = env.action_space.sample()
+            o2, r, done, info = env.step(a)
+            obs.append(o.tolist() if hasattr(o, "tolist") else o)
+            acts.append(int(a))
+            rews.append(float(r))
+            o = o2
+        fname = f"{run_id}_ep{ep}_{int(time.time())}.json"
+        local = os.path.join(out_dir, fname)
+        with open(local, "w") as f:
+            json.dump({"obs": obs, "acts": acts, "rews": rews, "env": env_name, "ep": ep, "ts": int(time.time())}, f)
+        s3_key = f"rl/collect/{run_id}/{fname}"
+        upload_file(local, s3_key)
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--env", default="CartPole-v1")
+    p.add_argument("--episodes", type=int, default=5)
+    p.add_argument("--run-id", default=str(uuid.uuid4())[:8])
+    p.add_argument("--out", default="/tmp/rl_collect")
+    args = p.parse_args()
+    collect(args.env, args.episodes, args.run_id, args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:rl/trainer/trainer_sb3.py
+#!/usr/bin/env python3
+"""
+RL Trainer (Stable-Baselines3 PPO) for CartPole pilot.
+ - Trains for a configurable number of timesteps (default small for CI/pilot)
+ - Saves model to /workspace/model/model.zip
+ - Uploads model and creates a manifest, evidence bundle, and registers artifact via Registry API
+
+Environment variables:
+ - EVIDENCE_BUCKET: bucket to upload evidence and model
+ - MODEL_ARTIFACT_BUCKET: bucket to copy manifest for promotion (optional)
+ - REGISTRY_URL: authoritative registry API (optional)
+ - COSIGN_KMS_KEY_ARN: optional cosign KMS key ARN to sign evidence
+ - TOKEN_BUDGET_URL: optional token-budget service to check quota
+
+Usage:
+  EVIDENCE_BUCKET=my-bucket python3 rl/trainer/trainer_sb3.py --timesteps 10000 --team myteam
+"""
+import os, time, json, tempfile, subprocess
+import argparse
+import gym
+
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+MODEL_ARTIFACT_BUCKET = os.environ.get("MODEL_ARTIFACT_BUCKET", "")
+REGISTRY_URL = os.environ.get("REGISTRY_URL", "")
+COSIGN_KMS = os.environ.get("COSIGN_KMS_KEY_ARN", "")
+TOKEN_BUDGET_URL = os.environ.get("TOKEN_BUDGET_URL", "")
+
+def check_quota(team, amount=1.0):
+    if not TOKEN_BUDGET_URL:
+        return True
+    try:
+        import requests
+        r = requests.post(TOKEN_BUDGET_URL + "/check_quota", json={"team": team, "kind": "rl", "amount": amount}, timeout=5)
+        return r.status_code == 200 and r.json().get("allowed", False)
+    except Exception:
+        return False
+
+def upload_file(local_path, s3_key):
+    if not EVIDENCE_BUCKET:
+        print("EVIDENCE_BUCKET not set, skipping upload for", local_path)
+        return
+    import boto3
+    s3 = boto3.client("s3")
+    s3.upload_file(local_path, EVIDENCE_BUCKET, s3_key)
+    print("Uploaded", local_path, "-> s3://{}/{}".format(EVIDENCE_BUCKET, s3_key))
+
+def sign_file(local_path):
+    if not COSIGN_KMS:
+        print("COSIGN_KMS_KEY_ARN not set; skipping cosign sign")
+        return
+    try:
+        subprocess.run(["cosign", "sign", "--key", f"awskms://{COSIGN_KMS}", local_path], check=False)
+    except Exception as e:
+        print("cosign sign failed:", e)
+
+def register_manifest(manifest):
+    if not REGISTRY_URL:
+        print("No REGISTRY_URL; skipping registry registration")
+        return
+    try:
+        import requests
+        r = requests.post(f"{REGISTRY_URL}/api/artifacts", json=manifest, timeout=10)
+        print("Registry response:", r.status_code, r.text[:200])
+    except Exception as e:
+        print("Registry registration failed:", e)
+
+def run_training(env_name, timesteps, team, output_dir="/workspace/model"):
+    # Import lazily to avoid heavy deps on import
+    from stable_baselines3 import PPO
+    from stable_baselines3.common.vec_env import DummyVecEnv
+    os.makedirs(output_dir, exist_ok=True)
+    env = DummyVecEnv([lambda: gym.make(env_name)])
+    model = PPO("MlpPolicy", env, verbose=1)
+    model.learn(total_timesteps=timesteps)
+    model_path = os.path.join(output_dir, "model.zip")
+    model.save(model_path)
+    return model_path
+
+def bundle_evidence(model_path, manifest):
+    tmp = tempfile.mkdtemp()
+    evidence_tar = os.path.join(tmp, f"rl_evidence_{int(time.time())}.tgz")
+    # include model and manifest
+    subprocess.run(["tar", "czf", evidence_tar, "-C", os.path.dirname(model_path), os.path.basename(model_path), "-C", os.path.dirname(manifest), os.path.basename(manifest)], check=False)
+    sign_file(evidence_tar)
+    if EVIDENCE_BUCKET:
+        upload_file(evidence_tar, f"rl/evidence/{os.path.basename(evidence_tar)}")
+    return evidence_tar
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--env", default="CartPole-v1")
+    p.add_argument("--timesteps", type=int, default=20000)
+    p.add_argument("--team", default="default")
+    args = p.parse_args()
+
+    if not check_quota(args.team, 1):
+        raise SystemExit("Quota denied for team " + args.team)
+
+    print("Training RL model:", args.env, "timesteps:", args.timesteps)
+    model_path = run_training(args.env, args.timesteps, args.team)
+    manifest = {
+        "artifact_id": f"rl-{int(time.time())}",
+        "model_name": "ppo-"+args.env,
+        "env": args.env,
+        "timesteps": args.timesteps,
+        "team": args.team,
+        "created_at": int(time.time())
+    }
+    manifest_path = "/tmp/rl_manifest.json"
+    with open(manifest_path, "w") as f:
+        json.dump(manifest, f, indent=2)
+
+    print("Bundling evidence and uploading")
+    evidence_tar = bundle_evidence(model_path, manifest_path)
+
+    # Upload model artifact (optional)
+    if MODEL_ARTIFACT_BUCKET:
+        upload_file(model_path, f"rl/models/{os.path.basename(model_path)}")
+
+    # Register manifest to registry (best-effort)
+    manifest["evidence_s3"] = f"s3://{EVIDENCE_BUCKET}/rl/evidence/{os.path.basename(evidence_tar)}" if EVIDENCE_BUCKET else ""
+    register_manifest(manifest)
+
+    print("Trainer finished. Model:", model_path, "evidence:", evidence_tar)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:rl/eval/evaluator.py
+#!/usr/bin/env python3
+"""
+RL Evaluator
+ - Loads a Stable-Baselines3 model and runs N episodes
+ - Writes average reward to a JSON and uploads to S3
+"""
+import argparse, os, json
+import gym
+import numpy as np
+
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+
+def upload_file(local_path, s3_key):
+    if not EVIDENCE_BUCKET:
+        print("EVIDENCE_BUCKET not set, skipping upload for", local_path)
+        return
+    import boto3
+    s3 = boto3.client("s3")
+    s3.upload_file(local_path, EVIDENCE_BUCKET, s3_key)
+    print("Uploaded", local_path, "-> s3://{}/{}".format(EVIDENCE_BUCKET, s3_key))
+
+def evaluate(model_path, env_name, episodes, out_path="/tmp/rl_eval.json"):
+    from stable_baselines3 import PPO
+    env = gym.make(env_name)
+    model = PPO.load(model_path)
+    rewards = []
+    for ep in range(episodes):
+        done = False
+        o = env.reset()
+        ep_ret = 0.0
+        while not done:
+            action, _ = model.predict(o, deterministic=True)
+            o, r, done, info = env.step(action)
+            ep_ret += r
+        rewards.append(ep_ret)
+    avg = float(np.mean(rewards))
+    out = {"env": env_name, "episodes": episodes, "avg_reward": avg, "rewards": rewards}
+    with open(out_path, "w") as f:
+        json.dump(out, f, indent=2)
+    print("Eval result:", out_path)
+    upload_file(out_path, f"rl/eval/{os.path.basename(out_path)}")
+    return out
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--model", required=True)
+    p.add_argument("--env", default="CartPole-v1")
+    p.add_argument("--episodes", type=int, default=5)
+    args = p.parse_args()
+    evaluate(args.model, args.env, args.episodes)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:argo/workflows/rl_pipeline.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: rl-pipeline-
+  namespace: aegis
+spec:
+  entrypoint: rl-pipeline
+  templates:
+    - name: rl-pipeline
+      dag:
+        tasks:
+          - name: collect
+            template: collector
+          - name: train
+            template: trainer
+            dependencies: [collect]
+          - name: evaluate
+            template: evaluator
+            dependencies: [train]
+
+    - name: collector
+      container:
+        image: ghcr.io/yourorg/aegis-rl:latest
+        command: [python3]
+        args: ["rl/collector/collector.py","--env","CartPole-v1","--episodes","20","--run-id","argo-{{workflow.name}}"]
+        resources:
+          limits:
+            cpu: "1"
+            memory: "1Gi"
+
+    - name: trainer
+      container:
+        image: ghcr.io/yourorg/aegis-rl:latest
+        command: [python3]
+        args: ["rl/trainer/trainer_sb3.py","--env","CartPole-v1","--timesteps","50000","--team","default"]
+        resources:
+          limits:
+            nvidia.com/gpu: 1
+            memory: "8Gi"
+            cpu: "2"
+
+    - name: evaluator
+      container:
+        image: ghcr.io/yourorg/aegis-rl:latest
+        command: [python3]
+        args: ["rl/eval/evaluator.py","--model","/workspace/model/model.zip","--env","CartPole-v1","--episodes","10"]
+        volumeMounts:
+          - name: model
+            mountPath: /workspace/model
+      volumes:
+        - name: model
+          emptyDir: {}
+
*** End Patch
*** Begin Patch
*** Add File:rl/monitoring/rl_metrics_exporter.py
+#!/usr/bin/env python3
+"""
+Simple Prometheus exporter for RL metrics:
+ - pushes average reward & episodes processed from S3 registry artifacts (best-effort)
+"""
+from prometheus_client import start_http_server, Gauge
+import os, time, boto3, json
+
+AVG_REWARD = Gauge("aegis_rl_avg_reward", "Latest RL avg reward")
+EPISODES = Gauge("aegis_rl_eval_episodes", "Number of evaluation episodes")
+
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+
+def poll_latest_eval():
+    if not EVIDENCE_BUCKET:
+        return
+    s3 = boto3.client("s3")
+    resp = s3.list_objects_v2(Bucket=EVIDENCE_BUCKET, Prefix="rl/eval/", MaxKeys=20)
+    for obj in (resp.get("Contents") or []):
+        key = obj["Key"]
+        if key.endswith(".json"):
+            tmp = "/tmp/rl_eval.json"
+            s3.download_file(EVIDENCE_BUCKET, key, tmp)
+            try:
+                j = json.load(open(tmp))
+                avg = float(j.get("avg_reward", 0.0))
+                eps = int(j.get("episodes", 0))
+                AVG_REWARD.set(avg)
+                EPISODES.set(eps)
+                print("Exported metrics from", key)
+                break
+            except Exception:
+                continue
+
+if __name__ == "__main__":
+    port = int(os.environ.get("METRICS_PORT", "9202"))
+    start_http_server(port)
+    print("RL exporter listening on", port)
+    while True:
+        try:
+            poll_latest_eval()
+        except Exception as e:
+            print("poll error", e)
+        time.sleep(30)
+
*** End Patch
*** Begin Patch
*** Add File:ci/rl/rl_ci_quick_test.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Quick CI job for RL: trains a tiny model for a few steps and produces evidence artifact (for PR validation)
+MODEL_DIR=${1:-./ml/example_rl_model}
+EVIDENCE_BUCKET=${EVIDENCE_BUCKET:-}
+COSIGN_KMS_KEY_ARN=${COSIGN_KMS_KEY_ARN:-}
+
+echo "Running quick RL CI test: small train"
+python3 -m pip install --upgrade pip >/dev/null
+python3 -m pip install stable-baselines3 gym boto3 >/dev/null
+python3 rl/trainer/trainer_sb3.py --env CartPole-v1 --timesteps 2000 --team ci || true
+
+echo "CI RL quick test finished"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/rl/run_local_pilot.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run a local end-to-end RL pilot (collector -> trainer -> eval)
+# Ensure EVIDENCE_BUCKET is set if you want artifacts uploaded.
+
+: "${EVIDENCE_BUCKET:-}" || echo "Note: EVIDENCE_BUCKET not set; uploads will be skipped"
+
+echo "1) Run collector (local)"
+python3 rl/collector/collector.py --env CartPole-v1 --episodes 10 --run-id localpilot
+
+echo "2) Train small model"
+python3 rl/trainer/trainer_sb3.py --env CartPole-v1 --timesteps 5000 --team localpilot
+
+echo "3) Evaluate produced model (assumes default /workspace or /tmp placement)"
+# trainer places manifest at /tmp/rl_manifest.json and model at /workspace/model/model.zip; search for the model
+MODEL_CANDIDATES=$(find /tmp /workspace -type f -name "model.zip" 2>/dev/null || true)
+MODEL=${MODEL_CANDIDATES%%$'\n'*}
+if [ -z "${MODEL}" ]; then
+  echo "Model not found; search results:"
+  find / -type f -name model.zip 2>/dev/null || true
+else
+  echo "Found model: ${MODEL}"
+  python3 rl/eval/evaluator.py --model "${MODEL}" --env CartPole-v1 --episodes 10
+fi
+
+echo "Local RL pilot complete. Check S3 for uploaded artifacts if EVIDENCE_BUCKET was configured."
+
*** End Patch
*** End Patch
