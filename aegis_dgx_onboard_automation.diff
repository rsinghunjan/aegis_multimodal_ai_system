diff --git a/scripts/dgx/ci_add_secrets_gh.sh b/scripts/dgx/ci_add_secrets_gh.sh
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/scripts/dgx/ci_add_secrets_gh.sh
@@ -0,0 +1,200 @@
+#!/usr/bin/env bash
+#
+# Add or update GitHub repository secrets required for DGX CI workflows using the GH CLI.
+# This script is a helper for operators to push KUBECONFIG_DGX, DGX registry credentials, COSIGN_KEY,
+# and other CI secrets into a repo or an organization.
+#
+# Requirements:
+#  - gh CLI installed and authenticated with sufficient permissions to write secrets
+#  - jq (optional)
+#
+# Usage:
+#   ./scripts/dgx/ci_add_secrets_gh.sh --repo owner/repo --kubeconfig ./kubeconfigs/kubeconfig-dgx \
+#       --registry ghcr.io/org --registry-user user --registry-pass pass --cosign-key ./cosign.key
+
+set -euo pipefail
+
+REPO=""
+KUBECONFIG_PATH=""
+REGISTRY=""
+REGISTRY_USER=""
+REGISTRY_PASS=""
+COSIGN_KEY_PATH=""
+DECISION_LOG_URL=""
+
+print_help() {
+  cat <<EOF
+Usage: $0 --repo owner/repo [--kubeconfig path] [--registry url --registry-user user --registry-pass pass] [--cosign-key path] [--decision-log-url url]
+
+This will write secrets into the specified repo (KUBECONFIG_DGX, DGX_IMAGE_REGISTRY, DGX_REGISTRY_USER, DGX_REGISTRY_PASS, COSIGN_KEY, DECISION_LOG_URL).
+EOF
+}
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --repo) REPO="$2"; shift 2 ;;
+    --kubeconfig) KUBECONFIG_PATH="$2"; shift 2 ;;
+    --registry) REGISTRY="$2"; shift 2 ;;
+    --registry-user) REGISTRY_USER="$2"; shift 2 ;;
+    --registry-pass) REGISTRY_PASS="$2"; shift 2 ;;
+    --cosign-key) COSIGN_KEY_PATH="$2"; shift 2 ;;
+    --decision-log-url) DECISION_LOG_URL="$2"; shift 2 ;;
+    -h|--help) print_help; exit 0 ;;
+    *) echo "Unknown arg: $1"; print_help; exit 2 ;;
+  esac
+done
+
+if [[ -z "$REPO" ]]; then
+  echo "ERROR: --repo is required"
+  exit 2
+fi
+
+if ! command -v gh >/dev/null 2>&1; then
+  echo "ERROR: gh CLI not found. Install from https://cli.github.com/"
+  exit 3
+fi
+
+echo "Will write secrets to: $REPO"
+
+write_secret() {
+  local name=$1
+  local value_file=$2
+  if [[ ! -f "$value_file" ]]; then
+    echo "Skipping $name: file not found: $value_file"
+    return
+  fi
+  echo "Writing secret $name -> $REPO"
+  gh secret set "$name" --repo "$REPO" --body-file "$value_file"
+}
+
+if [[ -n "$KUBECONFIG_PATH" ]]; then
+  if [[ ! -f "$KUBECONFIG_PATH" ]]; then echo "kubeconfig file not found: $KUBECONFIG_PATH"; exit 4; fi
+  # Use raw kubeconfig; GH Secret size supports kubeconfig content
+  echo "Storing KUBECONFIG_DGX"
+  write_secret "KUBECONFIG_DGX" "$KUBECONFIG_PATH"
+fi
+
+if [[ -n "$REGISTRY" ]]; then
+  echo "Storing DGX_IMAGE_REGISTRY"
+  printf '%s' "$REGISTRY" > /tmp/_dgx_registry.tmp
+  write_secret "DGX_IMAGE_REGISTRY" "/tmp/_dgx_registry.tmp"
+  rm -f /tmp/_dgx_registry.tmp
+fi
+
+if [[ -n "$REGISTRY_USER" && -n "$REGISTRY_PASS" ]]; then
+  printf '%s' "$REGISTRY_USER" > /tmp/_dgx_reg_user.tmp
+  printf '%s' "$REGISTRY_PASS" > /tmp/_dgx_reg_pass.tmp
+  write_secret "DGX_REGISTRY_USER" "/tmp/_dgx_reg_user.tmp"
+  write_secret "DGX_REGISTRY_PASS" "/tmp/_dgx_reg_pass.tmp"
+  rm -f /tmp/_dgx_reg_user.tmp /tmp/_dgx_reg_pass.tmp
+fi
+
+if [[ -n "$COSIGN_KEY_PATH" ]]; then
+  if [[ ! -f "$COSIGN_KEY_PATH" ]]; then echo "cosign key not found: $COSIGN_KEY_PATH"; exit 5; fi
+  write_secret "COSIGN_KEY" "$COSIGN_KEY_PATH"
+fi
+
+if [[ -n "$DECISION_LOG_URL" ]]; then
+  printf '%s' "$DECISION_LOG_URL" > /tmp/_dgx_decision_log.tmp
+  write_secret "DECISION_LOG_URL" "/tmp/_dgx_decision_log.tmp"
+  rm -f /tmp/_dgx_decision_log.tmp
+fi
+
+echo "All secrets processed. Ensure repository environment protection (Environments) is configured for release workflows that use these secrets."
+exit 0
+
diff --git a/scripts/dgx/automate_node_label_and_selector.sh b/scripts/dgx/automate_node_label_and_selector.sh
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/scripts/dgx/automate_node_label_and_selector.sh
@@ -0,0 +1,180 @@
+#!/usr/bin/env bash
+#
+# Convenience helper:
+#  - label specified DGX nodes with node.kubernetes.io/dgx=true
+#  - or update manifests nodeSelector to a provided key=value
+#
+# Usage:
+#  ./scripts/dgx/automate_node_label_and_selector.sh --nodes node1,node2
+#  ./scripts/dgx/automate_node_label_and_selector.sh --update-manifests --selector "node.kubernetes.io/role=dgx"
+
+set -euo pipefail
+
+NODES=""
+SELECTOR=""
+UPDATE_MANIFESTS="false"
+MANIFESTS_DIR="${MANIFESTS_DIR:-k8s/manifests}"
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --nodes) NODES="$2"; shift 2 ;;
+    --update-manifests) UPDATE_MANIFESTS="true"; shift ;;
+    --selector) SELECTOR="$2"; shift 2 ;;
+    --manifests-dir) MANIFESTS_DIR="$2"; shift 2 ;;
+    *) echo "Unknown arg $1"; exit 2 ;;
+  esac
+done
+
+if [[ "$UPDATE_MANIFESTS" == "true" ]]; then
+  if [[ -z "$SELECTOR" ]]; then
+    echo "--selector required with --update-manifests"; exit 2
+  fi
+  echo "Updating nodeSelector in YAML manifests under $MANIFESTS_DIR to use: $SELECTOR"
+  # naive replacement for nodeSelector blocks - ensure you review diffs
+  find "$MANIFESTS_DIR" -type f -name "*.yaml" -print0 | while IFS= read -r -d '' f; do
+    if grep -q "nodeSelector" "$f"; then
+      echo "Patching $f"
+      awk -v sel="$SELECTOR" '
+        BEGIN { split(sel,kv,"="); key=kv[1]; val=kv[2]; inserted=0 }
+        { print $0; if ($0 ~ /nodeSelector:/ && inserted==0) { print "      \"" key "\": \"" val "\""; inserted=1 } }
+      ' "$f" > "$f.tmp" && mv "$f.tmp" "$f"
+    fi
+  done
+  echo "Manifests updated. Please review changes with git diff."
+  exit 0
+fi
+
+if [[ -z "$NODES" ]]; then
+  echo "--nodes is required when not updating manifests"; exit 2
+fi
+
+IFS=',' read -r -a nodes_arr <<< "$NODES"
+for n in "${nodes_arr[@]}"; do
+  if kubectl get node "$n" >/dev/null 2>&1; then
+    echo "Labeling node $n with node.kubernetes.io/dgx=true"
+    kubectl label node "$n" node.kubernetes.io/dgx=true --overwrite || true
+  else
+    echo "Node $n not found; skipping"
+  fi
+done
+
+echo "Done."
+exit 0
+
diff --git a/scripts/dgx/automate_gpu_operator_install.sh b/scripts/dgx/automate_gpu_operator_install.sh
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/scripts/dgx/automate_gpu_operator_install.sh
@@ -0,0 +1,220 @@
+#!/usr/bin/env bash
+#
+# Install or upgrade NVIDIA GPU Operator with chosen driver strategy (autoInstall on/off).
+#
+# Usage:
+#   ./scripts/dgx/automate_gpu_operator_install.sh --autoInstall true
+#
+set -euo pipefail
+
+AUTO_INSTALL="true"
+VALUES_DIR="k8s/manifests/dgx"
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --autoInstall) AUTO_INSTALL="$2"; shift 2 ;;
+    --values-dir) VALUES_DIR="$2"; shift 2 ;;
+    *) echo "Unknown arg $1"; exit 2 ;;
+  esac
+done
+
+if [[ "$AUTO_INSTALL" == "false" ]]; then
+  VAL_FILE="${VALUES_DIR}/gpu-operator-values-no-driver.yaml"
+else
+  VAL_FILE="${VALUES_DIR}/gpu-operator-values.yaml"
+fi
+
+if [[ ! -f "$VAL_FILE" ]]; then
+  echo "Values file not found: $VAL_FILE"
+  exit 3
+fi
+
+if ! command -v helm >/dev/null 2>&1; then
+  echo "helm not found; install helm to proceed"
+  exit 4
+fi
+
+echo "Adding NVIDIA Helm repo and installing/upgrading GPU Operator with $VAL_FILE"
+helm repo add nvidia https://nvidia.github.io/gpu-operator || true
+helm repo update || true
+helm upgrade --install --namespace gpu-operator gpu-operator nvidia/gpu-operator -f "$VAL_FILE"
+
+echo "Waiting for GPU operator pods to be ready..."
+kubectl -n gpu-operator wait --for=condition=available deployment -l app.kubernetes.io/name=gpu-operator --timeout=180s || true
+kubectl -n gpu-operator get pods -o wide || true
+
+echo "GPU Operator installed/upgraded."
+exit 0
+
diff --git a/scripts/dgx/automate_build_publish_sign.sh b/scripts/dgx/automate_build_publish_sign.sh
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/scripts/dgx/automate_build_publish_sign.sh
@@ -0,0 +1,300 @@
+#!/usr/bin/env bash
+#
+# Build, SBOM, scan, cosign-sign and register validated DGX images for a given profile (h100/a100).
+# Delegates to existing helper scripts when available.
+#
+# Usage:
+#   REGISTRY=ghcr.io/org TARGET=h100 IMAGE_TAG=aegis-deepspeed:h100-cuda12.1-pytorch2.2 \
+#     ./scripts/dgx/automate_build_publish_sign.sh
+
+set -euo pipefail
+
+REGISTRY="${REGISTRY:-}"
+TARGET="${TARGET:-h100}"
+IMAGE_TAG="${IMAGE_TAG:-}"
+PUBLISH_SCRIPT="./scripts/dgx/publish_sign_register_image.sh"
+
+if [[ -z "$REGISTRY" || -z "$IMAGE_TAG" ]]; then
+  echo "REGISTRY and IMAGE_TAG environment variables are required."
+  exit 2
+fi
+
+if [[ ! -x "$PUBLISH_SCRIPT" ]]; then
+  echo "Publish script not found or not executable: $PUBLISH_SCRIPT"; exit 3
+fi
+
+echo "Building, scanning and signing image: ${REGISTRY}/${IMAGE_TAG} (target=${TARGET})"
+REGISTRY="$REGISTRY" TARGET="$TARGET" IMAGE_TAG="$IMAGE_TAG" "$PUBLISH_SCRIPT"
+
+echo "Build & publish finished. Please review docs/dgx/IMAGE_MATRIX.md for new entry."
+exit 0
+
diff --git a/scripts/dgx/automate_run_validation_and_chaos.sh b/scripts/dgx/automate_run_validation_and_chaos.sh
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/scripts/dgx/automate_run_validation_and_chaos.sh
@@ -0,0 +1,300 @@
+#!/usr/bin/env bash
+#
+# Trigger production validation and chaos runs on self-hosted DGX runners.
+# This script assumes the workflows are defined and the self-hosted runners are labeled 'dgx'.
+#
+# Usage (from a machine with gh CLI authenticated):
+#   gh workflow run dgx_production_validation.yml -f image=aegis-deepspeed:...   # or use this helper which wraps gh
+#
+set -euo pipefail
+
+WORKFLOW="dgx_production_validation.yml"
+CHAOS_WORKFLOW="chaos_matrix_with_dgx.yml"
+REPO=""
+IMAGE=""
+
+print_help() {
+  cat <<EOF
+Usage: $0 --repo owner/repo --image <image-ref>
+This helper triggers production validation workflow and (optionally) chaos workflow on self-hosted runners labeled 'dgx'.
+EOF
+}
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --repo) REPO="$2"; shift 2 ;;
+    --image) IMAGE="$2"; shift 2 ;;
+    -h|--help) print_help; exit 0 ;;
+    *) echo "Unknown arg $1"; print_help; exit 2 ;;
+  esac
+done
+
+if [[ -z "$REPO" || -z "$IMAGE" ]]; then
+  print_help; exit 2
+fi
+
+if ! command -v gh >/dev/null 2>&1; then
+  echo "gh CLI required"
+  exit 3
+fi
+
+echo "Triggering validation workflow for image: $IMAGE on repo $REPO"
+gh workflow run "$WORKFLOW" --repo "$REPO" -f image="$IMAGE"
+
+echo "Optionally triggering chaos matrix (DGX profile)"
+gh workflow run "$CHAOS_WORKFLOW" --repo "$REPO" -f profile=dgx || true
+
+echo "Workflows triggered. Monitor runs in GitHub Actions UI or via 'gh run watch'."
+exit 0
+
diff --git a/k8s/manifests/monitoring/alertmanager-dgx-route.yaml b/k8s/manifests/monitoring/alertmanager-dgx-route.yaml
new file mode 100644
index 0000000..6666666
--- /dev/null
+++ b/k8s/manifests/monitoring/alertmanager-dgx-route.yaml
@@ -0,0 +1,220 @@
+apiVersion: v1
+kind: ConfigMap
+metadata:
+  name: alertmanager-dgx-route
+  namespace: monitoring
+data:
+  alertmanager.yml: |
+    global:
+      resolve_timeout: 5m
+    route:
+      receiver: "slack"
+      group_wait: 10s
+      group_interval: 5m
+      repeat_interval: 1h
+      routes:
+        - match_re:
+            alertname: "DGX_.*"
+          receiver: "pagerduty-critical"
+    receivers:
+      - name: "slack"
+        slack_configs:
+          - api_url: "https://hooks.slack.com/services/XXX/YYY/ZZZ"
+            channel: "#dgx-alerts"
+      - name: "pagerduty-critical"
+        pagerduty_configs:
+          - service_key: "PAGERDUTY_KEY_PLACEHOLDER"
+
+# NOTE:
+# - Replace slack webhook and pagerduty key with your secrets or configure Alertmanager
+#   via the provider's CRD/values. This ConfigMap is illustrative; adapt to your Alertmanager deployment.
+
diff --git a/scripts/dgx/require_promotion_policy_check.sh b/scripts/dgx/require_promotion_policy_check.sh
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/scripts/dgx/require_promotion_policy_check.sh
@@ -0,0 +1,220 @@
+#!/usr/bin/env bash
+#
+# Enforce promotion policy: require cosign verification, SBOM presence, and validation artifacts before promotion.
+#
+# Usage:
+#   ./scripts/dgx/require_promotion_policy_check.sh --image ghcr.io/org/aegis-deepspeed:... --artifact-path ./artifacts/dgx_prod_validate
+
+set -euo pipefail
+
+IMAGE=""
+ARTIFACT_PATH=""
+IMAGE_MATRIX_FILE="${IMAGE_MATRIX_FILE:-docs/dgx/IMAGE_MATRIX.md}"
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --image) IMAGE="$2"; shift 2 ;;
+    --artifact-path) ARTIFACT_PATH="$2"; shift 2 ;;
+    --image-matrix) IMAGE_MATRIX_FILE="$2"; shift 2 ;;
+    *) echo "Unknown arg $1"; exit 2 ;;
+  esac
+done
+
+if [[ -z "$IMAGE" || -z "$ARTIFACT_PATH" ]]; then
+  echo "--image and --artifact-path are required"; exit 2
+fi
+
+echo "1) Verify cosign signature"
+if command -v cosign >/dev/null 2>&1; then
+  if ! cosign verify "$IMAGE" > /dev/null 2>&1; then
+    echo "Cosign verification failed for $IMAGE. Promotion not allowed."
+    exit 3
+  fi
+else
+  echo "cosign not available to verify signature; promotion denied."
+  exit 4
+fi
+
+echo "2) Check SBOM entry in IMAGE_MATRIX"
+if ! grep -q "$IMAGE" "$IMAGE_MATRIX_FILE"; then
+  echo "Image not recorded in $IMAGE_MATRIX_FILE; promotion denied."
+  exit 5
+fi
+
+echo "3) Check validation artifact presence"
+if [[ ! -d "$ARTIFACT_PATH" || -z "$(ls -A "$ARTIFACT_PATH")" ]]; then
+  echo "Validation artifacts not found in $ARTIFACT_PATH; promotion denied."
+  exit 6
+fi
+
+echo "Promotion checks passed for $IMAGE. You may now update production manifests to use the pinned digest."
+exit 0
+
diff --git a/docs/dgx/ONBOARDING_RUNBOOK.md b/docs/dgx/ONBOARDING_RUNBOOK.md
new file mode 100644
index 0000000..8888888
--- /dev/null
+++ b/docs/dgx/ONBOARDING_RUNBOOK.md
@@ -0,0 +1,240 @@
+# DGX Onboarding Runbook (automated helpers)
+
+This runbook explains the automated helpers included in scripts/dgx to complete DGX enablement for Aegis.
+
+1) Provisioning & kubeconfig
+ - Obtain DGX cluster from NVIDIA. Save kubeconfig to a secure location.
+ - Use scripts/dgx/ci_add_secrets_gh.sh --repo owner/repo --kubeconfig ./kubeconfigs/kubeconfig-dgx
+   to add the KUBECONFIG_DGX secret to your GitHub repo (requires gh CLI & permissions).
+
+2) CI secrets & self-hosted runners
+ - Add DGX registry creds and COSIGN_KEY via the same helper script.
+ - Provision self-hosted runners in a secure bastion that can reach DGX control plane. Label them 'dgx'.
+ - Protect secrets with GitHub Environments and require approvals for release workflows.
+
+3) Node targeting
+ - Label nodes: ./scripts/dgx/automate_node_label_and_selector.sh --nodes dgx-node-1,dgx-node-2
+ - Or update manifests to match your nodeSelector: ./scripts/dgx/automate_node_label_and_selector.sh --update-manifests --selector node.kubernetes.io/role=dgx
+
+4) Build / publish / sign images
+ - Build/publish via: REGISTRY=ghcr.io/org TARGET=h100 IMAGE_TAG=aegis-deepspeed:h100... ./scripts/dgx/automate_build_publish_sign.sh
+ - Verify docs/dgx/IMAGE_MATRIX.md contains the new entry.
+
+5) GPU Operator driver strategy
+ - Install/upgrade GPU Operator with chosen policy:
+     ./scripts/dgx/automate_gpu_operator_install.sh --autoInstall false
+ - If DGX provides drivers, set autoInstall=false.
+
+6) NCCL tuning & job updates
+ - Run tuning and apply to ConfigMap:
+     ./scripts/dgx/run_nccl_tune_apply_and_update_job.sh --out ./artifacts/nccl
+ - Ensure deepspeed job manifests reference envFrom: dgx-nccl-config or use the job-with-configmap manifest provided.
+
+7) Storage & offload
+ - Ensure dgx-checkpoints-pvc is bound to fast storage (NVMe / Lustre). Use the example PVC or your cluster's storageclass.
+ - Create S3 offloader secret & enable CronJob:
+     ./scripts/dgx/create_offloader_cronjob.sh --s3-bucket my-bucket
+
+8) Validation & chaos
+ - Trigger validation and chaos workflows on self-hosted 'dgx' runners:
+     ./scripts/dgx/automate_run_validation_and_chaos.sh --repo owner/repo --image ghcr.io/org/aegis-deepspeed:...
+ - Iterate on failures until nightly validation and chaos are green.
+
+9) Alerts & SRE playbooks
+ - Apply alert routing (k8s/manifests/monitoring/alertmanager-dgx-route.yaml) into your Alertmanager config or provider CR.
+ - Ensure runbooks in docs/runbooks/dgx_sre_playbooks.md are available to on-call.
+
+10) Promotion gating
+ - Enforce promotion checks with:
+     ./scripts/dgx/require_promotion_policy_check.sh --image ghcr.io/... --artifact-path ./artifacts/dgx_prod_validate
+ - Only promote digest-pinned images recorded in IMAGE_MATRIX.md.
+
+Notes & security
+ - Use ephemeral kubeconfigs and rotate COSIGN_KEY; use GitHub Environments and required reviewers for release workflows.
+ - Review all automated changes (manifests/nodeSelector) via pull requests.
+
+End of runbook.
+
