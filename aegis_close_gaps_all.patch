*** Begin Patch
*** Add File:ops/hsm/rotation_finalize/finalize_rotation.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Finalize HSM rotation runner.
+# - Supports vendors: yubihsm, thales, utimaco (extend as needed)
+# - Runs in dry-run mode by default. Use --apply to perform non-dry run operations.
+# - Performs basic validation by attempting a test sign/verify using platform signing helper if available.
+#
+DRY_RUN=1
+if [ "${1:-}" = "--apply" ]; then DRY_RUN=0; fi
+HSM_VENDOR="${HSM_VENDOR:-yubihsm}"
+LOGDIR="${LOGDIR:-/tmp/hsm_rotation_finalize}"
+mkdir -p "$LOGDIR"
+TIMESTAMP=$(date -u +"%Y%m%dT%H%M%SZ")
+LOG="$LOGDIR/rotation_finalize_${HSM_VENDOR}_${TIMESTAMP}.log"
+
+echo "HSM rotation finalize started vendor=$HSM_VENDOR dry_run=$DRY_RUN" | tee "$LOG"
+
+case "$HSM_VENDOR" in
+  yubihsm)
+    echo "Using YubiHSM template actions" | tee -a "$LOG"
+    if [ "$DRY_RUN" -eq 1 ]; then
+      echo "DRY RUN: Would create new signing key and map label in service config" | tee -a "$LOG"
+      echo "Example command: yubihsmctl -a rotate-authentication-key ..." | tee -a "$LOG"
+    else
+      echo "Performing YubiHSM rotation (operator MUST ensure yubihsmctl is configured)" | tee -a "$LOG"
+      # Example: create new key (operator to adapt)
+      if command -v yubihsmctl >/dev/null 2>&1; then
+        echo "yubihsmctl available - (operator: run vendor-specific commands here)" | tee -a "$LOG"
+        # Placeholder: operator should uncomment and adapt the vendor command
+        # yubihsmctl connector ... create asymmetric ...
+      else
+        echo "yubihsmctl not installed; cannot run actual rotation" | tee -a "$LOG"
+      fi
+    fi
+  ;;
+  thales|nshield)
+    echo "Using Thales/nShield template actions" | tee -a "$LOG"
+    if [ "$DRY_RUN" -eq 1 ]; then
+      echo "DRY RUN: Would provision new key container and publish public key to operator config" | tee -a "$LOG"
+    else
+      echo "Performing Thales rotation - operator MUST fill vendor CLI steps" | tee -a "$LOG"
+    fi
+  ;;
+  utimaco)
+    echo "Using Utimaco template actions" | tee -a "$LOG"
+    if [ "$DRY_RUN" -eq 1 ]; then
+      echo "DRY RUN: Would create new Utimaco key and map to signing service" | tee -a "$LOG"
+    else
+      echo "Performing Utimaco rotation - operator MUST fill vendor CLI steps" | tee -a "$LOG"
+    fi
+  ;;
+  *)
+    echo "Unknown HSM_VENDOR=$HSM_VENDOR" | tee -a "$LOG"
+    exit 2
+  ;;
+esac
+
+# Basic sign/verify validation using platform signing helper if available
+TEST_PAYLOAD="$LOGDIR/test_payload.bin"
+echo "rotation-test-$(date -u +%s)" > "$TEST_PAYLOAD"
+VALIDATION_OUT="$LOGDIR/validation_result.json"
+
+python3 - <<PY > "$VALIDATION_OUT" 2>> "$LOG"
+import json,sys
+res={"signed": False, "verify": False, "error": ""}
+try:
+    try:
+        from production.policy.signing.sign_with_retry import sign_payload, verify_signature
+    except Exception as e:
+        res["error"] = "sign_with_retry not available: " + str(e)
+        print(json.dumps(res))
+        sys.exit(0)
+    data = open("$TEST_PAYLOAD","rb").read()
+    sig,meta = sign_payload(data, None)
+    res["signed"] = bool(sig)
+    ok, vmeta = verify_signature(data, sig)
+    res["verify"] = bool(ok)
+    res["meta_signed_by"] = meta
+    res["meta_verify"] = vmeta
+except Exception as e:
+    res["error"] = str(e)
+print(json.dumps(res))
+PY
+
+echo "Validation written to $VALIDATION_OUT" | tee -a "$LOG"
+cat "$VALIDATION_OUT" | tee -a "$LOG"
+
+echo "Rotation finalize complete. Inspect $LOG for details." | tee -a "$LOG"
+
*** End Patch
*** Begin Patch
*** Add File:ops/hsm/validation/rotation_validation_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: hsm-rotation-validation-
+  namespace: aegis
+spec:
+  entrypoint: validate-rotation
+spec:
+  templates:
+    - name: validate-rotation
+      steps:
+        - - name: run-rotation-dryrun
+            template: run-finalize
+            arguments:
+              parameters:
+                - name: apply
+                  value: "false"
+        - - name: vendor-validation-suite
+            template: vendor-validate
+        - - name: upload-results
+            template: upload-results
+
+    - name: run-finalize
+      inputs:
+        parameters:
+          - name: apply
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - |
+            set -euo pipefail
+            if [ "{{inputs.parameters.apply}}" = "true" ]; then
+              bash ops/hsm/rotation_finalize/finalize_rotation.sh --apply || true
+            else
+              bash ops/hsm/rotation_finalize/finalize_rotation.sh || true
+            fi
+
+    - name: vendor-validate
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install boto3 || true
+            python3 ops/hsm/validation/run_vendor_validation_suite.py --runs 20 --out /tmp/hsm_validation.json || true
+            cat /tmp/hsm_validation.json
+
+    - name: upload-results
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - |
+            if [ -f /tmp/hsm_validation.json ] && [ -n "${EVIDENCE_BUCKET:-}" ]; then
+              aws s3 cp /tmp/hsm_validation.json s3://${EVIDENCE_BUCKET}/hsm/hsm_validation_$(date -u +%s).json || true
+            fi
+
*** End Patch
*** Begin Patch
*** Add File:ops/hsm/validation/run_vendor_validation_suite.py
+#!/usr/bin/env python3
+"""
+Run a small vendor validation suite: attempt repeated sign/verify operations and record success rates.
+"""
+import argparse, json, time
+def run_validation(runs=10):
+    results = {"runs": [], "summary": {}}
+    for i in range(runs):
+        start = time.time()
+        ok = False
+        err = None
+        try:
+            try:
+                from production.policy.signing.sign_with_retry import sign_payload, verify_signature
+            except Exception as e:
+                raise RuntimeError("sign_with_retry helper not available: " + str(e))
+            payload = f"validation-{i}-{int(time.time())}".encode()
+            sig,meta = sign_payload(payload, None)
+            verified, vmeta = verify_signature(payload, sig)
+            ok = bool(verified)
+        except Exception as e:
+            err = str(e)
+        results["runs"].append({"idx": i, "ok": ok, "error": err, "duration": time.time()-start})
+    trues = sum(1 for r in results["runs"] if r["ok"])
+    results["summary"] = {"total": runs, "success": trues, "fail": runs-trues}
+    return results
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--runs", type=int, default=10)
+    p.add_argument("--out", default="/tmp/hsm_validation.json")
+    args = p.parse_args()
+    res = run_validation(args.runs)
+    with open(args.out,"w") as f:
+        json.dump(res, f, indent=2)
+    print("Wrote", args.out)
+
*** End Patch
*** Begin Patch
*** Add File:feast/redis/values-ha-prod.yaml
+# Helm values for Redis in production for Feast online store (example)
+cluster:
+  enabled: true
+  replicaCount: 6
+  resources:
+    limits:
+      cpu: "2000m"
+      memory: "8Gi"
+    requests:
+      cpu: "1000m"
+      memory: "4Gi"
+persistence:
+  enabled: true
+  storageClass: "nvme-ssd"
+  size: 200Gi
+networkPolicy:
+  enabled: true
+service:
+  type: ClusterIP
+  port: 6379
+metrics:
+  enabled: true
+  serviceMonitor:
+    enabled: true
+tune:
+  maxclients: 10000
+  notify-keyspace-events: "Ex"
+
*** End Patch
*** Begin Patch
*** Add File:argo/benchmarks/feast_redis_load_test.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: feast-redis-load-
+  namespace: aegis
+spec:
+  entrypoint: redis-load
+  templates:
+    - name: redis-load
+      container:
+        image: redis:6.2
+        command: [sh, -c]
+        args:
+          - |
+            set -euo pipefail
+            echo "Running redis-benchmark against redis-headless.aegis.svc:6379 (demo)"
+            # Run a benchmark of GET/SET pattern for duration; adjust params as needed
+            redis-benchmark -h redis-headless.aegis.svc -p 6379 -c 200 -n 100000 -t get,set | tee /tmp/redis_bench.txt || true
+            echo "Uploading bench results if bucket set"
+            if [ -n "${EVIDENCE_BUCKET:-}" ]; then
+              aws s3 cp /tmp/redis_bench.txt s3://${EVIDENCE_BUCKET}/benchmarks/redis_bench_$(date -u +%s).txt || true
+            fi
+
*** End Patch
*** Begin Patch
*** Add File:prometheus/rules/feast_slo_rules.yaml
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: feast-slo-rules
+  namespace: aegis
+spec:
+  groups:
+    - name: feast-slo
+      rules:
+        - alert: FeastLookupLatencySLOBreach
+          expr: feast_online_lookup_p95 > 0.05
+          for: 5m
+          labels:
+            severity: page
+          annotations:
+            summary: "Feast lookup p95 exceeded 50ms"
+            description: "feast_online_lookup_p95 is {{ $value }} (> 0.05s) for 5m."
+
*** End Patch
*** Begin Patch
*** Add File:scripts/benchmarks/redis_tune_recommend.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run a redis benchmark and produce a recommended replica count (very coarse heuristic)
+OUT="/tmp/redis_tune_result.json"
+DURATION=${1:-60}
+QPS=${2:-1000}
+echo "Running redis benchmark (duration ${DURATION}s, target qps ${QPS})"
+docker run --rm --network host redis:6.2 redis-benchmark -h redis-headless.aegis.svc -p 6379 -c 200 -n 100000 -t get | tee /tmp/redis_bench.txt || true
+# Parse a simple latency heuristic (stub)
+AVG=$(grep -Eo '[0-9]+.[0-9]+ ms' /tmp/redis_bench.txt | head -n1 | sed 's/ ms//' || echo "10")
+RECOMMENDED_REPLICAS=3
+if (( $(echo "$AVG > 40" | bc -l) )); then
+  RECOMMENDED_REPLICAS=6
+elif (( $(echo "$AVG > 20" | bc -l) )); then
+  RECOMMENDED_REPLICAS=4
+fi
+cat > "$OUT" <<JSON
+{"avg_latency_ms": ${AVG}, "recommended_replicas": ${RECOMMENDED_REPLICAS}}
+JSON
+echo "Wrote $OUT"
+cat "$OUT"
+
*** End Patch
*** Begin Patch
*** Add File:deepspeed/mpi/rdma_deepspeed_validation.yaml
+apiVersion: kubeflow.org/v1
+kind: MPIJob
+metadata:
+  name: deepspeed-rdma-validate
+  namespace: aegis
+spec:
+  slotsPerWorker: 4
+  replicaSpecs:
+    Launcher:
+      replicas: 1
+      template:
+        spec:
+          containers:
+            - name: launcher
+              image: registry.example.com/aegis/deepspeed-trainer:latest
+              command: ["/bin/bash","-lc"]
+              args:
+                - |
+                  set -euo pipefail
+                  echo "Running NCCL/DeepSpeed RDMA validation (scaffold)"
+                  # Try to run NCCL benchmark if available
+                  if command -v nccl-tests >/dev/null 2>&1; then
+                    /opt/nccl-tests/build/all_reduce_perf -b 8 -e 512M -f 2 -g 4 || true
+                  fi
+                  # Run a deepspeed --num_nodes test (stub)
+                  deepspeed --num_nodes=${MPI_NUM_WORKER_REPLICAS:-2} --num_gpus=4 training/world_model/deepspeed_entrypoint.py --deepspeed_config deepspeed/deepspeed_config_zero2.json || true
+    Worker:
+      replicas: 2
+      template:
+        spec:
+          containers:
+            - name: deepspeed-worker
+              image: registry.example.com/aegis/deepspeed-trainer:latest
+              resources:
+                limits:
+                  nvidia.com/gpu: 4
+                requests:
+                  cpu: "8"
+                  memory: "32Gi"
+          nodeSelector:
+            feature.node.kubernetes.io/rdma: "true"
+
+# Note:
+# - Requires Kubeflow MPI Operator and RDMA-enabled nodes (feature node label example used).
+# - Operator must ensure NICs and SR-IOV/RDMA drivers are provisioned.
+
*** End Patch
*** Begin Patch
*** Add File:deepspeed/mpi/rdma_validation_README.md
+RDMA & DeepSpeed Validation
+--------------------------------
+This MPIJob runs a simple NCCL and DeepSpeed smoke test across worker replicas.
+
+Prereqs:
+- MPI Operator installed.
+- RDMA-enabled nodes (InfiniBand/ROCE) and node label feature.node.kubernetes.io/rdma=true set on those nodes.
+- deepspeed-trainer image contains deepspeed and optionally nccl-tests.
+
+How to run:
+kubectl apply -f deepspeed/mpi/rdma_deepspeed_validation.yaml -n aegis
+kubectl -n aegis get mpijob,deepspeed -w
+
+Interpretation:
+- If NCCL all_reduce_perf runs successfuly and deepspeed runs without comm errors, RDMA fabric is likely configured.
+- Collect pod logs and upload to evidence bucket for certification.
+
*** End Patch
*** Begin Patch
*** Add File:qpu/scheduler/prod_scheduler.py
+#!/usr/bin/env python3
+"""
+Production QPU Scheduler (Redis-backed).
+- Accepts job submissions over HTTP (POST JSON), persists to Redis list.
+- Worker threads pop jobs, call provider adapters (ops/quantum/providers/*), and record results to S3.
+
+This is a scaffold: secure with TLS, authentication, RBAC, and deploy behind Kubernetes Service with NetworkPolicy.
+"""
+import os, json, threading, time
+from http.server import BaseHTTPRequestHandler, HTTPServer
+import redis, subprocess
+
+REDIS_URL = os.environ.get("QPU_QUEUE_REDIS", "redis://redis-headless.aegis.svc:6379/0")
+redis_client = redis.from_url(REDIS_URL)
+QUEUE_KEY = os.environ.get("QPU_QUEUE_KEY", "qpu:jobs")
+OUT_BUCKET = os.environ.get("MODEL_ARTIFACT_BUCKET","")
+
+CONCURRENCY = int(os.environ.get("QPU_WORKER_CONCURRENCY","2"))
+
+def worker():
+    while True:
+        _, raw = redis_client.blpop(QUEUE_KEY, timeout=5) or (None, None)
+        if not raw:
+            time.sleep(0.2)
+            continue
+        job = json.loads(raw.decode())
+        jid = job.get("job_id","unknown")
+        provider = job.get("provider","braket")
+        try:
+            if provider == "braket":
+                cmd = ["python3","ops/quantum/providers/braket_submit.py","--program", job["program"], "--device", job["device"], "--shots", str(job.get("shots",100)), "--bucket", OUT_BUCKET]
+            else:
+                cmd = ["echo","unsupported-provider"]
+            print("Running:", cmd)
+            subprocess.run(cmd, check=True)
+            # In production record result location / metadata
+            redis_client.hset(f"qpu:jobs:{jid}", mapping={"status":"done","finished_at":time.time()})
+        except Exception as e:
+            print("Job failed", jid, e)
+            redis_client.hset(f"qpu:jobs:{jid}", mapping={"status":"error","error":str(e)})
+
+class Handler(BaseHTTPRequestHandler):
+    def _set_json(self, code=200):
+        self.send_response(code)
+        self.send_header('Content-Type','application/json')
+        self.end_headers()
+    def do_POST(self):
+        length = int(self.headers.get('Content-Length',0))
+        body = self.rfile.read(length)
+        job = json.loads(body.decode())
+        job_id = f"qjob-{int(time.time()*1000)}"
+        job["job_id"] = job_id
+        redis_client.rpush(QUEUE_KEY, json.dumps(job))
+        redis_client.hset(f"qpu:jobs:{job_id}", mapping={"status":"queued","created_at":time.time()})
+        self._set_json()
+        self.wfile.write(json.dumps({"job_id": job_id}).encode())
+
+def run_server(port=8080):
+    # start workers
+    for _ in range(CONCURRENCY):
+        t = threading.Thread(target=worker, daemon=True)
+        t.start()
+    srv = HTTPServer(('0.0.0.0', port), Handler)
+    print("QPU scheduler listening on", port)
+    srv.serve_forever()
+
+if __name__ == "__main__":
+    run_server(int(os.environ.get("QPU_SCHED_PORT","8080")))
+
*** End Patch
*** Begin Patch
*** Add File:qpu/scheduler/Dockerfile
+FROM python:3.10-slim
+RUN pip install redis boto3
+WORKDIR /app
+COPY qpu/scheduler/prod_scheduler.py /app/prod_scheduler.py
+CMD ["python3","/app/prod_scheduler.py"]
+
*** End Patch
*** Begin Patch
*** Add File:qpu/scheduler/k8s/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: qpu-scheduler
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: qpu-scheduler
+  template:
+    metadata:
+      labels:
+        app: qpu-scheduler
+    spec:
+      containers:
+        - name: scheduler
+          image: registry.example.com/aegis/qpu-scheduler:latest
+          env:
+            - name: QPU_QUEUE_REDIS
+              value: "redis://redis-headless.aegis.svc:6379/0"
+            - name: MODEL_ARTIFACT_BUCKET
+              valueFrom:
+                secretKeyRef:
+                  name: aegis-secrets
+                  key: model_artifact_bucket
+          ports:
+            - containerPort: 8080
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: qpu-scheduler
+  namespace: aegis
+spec:
+  ports:
+    - port: 8080
+      targetPort: 8080
+  selector:
+    app: qpu-scheduler
+
*** End Patch
*** Begin Patch
*** Add File:federated/secure_agg/agg_service.py
+#!/usr/bin/env python3
+"""
+Federated secure aggregator service scaffold.
+- Accepts model uploads (HTTP POST), stores them, and performs a secure aggregate operation (demo).
+- In production replace with CrypTen multi-host aggregator with TLS, authentication & audit logs.
+"""
+import os, json, time
+from http.server import BaseHTTPRequestHandler, HTTPServer
+import threading
+
+STORAGE_DIR = os.environ.get("FED_AGG_STORAGE","/tmp/fed_models")
+os.makedirs(STORAGE_DIR, exist_ok=True)
+
+class Handler(BaseHTTPRequestHandler):
+    def _set_json(self):
+        self.send_response(200)
+        self.send_header('Content-Type','application/json')
+        self.end_headers()
+    def do_POST(self):
+        length = int(self.headers.get('Content-Length',0))
+        body = self.rfile.read(length)
+        meta = json.loads(body.decode())
+        fname = f"{STORAGE_DIR}/{int(time.time()*1000)}.json"
+        with open(fname,"w") as f:
+            json.dump(meta,f)
+        print("Stored model meta to", fname)
+        self._set_json()
+        self.wfile.write(json.dumps({"status":"stored","path":fname}).encode())
+
+def aggregate_once():
+    files = sorted([os.path.join(STORAGE_DIR,f) for f in os.listdir(STORAGE_DIR) if f.endswith(".json")])
+    print("Aggregating", files)
+    # Demo aggregation: write a dummy aggregated file
+    if files:
+        out = os.path.join(STORAGE_DIR,"aggregated_"+str(int(time.time()))+".json")
+        with open(out,"w") as f:
+            json.dump({"aggregated_from": files, "timestamp": time.time()}, f)
+        print("Wrote aggregated model", out)
+
+def run(port=9100):
+    server = HTTPServer(("0.0.0.0", port), Handler)
+    print("Federated aggregator listening on", port)
+    # periodic aggregator thread
+    def agg_loop():
+        while True:
+            aggregate_once()
+            time.sleep(30)
+    t = threading.Thread(target=agg_loop, daemon=True)
+    t.start()
+    server.serve_forever()
+
+if __name__ == "__main__":
+    run(int(os.environ.get("FED_AGG_PORT","9100")))
+
*** End Patch
*** Begin Patch
*** Add File:federated/secure_agg/production_aggregator_deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: fed-aggregator
+  namespace: aegis
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: fed-aggregator
+  template:
+    metadata:
+      labels:
+        app: fed-aggregator
+    spec:
+      containers:
+        - name: agg
+          image: registry.example.com/aegis/fed-aggregator:latest
+          ports:
+            - containerPort: 9100
+          volumeMounts:
+            - name: storage
+              mountPath: /tmp/fed_models
+      volumes:
+        - name: storage
+          emptyDir: {}
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: fed-aggregator
+  namespace: aegis
+spec:
+  selector:
+    app: fed-aggregator
+  ports:
+    - port: 9100
+      targetPort: 9100
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/external_audit.yml
+name: External Audit Runner
+on:
+  workflow_dispatch:
+
+jobs:
+  run-audit:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: "3.10"
+      - name: Install deps
+        run: pip install boto3 requests
+      - name: Run readiness + assemble evidence
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG }}
+          MODEL_ARTIFACT_BUCKET: ${{ secrets.MODEL_ARTIFACT_BUCKET }}
+          EVIDENCE_BUCKET: ${{ secrets.EVIDENCE_BUCKET }}
+        run: |
+          echo "$KUBECONFIG" | base64 --decode > /github/home/.kube/config
+          bash scripts/compliance/run_external_audit.sh
+      - name: Create GitHub issue for legal review
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+          EVIDENCE_BUCKET: ${{ secrets.EVIDENCE_BUCKET }}
+        run: |
+          python3 scripts/compliance/create_audit_issue.py --title "Automated Audit Bundle Ready" --body "Evidence bundle uploaded to s3://${EVIDENCE_BUCKET}/audit/"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/compliance/create_audit_issue.py
+#!/usr/bin/env python3
+import os, argparse, requests, json
+
+def create_issue(title, body, repo=None, token=None):
+    repo = repo or os.environ.get("GITHUB_REPO")
+    token = token or os.environ.get("GITHUB_TOKEN")
+    if not repo or not token:
+        print("GITHUB_REPO and GITHUB_TOKEN required (env or args)")
+        return
+    url = f"https://api.github.com/repos/{repo}/issues"
+    headers = {"Authorization": f"token {token}"}
+    data = {"title": title, "body": body}
+    r = requests.post(url, headers=headers, json=data)
+    print("Issue create status", r.status_code)
+    print(r.text)
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--title", required=True)
+    p.add_argument("--body", default="")
+    p.add_argument("--repo", default=None)
+    args = p.parse_args()
+    create_issue(args.title, args.body, repo=args.repo)
+
*** End Patch
*** Begin Patch
*** Add File:docs/AUDIT_PLAYBOOK_SOC2_HIPAA.md
+# External Audit Playbook (SOC2 / HIPAA) â€” Aegis
+
+Overview
+- Steps to prepare for an external audit using Aegis evidence bundles.
+
+1. Run readiness checklist:
+   - bash scripts/certification/run_certification_checks.sh
+   - Ensure EVIDENCE_BUCKET is set and reachable.
+2. Run HSM rotation validation:
+   - argo submit ops/hsm/validation/rotation_validation_workflow.yaml -n aegis --watch
+   - Inspect /tmp/hsm_validation.json and upload to evidence.
+3. Run Feast/Redis SLO tests:
+   - argo submit argo/benchmarks/feast_redis_load_test.yaml -n aegis --watch
+   - Tune replicas via scripts/benchmarks/redis_tune_recommend.sh
+4. Run RDMA/DeepSpeed validation:
+   - kubectl apply -f deepspeed/mpi/rdma_deepspeed_validation.yaml -n aegis
+   - Collect pod logs and NCCL output.
+5. Run federated secure aggregation test:
+   - kubectl apply -f federated/secure_agg/production_aggregator_deployment.yaml -n aegis
+   - Launch federated/k8s/site_fed_job.yaml on two sites and observe aggregator logs.
+6. Assemble evidence:
+   - python3 evidence/enhanced_assemble_audit_bundle.py
+   - Upload to EVIDENCE_BUCKET or attach to legal ticket.
+7. Create legal ticket (GitHub issue) for auditors:
+   - python3 scripts/compliance/create_audit_issue.py --title "Aegis external audit bundle ready" --body "Evidence in s3://<EVIDENCE_BUCKET>/audit/"
+
+Notes
+- Operators must run vendor-specific HSM rotation apply steps in a staging rig and only use --apply after review.
+- Keep a signed record (MCP) for every rotation and attach to evidence bundle.
+
*** End Patch
*** Begin Patch
*** Add File:scripts/compliance/run_external_audit.sh
+#!/usr/bin/env bash
+set -euo pipefail
+echo "Running external audit readiness"
+OUT="/tmp/aegis_external_audit"
+mkdir -p "$OUT"
+bash scripts/certification/run_certification_checks.sh || true
+kubectl apply -f ops/hsm/validation/rotation_validation_workflow.yaml -n aegis || true
+kubectl apply -f argo/benchmarks/feast_redis_load_test.yaml -n aegis || true
+kubectl apply -f deepspeed/mpi/rdma_deepspeed_validation.yaml -n aegis || true
+python3 evidence/enhanced_assemble_audit_bundle.py || true
+echo "Upload evidence bundle to EVIDENCE_BUCKET if configured"
+if [ -n "${EVIDENCE_BUCKET:-}" ]; then
+  aws s3 cp /tmp/aegis_evidence/*.tar.gz s3://${EVIDENCE_BUCKET}/audit/ || true
+fi
+echo "External audit run completed. Create legal ticket referencing evidence in ${EVIDENCE_BUCKET:-<not-set>}"
+
*** End Patch
*** End Patch
