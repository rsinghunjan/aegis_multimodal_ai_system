*** Begin Patch
*** Add File: terraform/ibm/modules/key_protect/README.md
+# IBM Key Protect Terraform Module (best-effort)
+
+This module is a best-effort Terraform module to provision IBM Key Protect resources required by Aegis:
+ - Key Protect instance (service instance)
+ - Root/usage key (symmetric key) to be used for wrapping/unwrapping or as an HSM backing store
+ - (Optional) IAM/service bindings required for Vault or application access
+
+Important notes and manual review items
+- IBM Cloud resource names, service-plan availability and resource-provider IDs vary by account/region. This module makes *best-effort* choices but MUST be reviewed and tested by your IBM Cloud operator in a staging account before production usage.
+- Key Protect is a global/region-specific service; ensure the correct provider version and APIs are available in your tenancy.
+- Terraform support for some Key Protect features may be limited; where the provider lacks a resource we fallback to documentation and a placeholder output requiring operator action.
+- This module will not output secrets (private key material). It will create the Key Protect service and a key resource; operator must configure Vault to use the key (via PKCS#11 connector or Vault plugin) and may need to rotate/import keys manually.
+
+Security guidance
+- Do NOT store service credentials in Terraform state or Git. Use remote state with encryption and limited access.
+- After creating keys, push references (resource IDs, key CRNs) into Vault and avoid exposing them in CI/GitHub Secrets.
+
+Usage
+ - See example usage at terraform/ibm/native_example.tf
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/modules/key_protect/variables.tf
+variable "name" {
+  description = "Name prefix for Key Protect resources"
+  type        = string
+}
+
+variable "region" {
+  description = "IBM Cloud region"
+  type        = string
+}
+
+variable "resource_group" {
+  description = "IBM Cloud resource group name"
+  type        = string
+}
+
+variable "instance_plan" {
+  description = "Key Protect service plan (may vary by region/account)"
+  type        = string
+  default     = "standard"
+}
+
+variable "tags" {
+  description = "Tags to set on created resources"
+  type        = map(string)
+  default     = {}
+}
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/modules/key_protect/main.tf
+/* NOTE: This module uses the IBM Cloud Terraform provider where available.
+   Provider config (provider "ibm") must be defined at the root module including credentials.
+   Some environments may not have first-class Key Protect resources in Terraform provider. This file
+   attempts to create an instance and a key using known provider resources; if your provider version
+   lacks these resources you must replace the null_resource placeholders with CLI/manual steps.
+*/
+terraform {
+  required_providers {
+    ibm = {
+      source  = "IBM-Cloud/ibm"
+      version = ">= 1.38.0"
+    }
+  }
+}
+
+provider "ibm" {}
+
+# Create a Key Protect service instance (service instance resource may be provider-specific)
+resource "ibm_resource_instance" "key_protect_instance" {
+  name              = "${var.name}-keyprotect"
+  service           = "kms"
+  service_plan      = var.instance_plan
+  region            = var.region
+  resource_group_id = data.ibm_resource_group.rg.id
+  tags              = values(var.tags)
+}
+
+data "ibm_resource_group" "rg" {
+  name = var.resource_group
+}
+
+# Attempt to create a Key Protect key; provider support may vary.
+# If provider lacks a direct 'ibm_kms_key' resource, this can be replaced by a null_resource that runs ibmcloud CLI.
+resource "ibm_kms_key" "aegis_signing_key" {
+  name       = "${var.name}-signing-key"
+  instance_id = ibm_resource_instance.key_protect_instance.id
+  # algorithm / usage fields are provider dependent
+  lifecycle {
+    ignore_changes = []
+  }
+  depends_on = [ibm_resource_instance.key_protect_instance]
+}
+
+# Fallback: if ibm_kms_key resource isn't available in provider, we emit a null_resource with instructions
+resource "null_resource" "kp_manual_note" {
+  provisioner "local-exec" {
+    when    = destroy
+    command = "echo 'Ensure Key Protect key ${ibm_kms_key.aegis_signing_key.name} exists and is accessible to Vault/PKCS#11 connector'"
+  }
+  depends_on = [ibm_kms_key.aegis_signing_key]
+}
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/modules/key_protect/outputs.tf
+output "key_protect_instance_id" {
+  description = "Resource ID of the Key Protect instance"
+  value       = ibm_resource_instance.key_protect_instance.id
+}
+
+output "key_protect_key_id" {
+  description = "ID/CRN of the created signing key (may be provider-specific)"
+  value       = try(ibm_kms_key.aegis_signing_key.id, "")
+}
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/modules/cos/README.md
+# IBM Cloud Object Storage (COS) Terraform Module (best-effort)
+
+This module provisions:
+ - A Cloud Object Storage instance / service instance (if needed)
+ - A COS bucket that Aegis can use to store quantum/artifact results and model checkpoints
+
+Important notes:
+ - COS provisioning behavior varies by account and may require granting entitlements or creating a service instance first.
+ - This module attempts to create a bucket using the IBM provider; if the provider version or account restrictions prevent automated creation, the module emits a clear manual action note.
+ - Buckets created for sensitive artifacts should have lifecycle/policy rules and IAM roles configured; consider bucket encryption and access logs.
+
+Security guidance:
+ - Do not commit COS credentials into Git.
+ - Use Vault to store any COS HMAC credentials or service keys and use short-lived SAS-like tokens or Vault proxies in runtime.
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/modules/cos/variables.tf
+variable "name" {
+  description = "Name prefix for COS bucket"
+  type        = string
+}
+
+variable "region" {
+  description = "IBM Cloud region where bucket will be created"
+  type        = string
+}
+
+variable "resource_group" {
+  description = "IBM Cloud resource group"
+  type        = string
+}
+
+variable "bucket_name" {
+  description = "Desired bucket name (must be globally unique within IBM COS namespace)"
+  type        = string
+}
+
+variable "storage_class" {
+  description = "Storage class for the bucket (standard, vault, cold, etc) - provider dependent"
+  type        = string
+  default     = "standard"
+}
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/modules/cos/main.tf
+terraform {
+  required_providers {
+    ibm = {
+      source  = "IBM-Cloud/ibm"
+      version = ">= 1.38.0"
+    }
+  }
+}
+
+provider "ibm" {}
+
+data "ibm_resource_group" "rg" {
+  name = var.resource_group
+}
+
+# Many IBM COS operations require a service instance. Create a service instance for COS if not present.
+resource "ibm_resource_instance" "cos_instance" {
+  name              = "${var.name}-cos"
+  service           = "cloud-object-storage"
+  service_plan      = "standard"
+  region            = var.region
+  resource_group_id = data.ibm_resource_group.rg.id
+  tags              = []
+}
+
+# Create a COS bucket using provider's 'ibm_cos_bucket' if available; provider API names can vary.
+resource "ibm_cos_bucket" "bucket" {
+  bucket     = var.bucket_name
+  region     = var.region
+  service_instance_id = ibm_resource_instance.cos_instance.id
+  # provider-specific options may go here (locationConstraint, storageClass)
+}
+
+resource "null_resource" "cos_manual_note" {
+  provisioner "local-exec" {
+    when    = destroy
+    command = "echo 'If ibm_cos_bucket failed to create, use ibmcloud cos CLI to create ${var.bucket_name} and ensure service instance ${ibm_resource_instance.cos_instance.name} exists.'"
+  }
+  depends_on = [ibm_cos_bucket.bucket]
+}
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/modules/cos/outputs.tf
+output "cos_bucket_name" {
+  description = "Name of the COS bucket created"
+  value       = ibm_cos_bucket.bucket.bucket
+}
+
+output "cos_service_instance_id" {
+  description = "COS service instance ID"
+  value       = ibm_resource_instance.cos_instance.id
+}
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/native_example.tf
+/*
+Example use of the native IBM Key Protect & COS modules.
+Fill provider configuration (credentials) at the root level or via environment variables.
+This example is best-effort: some resources may require manual validation.
+*/
+provider "ibm" {
+  ibmcloud_api_key = var.ibm_api_key # Prefer using a CI secret or env var; do NOT store in plain text
+  region           = var.region
+}
+
+variable "region" {
+  default = "us-south"
+}
+
+variable "resource_group" {
+  default = "default"
+}
+
+variable "ibm_api_key" {
+  default = ""
+}
+
+module "key_protect" {
+  source         = "./modules/key_protect"
+  name           = "aegis"
+  region         = var.region
+  resource_group = var.resource_group
+  tags           = { project = "aegis" }
+}
+
+module "cos" {
+  source         = "./modules/cos"
+  name           = "aegis"
+  region         = var.region
+  resource_group = var.resource_group
+  bucket_name    = "aegis-artifacts-${var.region}"
+}
+
*** End Patch
*** Begin Patch
*** Add File: terraform/ibm/README_TF_NATIVE.md
+# Native Terraform modules for IBM Key Protect & COS (best-effort)
+
+Overview
+- This directory contains Terraform modules to provision IBM Key Protect (Key Management) and Cloud Object Storage (COS) resources.
+- The modules rely on the IBM Cloud Terraform provider. Due to provider/version/account differences some resource types may not be available; where that is the case the module will fail clearly or provide guidance to use the ibmcloud CLI or manual steps.
+
+Operator checklist (before running)
+1. Install and authenticate ibmcloud CLI and obtain an API key with sufficient privileges.
+2. Ensure Terraform has access to the ibm provider (set TF_VAR_ibm_api_key or provide provider configuration with credentials via environment).
+3. Review modules in terraform/ibm/modules/* and mark any provider-specific items for manual verification.
+4. Run terraform init && terraform plan in terraform/ibm and inspect the plan carefully. Do NOT apply without review.
+
+Manual review points (must validate)
+- Confirm the provider version supports ibm_kms_key and ibm_cos_bucket resources in your region.
+- Confirm that service plans (kms, cloud-object-storage) are available and entitled in your account.
+- Validate network & IAM policies required for Vault to access Key Protect (e.g., service endpoints, VPC endpoint, etc).
+
+If provider resources are missing
+- Use the CLI-first scripts (scripts/ibm/create_ibm_resources.sh) to create the service instances and keys, then call scripts/ibm/store_ibm_secrets_to_vault.sh to push secrets into Vault.
+
*** End Patch
*** Begin Patch
*** Add File: scripts/ibm/terraform_validate_and_apply.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Helper to run terraform plan and apply for the native IBM modules with safety prompts.
+ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
+TF_DIR="$ROOT_DIR/terraform/ibm"
+
+if [ -z "${IBMCLOUD_API_KEY:-}" ]; then
+  echo "Please set IBMCLOUD_API_KEY env var with a short-lived API key (do NOT commit into git)."
+  exit 2
+fi
+
+export TF_VAR_ibm_api_key="$IBMCLOUD_API_KEY"
+
+pushd "$TF_DIR" >/dev/null
+terraform init
+terraform plan -out=tfplan
+echo "Terraform plan saved to tfplan. Review it carefully before applying."
+read -r -p "Apply plan now? [y/N]: " ok
+if [[ "$ok" =~ ^[Yy] ]]; then
+  terraform apply -auto-approve tfplan
+else
+  echo "Aborting; inspect plan and re-run when ready."
+fi
+popd >/dev/null
+
*** End Patch
*** Begin Patch
*** Add File: docs/runbook_ibm_full_automation.md
+# Runbook: Make IBM Cloud fully automated for Aegis (step-by-step)
+
+This runbook walks an operator through converting the Aegis IBM integration from CLI-driven to a native Terraform + Vault automated flow.
+Prerequisites
+- An IBM Cloud account with permissions to create service instances and Key Protect resources.
+- ibmcloud CLI, terraform >= 1.0, jq, vault CLI, kubectl, helm.
+- A staging project/account for dry-run.
+
+Step 0 — Prep & safety
+ - Create a staging resource group in IBM for testing.
+ - Ensure you have an API key for an account admin user; do NOT commit it to Git. Use it as TF_VAR_ibm_api_key or export IBMCLOUD_API_KEY.
+ - Review terraform/ibm/modules/* and docs noted in the repo. Identify manual review points.
+
+Step 1 — Validate provider & region support
+ - Confirm the IBM Terraform provider version supports Key Protect and COS in your region:
+   terraform init
+   terraform providers mirror ./provider-cache
+ - Check provider docs for ibm_kms_key and ibm_cos_bucket support. If missing, fallback to CLI-first flow.
+
+Step 2 — Dry-run native Terraform in staging
+ - Set environment:
+     export IBMCLOUD_API_KEY="<staging-api-key>"
+ - Plan:
+     ./scripts/ibm/terraform_validate_and_apply.sh
+ - Inspect the plan for service instance creation and key creation. If plan fails due to missing resources, switch to CLI-first approach and record required manual steps.
+
+Step 3 — Configure Vault integration
+ - Ensure Vault is deployed and reachable by Aegis control plane.
+ - Enable KV v2 and transit (scripts/vault/*.sh can be used as templates).
+ - Create transit key (scripts/vault/vault_transit_setup.sh) and policy for signing (aegis-transit-sign).
+ - Configure Vault to allow apps to read secret/data/ibm (scripts/vault/enable_kv_and_policies.sh).
+ - Create Kubernetes auth role or GitHub OIDC role (scripts/vault/create_ibm_policy_and_role.sh & configure_vault_for_github_oidc.sh).
+
+Step 4 — Wire Key Protect -> Vault (HSM backing)
+ - Options:
+   A) Use Vault Transit keys and rotate them independently; Key Protect can be used to wrap key material manually.
+   B) Use PKCS#11 connector if you have a VM that can mount Key Protect via a connector (advanced).
+ - If you plan to have Vault call Key Protect directly, create required network access (VPC endpoint) and test sign/verify flows.
+ - Validate signing flow with the Vault transit cosign wrapper (scripts/ibm/vault_transit_cosign_wrapper.sh).
+
+Step 5 — COS integration
+ - If Terraform created a COS bucket, verify HMAC/service credentials.
+ - Store COS credentials in Vault (use vault kv put secret/cos ...).
+ - Update Aegis worker Deployments/Jobs to read COS creds via Vault Agent Injector (see examples/vault/ibm/...).
+
+Step 6 — CI OIDC -> Vault
+ - Configure Vault OIDC/JWT auth method for GitHub in a safe manner (see scripts/vault/configure_vault_for_github_oidc.sh).
+ - Create role(s) that allow the GitHub repo's OIDC tokens to acquire a short-lived Vault token bound to policy aegis-ibm-read.
+ - Test exchange via GitHub Actions in a non-prod repo.
+
+Step 7 — Deploy & test quantum flows
+ - Build and push qiskit worker image to your registry.
+ - Deploy Redis, quantum-controller, simulator/worker in staging.
+ - Submit Argo workflows for Qiskit (quantum/argo/ibmq_workflow.yaml) to ensure jobs can run end-to-end:
+    - Worker reads IBM_API_TOKEN from Vault (via Vault Agent).
+    - Jobs produce MLflow runs & upload artifacts to COS.
+    - Workers sign circuit snapshots with Vault transit and optionally record Rekor entries.
+
+Step 8 — Harden & promote
+ - Run pen-tests and SRE runbook rehearsals.
+ - Convert any remaining CLI steps to Terraform if stable, and add smoke tests to CI.
+ - Promote from staging to production with PR-based changes and a policy review.
+
+Appendix: common troubleshooting
+- Provider errors: check provider version and change terraform required_providers pin accordingly.
+- Key Protect quotas/plan errors: verify account entitlements with IBM representative.
+- Vault access errors: ensure Vault's network allows calls to Key Protect if integrating directly; configure appropriate service IDs / IBM API keys in Vault.
+
*** End Patch
*** Begin Patch
*** Add File: scripts/ibm/notes_manual_review.md
+Manual review checklist after running native Terraform modules
+
+1) Confirm Key Protect instance created: check console, verify instance id, region, and service-plan.
+2) Confirm Key creation: verify key id/CRN and permissions to access key via service-id or service principal.
+3) Confirm COS bucket created, accessible, and has correct lifecycle/policy.
+4) Ensure Terraform state file is stored securely (remote backend with encryption).
+5) Ensure Vault has entries for:
+   - secret/data/ibm (service id, api key id, api key should not be in plain where not needed)
+   - transit key exists and policy aegis-transit-sign applied to required roles
+6) Ensure network access: Vault -> Key Protect connectivity (if using direct integration), worker nodes -> COS endpoints.
+
*** End Patch
*** End Patch
