*** Begin Patch
*** Add File: services/transaction_manager.py
+#!/usr/bin/env python3
+"""
+Transaction Manager service (2PC coordinator).
+ - Durable SQLite store of transactions and participants
+ - HTTP API:
+   POST /tx/start {tx_id(optional)} -> tx_id
+   POST /tx/{tx_id}/participant {name, prepare_url, commit_url, abort_url}
+   POST /tx/{tx_id}/prepare -> coordinator asks participants to prepare
+   POST /tx/{tx_id}/commit  -> coordinator asks participants to commit
+   POST /tx/{tx_id}/abort   -> coordinator asks participants to abort
+   GET  /tx/{tx_id}         -> status
+
+Participants are expected to implement the prepare/commit/abort endpoints.
+This is a small durable coordinator intended to integrate with the agent orchestrator.
+"""
+import os, sqlite3, json, requests, uuid, time
+from fastapi import FastAPI, HTTPException
+from pydantic import BaseModel
+from typing import List
+
+DB = os.environ.get("TX_DB", "/data/transactions.sqlite")
+os.makedirs(os.path.dirname(DB), exist_ok=True)
+
+def conn():
+    c = sqlite3.connect(DB, check_same_thread=False)
+    c.execute("""CREATE TABLE IF NOT EXISTS tx (
+        tx_id TEXT PRIMARY KEY,
+        status TEXT,
+        created_at INTEGER
+    )""")
+    c.execute("""CREATE TABLE IF NOT EXISTS participants (
+        id INTEGER PRIMARY KEY AUTOINCREMENT,
+        tx_id TEXT,
+        name TEXT,
+        prepare_url TEXT,
+        commit_url TEXT,
+        abort_url TEXT,
+        status TEXT
+    )""")
+    c.commit()
+    return c
+
+app = FastAPI(title="Aegis Transaction Manager")
+
+class ParticipantIn(BaseModel):
+    name: str
+    prepare_url: str
+    commit_url: str
+    abort_url: str
+
+@app.post("/tx/start")
+def start(tx_id: str = None):
+    tx_id = tx_id or ("tx-" + uuid.uuid4().hex)
+    c = conn()
+    c.execute("INSERT OR IGNORE INTO tx (tx_id,status,created_at) VALUES (?,?,?)", (tx_id, "started", int(time.time())))
+    c.commit()
+    return {"tx_id": tx_id}
+
+@app.post("/tx/{tx_id}/participant")
+def add_participant(tx_id: str, p: ParticipantIn):
+    c = conn()
+    cur = c.cursor()
+    cur.execute("SELECT tx_id FROM tx WHERE tx_id=?", (tx_id,))
+    if not cur.fetchone():
+        raise HTTPException(status_code=404, detail="tx not found")
+    cur.execute("INSERT INTO participants (tx_id,name,prepare_url,commit_url,abort_url,status) VALUES (?,?,?,?,?,?)",
+                (tx_id, p.name, p.prepare_url, p.commit_url, p.abort_url, "registered"))
+    c.commit()
+    return {"ok": True}
+
+def call_http(url, payload=None, timeout=10):
+    try:
+        r = requests.post(url, json=payload or {}, timeout=timeout)
+        return r.status_code, r.text
+    except Exception as e:
+        return None, str(e)
+
+@app.post("/tx/{tx_id}/prepare")
+def prepare(tx_id: str):
+    c = conn()
+    cur = c.cursor()
+    cur.execute("SELECT prepare_url, id FROM participants WHERE tx_id=?", (tx_id,))
+    parts = cur.fetchall()
+    if not parts:
+        raise HTTPException(status_code=404, detail="no participants")
+    results = []
+    for url, pid in parts:
+        status, body = call_http(url, {"action":"prepare", "tx_id": tx_id})
+        ok = (status and 200 <= status < 300)
+        cur.execute("UPDATE participants SET status=? WHERE id=?", ("prepared" if ok else "failed_prepare", pid))
+        results.append({"participant_id": pid, "url": url, "status_code": status, "body": body})
+        if not ok:
+            # abort on first failure
+            c.execute("UPDATE tx SET status=? WHERE tx_id=?", ("aborting", tx_id))
+            c.commit()
+            return {"ok": False, "failed": results}
+    c.execute("UPDATE tx SET status=? WHERE tx_id=?", ("prepared", tx_id))
+    c.commit()
+    return {"ok": True, "results": results}
+
+@app.post("/tx/{tx_id}/commit")
+def commit(tx_id: str):
+    c = conn()
+    cur = c.cursor()
+    cur.execute("SELECT commit_url, id FROM participants WHERE tx_id=?", (tx_id,))
+    results = []
+    for url, pid in cur.fetchall():
+        status, body = call_http(url, {"action":"commit", "tx_id": tx_id})
+        ok = (status and 200 <= status < 300)
+        cur.execute("UPDATE participants SET status=? WHERE id=?", ("committed" if ok else "failed_commit", pid))
+        results.append({"participant_id": pid, "url": url, "status_code": status, "body": body})
+    c.execute("UPDATE tx SET status=? WHERE tx_id=?", ("committed", tx_id))
+    c.commit()
+    return {"ok": True, "results": results}
+
+@app.post("/tx/{tx_id}/abort")
+def abort(tx_id: str):
+    c = conn()
+    cur = c.cursor()
+    cur.execute("SELECT abort_url, id FROM participants WHERE tx_id=?", (tx_id,))
+    results = []
+    for url, pid in cur.fetchall():
+        status, body = call_http(url, {"action":"abort", "tx_id": tx_id})
+        cur.execute("UPDATE participants SET status=? WHERE id=?", ("aborted", pid))
+        results.append({"participant_id": pid, "url": url, "status_code": status, "body": body})
+    c.execute("UPDATE tx SET status=? WHERE tx_id=?", ("aborted", tx_id))
+    c.commit()
+    return {"ok": True, "results": results}
+
+@app.get("/tx/{tx_id}")
+def tx_status(tx_id: str):
+    c = conn()
+    cur = c.cursor()
+    cur.execute("SELECT status,created_at FROM tx WHERE tx_id=?", (tx_id,))
+    row = cur.fetchone()
+    if not row:
+        raise HTTPException(status_code=404)
+    cur.execute("SELECT id,name,prepare_url,commit_url,abort_url,status FROM participants WHERE tx_id=?", (tx_id,))
+    parts = [{"id":r[0],"name":r[1],"status":r[5],"prepare":r[2],"commit":r[3],"abort":r[4]} for r in cur.fetchall()]
+    return {"tx_id": tx_id, "status": row[0], "created_at": row[1], "participants": parts}
+
+if __name__=="__main__":
+    import uvicorn
+    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT","8301")))
+
*** End Patch
*** Begin Patch
*** Add File: services/approval_orchestrator.py
+#!/usr/bin/env python3
+"""
+Approval Orchestrator:
+ - Durable SQLite-backed approval queue for operator reviews
+ - Supports assign, escalate, batch-approve, auto-timeout
+ - Notifies via webhook (operator) when new approvals arrive or are delayed
+"""
+import os, sqlite3, time, uuid
+from fastapi import FastAPI, HTTPException
+from pydantic import BaseModel
+from typing import Optional
+import threading, requests
+
+DB = os.environ.get("APPROVAL_DB", "/data/approvals.sqlite")
+os.makedirs(os.path.dirname(DB), exist_ok=True)
+
+def conn():
+    c = sqlite3.connect(DB, check_same_thread=False)
+    c.execute("""CREATE TABLE IF NOT EXISTS approvals (
+        id TEXT PRIMARY KEY,
+        plan TEXT,
+        tenant TEXT,
+        status TEXT,
+        assigned_to TEXT,
+        created_at INTEGER,
+        updated_at INTEGER
+    )""")
+    c.commit()
+    return c
+
+app = FastAPI(title="Aegis Approval Orchestrator")
+OPERATOR_WEBHOOK = os.environ.get("OPERATOR_NOTIFY_WEBHOOK")
+AUTO_TIMEOUT_SEC = int(os.environ.get("APPROVAL_AUTO_TIMEOUT", str(60*60*24)))  # default 24h
+
+class ApprovalIn(BaseModel):
+    plan: dict
+    tenant: Optional[str] = "unknown"
+
+@app.post("/submit")
+def submit(a: ApprovalIn):
+    aid = "appr-" + uuid.uuid4().hex
+    t = int(time.time())
+    c = conn()
+    c.execute("INSERT INTO approvals (id,plan,tenant,status,created_at,updated_at) VALUES (?,?,?,?,?,?)",
+              (aid, json.dumps(a.plan), a.tenant, "pending", t, t))
+    c.commit()
+    # notify operators
+    if OPERATOR_WEBHOOK:
+        try:
+            requests.post(OPERATOR_WEBHOOK, json={"event":"approval_submitted","id":aid,"tenant":a.tenant}, timeout=3)
+        except Exception:
+            pass
+    return {"id": aid}
+
+@app.get("/pending")
+def pending(limit: int = 50):
+    c = conn()
+    cur = c.cursor()
+    cur.execute("SELECT id,plan,tenant,status,assigned_to,created_at FROM approvals WHERE status!='approved' ORDER BY created_at DESC LIMIT ?", (limit,))
+    rows = cur.fetchall()
+    return [{"id": r[0], "plan": json.loads(r[1]), "tenant": r[2], "status": r[3], "assigned_to": r[4], "created_at": r[5]} for r in rows]
+
+@app.post("/assign/{aid}")
+def assign(aid: str, to: str):
+    c = conn()
+    t = int(time.time())
+    cur = c.cursor()
+    cur.execute("UPDATE approvals SET assigned_to=?, updated_at=? WHERE id=?", (to, t, aid))
+    c.commit()
+    return {"ok": True}
+
+@app.post("/approve/{aid}")
+def approve(aid: str, operator: str = "operator"):
+    c = conn()
+    t = int(time.time())
+    cur = c.cursor()
+    cur.execute("UPDATE approvals SET status=?, assigned_to=?, updated_at=? WHERE id=?", ("approved", operator, t, aid))
+    c.commit()
+    # notify
+    if OPERATOR_WEBHOOK:
+        try:
+            requests.post(OPERATOR_WEBHOOK, json={"event":"approval_approved","id":aid,"by":operator}, timeout=3)
+        except Exception:
+            pass
+    return {"ok": True}
+
+@app.post("/reject/{aid}")
+def reject(aid: str, operator: str = "operator", note: str = ""):
+    c = conn()
+    t = int(time.time())
+    cur = c.cursor()
+    cur.execute("UPDATE approvals SET status=?, assigned_to=?, updated_at=? WHERE id=?", ("rejected", operator, t, aid))
+    c.commit()
+    if OPERATOR_WEBHOOK:
+        try:
+            requests.post(OPERATOR_WEBHOOK, json={"event":"approval_rejected","id":aid,"by":operator,"note":note}, timeout=3)
+        except Exception:
+            pass
+    return {"ok": True}
+
+def auto_timeout_loop():
+    while True:
+        try:
+            c = conn()
+            cur = c.cursor()
+            cutoff = int(time.time()) - AUTO_TIMEOUT_SEC
+            cur.execute("SELECT id FROM approvals WHERE status='pending' AND created_at < ?", (cutoff,))
+            rows = cur.fetchall()
+            for (aid,) in rows:
+                cur.execute("UPDATE approvals SET status=?, updated_at=? WHERE id=?", ("timed_out", int(time.time()), aid))
+                if OPERATOR_WEBHOOK:
+                    try:
+                        requests.post(OPERATOR_WEBHOOK, json={"event":"approval_timed_out","id":aid}, timeout=3)
+                    except Exception:
+                        pass
+            c.commit()
+        except Exception:
+            pass
+        time.sleep(60)
+
+t = threading.Thread(target=auto_timeout_loop, daemon=True)
+t.start()
+
+if __name__=="__main__":
+    import uvicorn
+    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT","8207")))
+
*** End Patch
*** Begin Patch
*** Add File: ui/operator_ui_improved.py
+#!/usr/bin/env python3
+"""
+Improved Operator Approval UI (Flask) backed by the approval_orchestrator SQLite DB via API.
+ - Shows pending approvals, assigned-to, created_at, and plan snippets
+ - Supports bulk approve/reject and simple search
+ - Requires OIDC header X-Forwarded-User (provided by oauth2-proxy in front)
+"""
+import os, requests, json
+from flask import Flask, render_template_string, redirect, url_for, request, abort
+
+APPROVAL_API = os.environ.get("APPROVAL_API", "http://approval-orchestrator.aegis.svc:8207")
+
+app = Flask("operator-ui")
+
+TEMPLATE = """
+<html><head><title>Aegis Approvals</title></head>
+<body>
+<h1>Pending Approvals ({{pending|length}})</h1>
+<form method="post" action="/bulk">
+  <button type="submit" name="action" value="approve">Bulk Approve</button>
+  <button type="submit" name="action" value="reject">Bulk Reject</button>
+  <input type="text" name="operator" placeholder="operator" />
+  <ul>
+  {% for p in pending %}
+    <li>
+      <input type="checkbox" name="aid" value="{{p.id}}" />
+      <strong>{{p.id}}</strong> tenant={{p.tenant}} assigned={{p.assigned_to}} created={{p.created_at}}<br/>
+      <pre style="max-height:150px;overflow:auto">{{ p.plan | tojson(indent=2) }}</pre>
+      <form method="post" action="/approve/{{p.id}}" style="display:inline">
+        <input type="hidden" name="operator" value="{{user}}">
+        <button type="submit">Approve</button>
+      </form>
+      <form method="post" action="/reject/{{p.id}}" style="display:inline">
+        <input type="text" name="note" placeholder="note"/>
+        <input type="hidden" name="operator" value="{{user}}">
+        <button type="submit">Reject</button>
+      </form>
+    </li>
+  {% endfor %}
+  </ul>
+</form>
+</body></html>
+"""
+
+def current_user():
+    # OIDC proxy should set X-Forwarded-User header; fallback to env
+    return os.environ.get("OPERATOR_DEFAULT", "operator")
+
+@app.route("/")
+def index():
+    r = requests.get(APPROVAL_API + "/pending")
+    pending = r.json() if r.ok else []
+    user = request.headers.get("X-Forwarded-User") or current_user()
+    return render_template_string(TEMPLATE, pending=pending, user=user)
+
+@app.route("/approve/<aid>", methods=["POST"])
+def approve(aid):
+    user = request.form.get("operator") or current_user()
+    requests.post(f"{APPROVAL_API}/approve/{aid}", params={"operator": user})
+    return redirect(url_for("index"))
+
+@app.route("/reject/<aid>", methods=["POST"])
+def reject(aid):
+    user = request.form.get("operator") or current_user()
+    note = request.form.get("note", "")
+    requests.post(f"{APPROVAL_API}/reject/{aid}", params={"operator": user, "note": note})
+    return redirect(url_for("index"))
+
+@app.route("/bulk", methods=["POST"])
+def bulk():
+    action = request.form.get("action")
+    aids = request.form.getlist("aid")
+    user = request.form.get("operator") or current_user()
+    for aid in aids:
+        if action == "approve":
+            requests.post(f"{APPROVAL_API}/approve/{aid}", params={"operator": user})
+        elif action == "reject":
+            requests.post(f"{APPROVAL_API}/reject/{aid}", params={"operator": user, "note": "bulk_reject"})
+    return redirect(url_for("index"))
+
+if __name__=="__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT","8301")))
+
*** End Patch
*** Begin Patch
*** Add File: k8s/approval-orchestrator-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: approval-orchestrator
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: approval-orchestrator
+  template:
+    metadata:
+      labels:
+        app: approval-orchestrator
+    spec:
+      containers:
+        - name: approval-orchestrator
+          image: aegis/approval-orchestrator:latest
+          ports:
+            - containerPort: 8207
+          env:
+            - name: OPERATOR_NOTIFY_WEBHOOK
+              value: "https://ops.example/notify"
+            - name: APPROVAL_DB
+              value: "/data/approvals.sqlite"
+          volumeMounts:
+            - name: approval-data
+              mountPath: /data
+      volumes:
+        - name: approval-data
+          emptyDir: {}
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: approval-orchestrator
+  namespace: aegis
+spec:
+  selector:
+    app: approval-orchestrator
+  ports:
+    - port: 8207
+      targetPort: 8207
+
*** End Patch
*** Begin Patch
*** Add File: k8s/transaction-manager-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: transaction-manager
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: transaction-manager
+  template:
+    metadata:
+      labels:
+        app: transaction-manager
+    spec:
+      containers:
+        - name: txmgr
+          image: aegis/transaction-manager:latest
+          ports:
+            - containerPort: 8301
+          env:
+            - name: TX_DB
+              value: "/data/transactions.sqlite"
+          volumeMounts:
+            - name: tx-data
+              mountPath: /data
+      volumes:
+        - name: tx-data
+          emptyDir: {}
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: transaction-manager
+  namespace: aegis
+spec:
+  selector:
+    app: transaction-manager
+  ports:
+    - port: 8301
+      targetPort: 8301
+
*** End Patch
*** Begin Patch
*** Add File: agents/sandbox_scale_test.sh
+#!/usr/bin/env bash
+#
+# Creates many ephemeral kata-runtime pods in the aegis-sandbox namespace to validate isolation at scale.
+#
+set -euo pipefail
+N=${COUNT:-50}
+NS=${NAMESPACE:-aegis-sandbox}
+
+echo "Creating $N sandbox pods in namespace $NS"
+for i in $(seq 1 $N); do
+  name="sandbox-scale-$i-$(date +%s%3N)"
+  cat > /tmp/pod-$i.json <<EOF
+{
+  "apiVersion":"v1",
+  "kind":"Pod",
+  "metadata":{"name":"${name}"},
+  "spec":{
+    "runtimeClassName":"kata-runtime",
+    "containers":[{"name":"sandbox","image":"alpine:3.18","command":["/bin/sh","-c","echo hello; sleep 5"]}],
+    "restartPolicy":"Never"
+  }
+}
+EOF
+  kubectl apply -f /tmp/pod-$i.json -n ${NS} || true
+done
+
+echo "Waiting for pods to complete"
+kubectl wait --for=condition=Succeeded pod -n ${NS} --selector 'name notin ()' --all --timeout=120s || true
+
+echo "Collecting logs and checking for host exposures"
+for p in $(kubectl get pods -n ${NS} -o jsonpath='{.items[*].metadata.name}'); do
+  logs=$(kubectl logs $p -n ${NS} || true)
+  if echo "$logs" | grep -q "/host-root"; then
+    echo "Isolation FAILURE: pod $p wrote host-root"
+    exit 2
+  fi
+done
+
+echo "Cleanup pods"
+kubectl delete pod -n ${NS} --selector 'app notin ()' --all || true
+echo "Scale test completed successfully"
+
*** End Patch
*** Begin Patch
*** Add File: k8s/sandbox-scale-test-job.yaml
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: sandbox-scale-test
+  namespace: aegis
+spec:
+  template:
+    spec:
+      containers:
+        - name: tester
+          image: bitnami/kubectl:latest
+          command: ["/bin/sh","-c","/scripts/sandbox_scale_test.sh"]
+          env:
+            - name: COUNT
+              value: "50"
+            - name: NAMESPACE
+              value: "aegis-sandbox"
+          volumeMounts:
+            - name: scripts
+              mountPath: /scripts
+      restartPolicy: Never
+      volumes:
+        - name: scripts
+          configMap:
+            name: sandbox-scale-scripts
+  backoffLimit: 1
+
+---
+apiVersion: v1
+kind: ConfigMap
+metadata:
+  name: sandbox-scale-scripts
+  namespace: aegis
+data:
+  sandbox_scale_test.sh: |
+    #!/bin/sh
+    set -e
+    /scripts/sandbox_scale_test.sh
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/sandbox_scale_ci.yml
+name: Sandbox Scale CI
+on:
+  workflow_dispatch:
+
+jobs:
+  run-scale-test:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Apply sandbox-scale Job and run
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG_INTEGRATION }}
+        run: |
+          kubectl apply -f k8s/sandbox-scale-test-job.yaml
+          kubectl wait --for=condition=complete job/sandbox-scale-test -n aegis --timeout=300s
+
*** End Patch
*** Begin Patch
*** Add File: prometheus/alerts-agent.rules.yaml
+groups:
+- name: aegis-agent-alerts
+  rules:
+  - alert: ApprovalLatencyHigh
+    expr: histogram_quantile(0.95, sum(rate(approval_request_latency_seconds_bucket[5m])) by (le)) > 300
+    for: 10m
+    labels:
+      severity: page
+    annotations:
+      summary: "Approval latency high (95th percentile > 5m)"
+      description: "Approvals are slow: investigate operator responsiveness."
+
+  - alert: SandboxFailureRate
+    expr: increase(sandbox_failures_total[10m]) / increase(sandbox_runs_total[10m]) > 0.01
+    for: 5m
+    labels:
+      severity: warning
+    annotations:
+      summary: "Sandbox failure rate is high"
+      description: "More than 1% of sandbox runs failing in the last 10m."
+
*** End Patch
*** Begin Patch
*** Add File: runbooks/agent_runbook.md
+# Aegis Agent Runbook & SLOs
+
+Purpose: operational runbook for agent orchestration, approvals, sandboxing and transactions.
+
+SLOs / Objectives
+- Approval latency: 95th percentile approval latency <= 5 minutes for critical approvals during pilot; <= 4 hours for standard approvals.
+- Sandbox isolation: 100% of kata-runtime sandbox tests must not see host files (no escapes).
+- Transaction success: 99.9% of planned transactions commit cleanly; on failure system must abort and rollback within 5 minutes.
+- Agent uptime: orchestrator availability > 99.9% (monitored via readiness and error-rate).
+
+Run playbooks
+1. Approval backlog spike:
+   - Run: kubectl get pods -n aegis | grep approval-orchestrator
+   - Check UI: operator UI pending list
+   - Engage on-call approvers; use /assign endpoint to directly assign items
+2. Sandbox failure spike:
+   - Run sandbox isolation scale test: agents/sandbox_scale_test.sh
+   - If failures observed, cordon kata nodes and investigate host config, kernel patches, or runtimeClass handler.
+3. Transaction failure:
+   - Query transaction manager: GET /tx/{tx_id}
+   - If participants failed_prepare, call /tx/{tx_id}/abort to ensure cleanup
+4. Long-running agent tasks:
+   - Ensure operator approval in place; check audit_indexer for plan provenance; if stuck, escalate to operator with evidence links.
+
+Diagnostics and monitoring
+- Check Prometheus alerts (ApprovalLatencyHigh, SandboxFailureRate).
+- Use OpenSearch (aegis-audit) to fetch plan provenance: prompt->plan->transaction->Rekor link.
+
+Testing
+- Weekly: run sandbox_scale_test (k8s job) and RLHF smoke CI.
+- Nightly: run adversarial CI for models in canary.
+
*** End Patch
*** Begin Patch
*** Add File: rl/README_RLHF_PRODUCTION.md
+# RLHF Production Readme
+
+This document contains recommended steps to run RLHF at scale:
+
+1. Prepare accelerate config for multi-node GPU cluster (use accelerate config to set up mixed precision, CPU resources)
+2. Use trl PPO trainer (see rl/ppo_trainer_trl.py) for policy optimization; adapt batch/gradient accumulation to available GPU memory.
+3. Use rl/checkpoint_manager.py to upload intermediate checkpoints atomically to S3 and register to MLflow.
+4. Validate every checkpoint with rl/checkpoint_validate.py before using it for evaluation or promotion.
+5. Run adversarial_harness.py against candidate checkpoints and block promotion if hallucination rate above threshold.
+
*** End Patch
*** End Patch
