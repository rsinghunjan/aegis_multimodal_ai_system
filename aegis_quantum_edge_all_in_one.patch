*** Begin Patch
*** Add File:adapters/ibmq_adapter.py
+#!/usr/bin/env python3
+"""
+IBMQ adapter for QuantumJob operator.
+Requires IBM_TOKEN env var and qiskit-ibm-provider installed.
+If not configured, raises RuntimeError.
+"""
+import os
+import time
+
+def run_ibmq_circuit(circuit_name, shots=1024, params=None):
+    params = params or {}
+    token = os.environ.get("IBMQ_TOKEN")
+    if not token:
+        raise RuntimeError("IBMQ_TOKEN not set in environment")
+    try:
+        from qiskit_ibm_provider import IBMProvider
+        from qiskit import transpile, assemble
+        import importlib
+        provider = IBMProvider(token=token)
+        backend = provider.backends()[0]
+        mod = importlib.import_module(f"samples.{circuit_name}_circuit")
+        qc = mod.get_circuit(params)
+        tqc = transpile(qc, backend=backend)
+        qobj = assemble(tqc, shots=shots)
+        job = backend.run(qobj)
+        job_result = job.result()
+        counts = job_result.get_counts()
+        return {"counts": counts, "backend_name": backend.name(), "job_id": job.job_id()}
+    except Exception as e:
+        raise RuntimeError(f"IBMQ adapter failed: {e}")
+
*** End Patch
*** Begin Patch
*** Add File:adapters/braket_adapter.py
+#!/usr/bin/env python3
+"""
+AWS Braket adapter (placeholder).
+If AWS credentials & BRACKET_SDK are present, this adapter should be extended to submit a circuit.
+For now it raises if not configured.
+"""
+import os
+
+def run_braket_circuit(circuit_name, shots=1024, params=None):
+    # Placeholder implementation: require AWS credentials and BRACKET_ARN env var (device)
+    params = params or {}
+    if not os.environ.get("AWS_ACCESS_KEY_ID") or not os.environ.get("AWS_SECRET_ACCESS_KEY"):
+        raise RuntimeError("AWS credentials not configured for Braket adapter")
+    # Real implementation should build a Braket task and submit via boto3 'braket' client or AWS SDK v2
+    raise NotImplementedError("Braket adapter not implemented in this patch â€” extend as needed")
+
*** End Patch
*** Begin Patch
*** Add File:helm/quantum-operator/Chart.yaml
+apiVersion: v2
+name: quantum-operator
+description: QuantumJob operator for Aegis (deploys Kopf operator to run Qiskit/Aer and adapters)
+type: application
+version: 0.1.0
+appVersion: "0.1.0"
+
*** End Patch
*** Begin Patch
*** Add File:helm/quantum-operator/values.yaml
+replicaCount: 1
+image:
+  repository: registry.example.com/aegis/quantum-operator
+  tag: latest
+serviceAccount:
+  create: true
+  name: quantum-operator-sa
+resources:
+  requests:
+    cpu: "200m"
+    memory: "256Mi"
+  limits:
+    cpu: "1"
+    memory: "1Gi"
+modelArtifactBucket: ""
+env: {}
+
*** End Patch
*** Begin Patch
*** Add File:helm/quantum-operator/templates/serviceaccount.yaml
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: {{ .Values.serviceAccount.name }}
+  labels:
+    app: quantum-operator
+
*** End Patch
*** Begin Patch
*** Add File:helm/quantum-operator/templates/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: quantum-operator
+  labels:
+    app: quantum-operator
+spec:
+  replicas: {{ .Values.replicaCount }}
+  selector:
+    matchLabels:
+      app: quantum-operator
+  template:
+    metadata:
+      labels:
+        app: quantum-operator
+    spec:
+      serviceAccountName: {{ .Values.serviceAccount.name }}
+      containers:
+        - name: operator
+          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
+          env:
+            - name: MODEL_ARTIFACT_BUCKET
+              value: "{{ .Values.modelArtifactBucket }}"
+{{- if .Values.env }}
+{{ toYaml .Values.env | indent 12 }}
+{{- end }}
+          resources:
+{{ toYaml .Values.resources | indent 12 }}
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/quantum_ci.yml
+name: Quantum operator smoke test
+on:
+  workflow_dispatch:
+
+jobs:
+  quantum-smoke:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: "3.10"
+      - name: Install Qiskit
+        run: |
+          pip install qiskit==0.40.0
+      - name: Run smoke test (local Aer)
+        run: |
+          python3 ci/quantum_smoke_test.py
+
*** End Patch
*** Begin Patch
*** Add File:ci/quantum_smoke_test.py
+#!/usr/bin/env python3
+"""
+Run a quick Qiskit Aer bell circuit to verify local quantum runtime.
+This is used by CI to smoke-test the quantum capability.
+"""
+from qiskit import Aer, transpile, assemble
+from samples.bell_circuit import get_circuit
+
+def main():
+    backend = Aer.get_backend('aer_simulator')
+    qc = get_circuit()
+    tqc = transpile(qc, backend=backend)
+    qobj = assemble(tqc, shots=512)
+    job = backend.run(qobj)
+    res = job.result()
+    counts = res.get_counts()
+    print("Counts:", counts)
+    # Basic sanity: expect two-bit counts present
+    if not counts:
+        raise SystemExit(2)
+    print("Quantum smoke test passed")
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:policies/gatekeeper/ct_quantum_backend.yaml
+apiVersion: templates.gatekeeper.sh/v1
+kind: ConstraintTemplate
+metadata:
+  name: quantumbackend
+spec:
+  crd:
+    spec:
+      names:
+        kind: RequireQuantumBackendPolicy
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package quantumbackend
+
+        violation[{"msg": msg}] {
+          input.review.object.kind == "QuantumJob"
+          spec := input.review.object.spec
+          backend := spec.backend
+          not allowed_backend(backend, input)
+          msg := sprintf("QuantumJob backend %v is not allowed in this namespace", [backend])
+        }
+
+        allowed_backend(backend, input) {
+          backend == "qiskit"
+        }
+
+        # Allow other backends if namespace has annotation quantum/allow-paid = "true"
+        allowed_backend(backend, input) {
+          ns := input.review.object.metadata.namespace
+          ann := input.review.object.metadata.annotations
+          ann["quantum/allow-paid"] == "true"
+        }
+
*** End Patch
*** Begin Patch
*** Add File:policies/gatekeeper/constraint_quantum_backend.yaml
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: RequireQuantumBackendPolicy
+metadata:
+  name: require-quantum-backend-policy
+spec:
+  match:
+    kinds:
+      - apiGroups: ["aegis.ai"]
+        kinds: ["QuantumJob"]
+    namespaces: ["*"]
+
*** End Patch
*** Begin Patch
*** Add File:argo/quantum_budget_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: quantum-budget-check-
+  namespace: aegis
+spec:
+  entrypoint: budget-check
+  templates:
+    - name: budget-check
+      steps:
+        - - name: compute-usage
+            template: compute-usage
+        - - name: enforce
+            template: enforce
+
+    - name: compute-usage
+      script:
+        image: python:3.10-slim
+        command: [python3]
+        source: |
+          import json,requests,os
+          # Placeholder: query Prometheus for quantum job counts / cost metrics
+          print("Quantum usage compute placeholder; implement Prometheus queries for your metrics")
+          print("Usage OK")
+
+    - name: enforce
+      script:
+        image: python:3.10-slim
+        command: [python3]
+        source: |
+          print("Enforcement placeholder: annotate namespaces or create budget alerts via PagerDuty/Slack")
+
*** End Patch
*** Begin Patch
*** Add File:edge/agent/Dockerfile
+FROM python:3.10-slim
+RUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*
+WORKDIR /app
+COPY agent.py /app/agent.py
+COPY verify_signature.py /app/verify_signature.py
+RUN pip install paho-mqtt requests cryptography
+CMD ["python3","/app/agent.py"]
+
*** End Patch
*** Begin Patch
*** Add File:edge/agent/agent.py
+#!/usr/bin/env python3
+"""
+Edge device agent (minimal)
+- Subscribes to MQTT topic ota/<device_id>
+- On OTA message expects JSON: {"artifact_url": "...", "sig_url": "..."}
+- Downloads artifact and signature, verifies signature using /etc/aegis/public.pem, then writes to /opt/models/
+Note: This is a minimal PoC for demo purposes.
+"""
+import os, json, requests, time
+import paho.mqtt.client as mqtt
+from verify_signature import verify_signature
+
+MQTT_BROKER = os.environ.get("MQTT_BROKER","mqtt:1883")
+DEVICE_ID = os.environ.get("DEVICE_ID","device-001")
+PUBLIC_KEY = os.environ.get("PUBLIC_KEY_PATH","/etc/aegis/public.pem")
+MODEL_DIR = "/opt/models"
+os.makedirs(MODEL_DIR, exist_ok=True)
+
+def on_connect(client, userdata, flags, rc):
+    topic = f"ota/{DEVICE_ID}"
+    client.subscribe(topic)
+    print("Subscribed to", topic)
+
+def on_message(client, userdata, msg):
+    try:
+        payload = json.loads(msg.payload.decode())
+        artifact_url = payload["artifact_url"]
+        sig_url = payload["sig_url"]
+        print("OTA: download", artifact_url)
+        r = requests.get(artifact_url, timeout=30)
+        r.raise_for_status()
+        data = r.content
+        s = requests.get(sig_url, timeout=10).content
+        ok = verify_signature(data, s, PUBLIC_KEY)
+        if not ok:
+            print("Signature verification failed, ignoring artifact")
+            return
+        name = os.path.basename(artifact_url)
+        out = os.path.join(MODEL_DIR, name)
+        with open(out, "wb") as f:
+            f.write(data)
+        print("Wrote artifact to", out)
+    except Exception as e:
+        print("OTA handling failed:", e)
+
+def main():
+    client = mqtt.Client()
+    client.on_connect = on_connect
+    client.on_message = on_message
+    client.connect(MQTT_BROKER.split(":")[0], int(MQTT_BROKER.split(":")[1]))
+    client.loop_forever()
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:edge/agent/verify_signature.py
+#!/usr/bin/env python3
+from cryptography.hazmat.primitives import hashes, serialization
+from cryptography.hazmat.primitives.asymmetric import padding
+from cryptography.hazmat.backends import default_backend
+
+def verify_signature(payload_bytes, sig_bytes, public_key_path):
+    try:
+        pub = open(public_key_path, "rb").read()
+        pk = serialization.load_pem_public_key(pub, backend=default_backend())
+        pk.verify(
+            sig_bytes,
+            payload_bytes,
+            padding.PKCS1v15(),
+            hashes.SHA256()
+        )
+        return True
+    except Exception as e:
+        print("verify_signature failed:", e)
+        return False
+
*** End Patch
*** Begin Patch
*** Add File:edge/mqtt_kafka_bridge/Dockerfile
+FROM python:3.10-slim
+WORKDIR /app
+COPY bridge.py /app/bridge.py
+RUN pip install paho-mqtt kafka-python
+CMD ["python3","/app/bridge.py"]
+
*** End Patch
*** Begin Patch
*** Add File:edge/mqtt_kafka_bridge/bridge.py
+#!/usr/bin/env python3
+"""
+Simple MQTT -> Kafka bridge
+ - Subscribes to topic(s) and forwards messages to Kafka topic(s)
+"""
+import os
+import json
+import paho.mqtt.client as mqtt
+from kafka import KafkaProducer
+
+MQTT_BROKER = os.environ.get("MQTT_BROKER", "mqtt:1883")
+MQTT_TOPIC = os.environ.get("MQTT_TOPIC", "telemetry")
+KAFKA_BOOTSTRAP = os.environ.get("KAFKA_BOOTSTRAP", "kafka:9092")
+KAFKA_TOPIC = os.environ.get("KAFKA_TOPIC", "iot-telemetry")
+
+producer = KafkaProducer(bootstrap_servers=KAFKA_BOOTSTRAP, value_serializer=lambda v: json.dumps(v).encode())
+
+def on_connect(client, userdata, flags, rc):
+    client.subscribe(MQTT_TOPIC)
+    print("Subscribed to", MQTT_TOPIC)
+
+def on_message(client, userdata, msg):
+    try:
+        payload = json.loads(msg.payload.decode())
+        producer.send(KAFKA_TOPIC, payload)
+    except Exception as e:
+        print("Failed to forward message:", e)
+
+def main():
+    client = mqtt.Client()
+    client.on_connect = on_connect
+    client.on_message = on_message
+    host, port = MQTT_BROKER.split(":")
+    client.connect(host, int(port))
+    client.loop_forever()
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:docs/QUANTUM_PRODUCTION_ADAPTERS.md
+# Quantum production adapters & integration runbook
+
+This document explains how to enable production backends (IBMQ / Braket) for the QuantumJob operator.
+
+1) IBMQ adapter
+- Set IBMQ_TOKEN in the quantum-operator deployment (use Vault + k8s-injector).
+- Ensure qiskit-ibm-provider is installed in the operator image.
+- Add RBAC/Gatekeeper policy to restrict who can create QuantumJob with backend != "qiskit".
+- The adapter returns job_id, backend_name and counts. Operator will record job_id and include it in provenance.
+
+2) AWS Braket adapter
+- Provide AWS credentials via Vault and annotate the operator pod for Vault Agent injection.
+- Implement the Braket task submission using boto3 (braket) or AWS SDK v2 in adapters/braket_adapter.py (currently a placeholder).
+- Capture taskArn, deviceArn, and provider metadata in the MCP.
+
+3) Security
+- Use SPIRE to issue SPIFFE IDs and Gatekeeper to enforce that only attested service accounts in approved namespaces may request paid backends.
+- Store provider credentials in Vault and inject them as ephemeral secrets using the Vault Agent injector (example in vault/ekstemplate_vault_agent_example.yaml).
+
+4) Budgeting & quota
+- The Gatekeeper template included blocks paid backends in namespaces that lack the annotation quantum/allow-paid=true.
+- Implement budget checks in Argo (example quantum_budget_workflow.yaml) to compute usage via Prometheus and notify if thresholds are exceeded.
+
+5) Provenance & audit
+- The operator will create an MCP-like JSON and sign it when sign_with_retry is available. Upload artifacts to MODEL_ARTIFACT_BUCKET for archival.
+
*** End Patch
*** End Patch
