*** Begin Patch
*** Add File:k8s/crd/modelcontrolplane_crd.yaml
+apiVersion: apiextensions.k8s.io/v1
+kind: CustomResourceDefinition
+metadata:
+  name: modelcontrolplanes.aegis.ai
+spec:
+  group: aegis.ai
+  names:
+    kind: ModelControlPlane
+    plural: modelcontrolplanes
+    singular: modelcontrolplane
+    shortNames:
+      - mcpv2
+  scope: Namespaced
+  versions:
+    - name: v1alpha1
+      served: true
+      storage: true
+      schema:
+        openAPIV3Schema:
+          type: object
+          properties:
+            spec:
+              type: object
+              properties:
+                model_id:
+                  type: string
+                model_version:
+                  type: string
+                lifecycle_state:
+                  type: string
+                  enum: ["Dev","Staging","Certified","Production","Retired"]
+                mcp_uri:
+                  type: string
+                certification:
+                  type: object
+                export_control:
+                  type: object
+                  properties:
+                    flag:
+                      type: string
+                    jurisdiction:
+                      type: string
+                data_residency:
+                  type: object
+                  properties:
+                    region:
+                      type: string
+                    allowed_regions:
+                      type: array
+                      items: { type: string }
+                tenancy:
+                  type: object
+                  properties:
+                    tenant_id:
+                      type: string
+                    quota:
+                      type: object
+            status:
+              type: object
+              properties:
+                observedGeneration:
+                  type: integer
+                state:
+                  type: string
+                message:
+                  type: string
+      subresources:
+        status: {}
+
*** End Patch
*** Begin Patch
*** Add File:controllers/modelcontrolplane_controller.py
+#!/usr/bin/env python3
+"""
+Minimal Model Control Plane operator.
+Watches ModelControlPlane CRs and performs basic reconciliation:
+ - validate MCP presence
+ - enforce data residency checks (simple)
+ - update status with certification state
+
+This is a skeleton; extend with proper controller frameworks (kopf/controller-runtime) for production.
+"""
+import os, time, json
+from kubernetes import client, config, watch
+import subprocess
+
+def check_mcp(mcp_uri):
+    # Reuse mcp_validate_cli if available
+    try:
+        ret = subprocess.call(["python3","tools/mcp_validate_cli.py","--mcp-uri",mcp_uri])
+        return ret == 0
+    except Exception:
+        return False
+
+def main():
+    if os.environ.get("KUBERNETES_SERVICE_HOST"):
+        config.load_incluster_config()
+    else:
+        config.load_kube_config()
+    api = client.CustomObjectsApi()
+    group = "aegis.ai"
+    version = "v1alpha1"
+    plural = "modelcontrolplanes"
+    ns = os.environ.get("WATCH_NAMESPACE","aegis")
+    w = watch.Watch()
+    print("Starting ModelControlPlane controller in", ns)
+    for evt in w.stream(api.list_namespaced_custom_object, group, version, ns, plural, timeout_seconds=0):
+        try:
+            typ = evt["type"]
+            obj = evt["object"]
+            name = obj["metadata"]["name"]
+            spec = obj.get("spec",{})
+            print("Event", typ, name)
+            mcp_uri = spec.get("mcp_uri")
+            state = "Unknown"
+            msg = ""
+            if mcp_uri:
+                ok = check_mcp(mcp_uri)
+                if ok:
+                    state = "Certified"
+                    msg = "MCP validated"
+                else:
+                    state = "MCPInvalid"
+                    msg = "MCP validation failed"
+            else:
+                state = "NoMCP"
+                msg = "No MCP URI provided"
+            status = {"status": {"observedGeneration": obj["metadata"].get("generation",0), "state": state, "message": msg}}
+            api.patch_namespaced_custom_object_status(group, version, ns, plural, name, status)
+        except Exception as e:
+            print("Controller error:", e)
+            time.sleep(1)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:k8s/webhook/mcp_validating_webhook.yaml
+apiVersion: admissionregistration.k8s.io/v1
+kind: ValidatingWebhookConfiguration
+metadata:
+  name: aegis-mcp-validator
+webhooks:
+  - name: mcp.validation.aegis.ai
+    admissionReviewVersions: ["v1","v1beta1"]
+    sideEffects: None
+    timeoutSeconds: 5
+    clientConfig:
+      service:
+        name: aegis-admission
+        namespace: aegis
+        path: "/validate"
+      caBundle: ""
+    rules:
+      - apiGroups: [""]
+        apiVersions: ["v1"]
+        operations: ["CREATE","UPDATE"]
+        resources: ["deployments"]
+    failurePolicy: Fail
+    namespaceSelector:
+      matchExpressions:
+        - key: "aegis/enforce-mcp"
+          operator: Exists
+
*** End Patch
*** Begin Patch
*** Add File:controllers/admission_server.py
+#!/usr/bin/env python3
+"""
+Admission webhook that enforces:
+ - presence of 'aegis/mcp-uri' annotation (unless policy permits)
+ - export-control labeling: if export_control.flag present, block deployments to restricted clusters
+ - data residency: check annotation 'aegis/data-residency' against allowed regions
+
+Simplified: returns AdmissionReview responses validating or denying deployment.
+"""
+from flask import Flask, request, jsonify
+import json, os
+
+app = Flask(__name__)
+
+def deny(uid, msg):
+    return {"response": {"uid": uid, "allowed": False, "status": {"message": msg}}}
+
+def allow(uid):
+    return {"response": {"uid": uid, "allowed": True}}
+
+@app.route("/validate", methods=["POST"])
+def validate():
+    req = request.json
+    uid = req["request"]["uid"]
+    obj = req["request"]["object"]
+    metadata = obj.get("metadata",{})
+    annotations = metadata.get("annotations",{})
+    labels = metadata.get("labels",{})
+    # enforce MCP presence
+    mcp_uri = annotations.get("aegis/mcp-uri")
+    enforce = True
+    # allow opt-out via label for special namespaces (operator decision)
+    if labels.get("aegis/allow-no-mcp","false") == "true":
+        enforce = False
+    if enforce and not mcp_uri:
+        return jsonify(deny(uid, "Deployment blocked: missing aegis/mcp-uri annotation (Model Context Protocol)"))
+    # export control: if model flagged 'restricted', prevent deploy in clusters not whitelisted
+    export_flag = annotations.get("aegis/export-control-flag")
+    if export_flag == "restricted":
+        allowed_cluster = os.environ.get("CLUSTER_EXPORT_WHITELIST","")
+        cluster_name = os.environ.get("CLUSTER_NAME","local")
+        if cluster_name not in allowed_cluster.split(","):
+            return jsonify(deny(uid, f"Export-control restricted: cluster {cluster_name} not allowed"))
+    # data residency: ensure target cluster region matches residency annotation
+    residency = annotations.get("aegis/data-residency")
+    if residency:
+        cluster_region = os.environ.get("CLUSTER_REGION","us-west-2")
+        if cluster_region not in residency.split(","):
+            return jsonify(deny(uid, f"Data residency violation: cluster region {cluster_region} not in allowed {residency}"))
+    return jsonify(allow(uid))
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", "8443")))
+
*** End Patch
*** Begin Patch
*** Add File:policy/opa/catalog/policies.rego
+# OPA policy: deny deployment without MCP annotation OR if data residency mismatch
+package aegis.policy
+
+deny[msg] {
+  input.kind == "Deployment"
+  not has_mcp
+  msg = "Deployment blocked: missing aegis/mcp-uri annotation"
+}
+
+has_mcp {
+  input.metadata.annotations["aegis/mcp-uri"]
+}
+
+deny[msg] {
+  input.metadata.annotations["aegis/data-residency"]
+  not allowed_region
+  msg = sprintf("Deployment blocked: cluster region %v not allowed by aegis/data-residency", [input.cluster_region])
+}
+
+allowed_region {
+  regions := split(input.metadata.annotations["aegis/data-residency"], ",")
+  input.cluster_region == regions[_]
+}
+
*** End Patch
*** Begin Patch
*** Add File:ui/policy_ui.py
+#!/usr/bin/env python3
+"""
+Small policy UI to list OPA policy files and allow manual versioning.
+This is a minimal Flask app used by policy owners to view policy sources stored in policy/opa/catalog.
+"""
+from flask import Flask, jsonify, request, render_template_string
+import os, glob
+
+app = Flask(__name__)
+POLICY_DIR = os.environ.get("OPA_POLICY_DIR","policy/opa/catalog")
+
+INDEX = """
+<h1>Aegis Policy Catalog</h1>
+<ul>
+{% for p in policies %}
+  <li><a href="/policy/{{p}}">{{p}}</a></li>
+{% endfor %}
+</ul>
+"""
+
+VIEW = """
+<h1>{{name}}</h1>
+<pre>{{content}}</pre>
+"""
+
+@app.route("/")
+def index():
+    files = [os.path.basename(x) for x in glob.glob(os.path.join(POLICY_DIR,"*"))]
+    return render_template_string(INDEX, policies=files)
+
+@app.route("/policy/<name>")
+def view(name):
+    path = os.path.join(POLICY_DIR, name)
+    if not os.path.exists(path):
+        return "Not found", 404
+    with open(path) as f:
+        content = f.read()
+    return render_template_string(VIEW, name=name, content=content)
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=8082)
+
*** End Patch
*** Begin Patch
*** Add File:explainability/shap_runner.py
+#!/usr/bin/env python3
+"""
+Compute SHAP explanations for a model and attach explanation artifacts to MLflow and MCP.
+Usage:
+  python3 explainability/shap_runner.py --model /path/to/model.pkl --data /path/to/data.csv --mlflow-run <run_id> --out /tmp/shap.json
+"""
+import argparse, joblib, pandas as pd, json, os
+import mlflow
+import shap
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--model", required=True)
+    p.add_argument("--data", required=True)
+    p.add_argument("--mlflow-run", default=None)
+    p.add_argument("--out", default="/tmp/shap_explain.json")
+    args = p.parse_args()
+    model = joblib.load(args.model)
+    df = pd.read_csv(args.data)
+    X = df.select_dtypes(include=['number']).fillna(0)
+    explainer = shap.Explainer(model.predict, X)
+    shap_values = explainer(X)
+    summary = shap_values.mean(0).values.tolist() if hasattr(shap_values, "mean") else []
+    out = {"summary": summary, "feature_names": list(X.columns)}
+    with open(args.out, "w") as f:
+        json.dump(out, f)
+    if args.mlflow_run:
+        mlflow.set_tracking_uri(os.environ.get("MLFLOW_URL",""))
+        with mlflow.start_run(run_id=args.mlflow_run):
+            mlflow.log_artifact(args.out, artifact_path="explainability")
+    print("SHAP explanation saved to", args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:fairness/fairness_checks.py
+#!/usr/bin/env python3
+"""
+Fairness checks: compute group metrics parity (equality of opportunity/example).
+This tool expects a CSV with 'label', 'pred', and 'sensitive_attr' columns.
+"""
+import argparse, pandas as pd, json
+
+def compute_metrics(df, group_col="sensitive_attr"):
+    groups = df[group_col].unique()
+    out = {}
+    for g in groups:
+        sub = df[df[group_col]==g]
+        tp = ((sub["pred"]==1) & (sub["label"]==1)).sum()
+        pos = (sub["label"]==1).sum()
+        tpr = tp / pos if pos>0 else None
+        out[str(g)] = {"tpr": tpr, "count": len(sub)}
+    return out
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--data", required=True)
+    p.add_argument("--out", default="/tmp/fairness_report.json")
+    args = p.parse_args()
+    df = pd.read_csv(args.data)
+    r = compute_metrics(df)
+    with open(args.out, "w") as f:
+        json.dump(r, f, indent=2)
+    print("Fairness report written to", args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:privacy/dp_adapter.py
+"""
+Differential privacy training adapter (PyTorch / Opacus skeleton).
+Wraps a training step and applies DP-SGD if configured.
+This file provides a high-level interface; integrate into your training image.
+"""
+from typing import Callable
+
+def train_with_dp(train_fn: Callable, use_dp: bool=False, dp_config: dict=None):
+    """
+    train_fn: function that runs training and returns a PyTorch model
+    use_dp: enable DP-SGD via Opacus
+    dp_config: dict with epsilon, delta, max_grad_norm, noise_multiplier
+    """
+    if use_dp:
+        print("DP enabled with config", dp_config)
+        # In production, wrap model + optimizer with opacus.PrivacyEngine
+        # Example (not executed here): PrivacyEngine(optimizer, sample_rate=..., noise_multiplier=..., max_grad_norm=...)
+        model = train_fn(dp=True, dp_config=dp_config)
+    else:
+        model = train_fn(dp=False)
+    return model
+
*** End Patch
*** Begin Patch
*** Add File:secure_inference/tf_encrypted_adapter.py
+"""
+Placeholder adapter to wrap TensorFlow models for secure inference (TF Encrypted / HE).
+In production integrate frameworks like TF Encrypted, CrypTen, or HE libs.
+"""
+def wrap_model_secure(model_path, backend="tfe", out_path=None):
+    # Placeholder: in real integration, load model and transform into secure computation graph
+    out = out_path or model_path + ".secure"
+    with open(out, "w") as f:
+        f.write("secure-wrapper-placeholder for " + model_path)
+    return out
+
*** End Patch
*** Begin Patch
*** Add File:federated/fl_framework.py
+"""
+Very small federated learning orchestrator skeleton using HTTP clients.
+Clients register endpoints and the server performs FedAvg rounds by pulling weights and averaging.
+This is a PoC skeleton; production will need secure aggregation and orchestration.
+"""
+import json, requests, time
+
+class FederatedServer:
+    def __init__(self):
+        self.clients = []
+
+    def register(self, url):
+        self.clients.append(url)
+
+    def fetch_weights(self, client):
+        resp = requests.get(client + "/weights", timeout=30)
+        return resp.json()
+
+    def aggregate(self, weights_list):
+        # simple average
+        agg = {}
+        for k in weights_list[0].keys():
+            vals = [w[k] for w in weights_list]
+            agg[k] = sum(vals)/len(vals)
+        return agg
+
+    def distribute(self, agg):
+        for c in self.clients:
+            requests.post(c + "/weights", json=agg, timeout=30)
+
+    def run_round(self):
+        weights = []
+        for c in self.clients:
+            weights.append(self.fetch_weights(c))
+        agg = self.aggregate(weights)
+        self.distribute(agg)
+
+if __name__ == "__main__":
+    server = FederatedServer()
+    # register clients via config / service discovery in production
+    # server.register("http://client1:8000")
+    # server.run_round()
+    print("Federated skeleton ready")
+
*** End Patch
*** Begin Patch
*** Add File:lineage/lineage_collector.py
+"""
+Collect dataset snapshot metadata and register lineage with MLflow and MCP.
+This script creates a dataset snapshot id and logs it into MLflow run tags and MCP metadata.
+"""
+import argparse, json, os, hashlib
+import mlflow
+
+def snapshot_dataset(path):
+    # create a simple hash as snapshot id (in real life use checksums + storage link)
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        for chunk in iter(lambda: f.read(8192), b""):
+            h.update(chunk)
+    return "snapshot-" + h.hexdigest()[:12]
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--data", required=True)
+    p.add_argument("--mlflow-run", required=True)
+    args = p.parse_args()
+    sid = snapshot_dataset(args.data)
+    mlflow.set_tracking_uri(os.environ.get("MLFLOW_URL",""))
+    with mlflow.start_run(run_id=args.mlflow_run):
+        mlflow.set_tag("dataset_snapshot_id", sid)
+    print("Snapshot ID:", sid)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:autoschedulers/hpc_scheduler_integration.py
+"""
+Simple scheduler helper to pick resource partitions for HPC jobs (Slurm) or K8s nodes.
+Implements resource-aware placement heuristics and spot/preemptible selection stub.
+"""
+def pick_partition(job_requirements, partitions):
+    """
+    job_requirements: dict(cpu, mem, gpu, priority, budget)
+    partitions: list of dict(name, cpu_avail, mem_avail, spot_price)
+    """
+    # naive scoring: prefer partitions that satisfy resources and lowest spot_price within budget
+    candidates = []
+    for p in partitions:
+        if p["cpu_avail"] >= job_requirements["cpu"] and p["mem_avail"] >= job_requirements["mem"]:
+            score = p.get("spot_price", 9999) * (1 if job_requirements.get("priority","normal")=="low" else 0.8)
+            candidates.append((score, p))
+    if not candidates:
+        return None
+    candidates.sort(key=lambda x:x[0])
+    return candidates[0][1]
+
*** End Patch
*** Begin Patch
*** Add File:marketplace/api.py
+"""
+Model Marketplace API (simple): multi-tenant model listing, per-tenant MCPs, quotas and billing hooks.
+This is a lightweight Flask app with in-memory store for POC; replace with DB backend in production.
+"""
+from flask import Flask, jsonify, request
+import os, uuid, time
+
+app = Flask(__name__)
+TENANTS = {}
+MODELS = {}
+
+@app.route("/tenant", methods=["POST"])
+def create_tenant():
+    payload = request.json or {}
+    tenant_id = str(uuid.uuid4())
+    TENANTS[tenant_id] = {"tenant_id": tenant_id, "created_at": time.time(), "quota": payload.get("quota", {})}
+    return jsonify(TENANTS[tenant_id])
+
+@app.route("/tenant/<tid>/model", methods=["POST"])
+def publish_model(tid):
+    payload = request.json or {}
+    if tid not in TENANTS:
+        return jsonify({"error":"unknown tenant"}), 404
+    model_id = str(uuid.uuid4())
+    MODELS[model_id] = {"model_id": model_id, "tenant_id": tid, "name": payload.get("name"), "mcp_uri": payload.get("mcp_uri"), "created_at": time.time()}
+    return jsonify(MODELS[model_id])
+
+@app.route("/models", methods=["GET"])
+def list_models():
+    return jsonify(list(MODELS.values()))
+
+@app.route("/tenant/<tid>/billing", methods=["GET"])
+def tenant_billing(tid):
+    # placeholder: integrate with chargeback mapping
+    return jsonify({"tenant_id": tid, "estimated_monthly": 0.0})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=8090)
+
*** End Patch
*** Begin Patch
*** Add File:cost_optimizer/placement.py
+"""
+Simple cost-aware placement helper that chooses cloud region and instance type.
+This uses a stubbed cost model; integrate with cloud pricing APIs for production.
+"""
+def choose_placement(job, candidates):
+    # job: {cpu, mem, max_cost}
+    # candidates: [{provider,region,instance_type,cost_per_hour,available}]
+    feasible = [c for c in candidates if c["cost_per_hour"] <= job.get("max_cost", 9999) and c["available"]]
+    if not feasible:
+        return None
+    feasible.sort(key=lambda x: x["cost_per_hour"])
+    return feasible[0]
+
*** End Patch
*** Begin Patch
*** Add File:ci/chaos/chaos_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-chaos-
+spec:
+  entrypoint: chaos
+  templates:
+    - name: chaos
+      steps:
+        - - name: stop-pod
+            template: run-script
+            arguments:
+              parameters:
+                - name: script
+                  value: "kubectl -n aegis delete pod -l app=aegis-model --grace-period=0 || true"
+        - - name: wait
+            template: run-script
+            arguments:
+              parameters:
+                - name: script
+                  value: "sleep 30"
+        - - name: check-recovery
+            template: run-script
+            arguments:
+              parameters:
+                - name: script
+                  value: "kubectl -n aegis rollout status deployment/aegis-model --timeout=120s || exit 2"
+
+    - name: run-script
+      inputs:
+        parameters:
+          - name: script
+      container:
+        image: bitnami/kubectl:1.27
+        command: [sh, -c]
+        args: ["{{inputs.parameters.script}}"]
+
*** End Patch
*** Begin Patch
*** Add File:reproducible/notebook_metadata.py
+"""
+Attach reproducibility metadata (container image, seed, dataset snapshot id)
+to MLflow run and to the MCP document.
+"""
+import argparse, os, json, mlflow
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--run-id", required=True)
+    p.add_argument("--image", required=True)
+    p.add_argument("--seed", default="42")
+    p.add_argument("--dataset-snapshot", default="")
+    args = p.parse_args()
+    mlflow.set_tracking_uri(os.environ.get("MLFLOW_URL",""))
+    with mlflow.start_run(run_id=args.run_id):
+        mlflow.set_tag("repro_container", args.image)
+        mlflow.set_tag("repro_seed", args.seed)
+        if args.dataset_snapshot:
+            mlflow.set_tag("dataset_snapshot_id", args.dataset_snapshot)
+    print("Reproducibility metadata attached to run", args.run_id)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:docs/FEATURES_ENTERPRISE.md
+# Aegis â€” Enterprise Feature Scaffolding
+
+This patch contains scaffolding and skeleton implementations for advanced enterprise features:
+
+- Admission controller (validating webhook) that enforces MCP annotation, export-control flags, and data residency checks.
+- Model Control Plane CRD + lightweight controller (ModelControlPlane) to track lifecycle state, certification and reconciliation.
+- Policy-as-code (OPA) catalog and a small policy UI for owners to view policies.
+- Explainability (SHAP) runner and fairness checks to auto-generate artifacts and enrich model cards.
+- Differential Privacy adapter (Opacus/TensorFlow Privacy) placeholder and secure inference adapter stub.
+- Federated learning orchestration skeleton (FedAvg).
+- Dataset lineage collector to produce dataset snapshot IDs and attach to MLflow runs / MCPs.
+- Auto-scheduler and cost optimizer stubs for HPC scheduling and spot placement.
+- Marketplace API skeleton for multi-tenant model listings and per-tenant MCPs.
+- Chaos testing Argo workflow, reproducible notebook metadata script.
+
+Notes:
+- These are skeletons designed to be integrated and hardened for your environment. Security, production readiness, and scalability work remain.
+- Controllers should be migrated to operator frameworks (kopf/controller-runtime) for production.
+- Replace stubs with real integrations (Opacus, TF Encrypted, secure aggregation libs, cloud/price APIs).
+
*** End Patch
*** End Patch
