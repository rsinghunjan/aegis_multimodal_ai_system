*** Begin Patch
*** Add File: .github/workflows/promote_with_baa_check.yml
+name: Promotion with BAA Gate (regulated)
+on:
+  workflow_dispatch:
+    inputs:
+      provider:
+        description: "Provider name (eg: braket)"
+        required: true
+      regulated:
+        description: "Is this a regulated promotion? true/false"
+        required: true
+      artifact:
+        description: "Path to artifact to promote"
+        required: true
+
+jobs:
+  promote:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Validate BAA precheck
+        env:
+          PROVIDER_NAME: ${{ github.event.inputs.provider }}
+          REGULATED: ${{ github.event.inputs.regulated }}
+        run: |
+          python provider/legal/enforce_baa_precheck.py || (echo "BAA precheck failed — aborting promotion" && exit 2)
+
+      - name: Promote artifact (stub)
+        run: |
+          echo "Promotion would run here for artifact: ${{ github.event.inputs.artifact }}"
+          # Insert your actual promotion steps (upload, release orchestration) here
+
+      - name: Notify compliance (if regulated)
+        if: ${{ github.event.inputs.regulated == 'true' }}
+        run: |
+          echo "Regulated promotion completed; ensure evidence is archived per policy."
+
*** End Patch
*** Begin Patch
*** Add File: hooks/scheduler_pre_create_job.py
+#!/usr/bin/env python3
+"""
+Scheduler hook: run before creating provider job resources.
+- Enforces required tags for billing/reconciliation.
+- Enforces BAA precheck for regulated workloads.
+This script is intended to be invoked by the scheduler code-path with the job payload passed as JSON on stdin.
+"""
+import sys, json, os, subprocess
+from billing.scheduler_tag_enforcer import ensure_tags
+
+def run_baa_check(provider, regulated):
+    env = os.environ.copy()
+    env["PROVIDER_NAME"]=provider
+    env["REGULATED"]="true" if regulated else "false"
+    res = subprocess.run(["python","provider/legal/enforce_baa_precheck.py"], env=env)
+    return res.returncode == 0
+
+def main():
+    raw = sys.stdin.read()
+    payload = json.loads(raw) if raw else {}
+    provider = payload.get("provider", os.environ.get("PROVIDER_NAME"))
+    regulated = payload.get("regulated", os.environ.get("REGULATED","false").lower() in ("1","true"))
+    # enforce tags
+    tenant = payload.get("owner")
+    job_id = payload.get("job_id")
+    payload = ensure_tags(payload, tenant=tenant, job_id=job_id)
+    # write back the payload (printed JSON consumed by scheduler)
+    print(json.dumps(payload))
+    # BAA check (if regulated)
+    if regulated:
+        ok = run_baa_check(provider, True)
+        if not ok:
+            print("BAA check failed for provider:", provider, file=sys.stderr)
+            sys.exit(2)
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: k8s/cron/billing-reconcile-cron.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: aegis-billing-reconcile
+  namespace: aegis
+spec:
+  schedule: "0 7 * * *" # daily at 07:00 UTC
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          containers:
+            - name: reconcile
+              image: python:3.10-slim
+              env:
+                - name: AWS_REGION
+                  valueFrom:
+                    secretKeyRef:
+                      name: aws-secrets
+                      key: region
+                - name: DATABASE_URL
+                  valueFrom:
+                    secretKeyRef:
+                      name: db-secrets
+                      key: database_url
+                - name: BILLING_SNS_TOPIC
+                  valueFrom:
+                    secretKeyRef:
+                      name: billing-secrets
+                      key: sns_topic
+              command: ["sh", "-c"]
+              args:
+                - pip install boto3 sqlalchemy psycopg2-binary && python /opt/aegis/billing/reconcile_automated.py
+              volumeMounts:
+                - name: repo
+                  mountPath: /opt/aegis
+          restartPolicy: OnFailure
+          volumes:
+            - name: repo
+              configMap:
+                name: aegis-repo-snapshot
+
*** End Patch
*** Begin Patch
*** Add File: k8s/cron/db-partition-cron.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: aegis-db-partition-maintenance
+  namespace: aegis
+spec:
+  schedule: "5 0 * * *" # daily at 00:05 UTC
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          containers:
+            - name: create-partitions
+              image: python:3.10-slim
+              env:
+                - name: DATABASE_URL
+                  valueFrom:
+                    secretKeyRef:
+                      name: db-secrets
+                      key: database_url
+              command: ["sh", "-c"]
+              args:
+                - pip install psycopg2-binary && python /opt/aegis/db/partitioning/auto_partition_creator.py
+              volumeMounts:
+                - name: repo
+                  mountPath: /opt/aegis
+          restartPolicy: OnFailure
+          volumes:
+            - name: repo
+              configMap:
+                name: aegis-repo-snapshot
+
*** End Patch
*** Begin Patch
*** Add File: ansible/provision/run_jetson_pilot.yml
+- name: Run Jetson pilot onboarding (orchestrator)
+  hosts: localhost
+  connection: local
+  gather_facts: false
+  vars:
+    inventory: "ansible/provision/hosts.ini"
+  tasks:
+    - name: Kick off Jetson pilot playbook for inventory
+      shell: |
+        ansible-playbook -i {{ inventory }} ansible/provision/jetson_pilot_full.yml --ask-vault-pass
+      register: pilot_run
+    - name: Pause briefly for metrics to appear
+      pause:
+        minutes: 2
+    - name: Verify Prometheus metrics via API (operator input required)
+      debug:
+        msg: "Verify node_exporter metrics appear in Prometheus; check CI runner list for registered runners."
+    - name: Print pilot run result
+      debug:
+        var: pilot_run.stdout_lines
+
*** End Patch
*** Begin Patch
*** Add File: quantum/hardening/run_sla_tune_apply.sh
+#!/usr/bin/env bash
+set -euo pipefail
+OUTDIR=${OUTDIR:-/tmp/qpu_reports}
+RECS=/tmp/adapter_recommendations.json
+SUG=/tmp/mitigation_suggestions.json
+
+mkdir -p "$OUTDIR"
+echo "1) Launch distributed SLA harness (CI/k8s jobs)"
+echo "   Use provider_live_test_orchestrator.py or CI workflow to start harness jobs."
+python quantum/hardening/provider_live_test_orchestrator.py --jobs 10 --s3-bucket "${S3_BUCKET:-my-compliance-bucket}" || true
+
+echo "2) Aggregate & measure"
+python quantum/hardening/aggregate_sla_reports.py || true
+python quantum/hardening/measure_and_tune.py || true
+
+echo "3) Apply adapter recommendations"
+python quantum/tuning/auto_apply_adapter_recs.py || true
+
+echo "4) Run mitigation experiments"
+python mitigation/run_mitigation_batch.py || true
+python mitigation/auto_apply_mitigation.py || true
+
+echo "5) Re-run harness to validate changes (repeat as needed)"
+echo "Complete. Check /tmp/qpu_sla_summary.json, ${RECS}, ${SUG}"
+
*** End Patch
*** Begin Patch
*** Add File: sre/run_locust_scale_tune.sh
+#!/usr/bin/env bash
+set -euo pipefail
+N=${1:-500}
+MASTER_YAML="edge/loadtest/locust_master_deployment.yaml"
+WORKER_JOB_YAML="edge/loadtest/locust_distributed_jobs.yaml"
+echo "Deploy locust master"
+kubectl apply -f "${MASTER_YAML}"
+echo "Launch ${N} worker jobs (as k8s Jobs)"
+for i in $(seq 1 $N); do
+  kubectl create -f ${WORKER_JOB_YAML} || true
+done
+echo "Run for 30m"
+sleep 1800
+echo "Collect Prometheus snapshot (requires accessible Prometheus)"
+kubectl port-forward svc/prometheus-operated -n monitoring 9090:9090 >/dev/null 2>&1 &
+PF=$!
+sleep 2
+curl -s "http://127.0.0.1:9090/api/v1/query?query=sum(rate(http_requests_total[5m]))" -o /tmp/locust_prom_snapshot.json || true
+kill $PF || true
+echo "Saved /tmp/locust_prom_snapshot.json"
+echo "Run DB partition create and suggestions"
+python db/partitioning/auto_partition_creator.py || true
+python db/tuning/pg_conf_suggester.py 100000 || true
+echo "Completed scale test; review Prometheus snapshot and pg_conf suggestions."
+
*** End Patch
*** Begin Patch
*** Add File: billing/README_enforce_tagging.md
+Enforce tagging policy in scheduler
+
+1) Ensure scheduler calls billing.scheduler_tag_enforcer.ensure_tags(job_payload)
+   - This will inject aegis:tenant and aegis:job_id tags into provider resource creation payloads.
+
+2) Validate all IaC / adapter code paths include tag propagation when creating provider-side resources (Braket runs, AWS tasks, etc).
+
+3) Run daily reconcile job and review /tmp/reconcile_report.json; tune matching heuristics for provider invoice formats.
+
+4) If tags are missing for jobs, alert billing owner and consider blocking promotions until tags are present for tenanted workloads.
+
*** End Patch
*** Begin Patch
*** Add File: README/operational_playbook.md
+# Aegis Operational Playbook (summary)
+
+This document summarizes the remediation steps and scripts to close the remaining high‑priority operational gaps.
+
+Legal (critical)
+- Use provider/legal/upload_baa.py to archive signed BAAs to the compliance bucket.
+- Run the GHA workflow .github/workflows/promote_with_baa_check.yml for regulated promotions.
+- Verify Rekor attestation with provider/legal/verify_archive_and_attest.py.
+
+HSM / CloudHSM (high)
+- Run scripts/cloudhsm/operator_checklist.sh (fill placeholders) on admin host to build cluster, configure client and validate PKCS11 signing.
+- Use infra/hsm/cloudhsm_admin_playbook.yml (Ansible) to install helpers on admin host.
+- Run hsm/rotation/rotation_drill.sh to exercise rotation and run hsm/cloudtrail/generate_audit_report.py to collect audit evidence.
+
+Physical runner ops (high)
+- Use packer/jetson_ubuntu_arm.pkr.hcl and cloud-init/jetson-user-data.yaml to build and boot images.
+- Run ansible/provision/run_jetson_pilot.yml to orchestrate onboarding of 3–10 devices.
+- Verify Prometheus metrics, CI registration and TensorRT validation.
+
+Provider live hardening (high → iterative)
+- Use quantum/hardening/run_sla_tune_apply.sh to run harness, aggregate reports and apply tuning & mitigation.
+- Iterate until provider p95 & error rates meet SLA.
+
+Billing & SRE
+- Ensure scheduler injects aegis:tenant tags via billing/scheduler_tag_enforcer.py.
+- Deploy k8s/cron/billing-reconcile-cron.yaml and k8s/cron/db-partition-cron.yaml to run daily reconciliation & partitioning.
+- Run sre/run_locust_scale_tune.sh to exercise scale and tune Postgres using db/tuning/pg_conf_suggester.py.
+
+Contacts & escalation
+- CloudOps: run CloudHSM steps and capture evidence to compliance bucket.
+- Legal: sign & upload BAAs and confirm Rekor attestation.
+- SRE: execute Locust runs, adjust DB & Kafka buffering as needed.
+
*** End Patch
*** End Patch
