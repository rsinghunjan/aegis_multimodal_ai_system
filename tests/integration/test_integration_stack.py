  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
import os
import subprocess
import time
import json
import requests
import tempfile
import shutil
from pathlib import Path

import pytest

ROOT = Path(__file__).resolve().parents[2]
COMPOSE = ROOT / "docker" / "docker-compose.integration.yml"
API_BASE = "http://localhost:8081"

def run(cmd, **kwargs):
    print("RUN:", cmd)
    return subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, **kwargs)

@pytest.fixture(scope="session", autouse=True)
def integration_stack():
    """
    Bring up docker-compose integration stack for the session,
    wait for readiness, and tear down when tests finish.
    """
    cwd = str(ROOT)
    # bring down any prior residual env
    try:
        subprocess.run(f"docker compose -f {COMPOSE} down --volumes --remove-orphans", shell=True, check=False, cwd=cwd)
    except Exception:
        pass

    # start stack
    subprocess.run(f"docker compose -f {COMPOSE} up -d --build", shell=True, check=True, cwd=cwd)

    # wait for api health
    try:
        subprocess.run(f"scripts/wait_for_services.sh {API_BASE}/health 60 2", shell=True, check=True, cwd=cwd)
    except subprocess.CalledProcessError as exc:
        # dump logs for debugging
        print("API failed to become healthy. Dumping logs:")
        subprocess.run(f"docker compose -f {COMPOSE} logs api", shell=True, cwd=cwd)
        raise

    # Run migrations inside api container
    print("Running alembic migrations inside api container...")
    subprocess.run(f"docker compose -f {COMPOSE} exec -T api alembic upgrade head", shell=True, check=True, cwd=cwd)

    # seed db
    subprocess.run(f"docker compose -f {COMPOSE} exec -T api python scripts/seed_db.py", shell=True, check=True, cwd=cwd)

    yield

    # teardown
    subprocess.run(f"docker compose -f {COMPOSE} down --volumes --remove-orphans", shell=True, check=True, cwd=cwd)


def test_health_and_token(integration_stack):
    r = requests.get(f"{API_BASE}/health", timeout=5)
    assert r.status_code == 200
    # get token for seeded admin user
    resp = requests.post(f"{API_BASE}/auth/token", data={"username":"admin","password":"adminpass"}, timeout=10)
    assert resp.status_code == 200, resp.text
    tok = resp.json().get("access_token")
    assert tok, resp.text
    # basic predict (demo model seeded by seed_db)
    headers = {"Authorization": f"Bearer {tok}", "Content-Type": "application/json"}
    r = requests.post(f"{API_BASE}/v1/models/multimodal_demo/versions/v1/predict", json={"text":"hello"}, headers=headers, timeout=10)
    assert r.status_code in (200,404)  # if model_runner isn't wired to actual artifact, accept 404; primarily check auth+routing works


def test_enqueue_job_and_worker_processing(integration_stack):
    # obtain admin token
    resp = requests.post(f"{API_BASE}/auth/token", data={"username":"admin","password":"adminpass"}, timeout=10)
    tok = resp.json()["access_token"]
    headers = {"Authorization": f"Bearer {tok}", "Content-Type": "application/json"}
    # enqueue a job that the worker will process (work_units small)
    payload = {"work_units": 2, "parameters": {"test": True}}
    r = requests.post(f"{API_BASE}/v1/jobs", json=payload, headers=headers, timeout=10)
    assert r.status_code == 202, r.text
    data = r.json()
    request_id = data["request_id"]
    # poll job status until success or timeout
    for _ in range(30):
        r = requests.get(f"{API_BASE}/v1/jobs/{request_id}", headers=headers, timeout=10)
        assert r.status_code == 200
        s = r.json().get("status")
        if s in ("SUCCESS", "FAILED", "CANCELLED"):
            break
        time.sleep(1)
    assert s in ("SUCCESS", "FAILED")  # worker executed; we consider FAIL also meaningful (task run)
tests/integration/test_integration_stack.py
