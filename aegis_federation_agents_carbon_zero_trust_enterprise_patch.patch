*** Begin Patch
*** Add File:federated/flower_server.py
+#!/usr/bin/env python3
+"""
+Minimal Flower server scaffold for Federated Learning orchestration.
+This is a lightweight scaffold demonstrating how to run a Flower server inside a pod
+and how Argo can submit clients as jobs. Replace the model, strategy and persistence
+with your production RL/ML stack (PyTorch/TF checkpoints in S3).
+
+Usage (inside container):
+  python3 federated/flower_server.py --host 0.0.0.0 --port 8080 --rounds 3
+
+Notes:
+ - This script requires `flwr` (pip install flwr). In production, run a hardened server image.
+ - Secure aggregation and privacy-preserving aggregation should be integrated at the FL backend.
+"""
+import argparse
+import logging
+import tempfile
+import os
+
+def run_server(host, port, rounds):
+    try:
+        import flwr as fl
+    except Exception:
+        raise SystemExit("Install Flower (pip install flwr) in the server image")
+
+    logging.info("Starting Flower server (scaffold)")
+
+    # Minimal strategy placeholder: FedAvg (default)
+    strategy = fl.server.strategy.FedAvg(
+        fraction_fit=1.0,
+        fraction_evaluate=0.5,
+        min_fit_clients=1,
+        min_evaluate_clients=1,
+        min_available_clients=1,
+    )
+
+    fl.server.start_server(
+        server_address=f"{host}:{port}",
+        config=fl.server.ServerConfig(num_rounds=rounds),
+        strategy=strategy,
+    )
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--host", default="0.0.0.0")
+    p.add_argument("--port", type=int, default=8080)
+    p.add_argument("--rounds", type=int, default=3)
+    args = p.parse_args()
+    run_server(args.host, args.port, args.rounds)
+
*** End Patch
*** Begin Patch
*** Add File:federated/client_stub.py
+#!/usr/bin/env python3
+"""
+Federated client stub (Flower) to be run on edge or training nodes.
+It loads a local model, performs a local update, and returns weights to the server.
+
+Usage:
+  python3 federated/client_stub.py --server-address <host:port> --client-id id1
+"""
+import argparse, logging
+import os, time
+
+def run_client(server_address, client_id):
+    try:
+        import flwr as fl
+    except Exception:
+        raise SystemExit("Install Flower (pip install flwr) in client image")
+
+    # Minimal local model function for demo (no real training)
+    class NumPyClient(fl.client.NumPyClient):
+        def get_parameters(self):
+            import numpy as np
+            return [np.zeros((1,))]
+
+        def fit(self, parameters, config):
+            # Placeholder: perform a single-step "update"
+            return parameters, 1, {}
+
+        def evaluate(self, parameters, config):
+            return 0.0, 0, {}
+
+    client = NumPyClient()
+    fl.client.start_numpy_client(server_address=server_address, client=client)
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--server-address", required=True)
+    p.add_argument("--client-id", required=True)
+    args = p.parse_args()
+    run_client(args.server_address, args.client_id)
+
*** End Patch
*** Begin Patch
*** Add File:scripts/federated/onboard_client.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Onboard a federated client: register it in the registry and create a Vault secret entry for credentials.
+#
+CLIENT_ID=${1:?client id required}
+REGISTRY_URL=${REGISTRY_URL:-http://aegis-registry.aegis-core.svc:8080}
+VAULT_ADDR=${VAULT_ADDR:-https://vault.vault.svc:8200}
+
+echo "Registering federated client ${CLIENT_ID} in registry..."
+cat > /tmp/${CLIENT_ID}_meta.json <<JSON
+{"client_id":"${CLIENT_ID}","registered_at":$(date +%s)}
+JSON
+curl -s -X POST -H "Content-Type: application/json" -d @/tmp/${CLIENT_ID}_meta.json "${REGISTRY_URL}/api/clients" || true
+
+echo "Creating Vault secret (enrollment token) for client..."
+ENROLL_TOKEN="enroll-${CLIENT_ID}-$(date +%s)"
+vault kv put secret/aegis/federated/${CLIENT_ID} token=${ENROLL_TOKEN} || true
+echo "Client ${CLIENT_ID} onboarded. Enrollment token stored in Vault path secret/aegis/federated/${CLIENT_ID}"
+
*** End Patch
*** Begin Patch
*** Add File:federated/secure_aggregation_stub.py
+#!/usr/bin/env python3
+"""
+Secure aggregation stub for FL rounds.
+This is a placeholder showing where to integrate cryptographic secure aggregation
+(e.g., PySyft, CrypTen, or FedAvg with differential privacy).
+
+In production, replace this with a real secure aggregation implementation that:
+ - Accepts encrypted / masked updates from clients
+ - Performs aggregation without revealing individual updates
+ - Produces a signed aggregated update artifact and uploads to S3/Rekor
+"""
+import json, os
+
+def aggregate(updates_dir, out_path):
+    # Simple additive aggregation (NOT secure) as placeholder
+    import glob
+    import numpy as np
+    files = glob.glob(os.path.join(updates_dir, "*.json"))
+    if not files:
+        raise SystemExit("No client updates found")
+    sum_arr = None
+    for f in files:
+        j = json.load(open(f))
+        arr = np.array(j.get("weights", [0.0]))
+        if sum_arr is None:
+            sum_arr = arr
+        else:
+            sum_arr += arr
+    avg = (sum_arr / len(files)).tolist()
+    json.dump({"avg_weights": avg}, open(out_path, "w"), indent=2)
+    print("Wrote aggregated update to", out_path)
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--updates-dir", default="/tmp/updates")
+    p.add_argument("--out", default="/tmp/aggregate.json")
+    args = p.parse_args()
+    aggregate(args.updates_dir, args.out)
+
*** End Patch
*** Begin Patch
*** Add File:argo/federated/argo_flower_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: fl-federated-
+  namespace: aegis
+spec:
+  entrypoint: fl
+  templates:
+    - name: fl
+      dag:
+        tasks:
+          - name: start-server
+            template: server
+          - name: onboard-clients
+            template: onboard
+            dependencies: [start-server]
+          - name: run-clients
+            template: client
+            dependencies: [onboard-clients]
+          - name: aggregate
+            template: aggregator
+            dependencies: [run-clients]
+
+    - name: server
+      container:
+        image: ghcr.io/yourorg/federated-server:latest
+        command: ["python3","/opt/federated/flower_server.py","--host","0.0.0.0","--port","8080","--rounds","3"]
+        resources:
+          limits:
+            cpu: "500m"
+            memory: "512Mi"
+
+    - name: onboard
+      container:
+        image: bitnami/curl:latest
+        command: [sh, -c]
+        args:
+          - |
+            python3 /opt/scripts/onboard_client.py --count 3 || true
+
+    - name: client
+      container:
+        image: ghcr.io/yourorg/federated-client:latest
+        command: ["python3","/opt/federated/client_stub.py","--server-address","0.0.0.0:8080","--client-id","client-{{pod.name}}"]
+        resources:
+          limits:
+            cpu: "500m"
+            memory: "512Mi"
+
+    - name: aggregator
+      container:
+        image: ghcr.io/yourorg/federated-server:latest
+        command: ["python3","/opt/federated/secure_aggregation_stub.py","--updates-dir","/tmp/updates","--out","/tmp/aggregate.json"]
+        resources:
+          limits:
+            cpu: "200m"
+            memory: "256Mi"
+
*** End Patch
*** Begin Patch
*** Add File:agents/agent_executor.py
+#!/usr/bin/env python3
+"""
+Agent executor scaffold:
+ - Runs an agent loop: receives a prompt, optionally executes sandboxed tools, queries model (Triton/HF)
+ - Bundles evidence (inputs/outputs/tool traces), signs and uploads to evidence bucket
+
+Usage:
+  python3 agents/agent_executor.py --task '{"prompt":"Hello"}'
+
+In production this runs as a container in an Argo workflow (see argo/agents/agent_workflow.yaml).
+"""
+import argparse, json, os, subprocess, tempfile, time
+
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+COSIGN_KMS = os.environ.get("COSIGN_KMS_KEY_ARN", "")
+TRITON_URL = os.environ.get("TRITON_URL", "http://triton.aegis.svc:8000")
+
+def call_triton(model, prompt):
+    import requests
+    payload = {"inputs":[{"name":"input_ids","shape":[1,8],"datatype":"INT32","data":[[1,2,3,4,5,6,7,8]]}]}
+    r = requests.post(f"{TRITON_URL}/v2/models/{model}/infer", json=payload, timeout=30)
+    return {"status": r.status_code, "resp": r.text[:500]}
+
+def run_tool_sandbox(tool_cmd, timeout=5):
+    # Very small sandbox: run with timeout and capture stdout/stderr
+    try:
+        p = subprocess.run(tool_cmd, shell=True, capture_output=True, timeout=timeout)
+        return {"rc": p.returncode, "stdout": p.stdout.decode()[:1000], "stderr": p.stderr.decode()[:1000]}
+    except subprocess.TimeoutExpired:
+        return {"rc": -1, "error": "timeout"}
+
+def upload_evidence(local_path, s3_key):
+    if not EVIDENCE_BUCKET:
+        print("No EVIDENCE_BUCKET; skipping upload")
+        return
+    subprocess.run(["aws","s3","cp", local_path, f"s3://{EVIDENCE_BUCKET}/{s3_key}"], check=False)
+
+def sign_file(file_path):
+    if not COSIGN_KMS:
+        return
+    subprocess.run(["cosign","sign","--key",f"awskms://{COSIGN_KMS}", file_path], check=False)
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--task", required=True, help="JSON task description")
+    args = p.parse_args()
+    task = json.loads(args.task)
+    prompt = task.get("prompt","")
+    model = task.get("model","mymodel")
+    tools = task.get("tools",[])
+
+    evidence = {"prompt": prompt, "model": model, "tools": [], "start_ts": int(time.time())}
+    # call model
+    model_resp = call_triton(model, prompt)
+    evidence["model_resp"] = model_resp
+
+    # run tools if requested
+    for t in tools:
+        res = run_tool_sandbox(t.get("cmd","echo no-tool"))
+        evidence["tools"].append({"tool": t, "result": res})
+
+    evidence["end_ts"] = int(time.time())
+    tmp = tempfile.mkdtemp()
+    evidence_file = os.path.join(tmp,"evidence.json")
+    json.dump(evidence, open(evidence_file,"w"), indent=2)
+    if EVIDENCE_BUCKET:
+        s3key = f"agents/evidence/{os.path.basename(evidence_file)}"
+        upload_evidence(evidence_file, s3key)
+    sign_file(evidence_file)
+    print("Agent execution complete. Evidence:", evidence_file)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:argo/agents/agent_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: agent-exec-
+  namespace: aegis
+spec:
+  entrypoint: run-agent
+  templates:
+    - name: run-agent
+      inputs:
+        parameters:
+          - name: task-json
+      container:
+        image: ghcr.io/yourorg/aegis-agent:latest
+        command: ["python3"]
+        args: ["agents/agent_executor.py","--task","{{inputs.parameters.task-json}}"]
+        resources:
+          limits:
+            cpu: "500m"
+            memory: "1Gi"
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon_aware_submit.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Carbon-aware Argo submit wrapper (MVP)
+# - Queries a carbon intensity API (placeholder) and decides whether to submit now or schedule for off-peak
+# - If low-carbon, submits the given Argo workflow file; else delays until a low-carbon window
+#
+WORKFLOW_FILE=${1:?workflow yaml required}
+THRESHOLD=${CARBON_THRESHOLD:-100}  # example gCO2eq/kWh threshold
+REGION=${CARBON_REGION:-us-west-2}
+
+echo "Querying carbon intensity for region ${REGION} (placeholder)"
+# Placeholder API: integrate with real feed (e.g., https://api.co2signal.com/)
+INTENSITY=$(curl -s "https://api.co2signal.com/v1/latest?countryCode=US" -H "auth-token: ${CO2SIGNAL_API_KEY:-}" 2>/dev/null | jq -r '.data.carbonIntensity' || echo "999")
+echo "Current intensity: ${INTENSITY}"
+if [ "${INTENSITY}" = "null" ] || [ -z "${INTENSITY}" ]; then
+  INTENSITY=999
+fi
+
+if [ "${INTENSITY}" -le "${THRESHOLD}" ]; then
+  echo "Carbon intensity ${INTENSITY} <= ${THRESHOLD}: submitting workflow now"
+  argo submit "${WORKFLOW_FILE}" --watch || true
+else
+  echo "High-carbon window (${INTENSITY}). Scheduling submission in 1 hour (operator may adjust)"
+  sleep 3600
+  argo submit "${WORKFLOW_FILE}" --watch || true
+fi
+
*** End Patch
*** Begin Patch
*** Add File:argo/carbon/carbon_aware_job.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: carbon-job-
+  namespace: aegis
+spec:
+  entrypoint: carbon-task
+  templates:
+    - name: carbon-task
+      container:
+        image: ghcr.io/yourorg/aegis-task:latest
+        command: [sh, -c]
+        args: ["echo Running carbon-aware job; sleep 5"]
+        nodeSelector:
+          carbon_preference: low
+
*** End Patch
*** Begin Patch
*** Add File:opa/gatekeeper/constraints.yaml
+apiVersion: templates.gatekeeper.sh/v1
+kind: ConstraintTemplate
+metadata:
+  name: k8srequiredlabels
+spec:
+  crd:
+    spec:
+      names:
+        kind: K8sRequiredLabels
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package k8srequiredlabels
+        violation[{"msg": msg}] {
+          provided := {label | input.review.object.metadata.labels[label]}
+          required := {"owner", "team"}
+          missing := required - provided
+          count(missing) > 0
+          msg := sprintf("Missing required labels: %v", [missing])
+        }
+
+---
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: K8sRequiredLabels
+metadata:
+  name: ns-must-have-owner-team
+spec:
+  match:
+    kinds:
+      - apiGroups: [""]
+        kinds: ["Namespace"]
+  parameters: {}
+
*** End Patch
*** Begin Patch
*** Add File:attestation/continuous_attestor.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Continuous attestation: capture a cluster snapshot (pods/nodes), sign it with cosign (KMS) and upload to Rekor/evidence.
+#
+: "${EVIDENCE_BUCKET:?EVIDENCE_BUCKET required}"
+: "${COSIGN_KMS_KEY_ARN:?COSIGN_KMS_KEY_ARN required}"
+
+TS=$(date -u +"%Y%m%dT%H%M%SZ")
+OUT="/tmp/cluster_attestation_${TS}.json"
+
+echo "Collecting cluster state..."
+kubectl get pods --all-namespaces -o json > /tmp/pods_${TS}.json || true
+kubectl get nodes -o json > /tmp/nodes_${TS}.json || true
+python3 - <<PY
+import json
+pods = json.load(open("/tmp/pods_${TS}.json"))
+nodes = json.load(open("/tmp/nodes_${TS}.json"))
+report = {"ts":"${TS}","pods_count": len(pods.get("items",[])), "nodes_count": len(nodes.get("items",[]))}
+open("${OUT}","w").write(json.dumps(report, indent=2))
+PY
+
+echo "Signing attestation with cosign..."
+cosign sign --key "awskms://${COSIGN_KMS_KEY_ARN}" "${OUT}" || true
+echo "Uploading attestation to s3://${EVIDENCE_BUCKET}/attestations/$(basename ${OUT})"
+aws s3 cp "${OUT}" "s3://${EVIDENCE_BUCKET}/attestations/$(basename ${OUT})" || true
+echo "Attestation uploaded."
+
*** End Patch
*** Begin Patch
*** Add File:prod/automation/run_readiness_and_sign.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run a set of readiness checks and produce a signed readiness report uploaded to evidence bucket.
+#
+: "${EVIDENCE_BUCKET:?EVIDENCE_BUCKET required}"
+: "${COSIGN_KMS_KEY_ARN:?COSIGN_KMS_KEY_ARN required}"
+
+TS=$(date -u +"%Y%m%dT%H%M%SZ")
+OUT="/tmp/aegis_readiness_${TS}.json"
+
+echo "Running readiness checks..."
+python3 - <<PY
+import json, subprocess, time
+checks = {}
+def run(cmd):
+    try:
+        out = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT, timeout=60)
+        return {"ok": True, "out": out.decode()[:1000]}
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+checks["kubectl_version"] = run("kubectl version --client --short")
+checks["prometheus_health"] = run("curl -sS http://prometheus.aegis.svc:9090/-/healthy || true")
+checks["triton_metrics"] = run("curl -sS http://triton.aegis.svc:8002/metrics || true")
+checks["registry_health"] = run("curl -sS http://aegis-registry.aegis-core.svc:8080/health || true")
+checks["evidence_bucket"] = run("aws s3 ls s3://${EVIDENCE_BUCKET} || true")
+report = {"ts": int(time.time()), "checks": checks}
+open("${OUT}","w").write(json.dumps(report, indent=2))
+print("Wrote readiness report to ${OUT}")
+PY
+
+echo "Signing report..."
+cosign sign --key "awskms://${COSIGN_KMS_KEY_ARN}" "${OUT}" || true
+echo "Uploading signed report..."
+aws s3 cp "${OUT}" "s3://${EVIDENCE_BUCKET}/readiness/$(basename ${OUT})" || true
+echo "Readiness report uploaded: s3://${EVIDENCE_BUCKET}/readiness/$(basename ${OUT})"
+
*** End Patch
*** Begin Patch
*** Add File:docs/runbooks/README_ACTIONS.md
+# Runbook: Actions to Close Remaining Gaps
+
+This document maps scripts and manifests in the repo to operator actions to harden Aegis.
+- Run federated onboarding and Flower scaffolds: federated/* and argo/federated/*
+- Deploy agent runtime and Argo agent workflows: agents/* and argo/agents/*
+- Use carbon-aware submit wrapper: scheduler/carbon_aware_submit.sh
+- Enable service mesh mTLS: ops/mesh/install_linkerd.sh and annotate namespaces
+- Enforce Gatekeeper constraints after review: opa/gatekeeper/enforce_constraints.sh
+- Run continuous attestation: attestation/continuous_attestor.sh (schedule as CronJob)
+- Produce readiness signed report: prod/automation/run_readiness_and_sign.sh
+
+Follow the scripts in order, review outputs and upload artifacts to evidence bucket for audit.
+
*** End Patch
*** End Patch
