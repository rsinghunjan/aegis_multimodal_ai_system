*** Begin Patch
*** Add File:graph/gnn_preprocess_and_train.py
+#!/usr/bin/env python3
+"""
+Graph ML training example (GCN) using PyTorch Geometric if available,
+with a fallback synthetic pipeline if PyG is not installed.
+
+Outputs:
+ - trained model artifact to /tmp/gnn_model.pt
+ - graph dataset artifact to /tmp/graph_features.parquet (for registry / serving)
+ - MLflow logging integration (if MLFLOW_TRACKING_URI set)
+"""
+import os
+import sys
+import numpy as np
+
+MLFLOW = os.environ.get("MLFLOW_TRACKING_URI")
+if MLFLOW:
+    import mlflow
+    mlflow.set_tracking_uri(MLFLOW)
+
+try:
+    import torch
+    from torch_geometric.nn import GCNConv, global_mean_pool
+    from torch_geometric.data import Data, DataLoader
+    PYG_AVAILABLE = True
+except Exception:
+    PYG_AVAILABLE = False
+
+import pandas as pd
+
+def synthetic_graph():
+    # create synthetic graph dataset
+    import networkx as nx
+    G = nx.erdos_renyi_graph(300, 0.02, seed=42)
+    # node features: degree + random
+    feats = []
+    labels = []
+    for n in G.nodes():
+        deg = G.degree[n]
+        feats.append([deg, np.random.rand()])
+        labels.append(0 if deg < 3 else 1)
+    X = np.array(feats)
+    y = np.array(labels)
+    edges = np.array(list(G.edges())).T
+    return X, y, edges
+
+def train_pyg():
+    import torch.nn.functional as F
+    class GCN(torch.nn.Module):
+        def __init__(self, in_channels, hid, num_classes):
+            super().__init__()
+            self.conv1 = GCNConv(in_channels, hid)
+            self.conv2 = GCNConv(hid, hid)
+            self.lin = torch.nn.Linear(hid, num_classes)
+        def forward(self, x, edge_index, batch=None):
+            x = self.conv1(x, edge_index).relu()
+            x = self.conv2(x, edge_index).relu()
+            x = global_mean_pool(x, batch) if batch is not None else x
+            return self.lin(x)
+
+    X,y,edges = synthetic_graph()
+    # create PyG Data list (we will use single graph split for demo)
+    x = torch.tensor(X, dtype=torch.float)
+    edge_index = torch.tensor(edges, dtype=torch.long)
+    data = Data(x=x, edge_index=edge_index, y=torch.tensor(y, dtype=torch.long))
+    # simple per-node supervised demo: use small GCN to predict node label
+    model = GCN(in_channels=X.shape[1], hid=32, num_classes=2)
+    opt = torch.optim.Adam(model.parameters(), lr=1e-3)
+    model.train()
+    for epoch in range(50):
+        opt.zero_grad()
+        out = model(data.x, data.edge_index)
+        # if out is per-graph, reshape; here keep simple: treat out shape equal nodes
+        if out.shape[0] != data.y.shape[0]:
+            out = out.repeat(data.y.shape[0],1)[:data.y.shape[0]]
+        loss = F.cross_entropy(out, data.y)
+        loss.backward(); opt.step()
+    torch.save(model.state_dict(), "/tmp/gnn_model.pt")
+    print("Saved /tmp/gnn_model.pt")
+    # write simple node features to parquet for downstream use
+    df = pd.DataFrame(X, columns=[f"x{i}" for i in range(X.shape[1])])
+    df["label"] = y
+    df.to_parquet("/tmp/graph_features.parquet")
+    print("Wrote /tmp/graph_features.parquet")
+    if MLFLOW:
+        with mlflow.start_run() as run:
+            mlflow.log_artifact("/tmp/gnn_model.pt", artifact_path="model")
+            mlflow.log_artifact("/tmp/graph_features.parquet", artifact_path="data")
+
+def fallback_train():
+    # simple node classification with sklearn on aggregated features
+    X,y,edges = synthetic_graph()
+    from sklearn.ensemble import RandomForestClassifier
+    clf = RandomForestClassifier(n_estimators=50)
+    clf.fit(X, y)
+    import joblib
+    joblib.dump(clf, "/tmp/gnn_model.pt")
+    df = pd.DataFrame(X, columns=[f"x{i}" for i in range(X.shape[1])])
+    df["label"] = y
+    df.to_parquet("/tmp/graph_features.parquet")
+    print("Saved fallback model and features")
+    if MLFLOW:
+        with mlflow.start_run() as run:
+            mlflow.log_artifact("/tmp/gnn_model.pt", artifact_path="model")
+            mlflow.log_artifact("/tmp/graph_features.parquet", artifact_path="data")
+
+def main():
+    if PYG_AVAILABLE:
+        train_pyg()
+    else:
+        print("PyG unavailable, running fallback sklearn trainer")
+        fallback_train()
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:graph/README.md
+# Graph ML (GNN) scaffolds
+
+Files:
+- gnn_preprocess_and_train.py â€” trains a simple GCN (if PyG installed) or fallback RandomForest on synthetic data; writes model and features artifacts.
+
+How to use:
+- Install dependencies: torch, torch_geometric (optional), scikit-learn, mlflow
+- Run: python graph/gnn_preprocess_and_train.py
+- Replace synthetic data generation with lakeFS/S3 graph dataset loader for production.
+
+Notes:
+- For production graph storage consider using Neptune/JanusGraph/DGL data storage patterns and persist adjacency+features in Parquet for replay.
+
*** End Patch
*** Begin Patch
*** Add File:multimodal/preprocess_multimodal.py
+#!/usr/bin/env python3
+"""
+Multimodal preprocessing: align image and text inputs into a unified Parquet file for training.
+ - Reads images from an S3 prefix (or local folder) and text from CSV/Parquet.
+ - Extracts image embeddings via a torchvision backbone (ResNet18) and text embeddings via HuggingFace tokenizer+model.
+ - Outputs a combined Parquet with columns: id, image_emb_*, text_emb_*, label
+"""
+import os, sys
+import numpy as np
+import pandas as pd
+import torch
+from PIL import Image
+
+MLFLOW = os.environ.get("MLFLOW_TRACKING_URI")
+if MLFLOW:
+    import mlflow; mlflow.set_tracking_uri(MLFLOW)
+
+def image_embed(image_path, model, transform):
+    img = Image.open(image_path).convert("RGB")
+    x = transform(img).unsqueeze(0)
+    with torch.no_grad():
+        emb = model(x).squeeze(0).numpy()
+    return emb
+
+def text_embed(texts, tokenizer, model):
+    enc = tokenizer(texts, truncation=True, padding=True, return_tensors="pt")
+    with torch.no_grad():
+        out = model(**enc)
+    # use CLS/pooled output if available
+    if hasattr(out, "pooler_output"):
+        emb = out.pooler_output.numpy()
+    else:
+        emb = out.last_hidden_state[:,0,:].numpy()
+    return emb
+
+def main():
+    # simple config via env
+    IMAGE_DIR = os.environ.get("IMAGE_DIR", "data/images")
+    TEXT_FILE = os.environ.get("TEXT_FILE", "data/text.csv")
+    OUT = os.environ.get("OUT", "/tmp/multimodal_dataset.parquet")
+
+    # load lightweight torchvision model
+    import torchvision.transforms as T
+    import torchvision.models as models
+    resnet = models.resnet18(pretrained=True)
+    resnet.fc = torch.nn.Identity()
+    resnet.eval()
+    transform = T.Compose([T.Resize((224,224)), T.ToTensor(), T.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])])
+
+    # tokenizer & model (distilbert for speed)
+    from transformers import AutoTokenizer, AutoModel
+    tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
+    text_model = AutoModel.from_pretrained("distilbert-base-uncased")
+    text_model.eval()
+
+    # read text file with id,text,label
+    df_text = pd.read_csv(TEXT_FILE) if os.path.exists(TEXT_FILE) else pd.DataFrame(columns=["id","text","label"])
+    rows = []
+    for _, r in df_text.iterrows():
+        id = r["id"]
+        text = r["text"]
+        label = r.get("label", None)
+        img_path = os.path.join(IMAGE_DIR, f"{id}.jpg")
+        if not os.path.exists(img_path):
+            continue
+        img_emb = image_embed(img_path, resnet, transform)
+        txt_emb = text_embed([text], tokenizer, text_model)[0]
+        rec = {}
+        for i,v in enumerate(img_emb): rec[f"img_emb_{i}"] = float(v)
+        for i,v in enumerate(txt_emb): rec[f"txt_emb_{i}"] = float(v)
+        rec["id"] = id; rec["label"] = label
+        rows.append(rec)
+    if rows:
+        outdf = pd.DataFrame(rows)
+        outdf.to_parquet(OUT, index=False)
+        print("Wrote", OUT)
+        if MLFLOW:
+            with mlflow.start_run(): mlflow.log_artifact(OUT, artifact_path="data")
+    else:
+        print("No multimodal records processed.")
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:seq2seq/train_seq2seq.py
+#!/usr/bin/env python3
+"""
+Seq2Seq training example using Hugging Face Transformers (T5 small).
+ - Fine-tunes on a simple dataset (placeholder)
+ - Logs model and metrics to MLflow
+"""
+import os
+MLFLOW = os.environ.get("MLFLOW_TRACKING_URI")
+if MLFLOW:
+    import mlflow; mlflow.set_tracking_uri(MLFLOW)
+
+from datasets import load_dataset
+from transformers import T5ForConditionalGeneration, T5TokenizerFast, Trainer, TrainingArguments
+
+def main():
+    model_name = "t5-small"
+    dataset = load_dataset("xsum") if False else None
+    # For demo, we use a tiny synthetic dataset to avoid heavy downloads
+    train_texts = ["translate English to French: Hello world", "summarize: This is a test"]
+    train_labels = ["Bonjour le monde", "Test summary"]
+    tokenizer = T5TokenizerFast.from_pretrained(model_name)
+    model = T5ForConditionalGeneration.from_pretrained(model_name)
+    enc = tokenizer(train_texts, truncation=True, padding=True, return_tensors="pt")
+    labels = tokenizer(train_labels, truncation=True, padding=True, return_tensors="pt")["input_ids"]
+    # convert to dataset object minimal
+    class TinyDataset:
+        def __len__(self): return len(train_texts)
+        def __getitem__(self,i): return {"input_ids": enc["input_ids"][i], "attention_mask": enc["attention_mask"][i], "labels": labels[i]}
+    train_ds = TinyDataset()
+    args = TrainingArguments(output_dir="/tmp/t5_out", per_device_train_batch_size=1, num_train_epochs=1, logging_steps=1)
+    trainer = Trainer(model=model, args=args, train_dataset=train_ds)
+    trainer.train()
+    model.save_pretrained("/tmp/t5_model")
+    print("Saved /tmp/t5_model")
+    if MLFLOW:
+        with mlflow.start_run():
+            mlflow.log_artifact("/tmp/t5_model", artifact_path="model")
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:rag/milvus_statefulset.yaml
+apiVersion: apps/v1
+kind: StatefulSet
+metadata:
+  name: milvus
+  namespace: aegis
+spec:
+  replicas: 2
+  serviceName: milvus
+  selector:
+    matchLabels:
+      app: milvus
+  template:
+    metadata:
+      labels:
+        app: milvus
+    spec:
+      containers:
+        - name: milvus
+          image: milvusdb/milvus:v2.2.6
+          ports:
+            - containerPort: 19530
+            - containerPort: 19121
+          env:
+            - name: MINIO_ADDRESS
+              value: "minio.aegis.svc.cluster.local:9000"
+          readinessProbe:
+            tcpSocket:
+              port: 19530
+            initialDelaySeconds: 15
+            periodSeconds: 10
+          resources:
+            requests:
+              memory: "2Gi"
+              cpu: "500m"
+            limits:
+              memory: "8Gi"
+              cpu: "2000m"
+  volumeClaimTemplates:
+    - metadata:
+        name: milvus-data
+      spec:
+        accessModes: ["ReadWriteOnce"]
+        resources:
+          requests:
+            storage: 200Gi
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: milvus
+  namespace: aegis
+spec:
+  selector:
+    app: milvus
+  ports:
+    - port: 19530
+      targetPort: 19530
+
+# Note: In production prefer official Milvus Helm chart with external storage and MinIO/S3 for persistence.
*** End Patch
*** Begin Patch
*** Add File:rag/milvus_backup_cronjob.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: milvus-backup
+  namespace: aegis
+spec:
+  schedule: "0 2 * * *"
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          containers:
+            - name: milvus-backup
+              image: ghcr.io/yourorg/aegis-milvus-tools:latest
+              command: ["sh","-c"]
+              args:
+                - |
+                  # placeholder backup commands; use milvusctl or minio/s3 copy of snapshot
+                  echo "Starting milvus backup..."
+                  # TODO: call milvus backup API or snapshot TTL
+                  exit 0
+          restartPolicy: OnFailure
+
*** End Patch
*** Begin Patch
*** Add File:rag/faiss_build_and_upload.py
+#!/usr/bin/env python3
+"""
+Build a FAISS vector index from embeddings stored in parquet (S3/lakeFS),
+persist index to local file and upload to S3 (or lakeFS) for serving.
+"""
+import os
+import numpy as np
+import pandas as pd
+import faiss
+import boto3
+
+S3_BUCKET = os.environ.get("EVIDENCE_BUCKET")
+EMB_PATH = os.environ.get("EMB_PATH", "/tmp/embeddings.parquet")
+OUT_INDEX = "/tmp/faiss.index"
+
+def load_embeddings(path):
+    # path can be s3://bucket/key or local; for demo, assume local parquet
+    df = pd.read_parquet(path)
+    # assume embedding columns prefixed with emb_
+    emb_cols = [c for c in df.columns if c.startswith("emb_")]
+    X = df[emb_cols].values.astype('float32')
+    return X
+
+def build_index(X, nlist=100):
+    d = X.shape[1]
+    quantizer = faiss.IndexFlatL2(d)
+    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)
+    index.train(X)
+    index.add(X)
+    faiss.write_index(index, OUT_INDEX)
+    return OUT_INDEX
+
+def upload_index(index_path, s3_bucket, s3_key):
+    s3 = boto3.client("s3")
+    s3.upload_file(index_path, s3_bucket, s3_key)
+    print(f"Uploaded index to s3://{s3_bucket}/{s3_key}")
+
+def main():
+    X = load_embeddings(EMB_PATH)
+    idx = build_index(X)
+    if S3_BUCKET:
+        upload_index(idx, S3_BUCKET, "milvus/faiss/indexes/faiss.index")
+    else:
+        print("No S3 bucket configured; index stored at", idx)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:federated/flower_server.py
+#!/usr/bin/env python3
+"""
+Flower (flwr) federated learning server scaffold.
+Operators should deploy this as a k8s Deployment (or use hosted FL infra).
+Clients (see federated/flower_client.py) will connect and perform local updates.
+This server uses default strategy; replace with secure aggregation strategy as needed.
+"""
+import flwr as fl
+import argparse
+
+def main():
+    parser = argparse.ArgumentParser()
+    parser.add_argument("--host", default="0.0.0.0")
+    parser.add_argument("--port", type=int, default=8080)
+    args = parser.parse_args()
+    # simple strategy with aggregation rounds
+    strategy = fl.server.strategy.FedAvg(min_fit_clients=2, min_available_clients=2)
+    fl.server.start_server(server_address=f"{args.host}:{args.port}", config=fl.server.ServerConfig(num_rounds=3), strategy=strategy)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:federated/flower_client.py
+#!/usr/bin/env python3
+"""
+Flower client example that trains a local sklearn model on local data and communicates with the server.
+Intended for demo; replace with your training loop & secure aggregation.
+"""
+import flwr as fl
+from sklearn.ensemble import RandomForestClassifier
+import numpy as np
+import argparse
+
+class SklearnClient(fl.client.NumPyClient):
+    def __init__(self, X, y):
+        self.model = RandomForestClassifier(n_estimators=10)
+        self.X = X; self.y = y
+    def get_parameters(self):
+        # return model parameters (placeholder: trees not supported); use sklearn-to-numpy conversion if desired
+        return []
+    def fit(self, parameters, config):
+        self.model.fit(self.X, self.y)
+        return [], len(self.X), {}
+    def evaluate(self, parameters, config):
+        return 0.0, len(self.X), {}
+
+def main():
+    X = np.random.randn(100,5)
+    y = (np.random.rand(100)>0.5).astype(int)
+    client = SklearnClient(X,y)
+    fl.client.start_numpy_client(server_address="localhost:8080", client=client)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:causal/uplift_two_model.py
+#!/usr/bin/env python3
+"""
+Two-model uplift example (treatment/control models).
+Trains two separate models on treated and control groups and computes uplift score.
+Logs results to MLflow if configured.
+"""
+import os
+import pandas as pd
+from sklearn.ensemble import GradientBoostingClassifier
+from sklearn.model_selection import train_test_split
+from sklearn.metrics import roc_auc_score
+
+MLFLOW = os.environ.get("MLFLOW_TRACKING_URI")
+if MLFLOW:
+    import mlflow; mlflow.set_tracking_uri(MLFLOW)
+
+def generate_synthetic(n=2000):
+    import numpy as np
+    X = np.random.randn(n, 10)
+    treatment = (np.random.rand(n) > 0.5).astype(int)
+    # outcome depends on X and treatment effect
+    base = (X[:,0] + X[:,1]*0.5 + np.random.randn(n)*0.1) > 0
+    uplift = (X[:,2] > 0) & (treatment==1)
+    y = (base | uplift).astype(int)
+    df = pd.DataFrame(X, columns=[f"x{i}" for i in range(X.shape[1])])
+    df["treatment"] = treatment
+    df["y"] = y
+    return df
+
+def train_two_model(df):
+    treated = df[df["treatment"]==1]
+    control = df[df["treatment"]==0]
+    features = [c for c in df.columns if c.startswith("x")]
+    X_t, y_t = treated[features].values, treated["y"].values
+    X_c, y_c = control[features].values, control["y"].values
+    m_t = GradientBoostingClassifier()
+    m_c = GradientBoostingClassifier()
+    m_t.fit(X_t, y_t)
+    m_c.fit(X_c, y_c)
+    # evaluate uplift on a validation set (random split for demo)
+    val = df.sample(frac=0.2)
+    xt = val[features].values
+    p_t = m_t.predict_proba(xt)[:,1]
+    p_c = m_c.predict_proba(xt)[:,1]
+    uplift = p_t - p_c
+    auc = roc_auc_score((val["y"]).astype(int), uplift.clip(0,1))
+    print("Uplift proxy AUC:", auc)
+    if MLFLOW:
+        with mlflow.start_run():
+            mlflow.log_metric("uplift_auc", float(auc))
+    # persist models
+    import joblib
+    joblib.dump(m_t, "/tmp/model_treated.joblib")
+    joblib.dump(m_c, "/tmp/model_control.joblib")
+    print("Saved models to /tmp")
+
+def main():
+    df = generate_synthetic()
+    train_two_model(df)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:README_graph_multimodal_rag_fed_causal.md
+# Graph / Multimodal / RAG / Federated / Causal capabilities for Aegis
+
+This patch adds scaffolding and example implementations for:
+- Graph ML (GNN) training and feature export (graph/gnn_preprocess_and_train.py)
+- Multimodal preprocessing (image + text) producing embeddings for training (multimodal/preprocess_multimodal.py)
+- Seq2Seq training demo (seq2seq/train_seq2seq.py)
+- RAG / vector index production:
+  - Milvus StatefulSet (rag/milvus_statefulset.yaml)
+  - Milvus backup CronJob scaffold (rag/milvus_backup_cronjob.yaml)
+  - FAISS index builder and uploader (rag/faiss_build_and_upload.py)
+- Federated learning scaffold using Flower:
+  - federated/flower_server.py
+  - federated/flower_client.py
+- Causal / uplift modeling scaffold:
+  - causal/uplift_two_model.py
+
+Operator notes:
+- These are scaffolds and examples. Replace placeholders and integrate with your lakeFS/S3, MLflow and Kubernetes secrets.
+- For Milvus, prefer the official Helm chart with object storage configured for persistence (S3/MinIO) and finalized resource sizing.
+- Federated learning requires network topology and secure aggregation; implement authentication and rate limiting for clients.
+- Causal/inference productionization requires careful covariate balance checks, logging, and legal review for decisioning systems.
+
*** End Patch
*** End Patch
