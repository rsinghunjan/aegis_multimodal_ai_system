*** Begin Patch
*** Add File: provider/onboarding/PROVIDER_CONTRACT_FINAL_TEMPLATE.md
+## Provider Energy Feed & Attestation Contract (Aegis - Final Template)
+
+This template is intended for procurement/legal to finalize a contract with an energy data provider.
+Operators must adapt legal language, but these are the required technical and SLA terms.
+
+1. Definitions
+- "Attestation": signed JSON blob containing fields provider_id, region, period_start, period_end, energy_kwh, method, metadata.
+
+2. Data Format & Delivery
+- JSON schema required: provider_id, region, period_start, period_end, energy_kwh (number), method ("metered"|"estimated"), metadata (object).
+- Delivery methods (pick one or both):
+  - S3: s3://<bucket>/<provider>/YYYY/MM/DD/HH/<attestation.json>
+  - HTTPS: POST to https://<operator-ingest>/provider-attestations with mutual TLS
+- Time requirement: each attestation for period (t, t+1h) must be available within 5 minutes after period_end.
+
+3. Signing & Proof
+- Each attestation MUST be signed using sigstore/cosign and a Rekor entry must be created for the artifact.
+- Provider will publish the public verification key and Rekor entries are to be accessible to operator.
+- Public key rotation: provider must provide at least 30 days prior notice and a rotation plan.
+
+4. SLAs & Penalties
+- Availability: 99.9% monthly uptime.
+- Freshness: max_age_minutes = 15 for hourly attestations.
+- Latency: attestations must be uploaded within 5 minutes of period_end.
+- Penalties: defined per contract (e.g., credits for missed attestations, step remediation).
+
+5. Security & Access
+- Provider will NOT upload private keys to operator systems.
+- Operator and provider will exchange public keys via secure OOB channel.
+- Provider must maintain logs of meter reads for 90 days and provide them to operator upon audit request.
+
+6. Audit & Reconciliation
+- Monthly reconciliation reports are required; provider will respond to reconciliation queries within 7 business days.
+- Provider agrees to periodic third-party verification on request (audit scope to be defined).
+
+7. Incident response
+- Provider will designate 24x7 contact for outages; initial response within 60 minutes of incident report.
+
+8. Termination & Data retention
+- On termination, provider will keep logs per data retention clause and provide a final signed attestation dump for operator archival.
+
+Operator note:
+- Pair this contract with the technical onboarding package produced (sample attestations, ingestion tests, Rekor verification steps).
+
*** End Patch
*** Begin Patch
*** Add File: provider/onboarding/onboarding_runbook.md
+## Provider Onboarding Runbook (Operator)
+
+Purpose: step-by-step operator actions to onboard a provider to Aegis attestation ingestion.
+
+1) Pre-contract
+ - Provide provider with PROVIDER_CONTRACT_FINAL_TEMPLATE.md and technical sample (provider_attestation_example.json).
+ - Agree on delivery method (S3 or HTTPS) and signing (cosign + Rekor).
+
+2) Technical test (provider)
+ - Provider: sign sample attestation via cosign, push artifact and signature to agreed S3 path.
+ - Provider: publish Rekor entry (rekor-cli upload).
+
+3) Operator validation
+ - Run provider/onboarding/ingestion_test.py against ingestion endpoint.
+ - Run provider/onboarding/reconcile_attestation_with_ledger.py for test attestation ID.
+ - Verify Rekor via rekor-cli search.
+
+4) SLA monitoring
+ - Add provider to trusted-source registry (use provider/auto_onboard.py)
+ - Configure attestation_validation_service.py to monitor freshness and signature validity.
+
+5) Pilot & GO/NO-GO
+ - Run a 2-week pilot: reconcile provider attestations with measured jobs daily.
+ - If discrepancies above agreed tolerance, require remediation and root cause.
+
+6) Production
+ - Mark provider trusted in registry; enable provider attestations as authoritative source in snapshot_service and reconciliation flows.
+
*** End Patch
*** Begin Patch
*** Add File: measurement/fleet_ansible_provision.yml
+- name: Deploy PDU exporters and register devices
+  hosts: edge-nodes
+  become: yes
+  vars:
+    device_list: /opt/aegis/devices.csv
+  tasks:
+    - name: Ensure exporter binary present
+      copy:
+        src: files/pdu_exporter
+        dest: /usr/local/bin/aegis_pdu_exporter
+        mode: '0755'
+
+    - name: Create systemd unit for exporter
+      copy:
+        dest: /etc/systemd/system/aegis-pdu-exporter.service
+        content: |
+          [Unit]
+          Description=Aegis PDU Exporter
+          After=network.target
+          [Service]
+          ExecStart=/usr/local/bin/aegis_pdu_exporter --device {{ inventory_hostname }} --mapping-file=/etc/aegis/device_mapping.json --interval=15
+          Restart=always
+          [Install]
+          WantedBy=multi-user.target
+
+    - name: Ensure mapping directory exists
+      file:
+        path: /etc/aegis
+        state: directory
+
+    - name: Start exporter
+      systemd:
+        name: aegis-pdu-exporter
+        state: started
+        enabled: true
+
+    - name: Register device via provisioning API (one-time)
+      uri:
+        url: "http://device-provisioning.aegis.svc:8130/provision"
+        method: POST
+        body_format: json
+        body:
+          device_id: "{{ inventory_hostname }}"
+          node: "{{ inventory_hostname }}"
+          ipmi_host: "{{ hostvars[inventory_hostname].ansible_default_ipv4.address | default('') }}"
+          rack: "rack-unknown"
+        status_code: 200
+
*** End Patch
*** Begin Patch
*** Add File: measurement/reconciliation_enhanced.py
+#!/usr/bin/env python3
+"""
+Improved reconciliation linking provider attestations to measured job kWh and computing bias/error bounds.
+Outputs JSON report and CSV summary for auditors.
+"""
+import os, json, csv
+from sqlalchemy import create_engine, text
+from datetime import datetime, timedelta
+import statistics
+
+DB_URL = os.environ.get("DATABASE_URL", "postgresql://aegis:aegis@localhost:5432/aegis")
+engine = create_engine(DB_URL)
+OUT_JSON = f"/tmp/reconciliation_report_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+OUT_CSV = f"/tmp/reconciliation_report_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.csv"
+
+def run(window_days=30):
+    with engine.connect() as conn:
+        attestations = conn.execute(text("SELECT id, provider, s3_key, metadata->'raw' as raw FROM provider_attestations WHERE created_at >= :since"), {"since": datetime.utcnow()-timedelta(days=window_days)}).fetchall()
+        rows = []
+        diffs=[]
+        for a in attestations:
+            raw = a.raw or {}
+            ps = raw.get("period_start"); pe = raw.get("period_end")
+            att_kwh = raw.get("energy_kwh") or 0.0
+            if not ps or not pe:
+                continue
+            measured = conn.execute(text("SELECT SUM((payload->>'kwh')::float) as kwh FROM job_events WHERE event='measured' AND ts >= :ps AND ts <= :pe"), {"ps": ps, "pe": pe}).scalar() or 0.0
+            diff = att_kwh - measured
+            diffs.append(diff)
+            rows.append({"attestation_id": a.id, "provider": a.provider, "att_kwh": att_kwh, "measured_kwh": measured, "diff_kwh": diff})
+    # summary
+    bias = statistics.mean(diffs) if diffs else None
+    stdev = statistics.pstdev(diffs) if len(diffs)>1 else None
+    report = {"ts": datetime.utcnow().isoformat(), "samples": len(diffs), "bias_kwh": bias, "stdev_kwh": stdev, "rows": rows}
+    open(OUT_JSON,"w").write(json.dumps(report, indent=2))
+    with open(OUT_CSV,"w", newline="") as fh:
+        w = csv.DictWriter(fh, fieldnames=["attestation_id","provider","att_kwh","measured_kwh","diff_kwh"])
+        w.writeheader()
+        for r in rows:
+            w.writerow(r)
+    print("Wrote", OUT_JSON, OUT_CSV)
+
+if __name__=="__main__":
+    run()
+
*** End Patch
*** Begin Patch
*** Add File: forecast/pi_calibrator.py
+#!/usr/bin/env python3
+"""
+Calibrate predictive interval width for Prophet forecasts.
+ - Uses sliding backtests to compute empirical PI coverage and scales interval width to target coverage.
+ - Stores calibration multiplier to model_registry or a local JSON.
+"""
+import os, json
+from forecast.backtest_calibrate import load_series, sliding_backtest
+from forecast.model_registry import register_model
+from datetime import datetime
+
+CAL_FILE = "/etc/aegis/forecast_pi_calibration.json"
+TARGET_COVERAGE = float(os.environ.get("PI_TARGET_COVERAGE", "0.9"))
+
+def calibrate(region):
+    df = load_series(region)
+    if df.empty:
+        print("no history"); return
+    metrics = sliding_backtest(df)
+    coverages = [m['pi_coverage'] for m in metrics if m.get('pi_coverage') is not None]
+    if not coverages:
+        print("no coverage data"); return
+    emp_cov = sum(coverages)/len(coverages)
+    multiplier = 1.0
+    if emp_cov < TARGET_COVERAGE:
+        multiplier = TARGET_COVERAGE / emp_cov
+    calib = {"region": region, "empirical_coverage": emp_cov, "target": TARGET_COVERAGE, "multiplier": multiplier, "ts": datetime.utcnow().isoformat()}
+    os.makedirs(os.path.dirname(CAL_FILE), exist_ok=True)
+    open(CAL_FILE,"w").write(json.dumps(calib, indent=2))
+    print("Wrote calibration", CAL_FILE)
+    return calib
+
+if __name__=="__main__":
+    import argparse
+    p=argparse.ArgumentParser()
+    p.add_argument("--region", default="US")
+    args=p.parse_args()
+    calibrate(args.region)
+
*** End Patch
*** Begin Patch
*** Add File: forecast/auto_rollback_controller.py
+#!/usr/bin/env python3
+"""
+Monitor live MAE in compliance bucket and automatically rollback to previous model via model_registry if degradation exceeds threshold.
+Intended to run as a Kubernetes CronJob or operator.
+"""
+import os, json
+from forecast.model_registry import list_models, rollback_to
+import boto3
+from datetime import datetime
+
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+REGION = os.environ.get("REGION","US")
+MAE_MULTIPLIER = float(os.environ.get("MAE_ROLLBACK_MULTIPLIER","1.2"))
+
+def fetch_latest_monitor():
+    s3=boto3.client("s3")
+    key = f"forecast_monitor/prophet_monitor_{REGION}.json"
+    tmp=f"/tmp/prophet_monitor_{REGION}.json"
+    try:
+        s3.download_file(COMPLIANCE_BUCKET, key, tmp)
+        return json.load(open(tmp))
+    except Exception:
+        return None
+
+def main():
+    monitor = fetch_latest_monitor()
+    if not monitor:
+        print("No monitor data")
+        return
+    mae = monitor.get("mae")
+    if mae is None:
+        print("No mae in monitor")
+        return
+    models = list_models(REGION)
+    if len(models) < 2:
+        print("Not enough models to consider rollback")
+        return
+    active = models[0]; previous = models[1]
+    try:
+        active_mae = float(active.get("mae") or 0.0)
+        prev_mae = float(previous.get("mae") or 0.0)
+    except Exception:
+        print("MAE missing"); return
+    print("active_mae", active_mae, "prev_mae", prev_mae, "live_mae", mae)
+    if mae > prev_mae * MAE_MULTIPLIER:
+        print("Triggering rollback to model", previous.get("id"))
+        rollback_to(previous.get("id"))
+    else:
+        print("No rollback required")
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: hsm/recovery_test.py
+#!/usr/bin/env python3
+"""
+Simulate HSM failure and validate recovery:
+ - For each HSM host, run a sign test; simulate a host failure by skipping one host and verifying remaining HSMs can sign sample artifact.
+ - Produce a JSON report for auditors.
+"""
+import os, subprocess, json, boto3
+from datetime import datetime
+
+HOSTS = [h for h in os.environ.get("HSM_ADMIN_HOSTS","").split(",") if h]
+SAMPLE_ART = os.environ.get("HSM_SAMPLE_ART","/opt/aegis/sample_snapshot.json")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+
+def test_hosts(active_hosts):
+    results=[]
+    for h in active_hosts:
+        try:
+            cmd = ["ssh", h, "bash -lc", f"'/opt/aegis/hsm_sign_snapshot_remote.sh \"{SAMPLE_ART}\"; tail -n 50 /var/log/aegis/hsm_signing.log'"]
+            out = subprocess.check_output(cmd, stderr=subprocess.STDOUT, timeout=120).decode()
+            results.append({"host":h,"ok":True,"log": out[:4000]})
+        except Exception as e:
+            results.append({"host":h,"ok":False,"error":str(e)})
+    return results
+
+def main():
+    report = {"ts": datetime.utcnow().isoformat(), "scenarios": []}
+    # baseline: all hosts
+    report["scenarios"].append({"name":"all_hosts", "results": test_hosts(HOSTS)})
+    # simulate each host failing
+    for i,h in enumerate(HOSTS):
+        active = [x for x in HOSTS if x != h]
+        report["scenarios"].append({"name": f"without_{h}", "results": test_hosts(active)})
+    out="/tmp/hsm_recovery_report.json"
+    open(out,"w").write(json.dumps(report, indent=2))
+    if COMPLIANCE_BUCKET:
+        s3=boto3.client("s3"); s3.upload_file(out, COMPLIANCE_BUCKET, f"hsm_recovery/{os.path.basename(out)}")
+    print("Wrote", out)
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: admission/throttle_accounting.py
+#!/usr/bin/env python3
+"""
+Monthly throttle accounting to compute dynamic capacities per tenant:
+ - Reads tenant billing/usage and adjusts monthly capacity tokens
+ - Stores adjustments in tenant_throttle table (throttle_db)
+"""
+import os
+from sqlalchemy import create_engine, text
+from datetime import datetime
+
+DB_URL = os.environ.get("DATABASE_URL", "postgresql://aegis:aegis@localhost:5432/aegis")
+engine = create_engine(DB_URL)
+
+def adjust_capacities():
+    # Example policy: capacity = baseline + (monthly_budget - used) * factor
+    with engine.begin() as conn:
+        rows = conn.execute(text("SELECT tenant, budget_monthly_kg, used_monthly_kg FROM tenant_budgets")).fetchall()
+        for r in rows:
+            tenant = r.tenant; budget = r.budget_monthly_kg or 0.0; used = r.used_monthly_kg or 0.0
+            remaining = max(budget - used, 0.0)
+            new_cap = max(remaining * 1.0, 10.0)  # ensure minimum capacity
+            conn.execute(text("INSERT INTO tenant_throttle (tenant, capacity, tokens, last_refill) VALUES (:tenant,:cap,:cap,now()) ON CONFLICT (tenant) DO UPDATE SET capacity = :cap, tokens = :cap"), {"tenant": tenant, "cap": new_cap})
+            print("Set capacity for", tenant, new_cap)
+
+if __name__=="__main__":
+    adjust_capacities()
+
*** End Patch
*** Begin Patch
*** Add File: scheduler/stress_test_runner.py
+#!/usr/bin/env python3
+"""
+Concurrent stress test runner for admission/throttle and scheduler adapter.
+Generates high concurrency submissions and records latency/denial stats.
+"""
+import threading, time, random, json, requests
+
+ADMIT = os.environ.get("ADMISSION_URL", "http://admission-prod.aegis.svc:9110/admit")
+SUBMIT = os.environ.get("SCHEDULER_SUBMIT", "http://scheduler-service.aegis.svc:8201/submit-job")
+RESULTS="/tmp/stress_results.json"
+
+def submit_job(i):
+    tenant = f"tenant-{random.randint(1,20)}"
+    kg = round(random.uniform(0.01,3.0),3)
+    start = time.time()
+    try:
+        r = requests.post(SUBMIT, json={"job_id":f"job-{i}", "tenant":tenant, "estimated_kgco2e": kg}, timeout=5)
+        latency = time.time() - start
+        return {"i": i, "status": r.status_code, "text": r.text[:200], "latency": latency}
+    except Exception as e:
+        return {"i": i, "status": "error", "error": str(e)}
+
+def run(n=1000, concurrency=50):
+    results=[]
+    def worker(idx):
+        r=submit_job(idx)
+        results.append(r)
+    threads=[]
+    for i in range(n):
+        t=threading.Thread(target=worker, args=(i,))
+        threads.append(t); t.start()
+        if len(threads) >= concurrency:
+            for th in threads:
+                th.join()
+            threads=[]
+    for th in threads: th.join()
+    open(RESULTS,"w").write(json.dumps(results, indent=2))
+    print("Wrote", RESULTS)
+
+if __name__=="__main__":
+    run(int(os.environ.get("NUM_JOBS","500")), int(os.environ.get("CONCURRENCY","50")))
+
*** End Patch
*** Begin Patch
*** Add File: experiments/sop_ci_workflow.yml
+name: Enforce A/B SOP before Promotion
+on:
+  workflow_dispatch:
+    inputs:
+      meta-path:
+        required: true
+
+jobs:
+  enforce:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Enforce SOP
+        run: |
+          python experiments/sop_enforcer.py "${{ github.event.inputs.meta-path }}"
+
*** End Patch
*** Begin Patch
*** Add File: compliance/auditor_signoff.py
+#!/usr/bin/env python3
+"""
+Simple auditor sign-off script:
+ - marks control evidence items as signed by auditor and uploads sign-off to compliance bucket
+"""
+import os, json, boto3
+from datetime import datetime
+
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+DB = "compliance/auditor_signoffs.json"
+
+def sign(control_id, auditor, note=""):
+    if not os.path.exists("compliance"):
+        os.makedirs("compliance")
+    if os.path.exists(DB):
+        db = json.load(open(DB))
+    else:
+        db = {"signoffs": []}
+    rec = {"control": control_id, "auditor": auditor, "note": note, "ts": datetime.utcnow().isoformat()}
+    db["signoffs"].append(rec)
+    open(DB,"w").write(json.dumps(db, indent=2))
+    if COMPLIANCE_BUCKET:
+        s3=boto3.client("s3"); s3.upload_file(DB, COMPLIANCE_BUCKET, f"auditor_signoffs/{os.path.basename(DB)}")
+    print("Signed", control_id)
+
+if __name__=="__main__":
+    import argparse
+    p=argparse.ArgumentParser()
+    p.add_argument("--control", required=True)
+    p.add_argument("--auditor", required=True)
+    p.add_argument("--note", default="")
+    args=p.parse_args()
+    sign(args.control, args.auditor, args.note)
+
*** End Patch
*** Begin Patch
*** Add File: security/vault_fetcher.py
+#!/usr/bin/env python3
+"""
+Demo Vault integration to fetch secrets for services (operators must configure Vault and auth).
+ - Fetches secret at given path and writes local env file for consumption by containers via projected secrets.
+"""
+import os, hvac, json
+
+VAULT_ADDR = os.environ.get("VAULT_ADDR", "http://127.0.0.1:8200")
+VAULT_TOKEN = os.environ.get("VAULT_TOKEN")
+
+def fetch(path, dest="/tmp/aegis_secrets.env"):
+    client = hvac.Client(url=VAULT_ADDR, token=VAULT_TOKEN)
+    resp = client.secrets.kv.v2.read_secret_version(path=path)
+    data = resp["data"]["data"]
+    with open(dest,"w") as fh:
+        for k,v in data.items():
+            fh.write(f"{k}={v}\n")
+    print("Wrote", dest)
+
+if __name__=="__main__":
+    import argparse
+    p=argparse.ArgumentParser()
+    p.add_argument("--path", required=True)
+    p.add_argument("--dest", default="/tmp/aegis_secrets.env")
+    args=p.parse_args()
+    fetch(args.path, args.dest)
+
*** End Patch
*** Begin Patch
*** Add File: ui/README_security_and_auth.md
+## Tenant UI Security & Auth Guidance
+
+This document outlines recommended production steps to harden tenant UI:
+
+1. Replace demo auth-server with proper OIDC provider (Auth0, Keycloak, Okta).
+2. Use HTTPS and enforce HSTS on UI ingress.
+3. Implement RBAC on backend APIs:
+   - admission endpoints must authenticate client service accounts.
+   - showback endpoints should authorize requests by tenant.
+4. Secrets:
+   - Use Vault (or cloud KMS + secret manager) for COSIGN keys, DB credentials, and S3 credentials.
+   - Do not store keys in repo or CI.
+5. Rate limiting and WAF:
+   - Apply rate limits on public UI endpoints and authentication endpoints.
+
+Operators: follow these steps before public tenant onboarding.
+
*** End Patch
*** End Patch
