*** Begin Patch
*** Add File:.github/workflows/image_build_cosign.yml
+name: Build, Push & Sign Image
+
+on:
+  push:
+    branches:
+      - main
+      - 'release/*'
+  workflow_dispatch:
+
+jobs:
+  build-push-sign:
+    runs-on: ubuntu-latest
+    permissions:
+      contents: write
+      packages: write
+      id-token: write
+    env:
+      IMAGE_REGISTRY: REPLACE_GHCR_ORG
+      IMAGE_NAME: aegis-quantum
+      IMAGE_TAG: ${{ github.sha }}
+      REKOR_URL: ${{ secrets.REKOR_URL }}
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Set up QEMU
+        uses: docker/setup-qemu-action@v2
+
+      - name: Set up Docker Buildx
+        uses: docker/setup-buildx-action@v2
+
+      - name: Login to registry
+        uses: docker/login-action@v2
+        with:
+          registry: REPLACE_GHCR_HOST
+          username: ${{ github.actor }}
+          password: ${{ secrets.GITHUB_TOKEN }}
+
+      - name: Build and push image
+        uses: docker/build-push-action@v4
+        with:
+          context: .
+          file: docker/quantum/Dockerfile
+          push: true
+          tags: ${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}
+
+      - name: Install cosign
+        run: |
+          COSIGN_VERSION="v2.1.0"
+          curl -sSL -o /tmp/cosign.tar.gz "https://github.com/sigstore/cosign/releases/download/${COSIGN_VERSION}/cosign-${COSIGN_VERSION}-linux-amd64.tar.gz"
+          tar -xzf /tmp/cosign.tar.gz -C /usr/local/bin cosign
+          cosign version
+
+      - name: Sign image with cosign (KMS)
+        env:
+          COSIGN_KMS_ARN: ${{ secrets.COSIGN_KMS_ARN }}
+        run: |
+          if [ -z "${COSIGN_KMS_ARN}" ]; then
+            echo "COSIGN_KMS_ARN not set; aborting signing step"
+            exit 1
+          fi
+          cosign sign --key "${COSIGN_KMS_ARN}" --rekor-url "${{ env.REKOR_URL }}" "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}"
+
+      - name: Verify signature and Rekor entry
+        run: |
+          cosign verify --rekor-server "${{ env.REKOR_URL }}" "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}"
+          echo "Image signed and Rekor entry created/verified."
+
+      - name: Set output image tag
+        id: set_output
+        run: echo "::set-output name=image::${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}"
+
*** End Patch
*** Begin Patch
*** Add File:gitops/argocd/application-staging.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Application
+metadata:
+  name: aegis-staging
+  namespace: argocd
+spec:
+  project: default
+  source:
+    repoURL: 'https://github.com/REPLACE_GITHUB_OWNER/REPLACE_GITOPS_REPO.git'
+    targetRevision: HEAD
+    path: 'overlays/staging'
+  destination:
+    server: 'https://kubernetes.default.svc'
+    namespace: aegis
+  syncPolicy:
+    automated:
+      prune: true
+      selfHeal: true
+    syncOptions:
+      - CreateNamespace=true
+
*** End Patch
*** Begin Patch
*** Add File:gitops/overlays/staging/kustomization.yaml
+apiVersion: kustomize.config.k8s.io/v1beta1
+kind: Kustomization
+resources:
+  - ../../base/inference
+namespace: aegis
+images:
+  - name: REPLACE_GHCR_ORG/aegis-quantum
+    newName: REPLACE_GHCR_ORG/aegis-quantum
+    newTag: REPLACE_IMAGE_TAG
+
*** End Patch
*** Begin Patch
*** Add File:k8s/istio/canary_virtualservice.yaml
+apiVersion: networking.istio.io/v1alpha3
+kind: VirtualService
+metadata:
+  name: aegis-model
+  namespace: aegis
+spec:
+  hosts:
+    - "aegis.example.com" # REPLACE with real host
+  http:
+    - route:
+        - destination:
+            host: aegis-model-stable.aegis.svc.cluster.local
+            subset: stable
+          weight: 90
+        - destination:
+            host: aegis-model-canary.aegis.svc.cluster.local
+            subset: canary
+          weight: 10
+      timeout: 10s
+      mirror:
+        host: aegis-model-canary.aegis.svc.cluster.local
+
*** End Patch
*** Begin Patch
*** Add File:ops/promote_to_gitops.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Update the GitOps repo (kustomize overlay) with a new image tag and open a PR
+#
+REPO=${1:-"REPLACE_GITOPS_REPO"}
+BRANCH=${2:-"promote-model-$(date +%s)"}
+IMAGE=${3:-"REPLACE_GHCR_ORG/aegis-quantum:REPLACE_IMAGE_TAG"}
+BASE=${4:-"main"}
+
+if [ -z "${GITHUB_TOKEN:-}" ]; then
+  echo "GITHUB_TOKEN must be set in environment to push and create PRs"
+  exit 2
+fi
+
+git clone https://x-access-token:${GITHUB_TOKEN}@github.com/${REPO} gitops
+cd gitops
+git checkout -b "${BRANCH}"
+sed -i "s|REPLACE_GHCR_ORG/aegis-quantum:.*|${IMAGE}|g" overlays/staging/kustomization.yaml || true
+git add overlays/staging/kustomization.yaml
+git commit -m "chore: promote model image ${IMAGE} to staging"
+git push origin "${BRANCH}"
+
+gh pr create --repo "${REPO}" --title "Promote model ${IMAGE} to staging" --body "Automated promotion PR for image ${IMAGE}" --head "${BRANCH}" --base "${BASE}"
+
+echo "Promotion PR created for ${IMAGE} in ${REPO}"
+
*** End Patch
*** Begin Patch
*** Add File:argo/rollout_promote_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: canary-monitor-promote-
+  namespace: aegis
+spec:
+  entrypoint: monitor-and-promote
+  arguments:
+    parameters:
+      - name: prometheus-url
+        value: "REPLACE_PROMETHEUS_URL"
+      - name: query-latency
+        value: 'histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="kserve",env="prod"}[5m])) by (le))'
+      - name: latency-threshold
+        value: "0.5"
+      - name: gitops-repo
+        value: "REPLACE_GITOPS_REPO"
+      - name: image
+        value: "REPLACE_GHCR_ORG/aegis-quantum:REPLACE_IMAGE_TAG"
+
+  templates:
+    - name: monitor-and-promote
+      steps:
+        - - name: query-metrics
+            template: prometheus-query
+            arguments:
+              parameters:
+                - name: prometheus-url
+                  value: "{{workflow.parameters.prometheus-url}}"
+                - name: query
+                  value: "{{workflow.parameters.query-latency}}"
+        - - name: decide
+            template: decide-and-promote
+
+    - name: prometheus-query
+      inputs:
+        parameters:
+          - name: prometheus-url
+          - name: query
+      container:
+        image: curlimages/curl:7.86.0
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            set -e
+            q=$(printf "%s" "{{inputs.parameters.query}}" | sed 's/ /%20/g')
+            url="{{inputs.parameters.prometheus-url}}/api/v1/query?query=${q}"
+            echo "Querying Prometheus: ${url}"
+            curl -s "${url}" | jq '.' > /tmp/prom_res.json
+            cat /tmp/prom_res.json
+            # Extract value or default to high
+            val=$(cat /tmp/prom_res.json | jq -r '.data.result[0].value[1] // "9999"')
+            echo "Latency value: $val"
+            echo "latency=$val" > /tmp/metrics.txt
+            cat /tmp/metrics.txt
+            cp /tmp/metrics.txt /tmp/output_metrics.txt
+        volumeMounts:
+          - name: tmp
+            mountPath: /tmp
+      outputs:
+        artifacts:
+          - name: metrics
+            path: /tmp/output_metrics.txt
+
+    - name: decide-and-promote
+      container:
+        image: bitnami/kubectl:1.28
+        command: ["/bin/sh","-c"]
+        env:
+          - name: GITOPS_REPO
+            value: "{{workflow.parameters.gitops-repo}}"
+        args:
+          - |
+            set -e
+            if [ ! -f /tmp/metrics.txt ]; then
+              echo "Metrics file missing; aborting"
+              exit 2
+            fi
+            latency=$(cat /tmp/metrics.txt | sed 's/latency=//')
+            echo "Latency read: ${latency}"
+            thr={{workflow.parameters.latency-threshold}}
+            # numeric compare
+            awk -v l="${latency}" -v t="${thr}" 'BEGIN{ if (l+0 <= t+0) exit 0; else exit 1 }'
+            if [ $? -eq 0 ]; then
+              echo "Latency OK; promoting canary to stable"
+              # Update gitops repo with new image via ops/promote_to_gitops.sh (requires GITHUB_TOKEN)
+              /bin/sh -c "/work/promote_to_gitops.sh {{workflow.parameters.gitops-repo}} promote-model-$(date +%s) {{workflow.parameters.image}} main"
+            else
+              echo "Latency too high; do not promote. Consider rollback."
+              exit 1
+            fi
+      volumeMounts:
+        - name: work
+          mountPath: /work
+
+  volumes:
+    - name: tmp
+      emptyDir: {}
+    - name: work
+      emptyDir: {}
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/drift_retrain_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: drift-detect-and-retrain-
+  namespace: aegis
+spec:
+  entrypoint: drift-and-retrain
+  arguments:
+    parameters:
+      - name: data-s3
+        value: "s3://REPLACE_EVIDENCE_BUCKET/inputs/prod_recent.csv"
+      - name: model-s3
+        value: "s3://REPLACE_EVIDENCE_BUCKET/models/stable/model.tar.gz"
+      - name: drift-threshold
+        value: "0.1"
+
+  templates:
+    - name: drift-and-retrain
+      steps:
+        - - name: run-drift
+            template: run-evidently
+            arguments:
+              parameters:
+                - name: data-s3
+                  value: "{{workflow.parameters.data-s3}}"
+                - name: model-s3
+                  value: "{{workflow.parameters.model-s3}}"
+        - - name: check-drift
+            template: check-and-trigger-retrain
+
+    - name: run-evidently
+      inputs:
+        parameters:
+          - name: data-s3
+          - name: model-s3
+      container:
+        image: python:3.10-slim
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            set -e
+            pip install evidently boto3 pandas
+            python - <<PY
+import os,sys,tempfile,subprocess,json
+from evidently.report import Report
+from evidently.metric_preset import DataDriftPreset
+import pandas as pd
+tmp=tempfile.mkdtemp()
+subprocess.check_call(["aws","s3","cp","'{{inputs.parameters.data-s3}}'","/tmp/data.csv"], shell=False)
+data=pd.read_csv("/tmp/data.csv")
+report=Report(metrics=[DataDriftPreset()])
+report.run(reference_data=data.sample(frac=0.5), current_data=data.sample(frac=0.5))
+drift_score=0.0
+try:
+    # Best-effort extract from report JSON export if needed
+    print("Drift evaluation complete")
+except Exception as e:
+    print("Drift eval parse failed", e)
+    sys.exit(2)
+print("0.2") # placeholder - callers will use exit code or artifact in real use
+PY
+
+    - name: check-and-trigger-retrain
+      container:
+        image: bitnami/kubectl:1.28
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            echo "Placeholder: evaluate Evidently output and decide whether to retrain"
+            # In a real deployment we'd parse output and if drift>threshold, submit a retrain argo workflow:
+            # argo submit -n aegis argo/retrain_workflow.yaml -p dataset-s3=... -p mlflow-tracking-uri=...
+            echo "No automatic retrain performed in placeholder run"
+
*** End Patch
*** Begin Patch
*** Add File:argo/retrain_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: retrain-
+  namespace: aegis
+spec:
+  entrypoint: retrain
+  arguments:
+    parameters:
+      - name: dataset-s3
+        value: "s3://REPLACE_EVIDENCE_BUCKET/datasets/latest"
+      - name: mlflow-tracking-uri
+        value: "REPLACE_MLFLOW_TRACKING_URI"
+      - name: image
+        value: "REPLACE_GHCR_ORG/train:REPLACE_IMAGE_TAG"
+
+  templates:
+    - name: retrain
+      steps:
+        - - name: run-retrain
+            template: run-training
+            arguments:
+              parameters:
+                - name: dataset-s3
+                  value: "{{workflow.parameters.dataset-s3}}"
+                - name: mlflow-tracking-uri
+                  value: "{{workflow.parameters.mlflow-tracking-uri}}"
+                - name: image
+                  value: "{{workflow.parameters.image}}"
+
+    - name: run-training
+      inputs:
+        parameters:
+          - name: dataset-s3
+          - name: mlflow-tracking-uri
+          - name: image
+      container:
+        image: "{{inputs.parameters.image}}"
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            set -e
+            aws s3 cp {{inputs.parameters.dataset-s3}} /tmp/dataset --recursive
+            python /opt/ops/train.py --data /tmp/dataset --mlflow-tracking-uri "{{inputs.parameters.mlflow-tracking-uri}}" --experiment "retrain" --output /tmp/output
+            tar czf /tmp/model.tar.gz -C /tmp/output model
+            aws s3 cp /tmp/model.tar.gz s3://REPLACE_EVIDENCE_BUCKET/models/retrain/${{workflow.uid}}/model.tar.gz
+
*** End Patch
*** Begin Patch
*** Add File:demo/e2e_auto_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-e2e-auto-
+  namespace: aegis
+spec:
+  entrypoint: e2e
+  arguments:
+    parameters:
+      - name: image
+        value: "REPLACE_GHCR_ORG/aegis-quantum:REPLACE_IMAGE_TAG"
+      - name: gitops-repo
+        value: "REPLACE_GITOPS_REPO"
+      - name: model-s3-prefix
+        value: "s3://REPLACE_EVIDENCE_BUCKET/models"
+
+  templates:
+    - name: e2e
+      steps:
+        - - name: train
+            template: train
+            arguments:
+              parameters:
+                - name: image
+                  value: "{{workflow.parameters.image}}"
+        - - name: promote-to-staging
+            template: promote
+            arguments:
+              parameters:
+                - name: gitops-repo
+                  value: "{{workflow.parameters.gitops-repo}}"
+                - name: image
+                  value: "{{workflow.parameters.image}}"
+        - - name: wait-for-sync
+            template: wait-for-argo-sync
+        - - name: start-canary-monitor
+            template: start-canary-monitor
+
+    - name: train
+      inputs:
+        parameters:
+          - name: image
+      container:
+        image: "{{inputs.parameters.image}}"
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            set -e
+            echo "Running training as part of demo E2E (placeholder)"
+            python /opt/ops/train.py --data tests/fixtures/tiny_dataset --mlflow-tracking-uri REPLACE_MLFLOW_TRACKING_URI --experiment "demo-e2e" --output /tmp/output
+            tar czf /tmp/model.tar.gz -C /tmp/output model
+            aws s3 cp /tmp/model.tar.gz REPLACE_S3_UPLOAD_DEST || true
+
+    - name: promote
+      inputs:
+        parameters:
+          - name: gitops-repo
+          - name: image
+      container:
+        image: alpine/gh:latest
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            set -e
+            # Use ops/promote_to_gitops.sh artifact mounted in the cluster or a sidecar; placeholder here
+            echo "Create promotion PR for image {{inputs.parameters.image}} in {{inputs.parameters.gitops-repo}}"
+            # In practice, mount a GitHub token and run the promote script
+
+    - name: wait-for-argo-sync
+      container:
+        image: bitnami/kubectl:1.28
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            echo "Wait for ArgoCD sync (placeholder): sleep 60"
+            sleep 60
+
+    - name: start-canary-monitor
+      container:
+        image: curlimages/curl:7.86.0
+        command: ["/bin/sh","-c"]
+        args:
+          - |
+            echo "Trigger canary monitor workflow (promote if metrics OK)"
+            # In production: use argo submit to start rollout_promote_workflow.yaml
+            echo "Done"
+
*** End Patch
*** Begin Patch
*** Add File:ops/automation_readme.md
+# Automation README — End-to-end automation for Aegis
+
+This folder and manifests implement the automation pieces for:
+- CI image build, push and cosign signing (.github/workflows/image_build_cosign.yml)
+- GitOps (ArgoCD) Application manifest (gitops/argocd/application-staging.yaml)
+- Kustomize staging overlay (gitops/overlays/staging/kustomization.yaml)
+- Canary traffic routing (k8s/istio/canary_virtualservice.yaml)
+- Promotion script to update GitOps repo (ops/promote_to_gitops.sh)
+- Argo workflows:
+  - rollout_promote_workflow.yaml — monitors Prometheus and promotes via GitOps
+  - drift_retrain_workflow.yaml — runs Evidently drift evaluation and optionally triggers retrain
+  - retrain_workflow.yaml — retrains and uploads retrain artifacts
+  - demo/e2e_auto_workflow.yaml — high level demo that sequences train → promote → monitor
+
+Placeholders
+All manifests contain REPLACE_* tokens for repo names, hostnames, S3 buckets, and other non-secret values. You must replace them before applying to production.
+
+Secrets & permissions
+- COSIGN_KMS_ARN (GitHub secret): used by the CI signing step
+- REKOR_URL (GitHub secret): Rekor server used by cosign
+- GITHUB_TOKEN (env/secret): required by ops/promote_to_gitops.sh and workflows that create PRs
+- Prometheus API needs to be reachable by the Argo workflow runner (or run within cluster)
+
+How to use
+1. Wire CI secrets in GitHub (COSIGN_KMS_ARN, REKOR_URL, etc.)
+2. Ensure GitHub Actions runners have permissions to push to container registry (or use GitHub Packages)
+3. Deploy ArgoCD and apply gitops/argocd/application-staging.yaml (fill placeholders)
+4. Ensure promote_to_gitops.sh is available to the Argo runner (or run promotion from an operator machine)
+5. Tune rollout_promote_workflow.yaml thresholds to match your SLOs
+
+Notes
+- These automations are templates and will likely require adaptation to your cluster's networking and security posture (service mesh, RBAC, GITHUB_TOKEN scope).
+- The workflows use simple Prometheus queries and shell/jq parsing — in production you may want a small service or controller to reliably monitor and drive promotion/rollback decisions.
+
*** End Patch
*** End Patch
