  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: aegis-inference-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: aegis-inference
  minReplicas: 2
  maxReplicas: 10
  metrics:
    # Example: CPU target as baseline
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60
    # Optional: scale on custom Prometheus metric (requires prometheus-adapter)
    # - type: Pods
    #   pods:
    #     metric:
    #       name: aegis_inference_latency_seconds
    #     target:
    #       type: AverageValue
    #       averageValue: "0.5"
