*** Begin Patch
*** Add File: .github/workflows/hsm_sign_and_rotate.yml
+name: HSM Sign & Rotation CI (SoftHSM staging)
+on:
+  workflow_dispatch:
+jobs:
+  hsm-sign-rotate:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y softhsm2 pkcs11-tool opensc
+          python3 -m pip install --upgrade pip
+          pip install -r quantum/crypto/requirements-hsm.txt || true
+      - name: Setup SoftHSM token
+        run: |
+          mkdir -p $GITHUB_WORKSPACE/softhsm_tokens
+          export SOFTHSM2_CONF=$GITHUB_WORKSPACE/softhsm2.conf
+          echo "directories.tokendir = $GITHUB_WORKSPACE/softhsm_tokens" > $SOFTHSM2_CONF
+          softhsm2-util --init-token --free --label "aegis-pq-token" --so-pin 1234 --pin 1234 || true
+          pkcs11-tool --module /usr/lib/softhsm/libsofthsm2.so --login --pin 1234 --keypairgen --key-type rsa:2048 --label pqkey || true
+      - name: Run hybrid signer HSM sign test
+        run: |
+          echo "hello hsm" > /tmp/aegis_hsm_test.bin
+          python3 quantum/crypto/hybrid_signer_hsm.py sign --artifact /tmp/aegis_hsm_test.bin --outdir /tmp/aegis_hsm_sigs --use-pkcs11 --pkcs11-lib /usr/lib/softhsm/libsofthsm2.so --pkcs11-slot 0 --pkcs11-pin 1234 --pkcs11-keylabel pqkey || true
+      - name: Verify metadata exists
+        run: |
+          test -f /tmp/aegis_hsm_sigs/hybrid-signature.json && echo "Hybrid metadata created" || (echo "Missing hybrid metadata" && false)
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/rekor_repro_check.yml
+name: Rekor Sign & Verify CI
+on:
+  workflow_dispatch:
+jobs:
+  rekor-sign:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install cosign & rekor-cli
+        run: |
+          curl -sSL https://github.com/sigstore/cosign/releases/download/v2.0.0/cosign-linux-amd64 -o cosign && chmod +x cosign && sudo mv cosign /usr/local/bin/
+          curl -sSL https://github.com/sigstore/rekor/releases/download/v0.10.0/rekor-cli_linux_amd64 -o rekor-cli && chmod +x rekor-cli && sudo mv rekor-cli /usr/local/bin/
+      - name: Create artifact & sign
+        run: |
+          echo "demo rekor" > /tmp/aegis_rekor_demo.bin
+          # Generate ephemeral key - for CI only
+          cosign generate-key-pair || true
+          cosign sign-blob --key cosign.key --output-signature /tmp/classical.sig /tmp/aegis_rekor_demo.bin
+          rekor-cli upload --artifact /tmp/aegis_rekor_demo.bin --signature /tmp/classical.sig --output json > /tmp/rekor_out.json || true
+      - name: Verify Rekor entry
+        run: |
+          cat /tmp/rekor_out.json && jq . /tmp/rekor_out.json || (echo "No Rekor entry created" && false)
+
*** End Patch
*** Begin Patch
*** Add File: providers/pilot/orchestrator.py
+#!/usr/bin/env python3
+"""
+Pilot orchestrator:
+ - Fetches provider credentials from Vault
+ - Runs Braket/IBM pilot scripts
+ - Collects artifacts and stores references into MLflow
+ - Signs metadata with rekor_programmatic and records Rekor entry into MLflow
+"""
+import os, json, subprocess, tempfile
+import hvac, mlflow
+from providers.pilot.braket_pilot import run_braket_pilot
+from providers.pilot.ibm_pilot import run_ibm_pilot
+
+def get_secret_from_vault(path, key):
+    client = hvac.Client(url=os.environ.get("VAULT_ADDR"), token=os.environ.get("VAULT_TOKEN"))
+    secret = client.secrets.kv.v2.read_secret_version(path=path)
+    return secret['data']['data'].get(key)
+
+def run_braket_job_from_vault(vault_path, program_path, s3_bucket):
+    device = get_secret_from_vault(vault_path, "braket_device")
+    prog = open(program_path).read()
+    return run_braket_pilot(prog, device, s3_bucket)
+
+def run_ibm_job_from_vault(vault_path, program_path, s3_bucket, backend):
+    # Ensure QISKIT_IBM_TOKEN exists in env (set from Vault secret)
+    token = get_secret_from_vault(vault_path, "ibm_token")
+    os.environ["QISKIT_IBM_TOKEN"] = token
+    qasm = open(program_path).read()
+    return run_ibm_pilot(qasm, backend, s3_bucket)
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--provider", required=True, choices=["braket","ibm"])
+    p.add_argument("--vault-path", required=True)
+    p.add_argument("--program", required=True)
+    p.add_argument("--s3-bucket", required=True)
+    p.add_argument("--backend", default=None)
+    args = p.parse_args()
+    if args.provider == "braket":
+        print(run_braket_job_from_vault(args.vault_path, args.program, args.s3_bucket))
+    else:
+        if not args.backend:
+            raise SystemExit("backend required for IBM")
+        print(run_ibm_job_from_vault(args.vault_path, args.program, args.s3_bucket, args.backend))
+
*** End Patch
*** Begin Patch
*** Add File: quantum/rekor/rekor_ci_check.sh
+#!/usr/bin/env bash
+#
+# CI helper: assert Rekor entry exists for artifact SHA
+ART=$1
+if [ -z "$ART" ]; then
+  echo "Usage: rekor_ci_check.sh <artifact>"
+  exit 2
+fi
+sha=$(sha256sum "$ART" | awk '{print $1}')
+echo "Looking for Rekor entry matching SHA256: $sha"
+if command -v rekor-cli >/dev/null 2>&1; then
+  rekor-cli search --hash "$sha" || (echo "Rekor entry not found" && exit 3)
+else
+  echo "rekor-cli not found; CI must install rekor-cli"
+  exit 1
+fi
+
*** End Patch
*** Begin Patch
*** Add File: broker/k8s/admin_routes_patch.py
+"""
+Patch: Adds admin endpoints to the broker app for fallback control & health.
+Import this module in the broker FastAPI app to expose admin endpoints.
+"""
+from fastapi import APIRouter, HTTPException, Request
+import os, json
+
+router = APIRouter(prefix="/admin")
+
+FALLBACK_FILE = os.environ.get("BROKER_FALLBACK_FILE", "/tmp/broker_fallback.json")
+
+@router.post("/set-fallback")
+async def set_fallback(payload: dict):
+    fb = bool(payload.get("fallback", False))
+    with open(FALLBACK_FILE, "w") as f:
+        json.dump({"fallback": fb}, f)
+    return {"ok": True, "fallback": fb}
+
+@router.get("/get-fallback")
+async def get_fallback():
+    if not os.path.exists(FALLBACK_FILE):
+        return {"fallback": False}
+    return json.load(open(FALLBACK_FILE))
+
*** End Patch
*** Begin Patch
*** Update File: quantum/job_broker/app_postgres.py
@@
 from fastapi import FastAPI, HTTPException, Depends, Header, Request
 from pydantic import BaseModel
 import os, uuid, json, time
 from sqlalchemy.orm import Session
 from jose import jwt, JWTError
 from . import db as jb_db
 from prometheus_client import start_http_server, Counter
+from broker.k8s.admin_routes_patch import router as admin_router
@@
 jb_db.init_db()
 
 app = FastAPI(title="Aegis Quantum Job Broker (Postgres)", version="1.0")
+app.include_router(admin_router)
*** End Patch
*** Begin Patch
*** Add File: observability/alertmanager/alertmanager_config.yaml
+global:
+  resolve_timeout: 5m
+route:
+  receiver: 'webhook'
+receivers:
+  - name: 'webhook'
+    webhook_configs:
+      - url: 'http://fallback-handler.aegis.svc.cluster.local:8085/webhook'
+
*** End Patch
*** Begin Patch
*** Add File: broker/quotas/chargeback_connector.py
+#!/usr/bin/env python3
+"""
+Chargeback ingestion connector:
+ - Sample script to ingest billing CSV from cloud provider and write cost rows to billing table
+ - Operator-run: schedule daily to seed billing DB table for cost_enforcer to read
+"""
+import csv, os, psycopg2, uuid, time
+
+DB = os.environ.get("JOB_DATABASE_URL")
+
+def ingest_csv(file_path, tenant="default"):
+    conn = psycopg2.connect(DB)
+    cur = conn.cursor()
+    with open(file_path) as f:
+        r = csv.DictReader(f)
+        for row in r:
+            jobid = str(uuid.uuid4())
+            cost = float(row.get("cost", 0.0))
+            cur.execute("INSERT INTO billing (id, job_id, user, cost, recorded_at) VALUES (%s,%s,%s,%s,now())", (jobid, row.get("job"), tenant, cost))
+    conn.commit()
+    conn.close()
+
+if __name__ == "__main__":
+    import sys
+    ingest_csv(sys.argv[1], tenant=sys.argv[2] if len(sys.argv)>2 else "default")
+
*** End Patch
*** Begin Patch
*** Add File: compliance/audit_packager.sh
+#!/usr/bin/env bash
+set -euo pipefail
+OUTDIR=${1:-/tmp/aegis_quantum_audit}
+mkdir -p "$OUTDIR"
+echo "Collecting broker logs, HSM audit, Rekor entries, MLflow artifacts..."
+kubectl logs -n aegis deployment/aegis-quantum-broker > "$OUTDIR/broker.log" || true
+kubectl get pods -n aegis -o wide > "$OUTDIR/pods.txt" || true
+vault kv get -format=json secret/pq-keys/customer1 > "$OUTDIR/pq_keys.json" || true
+aws s3 ls s3://$HSM_AUDIT_BUCKET/hsm-audit/ > "$OUTDIR/hsm_audit_list.txt" || true
+tar czf "${OUTDIR}.tar.gz" -C "$(dirname "$OUTDIR")" "$(basename "$OUTDIR")"
+echo "Audit bundle created: ${OUTDIR}.tar.gz"
+
*** End Patch
*** Begin Patch
*** Add File: docs/production_onboarding_checklist.md
+# Production Onboarding Checklist — Quantum & HSM
+
+1. Provision vendor HSM (CloudHSM / Thales / Entrust) in staging and grant operator access
+2. Provide PKCS#11 module path and slot info; test hybrid_signer_hsm against vendor HSM
+3. Add HSM PKCS#11 config to Vault using provided Terraform modules and restrict access
+4. Deploy managed Postgres (RDS / Cloud SQL) and update JOB_DATABASE_URL secrets in k8s
+5. Deploy cert-manager and issue broker TLS certs; enable mTLS for clients where needed
+6. Create provider credentials (Braket / IBM) and store in Vault; run pilot orchestrator
+7. Validate Rekor/cosign pipeline — ensure rekor-cli can upload and outputs entry UUIDs; add CI gate
+8. Run E2E pilot runbook; collect artifacts and package audit evidence
+9. Complete vendor contracts and export-control review; store evidence in compliance/evidence
+
*** End Patch
*** End Patch
