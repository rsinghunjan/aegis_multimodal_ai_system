*** Begin Patch
*** Add File:ci/build_sign_rekor.yml
+name: Build, Sign Images & Rekor
+
+on:
+  workflow_dispatch:
+  push:
+    paths:
+      - 'mcp/**'
+      - 'explainability/**'
+      - 'mcp_context/**'
+      - 'security/**'
+      - 'carbon/**'
+
+jobs:
+  build-and-sign:
+    runs-on: ubuntu-latest
+    env:
+      REGISTRY: ghcr.io/${{ github.repository_owner }}
+      IMAGE_TAG: ${{ github.sha }}
+    steps:
+      - uses: actions/checkout@v4
+      - name: Set up Docker Buildx
+        uses: docker/setup-buildx-action@v2
+      - name: Login to registry
+        uses: docker/login-action@v2
+        with:
+          registry: ghcr.io
+          username: ${{ github.actor }}
+          password: ${{ secrets.GITHUB_TOKEN }}
+      - name: Build images
+        run: |
+          docker build -t $REGISTRY/aegis-mcp:$IMAGE_TAG mcp/api
+          docker build -t $REGISTRY/aegis-mcp-operator:$IMAGE_TAG mcp/operator
+          docker build -t $REGISTRY/aegis-cosign-admission:$IMAGE_TAG security/cosign-admission
+      - name: Push images
+        run: |
+          docker push $REGISTRY/aegis-mcp:$IMAGE_TAG
+          docker push $REGISTRY/aegis-mcp-operator:$IMAGE_TAG
+          docker push $REGISTRY/aegis-cosign-admission:$IMAGE_TAG
+      - name: Install cosign & rekor-cli
+        run: |
+          COSIGN_VER="2.0.0"
+          REKOR_VER="0.12.0"
+          curl -sfLo /usr/local/bin/cosign https://github.com/sigstore/cosign/releases/download/v${COSIGN_VER}/cosign-linux-amd64
+          chmod +x /usr/local/bin/cosign
+          curl -sfLo /usr/local/bin/rekor-cli https://github.com/sigstore/rekor/releases/download/v${REKOR_VER}/rekor-cli_linux_amd64
+          chmod +x /usr/local/bin/rekor-cli
+      - name: Sign images with cosign (KMS)
+        env:
+          COSIGN_KEY: ${{ secrets.COSIGN_KEY }} # e.g., awskms://arn:aws:kms:...
+        run: |
+          set -euo pipefail
+          IMG_LIST=(
+            "$REGISTRY/aegis-mcp:$IMAGE_TAG"
+            "$REGISTRY/aegis-mcp-operator:$IMAGE_TAG"
+            "$REGISTRY/aegis-cosign-admission:$IMAGE_TAG"
+          )
+          for IMG in "${IMG_LIST[@]}"; do
+            echo "Signing $IMG"
+            cosign sign --key "$COSIGN_KEY" "$IMG"
+            cosign verify --key "$COSIGN_KEY" "$IMG"
+          done
+      - name: Upload Rekor entries (best-effort)
+        env:
+          REKOR_SERVER: ${{ secrets.REKOR_URL }}
+          REKOR_API_KEY: ${{ secrets.REKOR_API_KEY }}
+        run: |
+          # cosign writes to transparency log automatically when configured; this step is best-effort
+          echo "Rekor upload step: ensure cosign is configured to publish to REKOR_SERVER in your env."
+          echo "If using a separate Rekor client, you can upload artifact entries here."
+      - name: Export image tags
+        run: |
+          echo "mcp_image=$REGISTRY/aegis-mcp:$IMAGE_TAG" >> $GITHUB_OUTPUT
+          echo "operator_image=$REGISTRY/aegis-mcp-operator:$IMAGE_TAG" >> $GITHUB_OUTPUT
+          echo "admission_image=$REGISTRY/aegis-cosign-admission:$IMAGE_TAG" >> $GITHUB_OUTPUT
+
*** End Patch
*** Begin Patch
*** Add File:scripts/cosign_rekor_helper.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# Helper to sign an OCI image with cosign (KMS) and optionally verify Rekor entries.
+# Usage: ./scripts/cosign_rekor_helper.sh <image> <cosign_key_arn>
+IMG=${1:-}
+COSIGN_KEY=${2:-}
+if [ -z "$IMG" ] || [ -z "$COSIGN_KEY" ]; then
+  echo "Usage: $0 <image> <cosign_key_arn>"
+  exit 2
+fi
+echo "Signing $IMG with key $COSIGN_KEY"
+cosign sign --key "$COSIGN_KEY" "$IMG"
+echo "Verifying signature..."
+cosign verify --key "$COSIGN_KEY" "$IMG"
+echo "Signature OK. If Rekor server is configured for cosign, the entry should be present in Rekor."
+echo "To inspect Rekor entries (if rekor-cli configured): rekor-cli search --artifact $IMG"
+
*** End Patch
*** Begin Patch
*** Add File:mcp_context/middleware/redaction.py
+#!/usr/bin/env python3
+"""
+PII Redaction & Encrypted Upload helpers for Model Contexts.
+
+ - redact_text(text): redacts common PII patterns (emails, phones, SSNs, credit cards).
+ - upload_redacted_text(text, bucket, key, kms_key_arn): uploads text to S3 using server-side encryption (SSE-KMS).
+ - use these helpers from your inference middleware before including raw inputs in context.json.
+"""
+import re
+import boto3
+import json
+import tempfile
+import os
+
+EMAIL_RE = re.compile(r'[\w\.-]+@[\w\.-]+\.\w+')
+PHONE_RE = re.compile(r'(\+?\d{1,3}[-.\s]?)?(\(?\d{3}\)?[-.\s]?)?\d{3}[-.\s]?\d{4}')
+SSN_RE = re.compile(r'\b\d{3}-\d{2}-\d{4}\b')
+CC_RE = re.compile(r'\b(?:\d[ -]*?){13,16}\b')
+
+def redact_text(text, mask='[REDACTED]'):
+    if not text:
+        return text
+    t = EMAIL_RE.sub(mask, text)
+    t = SSN_RE.sub(mask, t)
+    t = CC_RE.sub(mask, t)
+    t = PHONE_RE.sub(mask, t)
+    return t
+
+def upload_redacted_text(text, bucket, key, kms_key_arn=None, region='us-west-2'):
+    s3 = boto3.client('s3', region_name=region)
+    tmp = tempfile.mktemp(suffix='.txt')
+    with open(tmp, 'w') as f:
+        f.write(text)
+    extra_args = {}
+    if kms_key_arn:
+        extra_args['ServerSideEncryption'] = 'aws:kms'
+        extra_args['SSEKMSKeyId'] = kms_key_arn
+    s3.upload_file(tmp, bucket, key, ExtraArgs=extra_args)
+    os.remove(tmp)
+    return f"s3://{bucket}/{key}"
+
+def redact_and_upload_input(raw_text, bucket, run_id, kms_key_arn=None, region='us-west-2'):
+    redacted = redact_text(raw_text)
+    key = f"audit/{run_id}/input_redacted.txt"
+    return upload_redacted_text(redacted, bucket, key, kms_key_arn, region)
+
*** End Patch
*** Begin Patch
*** Add File:mcp/verifier/service.py
+#!/usr/bin/env python3
+"""
+Lightweight Verifier Service
+
+Endpoints:
+ - POST /verify_claim : payload { 'claim': '<text>', 'context_docs': [ 's3://...' ] } -> returns {supported:bool, score:float, evidence: [...]}
+ - POST /verify_run/{run_id} : reads Model Context from registry (MODEL_CONTEXT_REGISTRY_URL) and runs a verification pass.
+
+This is a pragmatic verifier for promotion gates: implement more robust NLI/verifier models for production.
+"""
+import os
+import json
+from typing import List
+from fastapi import FastAPI, HTTPException
+import boto3
+import requests
+import re
+
+MODEL_CONTEXT_REGISTRY_URL = os.environ.get("MODEL_CONTEXT_REGISTRY_URL", "")
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+AWS_REGION = os.environ.get("AWS_REGION", "us-west-2")
+
+app = FastAPI(title="Aegis Verifier")
+s3 = boto3.client("s3", region_name=AWS_REGION)
+
+def simple_support_score(claim: str, doc_text: str):
+    # naive keyword overlap score
+    claim_terms = set(re.findall(r'\w+', claim.lower()))
+    doc_terms = set(re.findall(r'\w+', doc_text.lower()))
+    if not claim_terms:
+        return 0.0
+    overlap = claim_terms.intersection(doc_terms)
+    return len(overlap) / len(claim_terms)
+
+@app.post("/verify_claim")
+def verify_claim(payload: dict):
+    claim = payload.get("claim","")
+    docs = payload.get("context_docs", [])
+    evidence = []
+    scores = []
+    for d in docs:
+        # d can be s3://... or raw text
+        if isinstance(d, str) and d.startswith("s3://"):
+            parsed = d.replace("s3://","").split("/",1)
+            bucket = parsed[0]; key = parsed[1]
+            try:
+                obj = s3.get_object(Bucket=bucket, Key=key)
+                txt = obj["Body"].read().decode()
+            except Exception:
+                txt = ""
+        else:
+            txt = d
+        sc = simple_support_score(claim, txt)
+        scores.append(sc)
+        if sc > 0.1:
+            evidence.append({"source": d, "score": sc})
+    final_score = max(scores) if scores else 0.0
+    return {"supported": final_score > 0.3, "score": final_score, "evidence": evidence}
+
+@app.post("/verify_run/{run_id}")
+def verify_run(run_id: str):
+    if not MODEL_CONTEXT_REGISTRY_URL:
+        raise HTTPException(status_code=500, detail="MODEL_CONTEXT_REGISTRY_URL not configured")
+    r = requests.get(f"{MODEL_CONTEXT_REGISTRY_URL}/contexts/{run_id}", timeout=10)
+    if r.status_code != 200:
+        raise HTTPException(status_code=404, detail="run context not found")
+    rec = r.json()
+    s3_key = rec.get("s3_key")
+    parsed = s3_key.replace("s3://","").split("/",1)
+    bucket = parsed[0] if len(parsed)>1 else EVIDENCE_BUCKET
+    key = parsed[1] if len(parsed)>1 else parsed[0]
+    obj = s3.get_object(Bucket=bucket, Key=key)
+    ctx = json.loads(obj["Body"].read())
+    claim = ctx.get("outputs", {}).get("summary") or ctx.get("generation", {}).get("prompt_template","")
+    # collect retrieved snippet pointers if present
+    docs = []
+    for d in ctx.get("retrieval", {}).get("retrieved_docs", []):
+        if d.get("snippet_pointer"):
+            docs.append(d["snippet_pointer"])
+    return verify_claim({"claim": claim, "context_docs": docs})
+
+if __name__ == "__main__":
+    import uvicorn
+    uvicorn.run("service:app", host="0.0.0.0", port=int(os.environ.get("VERIFIER_PORT","8097")))
+
*** End Patch
*** Begin Patch
*** Add File:security/carbon-admission/carbon_admission.py
+#!/usr/bin/env python3
+"""
Admission webhook that checks estimated carbon/budget impact before allowing job/pod creation.
+ Expected behavior:
+  - For Pods/Jobs annotated with aegis.estimate_co2e_kg or aegis.run_context_estimate, query carbon-guard reserve endpoint.
+  - If reserve is denied or carbon budget insufficient, reject admission.
+  - Otherwise allow.
+Notes:
+  - This is best-effort and should be backed by Gatekeeper OPA policy in production.
+"""
+import os
+import json
+import requests
+from flask import Flask, request, jsonify
+
+CARBON_GUARD_URL = os.environ.get("CARBON_GUARD_URL", "http://aegis-carbon-guard.aegis.svc.cluster.local:8080")
+APP = Flask(__name__)
+
+def _admission_response(uid: str, allowed: bool, reason: str = ""):
+    resp = {
+        "apiVersion": "admission.k8s.io/v1",
+        "kind": "AdmissionReview",
+        "response": {
+            "uid": uid,
+            "allowed": allowed,
+        }
+    }
+    if not allowed:
+        resp["response"]["status"] = {"code": 403, "message": reason}
+    return resp
+
+@APP.route("/validate", methods=["POST"])
+def validate():
+    try:
+        review = request.get_json()
+        req = review.get("request", {})
+        uid = req.get("uid")
+        obj = req.get("object", {})
+        # Look for pod spec annotations
+        metadata = obj.get("metadata", {}) or {}
+        annotations = metadata.get("annotations", {}) or {}
+        # parse estimate if present
+        est = annotations.get("aegis.estimate_co2e_kg")
+        if not est:
+            # if no estimate, allow but recommend policy to enforce annotation presence
+            return jsonify(_admission_response(uid, True))
+        try:
+            est_val = float(est)
+        except Exception:
+            return jsonify(_admission_response(uid, False, "invalid aegis.estimate_co2e_kg"))
+        # call carbon-guard reserve endpoint
+        try:
+            r = requests.post(f"{CARBON_GUARD_URL}/reserve", json={"estimate_kg": est_val, "tenant": annotations.get("aegis.tenant","default")}, timeout=5)
+            if r.status_code == 200:
+                res = r.json()
+                if res.get("allowed", False):
+                    return jsonify(_admission_response(uid, True))
+                else:
+                    return jsonify(_admission_response(uid, False, "carbon budget exceeded"))
+            else:
+                return jsonify(_admission_response(uid, False, "carbon-guard error"))
+        except Exception as e:
+            return jsonify(_admission_response(uid, False, f"carbon-guard unreachable: {e}"))
+    except Exception as e:
+        uid = request.json.get("request", {}).get("uid", "unknown")
+        return jsonify(_admission_response(uid, False, f"admission webhook error: {e}"))
+
+if __name__ == "__main__":
+    APP.run(host="0.0.0.0", port=int(os.environ.get("PORT", "9450")))
+
*** End Patch
*** Begin Patch
*** Add File:devsecops/gatekeeper/constraint_require_run_context_and_card_signed.yaml
+apiVersion: templates.gatekeeper.sh/v1beta1
+kind: ConstraintTemplate
+metadata:
+  name: requirecontextandcardsigned
+spec:
+  crd:
+    spec:
+      names:
+        kind: RequireContextAndCardSigned
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package requirecontextandcardsigned
+        violation[{"msg": msg}] {
+          input.review.object.kind == "Deployment"
+          labels := input.review.object.metadata.labels
+          # only apply to inference deployments
+          labels["aegis.role"] == "inference"
+          ann := input.review.object.metadata.annotations
+          not ann["aegis.model_card_s3"]
+          msg := "Inference deployment missing model_card annotation (aegis.model_card_s3)"
+        }
+        violation[{"msg": msg}] {
+          input.review.object.kind == "Deployment"
+          labels := input.review.object.metadata.labels
+          labels["aegis.role"] == "inference"
+          ann := input.review.object.metadata.annotations
+          ann["aegis.model_card_signed"] != "true"
+          msg := "Inference deployment model_card is not signed (aegis.model_card_signed != true)"
+        }
+        violation[{"msg": msg}] {
+          input.review.object.kind == "Deployment"
+          labels := input.review.object.metadata.labels
+          labels["aegis.role"] == "inference"
+          ann := input.review.object.metadata.annotations
+          not ann["aegis.run_context_required"]
+          msg := "Inference deployment must indicate run context enforcement via annotation 'aegis.run_context_required'"
+        }
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/promotion_verifier_and_sign_check.yml
+name: Promotion â€” verifier and signature checks
+
+on:
+  workflow_dispatch:
+    inputs:
+      model_name:
+        description: 'Model name'
+        required: true
+      model_version:
+        description: 'Model version'
+        required: true
+
+jobs:
+  verify-and-sign-check:
+    runs-on: ubuntu-latest
+    env:
+      MODEL_NAME: ${{ github.event.inputs.model_name }}
+      MODEL_VERSION: ${{ github.event.inputs.model_version }}
+      MODEL_CONTEXT_REG_URL: ${{ secrets.MODEL_CONTEXT_REG_URL }}
+      VERIFIER_URL: ${{ secrets.VERIFIER_URL }}
+      MODEL_CARD_REG_URL: ${{ secrets.MODEL_CARD_REGISTRY_URL }}
+      COSIGN_KEY: ${{ secrets.COSIGN_KEY }}
+    steps:
+      - name: Basic checks
+        run: |
+          echo "Model: $MODEL_NAME:$MODEL_VERSION"
+      - name: Check model_card signed in registry
+        run: |
+          if [ -z "$MODEL_CARD_REG_URL" ]; then echo "No registry configured"; exit 1; fi
+          RES=$(curl -sS "$MODEL_CARD_REG_URL/cards?model_name=$MODEL_NAME")
+          SIG=$(echo "$RES" | jq -r ".[] | select(.version==\"$MODEL_VERSION\") | .signed" | head -n1)
+          if [ "$SIG" != "true" ]; then
+            echo "Model card not signed; failing"
+            exit 2
+          fi
+      - name: Run verifier on a recent run context
+        run: |
+          if [ -z "$MODEL_CONTEXT_REG_URL" ] || [ -z "$VERIFIER_URL" ]; then echo "Registry or verifier not configured; skipping"; exit 0; fi
+          RUNS=$(curl -sS "$MODEL_CONTEXT_REG_URL/search?model_name=$MODEL_NAME&limit=1")
+          RUN_ID=$(echo "$RUNS" | jq -r '.[0].run_id' || echo "")
+          if [ -z "$RUN_ID" ]; then echo "No run context found; failing"; exit 3; fi
+          echo "Running verifier for run $RUN_ID"
+          R=$(curl -sS -X POST "$VERIFIER_URL/verify_run/$RUN_ID")
+          SUPPORTED=$(echo "$R" | jq -r '.supported' || echo "false")
+          if [ "$SUPPORTED" != "true" ]; then
+            echo "Verifier did not support claim; require human approval"
+            # In your promotion flow, create an approval request here; for CI, we fail to require manual gating.
+            exit 4
+          fi
+      - name: Verify image signatures for serving image (example)
+        run: |
+          # This is an example: you must map model artifact to serving image.
+          SERVING_IMAGE="ghcr.io/${{ github.repository_owner }}/aegis-serving:latest"
+          echo "Verifying serving image signature (cosign verify)"
+          cosign verify --key "$COSIGN_KEY" "$SERVING_IMAGE" || (echo "Serving image not signed" && exit 5)
+      - name: Promotion gate passed
+        run: |
+          echo "Promotion checks passed; continue with promotion pipeline or request human approval if configured."
+
*** End Patch
*** Begin Patch
*** Add File:mcp_context/runbooks/pii_data_retention_policy.md
+# PII Handling & Retention Policy (Aegis)
+
+This document describes the recommended practice applied by the redaction middleware and retention controls.
+
+1. Redact-before-store
+ - Inference/agent runtimes MUST run inputs through mcp_context/middleware/redaction.redact_text before including raw text in any stored artifact.
+ - If raw input must be stored (for debugging), it MUST be uploaded to S3 with SSE-KMS using a restricted KMS key and kept only for a limited TTL with strict IAM access.
+
+2. Use pointers not raw PII
+ - Context JSON should include pointers (s3://...) to redacted or encrypted inputs rather than inline raw content.
+ - The pointer keys should be placed under audit/<run_id> and MLflow tags should only store the pointer, not the raw data.
+
+3. Retention TTL
+ - Default retention_ttl_days for run contexts: 90 days.
+ - For high-risk runs (contains PII), TTL = min(legal_hold, 365) or operator-defined retention.
+ - Implement lifecycle policy on S3 prefix audit/ to automatically transition and expire objects.
+
+4. Access controls
+ - Only authorized roles (auditor, security, data_steward) have access to decrypted raw inputs.
+ - Use IAM roles and S3 bucket policies to limit access; use KMS key policies to restrict decryption to specific principals.
+
+5. DSAR & deletion
+ - Implement DSAR workflow: on user request, locate run contexts referencing subject (by hash) and remove or redact as needed, honoring legal holds.
+
*** End Patch
*** Begin Patch
*** Add File:security/rekor/rekor_integration.md
+# Rekor Integration Guidance (Aegis)
+
+This file documents operator steps to ensure Rekor logging is wired into CI:
+
+1) Ensure Rekor server URL and API key (if protected) are stored in SecretsManager and exposed via ExternalSecrets (see infra/secrets/externalsecret_cosign_kms.yaml).
+2) Configure cosign to use the REKOR_PUBLIC_KEY or REKOR_URL where needed. Cosign will by default try to upload to Rekor if REKOR_SERVER is set in the environment.
+3) In CI, after cosign sign, verify with `cosign verify --key <key> <image>` and optionally inspect Rekor with `rekor-cli search --artifact <image>`.
+4) For model_card signing, use modelcard/signing/sign_model_card.py (it calls cosign) and ensure the signature is uploaded to S3; then register the signature in Rekor (operator can use Rekor CLI).
+
*** End Patch
*** End Patch
