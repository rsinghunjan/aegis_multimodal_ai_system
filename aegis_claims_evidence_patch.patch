*** Begin Patch
*** Add File: docs/CLAIM_EVIDENCE.md
+# Aegis Claim Evidence — what to collect, where it lives, and how to verify
+
+This document describes the minimal evidence artifacts and commands auditors/operators should use to validate the claim:
+
+"Aegis is a safe, auditable AI platform blueprint that helps teams build, run, and govern AI models across clouds."
+
+Store collected artifacts under the repository `artifacts/` directory (the orchestrator script does this for you). Typical artifact bundle path created by the orchestrator:
+- artifacts/run_YYYYMMDD-HHMMSS/
+- artifacts/run_YYYYMMDD-HHMMSS.tar.gz
+
+Required evidence (critical)
+1. Vault & signing artifacts
+   - File(s):
+     - artifacts/.../vault/status.txt
+     - artifacts/.../vault/policies.json
+     - artifacts/.../vault/secret_ibm.json (if IBM integrated) or equivalent secret export
+     - artifacts/.../vault/transit key outputs (if generated)
+   - How to verify:
+     - vault status
+     - vault policy list
+     - vault kv get secret/ibm
+     - vault list transit/keys
+
+2. cosign / signing & Rekor evidence
+   - File(s):
+     - Signed artifacts: any `*.sig`, `*.vault.sig`, or `*.cosign` files under artifacts/
+     - Rekor entries exported: artifacts/.../rekor_*.json or rekor CLI output
+   - How to verify:
+     - cosign verify --key <public-key> <artifact>
+     - rekor-cli search --artifact <artifact> (or use Rekor server UI)
+     - Example (if Vault transit signature present):
+       - cat artifact.vault.sig
+       - Verify signature format or query Rekor
+
+3. Terraform provisioning outputs
+   - File(s):
+     - artifacts/terraform_aws_output.json
+     - artifacts/terraform_gcp_output.json
+     - artifacts/terraform_ibm_output.json or terraform/ibm outputs saved by orchestrator
+   - How to verify:
+     - jq . <outputs.json> to inspect key ARNs / IDs
+     - Confirm resource existence in cloud consoles (KMS ARNs, TF-created service instances)
+
+4. MLflow / experiment provenance
+   - File(s):
+     - artifacts/.../mlflow (or `mlruns/` directory), or individual MLflow run export JSONs
+   - How to verify:
+     - mlflow server UI or `mlflow runs list` (using MLFLOW_TRACKING_URI from env)
+     - Check that runs contain parameters, metrics, and artifact links to signed artifacts
+
+5. Argo workflows & job outputs
+   - File(s):
+     - artifacts/argo/*.json (Argo workflow captures)
+     - artifacts/k8s/staging/* (pod logs, YAML)
+   - How to verify:
+     - argo get <workflow> --output json
+     - Inspect `status`, `outputs`, and returned artifacts
+
+6. K8s / application logs
+   - File(s):
+     - artifacts/k8s/<namespace>/*.log and *.yaml
+   - How to verify:
+     - Inspect logs for success/failure traces and MLflow/Rekor upload events
+
+7. Orchestrator runbook & artifacts
+   - Files created by orchestrator:
+     - artifacts/run_YYYY.../run_* logs and the .tar.gz
+   - How to verify:
+     - Ensure orchestrator completed and produced the tarball
+
+Optional but recommended evidence
+- Pen-test summary or remediation tickets (PDF/Markdown) placed under artifacts/security/
+- Cost-watcher outputs showing budget alerts (artifacts/cost_watcher/*.log)
+- DGX/TPU validation logs or checkpoint verification evidence
+
+Quick commands to reproduce checks (operator-run)
+- Inspect Terraform outputs:
+  - jq . artifacts/terraform_aws_output.json
+- Verify Vault secret:
+  - export VAULT_ADDR=https://vault.example.com
+  - vault login <token>
+  - vault kv get secret/ibm
+- Verify cosign/Vault-transit signature (example for Vault transit wrapper):
+  - cat artifact.bin.vault.sig
+  - # Use your Rekor or cosign verification commands as configured in your environment
+- Inspect Argo workflows:
+  - argo list -n staging
+  - argo get -n staging <workflow-name> --output json
+- Inspect MLflow runs:
+  - mlflow experiments list --tracking-uri ${MLFLOW_TRACKING_URI}
+  - mlflow runs list --experiment-id <id>
+
+Where to publish evidence links
+- Add a single `EVIDENCE.md` pointer to the repository root README that links to:
+  - the orchestrator artifact tarball(s)
+  - the Vault bootstrap log
+  - a canonical terraform outputs JSON
+  - sample cosign/Rekor verification commands and the corresponding artifacts
+
+Reducing audit friction
+- Always store orchestration artifacts in a single timestamped directory and produce a signed manifest (md5/sha256) for integrity.
+- Keep a short README inside each artifact bundle describing how to reproduce the key checks.
+
+If you want, run the provided `scripts/ci/validate_claim_evidence.sh` script to automatically check for the presence of the core artifacts described above.
+
*** End Patch
*** Begin Patch
*** Add File: README_CLAIM_BANNER.md
+# Platform Claim & Caveats (banner for top-level README)
+
+Claim
+------
+Aegis is a secure, auditable AI platform blueprint that helps teams build, run, and govern AI models across clouds — it helps organizations move powerful AI into production while keeping control, costs and compliance intact.
+
+Caveats
+-------
+- Operator-driven: Aegis is delivered as a comprehensive platform blueprint. Operators must provision cloud resources (KMS, Key Protect, COS), configure Vault, and validate tenancy-specific items as described in the runbooks.
+- Evidence-backed: The claim is supported by curated evidence collected by the orchestrator (Vault logs, cosign/Rekor signatures, Terraform outputs, MLflow runs, Argo workflow outputs). See `docs/CLAIM_EVIDENCE.md`.
+- Cloud coverage: AWS and GCP are production-validated with Terraform/CICD artifacts. IBM Cloud, Azure, OCI and other clouds are supported with native Terraform or CLI-centric flows and need tenancy validation; details in `docs/runbook_ibm_full_automation.md`.
+- Security & compliance: This repository provides tooling and runbooks to achieve secure, auditable deployment. Final regulatory claims (HIPAA, PCI, etc.) require independent audits and additional controls.
+
+Quick links
+-----------
+- Evidence & verification: docs/CLAIM_EVIDENCE.md
+- Runbook for IBM full automation: docs/runbook_ibm_full_automation.md
+- Orchestrator script (generates artifact bundle): scripts/orchestrator/run_full_end_to_end.sh
+
+Suggested placement
+-------------------
+Place this banner near the top of your top-level README (below the short project summary) so readers immediately see the platform claim plus the concise caveats and a pointer to evidence.
+
*** End Patch
*** Begin Patch
*** Add File: scripts/ci/validate_claim_evidence.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# validate_claim_evidence.sh
+#
+# Quick validator script that checks for presence of core evidence artifacts required to substantiate the
+# repository claim "Aegis is a safe, auditable AI platform...".
+#
+# Usage:
+#   scripts/ci/validate_claim_evidence.sh [--artifacts DIR] [--skip-vault] [--skip-terraform] [--skip-cosign] [--skip-mlflow] [--skip-argo]
+#
+# Exit codes:
+#   0  - all required checks passed
+#   1  - usage / missing commands
+#   2  - one or more required evidence checks failed
+#
+ARTIFACTS_DIR=${ARTIFACTS_DIR:-artifacts}
+SKIP_VAULT=false
+SKIP_TERRAFORM=false
+SKIP_COSIGN=false
+SKIP_MLFLOW=false
+SKIP_ARGO=false
+QUIET=false
+
+usage() {
+  cat <<EOF
+Usage: $0 [--artifacts DIR] [--skip-vault] [--skip-terraform] [--skip-cosign] [--skip-mlflow] [--skip-argo] [--quiet]
+EOF
+  exit 1
+}
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --artifacts) ARTIFACTS_DIR="$2"; shift 2;;
+    --skip-vault) SKIP_VAULT=true; shift;;
+    --skip-terraform) SKIP_TERRAFORM=true; shift;;
+    --skip-cosign) SKIP_COSIGN=true; shift;;
+    --skip-mlflow) SKIP_MLFLOW=true; shift;;
+    --skip-argo) SKIP_ARGO=true; shift;;
+    --quiet) QUIET=true; shift;;
+    -h|--help) usage;;
+    *) echo "Unknown arg: $1"; usage;;
+  esac
+done
+
+echo "Validating claim evidence in: $ARTIFACTS_DIR"
+failures=0
+
+report() {
+  if [ "$QUIET" = false ]; then
+    echo "$1"
+  fi
+}
+
+# Helper to find latest run dir if multiple
+find_latest_run_dir() {
+  if [ -d "$ARTIFACTS_DIR" ]; then
+    # prefer run_* directories
+    run_dirs=( $(ls -d "$ARTIFACTS_DIR"/run_* 2>/dev/null || true) )
+    if [ ${#run_dirs[@]} -gt 0 ]; then
+      echo "${run_dirs[-1]}"
+      return
+    fi
+    # fallback: first directory in artifacts
+    first_dir=$(find "$ARTIFACTS_DIR" -maxdepth 1 -type d | sed '1d' | head -n1)
+    if [ -n "$first_dir" ]; then
+      echo "$first_dir"
+      return
+    fi
+  fi
+  echo ""
+}
+
+RUN_DIR=$(find_latest_run_dir)
+report "Detected run directory: ${RUN_DIR:-<none>}"
+
+# 1) Terraform outputs check
+if [ "$SKIP_TERRAFORM" = false ]; then
+  tf_files=( $(find "$ARTIFACTS_DIR" -maxdepth 2 -type f -name "*_outputs.json" 2>/dev/null || true) )
+  if [ ${#tf_files[@]} -gt 0 ]; then
+    report "OK: Terraform outputs found:"
+    for f in "${tf_files[@]}"; do report "  - $f"; done
+  else
+    report "MISSING: Terraform outputs (expected *_outputs.json under $ARTIFACTS_DIR)."
+    failures=$((failures+1))
+  fi
+else
+  report "Skipping terraform outputs check"
+fi
+
+# 2) Vault evidence check
+if [ "$SKIP_VAULT" = false ]; then
+  vault_files=( $(find "$ARTIFACTS_DIR" -type f -path "*/vault/*" 2>/dev/null || true) )
+  if [ ${#vault_files[@]} -gt 0 ]; then
+    report "OK: Vault artifacts found (sample): ${vault_files[0]}"
+  else
+    # Try to query Vault if VAULT_ADDR & VAULT_TOKEN present
+    if command -v vault >/dev/null 2>&1 && [ -n "${VAULT_ADDR:-}" ] && [ -n "${VAULT_TOKEN:-}" ]; then
+      if vault kv get -format=json secret/ibm >/dev/null 2>&1; then
+        report "OK: Vault secret 'secret/ibm' accessible using VAULT_ADDR & VAULT_TOKEN env"
+      else
+        report "MISSING: Vault artifacts not found in $ARTIFACTS_DIR and cannot read secret/ibm from Vault"
+        failures=$((failures+1))
+      fi
+    else
+      report "MISSING: Vault evidence not present in artifacts and no Vault credentials provided to verify"
+      failures=$((failures+1))
+    fi
+  fi
+else
+  report "Skipping Vault evidence check"
+fi
+
+# 3) cosign / signing / Rekor evidence
+if [ "$SKIP_COSIGN" = false ]; then
+  sig_files=( $(find "$ARTIFACTS_DIR" -type f \( -name "*.sig" -o -name "*.vault.sig" -o -name "*.cosign" \) 2>/dev/null || true) )
+  rekor_files=( $(find "$ARTIFACTS_DIR" -type f -iname "*rekor*" 2>/dev/null || true) )
+  if [ ${#sig_files[@]} -gt 0 ] || [ ${#rekor_files[@]} -gt 0 ]; then
+    report "OK: Signing / Rekor evidence present"
+    [ ${#sig_files[@]} -gt 0 ] && report "  sample signature: ${sig_files[0]}"
+    [ ${#rekor_files[@]} -gt 0 ] && report "  sample rekor file: ${rekor_files[0]}"
+  else
+    report "MISSING: No signature (*.sig/*.vault.sig) or Rekor files found under $ARTIFACTS_DIR"
+    failures=$((failures+1))
+  fi
+else
+  report "Skipping signing/Rekor check"
+fi
+
+# 4) MLflow / experiment evidence
+if [ "$SKIP_MLFLOW" = false ]; then
+  mlflow_files=( $(find "$ARTIFACTS_DIR" -type f -iname "*mlflow*" -o -iname "mlruns" -o -iname "*mlruns*" 2>/dev/null || true) )
+  if [ ${#mlflow_files[@]} -gt 0 ]; then
+    report "OK: MLflow artifacts found (sample): ${mlflow_files[0]}"
+  else
+    report "MISSING: MLflow artifacts not found under $ARTIFACTS_DIR"
+    failures=$((failures+1))
+  fi
+else
+  report "Skipping MLflow check"
+fi
+
+# 5) Argo workflows evidence
+if [ "$SKIP_ARGO" = false ]; then
+  argo_files=( $(find "$ARTIFACTS_DIR" -type f -path "*/argo/*" -name "*.json" 2>/dev/null || true) )
+  if [ ${#argo_files[@]} -gt 0 ]; then
+    report "OK: Argo workflow JSONs found (sample): ${argo_files[0]}"
+  else
+    report "MISSING: No Argo workflow captures found under $ARTIFACTS_DIR/argo"
+    failures=$((failures+1))
+  fi
+else
+  report "Skipping Argo workflows check"
+fi
+
+# 6) K8s logs
+k8s_dirs=( $(find "$ARTIFACTS_DIR" -maxdepth 2 -type d -name "k8s" 2>/dev/null || true) )
+if [ ${#k8s_dirs[@]} -gt 0 ]; then
+  report "OK: Kubernetes logs artifacts detected under: ${k8s_dirs[0]}"
+else
+  report "WARNING: No Kubernetes logs found under $ARTIFACTS_DIR (optional but recommended)"
+fi
+
+# Final summary
+if [ "$failures" -eq 0 ]; then
+  report "VALIDATION PASS: All required evidence checks present"
+  exit 0
+else
+  report "VALIDATION FAIL: $failures required check(s) missing"
+  exit 2
+fi
+
*** End Patch
*** Begin Patch
*** Add File: marketing/MARKETING_BLURB.md
+Aegis — secure, auditable AI platform (legal‑safe blurb)
+
+Aegis is a secure, auditable AI platform blueprint designed to help teams build, run, and govern AI models across multiple clouds and heterogeneous infrastructure. It provides end‑to‑end tooling for reproducible model training (DGX/TPU), supply‑chain signing and provenance (cosign, Rekor, Vault), secrets management (Vault + KMS), multi‑vendor quantum orchestration (Braket, Cirq, Qiskit), and edge/OTA device provisioning — together with operator runbooks and CI patterns to enforce control, cost discipline, and compliance. 
+
+Note: Aegis is provided as an operator‑driven platform blueprint. Some cloud‑specific provisioning steps (e.g., IBM Key Protect tenancy configuration, COS entitlements, and HSM bridging) require tenancy validation and operator action; please consult the runbooks and evidence artifacts included in the repository before making environment‑level compliance claims.
+
*** End Patch
*** End Patch
