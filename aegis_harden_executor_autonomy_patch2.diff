diff --git a/policy/opa/agents_runtime.rego b/policy/opa/agents_runtime.rego
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/policy/opa/agents_runtime.rego
@@ -0,0 +1,220 @@
+package aegis.policies.runtime
+
+import data.models
+
+default decision = {"allow": false, "defer": false, "reason": "no-match"}
+
+# This policy augments auto-approval decisions with runtime metrics:
+# - input.metrics.canary_pass_rate (0..1)
+# - input.metrics.p95_latency (seconds)
+# - input.metrics.error_rate (fraction)
+# - input.params.estimated_cost_usd
+
+# Model budget lookup
+budget_for_model[m] = b {
+  bm := data.models.models[m]
+  b := bm.budget_usd_per_month
+}
+budget_for_model[m] = 1000 {
+  not data.models.models[m]
+}
+
+# Conservative thresholds (can be overridden via data.runtime_thresholds)
+p95_threshold(model) = t {
+  some t
+  t = data.runtime_thresholds.p95_default
+}
+
+error_rate_threshold = data.runtime_thresholds.error_rate_default
+
+# derived checks
+canary_ok {
+  input.metrics.canary_pass_rate != null
+  input.metrics.canary_pass_rate >= (data.runtime_thresholds.canary_min_pass_rate)
+}
+
+slo_ok {
+  input.metrics.p95_latency != null
+  input.metrics.p95_latency <= p95_threshold(input.model)
+  input.metrics.error_rate != null
+  input.metrics.error_rate <= error_rate_threshold
+}
+
+cost_ok {
+  input.params.estimated_cost_usd != null
+  b := budget_for_model[input.model]
+  input.params.estimated_cost_usd <= (b * data.runtime_thresholds.cost_fraction_for_auto_approve)
+}
+
+eligible_actions = {"scale_deployment","restart_deployment","retrain_non_critical"}
+
+is_eligible {
+  input.action == a
+  a := eligible_actions[_]
+  input.model
+}
+
+# auto-approve only when eligible and runtime checks pass
+auto_approve {
+  is_eligible
+  canary_ok
+  slo_ok
+  cost_ok
+}
+
+decision = {"allow": true, "defer": false, "reason": "auto-approved by runtime policy"} {
+  auto_approve
+}
+
+# Defer when eligible but runtime signals missing or marginal
+decision = {"allow": false, "defer": true, "reason": "deferred: runtime metrics missing or marginal"} {
+  is_eligible
+  not auto_approve
+}
+
+# Deny everything else (not eligible)
+decision = {"allow": false, "defer": false, "reason": "denied: action not eligible for auto-approval"} {
+  not is_eligible
+}
+
diff --git a/policy/opa/tests/agents_runtime_tests.rego b/policy/opa/tests/agents_runtime_tests.rego
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/policy/opa/tests/agents_runtime_tests.rego
@@ -0,0 +1,160 @@
+package aegis.policies.tests
+
+import data.aegis.policies.runtime
+
+test_auto_approve_when_metrics_good {
+  input := {
+    "action": "scale_deployment",
+    "model": "low-demo-model",
+    "params": {"estimated_cost_usd": 10},
+    "metrics": {"canary_pass_rate": 0.99, "p95_latency": 0.4, "error_rate": 0.001}
+  }
+  result := data.aegis.policies.runtime.decision with input as input
+  result.allow == true
+}
+
+test_defer_when_metrics_missing {
+  input := {
+    "action": "scale_deployment",
+    "model": "low-demo-model",
+    "params": {"estimated_cost_usd": 10},
+    "metrics": {}
+  }
+  result := data.aegis.policies.runtime.decision with input as input
+  result.defer == true
+}
+
+test_deny_non_eligible_action {
+  input := {
+    "action": "promote",
+    "model": "low-demo-model",
+    "params": {"estimated_cost_usd": 10},
+    "metrics": {"canary_pass_rate": 1.0, "p95_latency": 0.1, "error_rate": 0.0}
+  }
+  result := data.aegis.policies.runtime.decision with input as input
+  result.allow == false
+  result.defer == false
+}
+
diff --git a/services/executor_service/requirements.txt b/services/executor_service/requirements.txt
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/services/executor_service/requirements.txt
@@ -0,0 +1,9 @@
+Flask==2.2.5
+gunicorn==20.1.0
+requests==2.31.0
+kubernetes==26.1.0
+python-json-logger==2.0.4
+PyYAML==6.0
+PyJWT==2.8.0
+cryptography==40.0.2
+cachetools==5.3.1
diff --git a/services/executor_service/auth.py b/services/executor_service/auth.py
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/services/executor_service/auth.py
@@ -0,0 +1,260 @@
+import os
+import time
+import requests
+import jwt
+import threading
+from cachetools import TTLCache
+
+# Simple auth helpers:
+# - verify HMAC signature (X-Aegis-Signature) if EXECUTOR_HMAC_SECRET set
+# - verify JWT in Authorization: Bearer <token> using JWKS if AUTH_JWKS_URL set
+
+EXECUTOR_HMAC_SECRET = os.environ.get("EXECUTOR_HMAC_SECRET", "")
+AUTH_JWKS_URL = os.environ.get("AUTH_JWKS_URL", "")
+JWKS_CACHE = TTLCache(maxsize=2, ttl=300)
+JWKS_LOCK = threading.Lock()
+
+def get_jwks():
+    if "jwks" in JWKS_CACHE:
+        return JWKS_CACHE["jwks"]
+    with JWKS_LOCK:
+        if "jwks" in JWKS_CACHE:
+            return JWKS_CACHE["jwks"]
+        if not AUTH_JWKS_URL:
+            return None
+        r = requests.get(AUTH_JWKS_URL, timeout=5)
+        r.raise_for_status()
+        jwks = r.json()
+        JWKS_CACHE["jwks"] = jwks
+        return jwks
+
+def verify_hmac_signature(headers: dict, body_bytes: bytes) -> bool:
+    """
+    Expect header 'X-Aegis-Signature' with value 'sha256=<hex>'.
+    """
+    import hmac, hashlib
+    sig = headers.get("X-Aegis-Signature", "")
+    if not EXECUTOR_HMAC_SECRET or not sig:
+        return False
+    if sig.startswith("sha256="):
+        sig_hex = sig.split("=",1)[1]
+    else:
+        return False
+    mac = hmac.new(EXECUTOR_HMAC_SECRET.encode(), body_bytes, hashlib.sha256).hexdigest()
+    return hmac.compare_digest(mac, sig_hex)
+
+def verify_jwt_auth(authorization_header: str) -> dict:
+    """
+    Validate JWT against JWKS; returns decoded claims or raises.
+    """
+    if not authorization_header or not authorization_header.startswith("Bearer "):
+        raise ValueError("missing bearer")
+    token = authorization_header.split(" ",1)[1]
+    jwks = get_jwks()
+    if not jwks:
+        raise RuntimeError("jwks unavailable")
+    # find key
+    unverified = jwt.decode(token, options={"verify_signature": False, "verify_aud": False})
+    kid = unverified.get("kid") or unverified.get("header",{}).get("kid")
+    if not kid:
+        # fallback: try to verify with any key
+        for key in jwks.get("keys", []):
+            try:
+                pub = jwt.algorithms.RSAAlgorithm.from_jwk(json.dumps(key))
+                claims = jwt.decode(token, pub, algorithms=[key.get("alg","RS256")], options={"verify_aud": False})
+                return claims
+            except Exception:
+                continue
+        raise RuntimeError("no matching jwks key")
+    # find that kid
+    key = next((k for k in jwks.get("keys",[]) if k.get("kid")==kid), None)
+    if not key:
+        raise RuntimeError("kid not found")
+    pub = jwt.algorithms.RSAAlgorithm.from_jwk(key)
+    claims = jwt.decode(token, pub, algorithms=[key.get("alg","RS256")], options={"verify_aud": False})
+    return claims
+
+def validate_request(headers: dict, body_bytes: bytes) -> dict:
+    """
+    Validate the request using one of:
+     - HMAC signature
+     - Bearer JWT via JWKS
+    Returns a dict describing the authenticated principal (subject/claims) or raises.
+    """
+    # prefer JWKS if configured
+    auth_hdr = headers.get("Authorization", "")
+    if AUTH_JWKS_URL and auth_hdr:
+        claims = verify_jwt_auth(auth_hdr)
+        return {"principal": claims.get("sub") or claims.get("email") or claims}
+    # else try HMAC
+    if EXECUTOR_HMAC_SECRET:
+        ok = verify_hmac_signature(headers, body_bytes)
+        if ok:
+            return {"principal": "hmac-client"}
+        else:
+            raise RuntimeError("hmac verification failed")
+    # fallback: no auth configured -> reject
+    raise RuntimeError("no auth configured on executor")
+
diff --git a/services/executor_service/main.py b/services/executor_service/main.py
index 0000000..2222222
--- /dev/null
+++ b/services/executor_service/main.py
@@ -0,0 +1,420 @@
+#!/usr/bin/env python3
+"""
+Hardened executor service (updated):
+ - Uses auth.validate_request to support JWKS or HMAC signed requests
+ - Restricts allowed actions and checks ALLOWED_RESOURCES env for scoping
+ - Emits richer Prometheus metrics
+"""
+import os
+import json
+import time
+from functools import wraps
+from flask import Flask, request, jsonify, abort
+from python_json_logger import jsonlogger
+import logging
+
+from auth import validate_request
+
+AUTH_TOKEN = os.environ.get("EXECUTOR_AUTH_TOKEN", "")
+OPA_URL = os.environ.get("OPA_URL", "http://opa:8181")
+ALLOWED_RESOURCES = os.environ.get("ALLOWED_RESOURCES", "")  # comma-separated "namespace:deployment,..."
+
+app = Flask(__name__)
+handler = logging.StreamHandler()
+handler.setFormatter(jsonlogger.JsonFormatter())
+app.logger.addHandler(handler)
+app.logger.setLevel(logging.INFO)
+
+try:
+    from tools.decisionlog_client import insert_decision
+except Exception:
+    def insert_decision(agent, action, payload, evidence):
+        app.logger.info("decision_log stub", extra={"agent": agent, "action": action, "payload": payload, "evidence": evidence})
+        return None
+
+try:
+    from kubernetes import client, config
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    k8s_apps = client.AppsV1Api()
+    k8s_core = client.CoreV1Api()
+except Exception as e:
+    app.logger.warning("kubernetes client not available: %s", e)
+    k8s_apps = None
+    k8s_core = None
+
+# Metrics (simple counters)
+METRICS = {
+    "approvals_total": 0,
+    "denials_total": 0,
+    "deferred_total": 0,
+    "executions_total": 0,
+    "executions_by_action": {},
+}
+
+def inc_metric(name, action=None):
+    if action:
+        METRICS["executions_by_action"].setdefault(action, 0)
+        METRICS["executions_by_action"][action] += 1
+    else:
+        METRICS[name] = METRICS.get(name, 0) + 1
+
+def check_scope(params):
+    """
+    Ensure requested namespace:deployment appears in ALLOWED_RESOURCES (if configured)
+    ALLOWED_RESOURCES format: "ns:deploy,ns2:deploy2"
+    """
+    if not ALLOWED_RESOURCES:
+        return True
+    allowed = [s.strip() for s in ALLOWED_RESOURCES.split(",") if s.strip()]
+    target = f"{params.get('namespace')}:{params.get('name')}"
+    return target in allowed
+
+def opa_evaluate(input_obj):
+    try:
+        import requests
+        resp = requests.post(f"{OPA_URL}/v1/data/aegis/policies/auto_approval/result", json={"input": input_obj}, timeout=10)
+        resp.raise_for_status()
+        return resp.json().get("result", {})
+    except Exception as e:
+        app.logger.error("OPA eval failed: %s", e)
+        return None
+
+def safe_scale(namespace, name, replicas):
+    if not k8s_apps:
+        raise RuntimeError("kubernetes client not configured")
+    body = {"spec": {"replicas": int(replicas)}}
+    res = k8s_apps.patch_namespaced_deployment_scale(name, namespace, body)
+    return res.to_dict()
+
+def safe_restart_deployment(namespace, name):
+    if not k8s_apps:
+        raise RuntimeError("kubernetes client not configured")
+    body = {"spec": {"template": {"metadata": {"annotations": {"aegis-restart-ts": str(int(time.time()))}}}}}
+    res = k8s_apps.patch_namespaced_deployment(name, namespace, body)
+    return res.to_dict()
+
+ALLOWED_ACTIONS = {
+    "scale_deployment": {"handler": safe_scale, "required": ["namespace", "name", "replicas"]},
+    "restart_deployment": {"handler": safe_restart_deployment, "required": ["namespace", "name"]},
+}
+
+def require_auth(f):
+    @wraps(f)
+    def wrapper(*args, **kwargs):
+        # read raw body for HMAC verification
+        body_bytes = request.get_data() or b""
+        try:
+            principal = validate_request(request.headers, body_bytes)
+            request.environ["aegis_principal"] = principal
+        except Exception as e:
+            app.logger.warning("auth failed: %s", e)
+            return jsonify({"ok": False, "error": "auth_failed", "detail": str(e)}), 401
+        return f(*args, **kwargs)
+    return wrapper
+
+@app.route("/healthz")
+def healthz():
+    return "ok", 200
+
+@app.route("/metrics")
+def metrics():
+    lines = []
+    for k, v in METRICS.items():
+        if k == "executions_by_action":
+            for act, c in v.items():
+                lines.append(f'aegis_executor_executions_by_action{{action="{act}"}} {c}')
+        else:
+            lines.append(f"aegis_executor_{k} {v}")
+    return "\n".join(lines), 200, {"Content-Type": "text/plain; version=0.0.4"}
+
+@app.route("/execute", methods=["POST"])
+@require_auth
+def execute():
+    payload = request.get_json(force=True)
+    app.logger.info("execute request", extra={"payload": payload})
+
+    # scope check
+    params = payload.get("params", {}) or {}
+    if not check_scope(params):
+        METRICS["denials_total"] += 1
+        insert_decision("executor", "deny_scope", payload, {"reason": "out_of_scope"})
+        return jsonify({"ok": False, "reason": "out_of_scope"}), 403
+
+    opa_result = opa_evaluate(payload)
+    if opa_result is None:
+        METRICS["denials_total"] += 1
+        insert_decision("executor", "evaluate_failed", payload, {"error": "opa_unreachable"})
+        return jsonify({"ok": False, "reason": "policy_eval_failed"}), 503
+
+    if opa_result.get("allow"):
+        action = payload.get("action")
+        if action not in ALLOWED_ACTIONS:
+            METRICS["denials_total"] += 1
+            insert_decision("executor", "deny", payload, {"reason": "action_not_allowed"})
+            return jsonify({"ok": False, "reason": "action_not_allowed"}), 403
+        # validate params
+        for r in ALLOWED_ACTIONS[action]["required"]:
+            if r not in params:
+                METRICS["denials_total"] += 1
+                insert_decision("executor", "deny", payload, {"reason": f"missing_param:{r}"})
+                return jsonify({"ok": False, "reason": f"missing_param:{r}"}), 400
+
+        try:
+            handler = ALLOWED_ACTIONS[action]["handler"]
+            if action == "scale_deployment":
+                res = handler(params["namespace"], params["name"], params["replicas"])
+            else:
+                res = handler(params["namespace"], params["name"])
+            METRICS["executions_total"] += 1
+            inc_metric("executions_total")
+            inc_metric("executions_by_action", action)
+            insert_decision("executor", "executed", payload, {"result": "success"})
+            return jsonify({"ok": True, "result": "executed"}), 200
+        except Exception as e:
+            METRICS["denials_total"] += 1
+            insert_decision("executor", "execution_failed", payload, {"error": str(e)})
+            app.logger.exception("execution failed")
+            return jsonify({"ok": False, "reason": "execution_failed", "error": str(e)}), 500
+
+    elif opa_result.get("defer"):
+        METRICS["deferred_total"] += 1
+        insert_decision("executor", "deferred", payload, {"reason": opa_result.get("reason"), "timeout": opa_result.get("timeout_seconds")})
+        return jsonify({"ok": False, "deferred": True, "timeout_seconds": opa_result.get("timeout_seconds")}), 202
+    else:
+        METRICS["denials_total"] += 1
+        insert_decision("executor", "deny", payload, {"reason": opa_result.get("reason")})
+        return jsonify({"ok": False, "denied": True, "reason": opa_result.get("reason")}), 403
+
+if __name__ == "__main__":
+    bind = os.environ.get("LISTEN_ADDR", "0.0.0.0:8080")
+    app.logger.info("Starting hardened executor on %s", bind)
+    from werkzeug.middleware.proxy_fix import ProxyFix
+    app.wsgi_app = ProxyFix(app.wsgi_app)
+    app.run(host="0.0.0.0", port=int(bind.split(":")[-1]), debug=False)
+
diff --git a/k8s/manifests/executor_deployment_secure.yaml b/k8s/manifests/executor_deployment_secure.yaml
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/k8s/manifests/executor_deployment_secure.yaml
@@ -0,0 +1,260 @@
+apiVersion: v1
+kind: Secret
+metadata:
+  name: aegis-executor-secret
+  namespace: aegis-ml
+type: Opaque
+stringData:
+  token: "<replace-with-short-lived-token-or-rotation-mechanism>"
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: aegis-executor-role
+  namespace: aegis-ml
+rules:
+  - apiGroups: ["apps"]
+    resources: ["deployments/scale","deployments"]
+    resourceNames: ["aegis-vllm","aegis-canary"]  # restrict to specific deployments
+    verbs: ["get","list","patch"]
+  - apiGroups: [""]
+    resources: ["pods"]
+    verbs: ["get","list"]
+
+---
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-executor
+  namespace: aegis-ml
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: aegis-executor
+  template:
+    metadata:
+      labels:
+        app: aegis-executor
+    spec:
+      serviceAccountName: aegis-executor-sa
+      containers:
+        - name: executor
+          image: <REGISTRY>/aegis-executor:latest
+          env:
+            - name: EXECUTOR_HMAC_SECRET
+              valueFrom:
+                secretKeyRef:
+                  name: aegis-executor-secret
+                  key: token
+            - name: AUTH_JWKS_URL
+              value: "https://auth.example.com/.well-known/jwks.json"
+            - name: ALLOWED_RESOURCES
+              value: "aegis-ml:aegis-vllm,aegis-ml:aegis-canary"
+            - name: OPA_URL
+              value: "http://opa.aegis-ml.svc.cluster.local:8181"
+          ports:
+            - containerPort: 8080
+          readinessProbe:
+            httpGet:
+              path: /healthz
+              port: 8080
+            initialDelaySeconds: 10
+            periodSeconds: 10
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-executor
+  namespace: aegis-ml
+spec:
+  selector:
+    app: aegis-executor
+  ports:
+    - name: http
+      port: 8080
+      targetPort: 8080
+
diff --git a/tools/chaos_rollback_test.py b/tools/chaos_rollback_test.py
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/tools/chaos_rollback_test.py
@@ -0,0 +1,280 @@
+#!/usr/bin/env python3
+"""
+Chaos & rollback automated test:
+ - Introduces pod deletions and latency injections (best-effort)
+ - Waits for compensation_controller to detect SLO breach and call executor
+ - Validates that decision_log received executor invocation entries
+
+This script is a best-effort orchestrator for staging. It relies on:
+ - kubectl available
+ - access to decision_log DB or tools.decisionlog_client
+ - compensation_controller running
+"""
+import os
+import time
+import subprocess
+import json
+
+try:
+    from tools.decisionlog_client import query_decision_log_last
+except Exception:
+    def query_decision_log_last(limit=10):
+        print("decision_log stub: unable to query")
+        return []
+
+NAMESPACE = os.environ.get("NAMESPACE", "aegis-ml")
+TARGET_DEPLOYMENT = os.environ.get("TARGET_DEPLOYMENT", "aegis-vllm")
+SLEEP_AFTER_INJECTION = int(os.environ.get("SLEEP_AFTER_INJECTION", "120"))
+
+def kill_some_pods(n=1):
+    out = subprocess.check_output(["kubectl","-n",NAMESPACE,"get","pods","-l","app=aegis-vllm","-o","jsonpath={.items[*].metadata.name}"])
+    pods = out.decode().strip().split()
+    victims = pods[:n]
+    for p in victims:
+        print("Deleting pod", p)
+        subprocess.call(["kubectl","-n",NAMESPACE,"delete","pod",p,"--grace-period=0","--force"])
+
+def inject_latency():
+    # Placeholder: use an app-level injector or sidecar; here we patch deployment with annotation to enable ingress fault
+    print("Annotating deployment to simulate latency (operator must implement respect)")
+    subprocess.call(["kubectl","-n",NAMESPACE,"patch","deployment",TARGET_DEPLOYMENT,"-p","{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"aegis-inject-latency\":\"true\"}}}}}"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
+
+def revert_injection():
+    subprocess.call(["kubectl","-n",NAMESPACE,"patch","deployment",TARGET_DEPLOYMENT,"-p","{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"aegis-inject-latency\":null}}}}}"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
+
+def wait_for_compensation_event(timeout=300):
+    print("Waiting for compensation event in decision_log")
+    start = time.time()
+    while time.time() - start < timeout:
+        entries = query_decision_log_last(20)
+        for e in entries:
+            # naive matching
+            if "compensation_controller" in json.dumps(e).lower() or "executor" in json.dumps(e).lower():
+                print("Found compensation-related decision_log entry:", e)
+                return True
+        time.sleep(10)
+    return False
+
+def main():
+    print("Starting chaos rollback test against", TARGET_DEPLOYMENT)
+    kill_some_pods(n=1)
+    time.sleep(10)
+    inject_latency()
+    print("Sleeping to allow controller detect and act:", SLEEP_AFTER_INJECTION)
+    time.sleep(SLEEP_AFTER_INJECTION)
+    found = wait_for_compensation_event(timeout=300)
+    revert_injection()
+    if found:
+        print("Compensation detected -> PASS")
+        return 0
+    else:
+        print("No compensation detected -> FAIL")
+        return 2
+
+if __name__ == "__main__":
+    import sys
+    sys.exit(main())
+
diff --git a/tools/compensation_tuner.py b/tools/compensation_tuner.py
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/tools/compensation_tuner.py
@@ -0,0 +1,260 @@
+#!/usr/bin/env python3
+"""
+Compensation tuner:
+ - Queries Prometheus for recent SLO metrics
+ - Suggests thresholds for compensation_controller to act earlier/later
+ - Produces JSON suggestions for SLO thresholds (p95, error_rate)
+
+Usage:
+  PROM_URL=http://prometheus-operated.monitoring.svc.cluster.local:9090 python3 tools/compensation_tuner.py --lookback 60m
+"""
+import requests
+import os
+import argparse
+import statistics
+import time
+
+PROM_URL = os.environ.get("PROM_URL", "http://prometheus-operated.monitoring.svc.cluster.local:9090")
+
+def query_prom(expr):
+    r = requests.get(f"{PROM_URL}/api/v1/query", params={"query": expr}, timeout=10)
+    r.raise_for_status()
+    data = r.json()
+    if data.get("status") != "success":
+        return []
+    return data.get("data", {}).get("result", [])
+
+def sample_p95_over_range(range_m="5m"):
+    expr = f"histogram_quantile(0.95, sum(rate(aegis_inference_request_latency_seconds_bucket[{range_m}])) by (le))"
+    res = query_prom(expr)
+    vals = []
+    for r in res:
+        for v in r.get("value", []):
+            try:
+                vals.append(float(v))
+            except:
+                pass
+    return vals
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--lookback", default="5m")
+    args = p.parse_args()
+    vals = sample_p95_over_range(args.lookback)
+    if not vals:
+        print("No samples")
+        return 2
+    median = statistics.median(vals)
+    p95 = sorted(vals)[int(len(vals)*0.95)] if vals else median
+    suggestion = {"observed_median_p95": median, "observed_p95": p95, "suggested_compensation_p95_threshold": max(0.5, p95 * 0.9)}
+    print(suggestion)
+    return 0
+
+if __name__ == "__main__":
+    main()
+
diff --git a/ui/auditor_dashboard.py b/ui/auditor_dashboard.py
index 0000000..7777777
--- /dev/null
+++ b/ui/auditor_dashboard.py
@@ -0,0 +1,340 @@
+#!/usr/bin/env python3
+"""
+Auditor UI (enhanced):
+ - Requires JWT authentication (Authorization: Bearer <token>) using JWKS URL set in AUTH_JWKS_URL
+ - Pagination for pending approvals
+ - Approve endpoint that records approval in decision_log (requires authentication)
+
+Env:
+ - DECISIONLOG_DB_DSN
+ - AUTH_JWKS_URL
+"""
+import os
+import json
+import time
+from flask import Flask, jsonify, request, abort
+import psycopg2
+import psycopg2.extras
+import requests
+import jwt
+
+DSN = os.environ.get("DECISIONLOG_DB_DSN")
+AUTH_JWKS_URL = os.environ.get("AUTH_JWKS_URL")
+PAGE_SIZE = int(os.environ.get("PAGE_SIZE", "50"))
+
+app = Flask(__name__)
+
+def get_conn():
+    if not DSN:
+        raise RuntimeError("DECISIONLOG_DB_DSN not set")
+    return psycopg2.connect(DSN, cursor_factory=psycopg2.extras.RealDictCursor)
+
+JWKS_CACHE = {"jwks": None, "fetched": 0}
+
+def get_jwks():
+    if JWKS_CACHE["jwks"] and (time.time() - JWKS_CACHE["fetched"] < 300):
+        return JWKS_CACHE["jwks"]
+    if not AUTH_JWKS_URL:
+        raise RuntimeError("AUTH_JWKS_URL not configured")
+    r = requests.get(AUTH_JWKS_URL, timeout=5)
+    r.raise_for_status()
+    JWKS_CACHE["jwks"] = r.json()
+    JWKS_CACHE["fetched"] = time.time()
+    return JWKS_CACHE["jwks"]
+
+def require_jwt(f):
+    def wrapper(*args, **kwargs):
+        auth = request.headers.get("Authorization", "")
+        if not auth.startswith("Bearer "):
+            abort(401)
+        token = auth.split(" ",1)[1]
+        jwks = get_jwks()
+        # naive verification: try each key
+        verified = False
+        for key in jwks.get("keys", []):
+            try:
+                pub = jwt.algorithms.RSAAlgorithm.from_jwk(json.dumps(key))
+                claims = jwt.decode(token, pub, algorithms=[key.get("alg","RS256")], options={"verify_aud": False})
+                request.environ["aegis_user"] = claims.get("sub") or claims.get("email") or claims
+                verified = True
+                break
+            except Exception:
+                continue
+        if not verified:
+            abort(401)
+        return f(*args, **kwargs)
+    wrapper.__name__ = f.__name__
+    return wrapper
+
+@app.route("/healthz")
+def healthz():
+    return "ok", 200
+
+@app.route("/pending")
+@require_jwt
+def pending():
+    page = int(request.args.get("page", "1"))
+    size = int(request.args.get("size", str(PAGE_SIZE)))
+    offset = (page-1)*size
+    conn = get_conn()
+    with conn.cursor() as cur:
+        cur.execute("""
+            SELECT id, created_at, agent, payload, evidence
+            FROM decision_log
+            WHERE payload->>'action' IS NOT NULL
+              AND (evidence->>'status' IS NULL OR evidence->>'status' = 'deferred' OR evidence->>'status' = 'pending')
+            ORDER BY created_at DESC
+            LIMIT %s OFFSET %s
+        """, (size, offset))
+        rows = cur.fetchall()
+        cur.execute("SELECT count(1) FROM decision_log WHERE payload->>'action' IS NOT NULL AND (evidence->>'status' IS NULL OR evidence->>'status' = 'deferred' OR evidence->>'status' = 'pending')")
+        total = cur.fetchone()[0]
+    conn.close()
+    return jsonify({"items": rows, "page": page, "size": size, "total": total})
+
+@app.route("/approve", methods=["POST"])
+@require_jwt
+def approve():
+    data = request.get_json(force=True)
+    dec_id = data.get("id")
+    approver = request.environ.get("aegis_user", "auditor")
+    if not dec_id:
+        return jsonify({"ok": False, "error": "id required"}), 400
+    conn = get_conn()
+    with conn.cursor() as cur:
+        cur.execute("INSERT INTO decision_log (agent, payload, evidence) VALUES (%s, %s, %s) RETURNING id", ("auditor-ui", json.dumps({"approved_id": dec_id, "approver": approver}), json.dumps({"status": "approved", "approver": approver})))
+        new_id = cur.fetchone()[0]
+        conn.commit()
+    conn.close()
+    return jsonify({"ok": True, "id": new_id})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", "8081")))
+
diff --git a/docs/AUTONOMY_HARDENING_RUNBOOK.md b/docs/AUTONOMY_HARDENING_RUNBOOK.md
new file mode 100644
index 0000000..aaaaaaaa
--- /dev/null
+++ b/docs/AUTONOMY_HARDENING_RUNBOOK.md
@@ -0,0 +1,320 @@
+# Autonomy Hardening & Policy Reach â€” Runbook
+
+This patch implements several production hardening measures:
+ - Extended Rego policy (policy/opa/agents_runtime.rego) that evaluates runtime metrics (canary pass rate, p95, error rate, cost) for auto-approval decisions.
+ - Executor security hardening: JWT (JWKS) or HMAC signed requests, ALLOWED_RESOURCES scoping, more granular RBAC via executor_deployment_secure.yaml.
+ - Chaos & rollback automated test harness (tools/chaos_rollback_test.py) to exercise compensation_controller and executor.
+ - Compensation tuner (tools/compensation_tuner.py) that queries Prometheus and suggests thresholds for auto-compensation.
+ - Auditor UI improvement with JWT auth and pagination (ui/auditor_dashboard.py).
+
+Deployment checklist (recommended order)
+1. Apply OPA runtime policy and tune data.runtime_thresholds in OPA data (canary_min_pass_rate, p95_default, error_rate_default, cost_fraction_for_auto_approve).
+2. Build/push executor image with auth.py and main.py changes; create aegis-executor-secret and set EXECUTOR_HMAC_SECRET or AUTH_JWKS_URL + rotate token mechanism.
+3. Apply k8s/manifests/executor_deployment_secure.yaml (ensure resourceNames list matches allowed target deployments).
+4. Deploy compensation_controller and configure SLO queries; run tools/compensation_tuner.py to set thresholds.
+5. Deploy the enhanced auditor UI and secure it behind OIDC (AUTH_JWKS_URL).
+6. Run tools/chaos_rollback_test.py in staging and confirm compensation_controller triggers and executor performs actions. Inspect decision_log for audit trail.
+
+Operational notes
+- JWKS-based JWT verification is preferred for short-lived tokens issued by your IdP; HMAC is acceptable for CI-to-executor signed payloads but rotate secrets frequently.
+- Limit ALLOWED_RESOURCES to the minimal set required.
+- The executor emits simple Prometheus-friendly metrics at /metrics; ensure Prometheus scrapes the service.
+- The auditor UI must be placed behind authentication and should only be accessible by auditors (use OIDC & RBAC).
+
+Next steps
+- Integrate request signing (JWS) with the orchestrator so payloads cannot be tampered with.
+- Replace the simple JWKS verification with full token introspection + audience checks.
+- Add end-to-end tests that validate rollback behavior under multiple failure modes (pod kill, network partition, node drain).
+
+End of runbook.
+
