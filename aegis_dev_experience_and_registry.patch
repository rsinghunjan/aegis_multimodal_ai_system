*** Begin Patch
*** Add File:demo/e2e_demo/Makefile
+.PHONY: all build sbom sca manifest sign upload evidence clean demo
+
+all: demo
+
+build:
+	python3 build_model.py
+
+sbom:
+	# generate SBOM (requires syft installed)
+	syft packages dir:./out -o spdx-json > out/sbom.spdx.json || true
+
+sca:
+	# run Trivy SCA (requires trivy installed)
+	trivy fs --format json --output out/trivy_report.json --severity HIGH,CRITICAL out || true
+
+manifest:
+	python3 make_manifest.py
+
+sign:
+	# Cosign signing placeholder: requires COSIGN_KMS_KEY_ARN env + cosign installed
+	if [ -z "$$COSIGN_KMS_KEY_ARN" ]; then echo "COSIGN_KMS_KEY_ARN not set; skipping cosign"; else cosign sign --key "awskms://$$COSIGN_KMS_KEY_ARN" --rekor-url "$$REKOR_URL" out/manifest.json || true; fi
+
+upload:
+	# Upload artifacts to S3 if configured (requires AWS creds)
+	if [ -n "$$MODEL_ARTIFACT_BUCKET" ]; then aws s3 cp out/model.bin s3://$$MODEL_ARTIFACT_BUCKET/artifacts/model.bin || true; aws s3 cp out/manifest.json s3://$$MODEL_ARTIFACT_BUCKET/artifacts/manifest.json || true; fi
+
+evidence:
+	python3 ../scripts/evidence/attach_and_sign.py --manifest out/manifest.json --out out/evidence.tgz
+
+demo: build sbom sca manifest sign upload evidence
+
+clean:
+	rm -rf out
+
*** End Patch
*** Begin Patch
*** Add File:demo/e2e_demo/build_model.py
+import os
+os.makedirs("out", exist_ok=True)
+with open("out/model.bin","wb") as f:
+    f.write(b"DEMO_MODEL_CONTENT")
+print("Wrote out/model.bin")
+
*** End Patch
*** Begin Patch
*** Add File:demo/e2e_demo/make_manifest.py
+import json, hashlib, time
+sha=""
+with open("out/model.bin","rb") as f:
+    sha=hashlib.sha256(f.read()).hexdigest()
+manifest = {
+  "artifact": "model.bin",
+  "version": "demo-0.1",
+  "format": "bin",
+  "sha256": sha,
+  "sbom": "sbom.spdx.json",
+  "trivy_report": "trivy_report.json",
+  "provenance": {"git_sha":"","build_time":time.time(),"builder":"demo-make"}
+}
+with open("out/manifest.json","w") as f:
+    json.dump(manifest,f,indent=2)
+print("Wrote out/manifest.json")
+
*** End Patch
*** Begin Patch
*** Add File:demo/e2e_demo/README.md
+Demo: Minimal end-to-end (local) for Aegis model lifecycle
+
+Prereqs:
+- Python 3
+- syft (optional), trivy (optional), cosign (optional), aws CLI (optional)
+- The repo includes scripts/evidence/attach_and_sign.py which the demo will call
+
+Quickstart:
+1. cd demo/e2e_demo
+2. export MODEL_ARTIFACT_BUCKET=<your-bucket> (optional)
+3. export COSIGN_KMS_KEY_ARN=arn:aws:kms:... (optional)
+4. make demo
+
+What it does:
+- build a tiny model artifact into out/
+- generate SBOM and Trivy SCA if tools are present
+- create a manifest (sha, provenance)
+- optionally sign with cosign KMS and upload artifacts
+- bundle evidence and sign (using scripts/evidence/attach_and_sign.py)
+
+Use this to validate your developer flow end-to-end before wiring into CI/Argo.
+
*** End Patch
*** Begin Patch
*** Add File:docs/OPS_SIMPLIFY_ROADMAP.md
+# Aegis Roadmap: Simplify Ops by Moving to Managed Services (Executive & Engineering Guidance)
+
+Goal
+- Reduce operational overhead and increase reliability by migrating self-managed components to managed services while preserving security, auditability and evidence flows.
+
+Priority targets (in order)
+1. Rekor DB -> Amazon RDS (Postgres) — provides automated backups, Multi‑AZ and storage encryption.
+2. MongoDB -> Atlas (already scaffolded) — use Private Endpoints / VPC peering.
+3. Kafka -> Amazon MSK or Confluent Cloud — reduces SRE burden for Kafka.
+4. Couchbase -> Capella if you require managed sync/capabilities; otherwise keep operator for specialized needs.
+5. Elasticsearch -> Managed (OpenSearch Service / Elastic Cloud) for SIEM ingestion.
+
+Phased migration plan (weeks)
+- Week 1: Provision managed endpoints in staging, establish VPC peering and network routing, update k8s secrets with connection strings.
+- Week 2: Dual‑write (or replicate) data where necessary; verify parity and run smoke tests.
+- Week 3: Switch read traffic, monitor metrics, run restore drills from managed backup to ensure RPO/RTO.
+- Week 4: Decommission self-managed cluster after validation wave.
+
+Key considerations & checklist
+- Networking: VPC peering, routing, security groups, private endpoints — avoid public internet.
+- Secrets: store managed endpoints in k8s secrets and rotate credentials with Vault.
+- Auditing: ensure managed backups are exportable; schedule periodic exports into EVIDENCE_BUCKET (object-lock).
+- Cost: track costs and set budgets/alerts. Managed services trade operational cost for provider cost.
+- Compliance: ensure managed provider meets regulatory requirements (SOC2, FedRAMP, ISO) as needed.
+
+Automation & infra
+- Use Terraform modules (examples included) to provision Atlas/MSK/RDS and capture outputs to CI & k8s secrets.
+- Maintain IaC for both managed and self-managed artifacts to enable reproducible rollbacks.
+
+Rollback strategy
+- Keep self‑managed clusters in read-only mode until the managed path proves reliable for >1 week under load.
+- Keep backup snapshots for both systems during migration window.
+
+Recommendation
+- Start with Rekor -> RDS and MongoDB -> Atlas migrations to improve reliability for critical security and metadata stores.
+
*** End Patch
*** Begin Patch
*** Add File:registry/api/main.py
+from fastapi import FastAPI, HTTPException
+from pydantic import BaseModel
+from typing import List
+import os
+from pymongo import MongoClient
+import json
+
+app = FastAPI(title="Aegis Model Registry")
+MONGO_URI = os.environ.get("MONGO_URI","mongodb://localhost:27017")
+client = MongoClient(MONGO_URI)
+db = client.get_database("aegis")
+
+class Artifact(BaseModel):
+    artifact_id: str
+    git_sha: str
+    manifest_s3: str
+    created_at: float
+
+@app.get("/artifacts", response_model=List[Artifact])
+def list_artifacts(limit: int = 50):
+    docs = list(db.artifacts.find().sort("created_at",-1).limit(limit))
+    for d in docs:
+        d["artifact_id"] = d.get("artifact_id","")
+        d["git_sha"] = d.get("git_sha","")
+        d["manifest_s3"] = d.get("manifest_s3","")
+        d["created_at"] = d.get("created_at",0)
+        d["_id"] = str(d["_id"])
+    return docs
+
+@app.get("/artifact/{artifact_id}")
+def get_artifact(artifact_id: str):
+    doc = db.artifacts.find_one({"artifact_id": artifact_id})
+    if not doc:
+        raise HTTPException(status_code=404, detail="Not found")
+    # return doc and evidence references
+    evidence = list(db.evidence.find({"artifact_id": artifact_id}))
+    doc["_id"] = str(doc["_id"])
+    return {"artifact": doc, "evidence": evidence}
+
+@app.post("/artifact", status_code=201)
+def create_artifact(a: Artifact):
+    db.artifacts.insert_one(a.dict())
+    return {"status":"ok"}
+
+@app.get("/health")
+def health():
+    return {"status":"ok"}
+
*** End Patch
*** Begin Patch
*** Add File:registry/api/requirements.txt
+fastapi
+uvicorn[standard]
+pymongo
+pydantic
+
*** End Patch
*** Begin Patch
*** Add File:registry/api/Dockerfile
+FROM python:3.10-slim
+WORKDIR /app
+COPY requirements.txt /app/requirements.txt
+RUN pip install --no-cache-dir -r /app/requirements.txt
+COPY main.py /app/main.py
+EXPOSE 8080
+CMD ["uvicorn","main:app","--host","0.0.0.0","--port","8080"]
+
*** End Patch
*** Begin Patch
*** Add File:registry/k8s/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-registry
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: aegis-registry
+  template:
+    metadata:
+      labels:
+        app: aegis-registry
+    spec:
+      containers:
+        - name: registry
+          image: registry.example.com/aegis/registry:latest
+          env:
+            - name: MONGO_URI
+              valueFrom:
+                secretKeyRef:
+                  name: mongodb-connection
+                  key: MONGO_URI
+          ports:
+            - containerPort: 8080
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-registry
+  namespace: aegis
+spec:
+  selector:
+    app: aegis-registry
+  ports:
+    - port: 80
+      targetPort: 8080
+
*** End Patch
*** Begin Patch
*** Add File:registry/ui/index.html
+<!doctype html>
+<html>
+<head><meta charset="utf-8"><title>Aegis Model Registry</title></head>
+<body>
+  <h1>Aegis Model Registry</h1>
+  <div id="list">Loading...</div>
+  <script>
+    async function fetchList(){
+      const res = await fetch('/api/artifacts');
+      const data = await res.json();
+      const out = data.map(a => `<div><strong>${a.artifact_id}</strong> - ${new Date(a.created_at*1000).toISOString()} - ${a.manifest_s3}</div>`).join('');
+      document.getElementById('list').innerHTML = out || 'No artifacts';
+    }
+    fetchList();
+  </script>
+</body>
+</html>
+
*** End Patch
*** Begin Patch
*** Add File:registry/README.md
+# Aegis Model Registry (minimal)
+
+This is a simple FastAPI-backed model registry that stores artifact metadata in MongoDB and exposes:
+- GET /artifacts (list)
+- GET /artifact/{artifact_id} (detail)
+- POST /artifact (insert)
+
+Deployment:
+1. Build container: docker build -t registry.example.com/aegis/registry:latest -f registry/api/Dockerfile registry/api
+2. Push and update k8s deployment image in registry/k8s/deployment.yaml
+3. Ensure secret mongodb-connection exists in aegis namespace with key MONGO_URI
+4. kubectl apply -f registry/k8s/deployment.yaml
+
+UI:
+- Registry UI is a static HTML in registry/ui/index.html; serve it via a simple nginx or via the registry service (proxy).
+
*** End Patch
*** Begin Patch
*** Add File:dashboards/grafana/sample_simple_dashboard.json
+{
+  "dashboard": {
+    "id": null,
+    "title": "Aegis: Model Metrics (example)",
+    "panels": [
+      {
+        "type": "text",
+        "title": "Notes",
+        "gridPos": {"x":0,"y":0,"w":24,"h":3},
+        "options": {"content":"This is a sample dashboard. Connect Prometheus metrics exporters for real data."}
+      }
+    ]
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:README_DEVELOPER_ONBOARDING.md
+# Developer Onboarding: Minimal E2E + Registry + Ops Simplification
+
+What you get in this patch:
+- demo/e2e_demo: a local Makefile-driven demo that builds a tiny model, generates SBOM/SCA (if tools present), makes a manifest, optionally signs, uploads and bundles evidence.
+- registry/: a minimal FastAPI model registry and a small static UI to list artifacts; k8s manifests for deployment.
+- docs/OPS_SIMPLIFY_ROADMAP.md: a concise roadmap and checklist to move to managed services.
+- dashboards/: a sample Grafana JSON placeholder for quick dashboards.
+
+How to run the demo locally:
+1. cd demo/e2e_demo
+2. Install syft/trivy/cosign if you want full steps; otherwise the demo will still create model and manifest
+3. make demo
+4. Inspect out/ evidence bundles, and optionally upload outputs to your configured S3 buckets
+
+How to run the registry locally:
+1. cd registry/api
+2. docker build -t aegis-registry:local -f Dockerfile .
+3. docker run -e MONGO_URI="mongodb://localhost:27017" -p 8080:8080 aegis-registry:local
+4. Visit http://localhost:8080/docs for API docs; serve registry/ui/index.html from any static web server for a small UI
+
+Next steps I can do for you:
+- Wire the registry to the Argo promotion workflow so promotions automatically create registry entries.
+- Add authentication/authorization to the registry and UI (OIDC or GitHub SSO).
+- Provide Grafana dashboards integrated with Prometheus exporters included in the platform.
+
*** End Patch
*** End Patch
