*** Begin Patch
*** Add File:argo/quantum/qpu_submit_braket_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: qpu-braket-submit-
+  namespace: aegis
+spec:
+  entrypoint: submit-braket-task
+  templates:
+    - name: submit-braket-task
+      inputs:
+        parameters:
+          - name: program_s3_uri
+          - name: device_arn
+          - name: shots
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - |
+            set -euo pipefail
+            pip install boto3 || true
+            python3 - <<PY
+import os, sys, json, boto3, time
+program_s3 = "{{inputs.parameters.program_s3_uri}}"
+device_arn = "{{inputs.parameters.device_arn}}"
+shots = int("{{inputs.parameters.shots}}")
+br = boto3.client("braket")
+print("Submitting Braket quantum task (demo)...")
+try:
+    resp = br.create_quantum_task(
+        action={'s3Uri': program_s3},
+        deviceArn=device_arn,
+        shots=shots,
+        outputS3Bucket=os.environ.get('MODEL_ARTIFACT_BUCKET',''),
+    )
+    task_arn = resp.get('quantumTaskArn')
+    print("Submitted task:", task_arn)
+    # Poll status
+    for _ in range(120):
+        status = br.get_quantum_task(quantumTaskArn=task_arn)['status']
+        print("Status:", status)
+        if status in ('COMPLETED','FAILED','CANCELLED'):
+            break
+        time.sleep(5)
+    result = br.get_quantum_task(quantumTaskArn=task_arn)
+    outpath = "/tmp/braket_task_result.json"
+    with open(outpath,"w") as f:
+        json.dump(result, f)
+    print("Wrote result to", outpath)
+except Exception as e:
+    print("Braket submit failed (demo):", e, file=sys.stderr)
+    raise
+PY
+
*** End Patch
*** Begin Patch
*** Add File:ops/quantum/providers/braket_submit.py
+#!/usr/bin/env python3
+"""
+Small helper to submit a Braket program stored in S3 to a Braket device and fetch results.
+This is a best-effort scaffold; adapt to your IAM/role and Braket program format (IR).
+"""
+import boto3, os, time, json, argparse
+
+def submit(program_s3_uri, device_arn, shots, output_bucket=None):
+    br = boto3.client("braket")
+    print("Creating quantum task for program:", program_s3_uri)
+    resp = br.create_quantum_task(
+        action={'s3Uri': program_s3_uri},
+        deviceArn=device_arn,
+        shots=int(shots),
+        outputS3Bucket=output_bucket or os.environ.get("MODEL_ARTIFACT_BUCKET",""),
+    )
+    task_arn = resp.get("quantumTaskArn")
+    print("Task ARN:", task_arn)
+    # Poll
+    while True:
+        t = br.get_quantum_task(quantumTaskArn=task_arn)
+        status = t.get("status")
+        print("Status:", status)
+        if status in ("COMPLETED","FAILED","CANCELLED"):
+            return t
+        time.sleep(5)
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--program", required=True)
+    p.add_argument("--device", required=True)
+    p.add_argument("--shots", default=100)
+    p.add_argument("--bucket", default="")
+    args = p.parse_args()
+    res = submit(args.program, args.device, args.shots, args.bucket)
+    print("Result summary:", json.dumps(res, indent=2))
+
*** End Patch
*** Begin Patch
*** Add File:ops/quantum/providers/ibm_submit.py
+#!/usr/bin/env python3
+"""
+Stub for IBM Quantum Runtime submission using qiskit-ibm-runtime.
+This file is a scaffold — install and configure qiskit-ibm-runtime and IBM Cloud API token to use.
+"""
+import os, argparse, json
+try:
+    from qiskit_ibm_runtime import QiskitRuntimeService, Options
+except Exception:
+    QiskitRuntimeService = None
+
+def submit_ibm(program, backend, shots):
+    if QiskitRuntimeService is None:
+        raise RuntimeError("qiskit-ibm-runtime not installed in this environment")
+    service = QiskitRuntimeService()
+    print("Submitting job to IBM backend", backend)
+    # In production use service.run() with proper program or circuit
+    job = service.run(backend=backend, options=Options(), shots=int(shots))
+    print("Job ID:", job.job_id())
+    res = job.result()
+    return res
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--program", required=False)
+    p.add_argument("--backend", required=True)
+    p.add_argument("--shots", default=100)
+    args = p.parse_args()
+    print("Submitting to IBM (demo) — this will error in environments without Qiskit runtime configured.")
+    try:
+        r = submit_ibm(args.program, args.backend, args.shots)
+        print("Result:", r)
+    except Exception as e:
+        print("IBM submit error (expected in scaffold):", e)
+
*** End Patch
*** Begin Patch
*** Add File:simulator/simfarm/qiskit_aer/Dockerfile
+FROM python:3.10-slim
+RUN pip install qiskit-aer qiskit numpy pandas boto3
+WORKDIR /workspace
+COPY simulator/simfarm/run_aer_sim.py /workspace/run_aer_sim.py
+ENTRYPOINT ["python3","/workspace/run_aer_sim.py"]
+
*** End Patch
*** Begin Patch
*** Add File:simulator/simfarm/run_aer_sim.py
+#!/usr/bin/env python3
+"""
+Run a Qiskit Aer simulation for a list of circuits (JSON) and write results to /output.
+This is intended to run as a container in the simulator farm.
+"""
+import json, os, argparse
+from qiskit import QuantumCircuit
+from qiskit_aer import AerSimulator
+from qiskit.quantum_info import Statevector
+
+def run_sim(circuits_json, outdir):
+    os.makedirs(outdir, exist_ok=True)
+    sim = AerSimulator()
+    with open(circuits_json) as f:
+        circuits = json.load(f)
+    results = {}
+    for name, qc_repr in circuits.items():
+        # qc_repr could be QASM or a minimal description — this is a stub
+        qc = QuantumCircuit.from_qasm_str(qc_repr) if qc_repr.strip().startswith("OPENQASM") else None
+        if qc is None:
+            # produce dummy counts
+            results[name] = {"counts": {"0": 512, "1": 488}}
+        else:
+            job = sim.run(qc, shots=1024)
+            res = job.result().get_counts()
+            results[name] = {"counts": res}
+    with open(os.path.join(outdir, "sim_results.json"), "w") as f:
+        json.dump(results, f)
+    print("Wrote sim results to", os.path.join(outdir, "sim_results.json"))
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--circuits", default="/workspace/circuits.json")
+    p.add_argument("--out", default="/output")
+    args = p.parse_args()
+    run_sim(args.circuits, args.out)
+
*** End Patch
*** Begin Patch
*** Add File:argo/quantum/simulator_farm_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: quantum-simfarm-
+  namespace: aegis
+spec:
+  entrypoint: sim-farm
+  templates:
+    - name: sim-farm
+      steps:
+        - - name: run-simulators
+            template: run-sim
+            arguments:
+              parameters:
+                - name: circuits
+                  value: "/workspace/circuits.json"
+                - name: parallel
+                  value: "4"
+
+    - name: run-sim
+      inputs:
+        parameters:
+          - name: circuits
+          - name: parallel
+      container:
+        image: registry.example.com/aegis/qiskit-aer-sim:latest
+        command: [sh, -c]
+        args:
+          - |
+            mkdir -p /output
+            echo "Running simulator container for circuits {{inputs.parameters.circuits}}"
+            python3 /workspace/run_aer_sim.py --circuits {{inputs.parameters.circuits}} --out /output
+            ls -l /output
+
*** End Patch
*** Begin Patch
*** Add File:quantum/hybrid/pennylane_pqc_module.py
+"""
+Example hybrid PyTorch + PennyLane parameterized quantum circuit (PQC) module.
+Demonstrates how to wrap a PQC as a PyTorch nn.Module using PennyLane's Torch interface.
+"""
+import torch
+import torch.nn as nn
+try:
+    import pennylane as qml
+except Exception:
+    qml = None
+
+class PQCLayer(nn.Module):
+    def __init__(self, n_qubits=4, n_layers=2, dev_name='default.qubit'):
+        super().__init__()
+        self.n_qubits = n_qubits
+        self.n_layers = n_layers
+        if qml is None:
+            raise RuntimeError("pennylane not installed in this environment")
+        self.dev = qml.device(dev_name, wires=n_qubits)
+
+        @qml.qnode(self.dev, interface='torch')
+        def circuit(inputs, weights):
+            qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))
+            qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))
+            return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]
+
+        weight_shapes = {"weights": (n_layers, n_qubits)}
+        self.qlayer = qml.qnn.TorchLayer(circuit, weight_shapes)
+
+    def forward(self, x):
+        # x shape expected [batch, n_qubits]
+        return self.qlayer(x)
+
+if __name__ == "__main__":
+    m = PQCLayer()
+    import torch
+    x = torch.randn(2,4)
+    print(m(x))
+
*** End Patch
*** Begin Patch
*** Add File:argo/quantum/hybrid_train_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: quantum-hybrid-train-
+  namespace: aegis
+spec:
+  entrypoint: hybrid-train
+  templates:
+    - name: hybrid-train
+      steps:
+        - - name: prepare-data
+            template: prepare-data
+        - - name: run-train
+            template: run-train
+        - - name: upload-artifacts
+            template: upload-artifacts
+
+    - name: prepare-data
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install pandas numpy || true
+            python3 - <<PY
+import pandas as pd
+df = pd.DataFrame({'x':[0,1,2],'y':[0,1,1]})
+df.to_parquet('/tmp/train.parquet', index=False)
+print('Wrote /tmp/train.parquet')
+PY
+
+    - name: run-train
+      container:
+        image: registry.example.com/aegis/pennylane-train:latest
+        command: [sh, -c]
+        args:
+          - |
+            set -euo pipefail
+            echo "Running hybrid training using PennyLane + PyTorch (scaffold)"
+            python3 quantum/hybrid/hybrid_train.py --data /tmp/train.parquet --epochs 5 --out /tmp/model || true
+
+    - name: upload-artifacts
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install boto3 || true
+            if [ -f /tmp/model/model.pt ]; then
+              aws s3 cp /tmp/model/model.pt s3://${MODEL_ARTIFACT_BUCKET}/quantum/model_$(date -u +%s).pt || true
+            else
+              echo "Model not found"
+            fi
+
*** End Patch
*** Begin Patch
*** Add File:quantum/hybrid/hybrid_train.py
+#!/usr/bin/env python3
+"""
+Toy hybrid training loop that uses PennyLane PQC inside a PyTorch loop.
+This script is a scaffold demonstrating how to integrate QPU/simulator calls inside training.
+"""
+import argparse, torch, torch.nn as nn, torch.optim as optim, pandas as pd, os
+from quantum.hybrid.pennylane_pqc_module import PQCLayer
+
+def train(data_parquet, out_dir, epochs=3):
+    df = pd.read_parquet(data_parquet)
+    X = torch.randn(len(df), 4)
+    y = torch.randint(0,2,(len(df),))
+    model = PQCLayer(n_qubits=4, n_layers=2)
+    opt = optim.Adam(model.parameters(), lr=1e-3)
+    os.makedirs(out_dir, exist_ok=True)
+    for e in range(epochs):
+        pred = model(X)
+        loss = ((pred - torch.rand_like(pred))**2).mean()
+        opt.zero_grad(); loss.backward(); opt.step()
+        print("Epoch", e, "loss", loss.item())
+    torch.save({"state_dict": model.state_dict()}, os.path.join(out_dir, "model.pt"))
+    print("Wrote model to", os.path.join(out_dir, "model.pt"))
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--data", required=True)
+    p.add_argument("--out", required=True)
+    p.add_argument("--epochs", type=int, default=3)
+    args = p.parse_args()
+    train(args.data, args.out, args.epochs)
+
*** End Patch
*** Begin Patch
*** Add File:argo/quantum/calibration_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: quantum-calibration-
+  namespace: aegis
+spec:
+  entrypoint: calibrate
+  templates:
+    - name: calibrate
+      steps:
+        - - name: run-readout-cal
+            template: run-readout
+        - - name: run-error-mitigation-expt
+            template: run-mitigation
+        - - name: upload-manifest
+            template: upload-manifest
+
+    - name: run-readout
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install boto3 || true
+            python3 ops/quantum/calibration/readout_calibration.py --out /tmp/readout_cal.json || true
+
+    - name: run-mitigation
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install mthree || true
+            python3 ops/quantum/mitigation/error_mitigation.py --cal /tmp/readout_cal.json --out /tmp/mitigation_report.json || true
+
+    - name: upload-manifest
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install boto3 || true
+            if [ -f /tmp/readout_cal.json ]; then
+              aws s3 cp /tmp/readout_cal.json s3://${MODEL_ARTIFACT_BUCKET}/quantum/calibration_$(date -u +%s).json || true
+            fi
+            if [ -f /tmp/mitigation_report.json ]; then
+              aws s3 cp /tmp/mitigation_report.json s3://${MODEL_ARTIFACT_BUCKET}/quantum/mitigation_$(date -u +%s).json || true
+            fi
+
*** End Patch
*** Begin Patch
*** Add File:ops/quantum/calibration/readout_calibration.py
+#!/usr/bin/env python3
+"""
+Readout calibration scaffold.
+Produces a JSON manifest with calibration metadata (device, matrix) and signs it if signing helper exists.
+"""
+import argparse, json, time, os
+
+def run_calibration(device="simulator", shots=2000, out="/tmp/readout_cal.json"):
+    manifest = {
+        "device": device,
+        "shots": shots,
+        "created_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
+        "readout_matrix": [[0.99, 0.01],[0.02,0.98]],
+        "notes": "Stub calibration; replace with provider SDK calls"
+    }
+    # Try signing
+    try:
+        from production.policy.signing.sign_with_retry import sign_payload
+        sig,meta = sign_payload(json.dumps(manifest).encode(), None)
+        manifest["signature"] = sig
+        manifest["signed_by"] = meta
+    except Exception as e:
+        manifest["sign_error"] = str(e)
+    with open(out,"w") as f:
+        json.dump(manifest, f, indent=2)
+    print("Wrote calibration manifest to", out)
+    return out
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--device", default="simulator")
+    p.add_argument("--shots", type=int, default=2000)
+    p.add_argument("--out", default="/tmp/readout_cal.json")
+    args = p.parse_args()
+    run_calibration(args.device, args.shots, args.out)
+
*** End Patch
*** Begin Patch
*** Add File:ops/quantum/mitigation/error_mitigation.py
+#!/usr/bin/env python3
+"""
+Error mitigation scaffold. Uses mthree if available to create a mitigation report.
+This is a best-effort stub — replace with real mitigation steps using provider calibration and circuits.
+"""
+import argparse, json, os
+
+def run_mitigation(cal_manifest, out="/tmp/mitigation_report.json"):
+    # Load calibration manifest if provided
+    if os.path.exists(cal_manifest):
+        cal = json.load(open(cal_manifest))
+    else:
+        cal = {}
+    report = {"mitigation": "stub", "calibration": cal, "created_at": __import__('time').strftime("%Y-%m-%dT%H:%M:%SZ", __import__('time').gmtime())}
+    with open(out,"w") as f:
+        json.dump(report, f, indent=2)
+    print("Wrote mitigation report to", out)
+    return out
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--cal", required=True)
+    p.add_argument("--out", default="/tmp/mitigation_report.json")
+    args = p.parse_args()
+    run_mitigation(args.cal, args.out)
+
*** End Patch
*** Begin Patch
*** Add File:qpu/scheduler/qpu_scheduler.py
+#!/usr/bin/env python3
+"""
+Simple QPU scheduler: HTTP service that accepts quantum job submissions and enqueues them.
+Dequeuer limits concurrent QPU submissions and dispatches to provider adapters.
+This is intentionally lightweight and meant as a scaffold.
+"""
+import threading, time, queue, json, os
+from http.server import BaseHTTPRequestHandler, HTTPServer
+import subprocess
+
+JOB_QUEUE = queue.Queue()
+CONCURRENCY = int(os.environ.get("QPU_MAX_CONCURRENCY","2"))
+
+def worker_loop():
+    while True:
+        job = JOB_QUEUE.get()
+        if job is None:
+            break
+        print("Dispatching job:", job.get("id"))
+        provider = job.get("provider","braket")
+        if provider == "braket":
+            cmd = ["python3","ops/quantum/providers/braket_submit.py","--program", job.get("program"), "--device", job.get("device"), "--shots", str(job.get("shots",100))]
+        else:
+            cmd = ["echo","unknown-provider"]
+        try:
+            subprocess.run(cmd, check=True)
+            print("Job dispatched:", job.get("id"))
+        except Exception as e:
+            print("Job dispatch failed:", e)
+        JOB_QUEUE.task_done()
+
+class Handler(BaseHTTPRequestHandler):
+    def _set_json(self):
+        self.send_response(200)
+        self.send_header('Content-Type','application/json')
+        self.end_headers()
+    def do_POST(self):
+        length = int(self.headers.get('Content-Length',0))
+        body = self.rfile.read(length)
+        job = json.loads(body.decode())
+        job_id = f"job-{int(time.time()*1000)}"
+        job['id'] = job_id
+        JOB_QUEUE.put(job)
+        self._set_json()
+        self.wfile.write(json.dumps({"status":"queued","job_id":job_id}).encode())
+
+def run_server(port=8080):
+    # Start worker threads
+    for _ in range(CONCURRENCY):
+        t = threading.Thread(target=worker_loop, daemon=True)
+        t.start()
+    srv = HTTPServer(('0.0.0.0', port), Handler)
+    print("QPU Scheduler running on port", port)
+    srv.serve_forever()
+
+if __name__ == "__main__":
+    run_server(int(os.environ.get("QPU_SCHED_PORT", "8080")))
+
*** End Patch
*** Begin Patch
*** Add File:governance/gatekeeper_quantum_constraint.yaml
+apiVersion: templates.gatekeeper.sh/v1
+kind: ConstraintTemplate
+metadata:
+  name: requirequantumallowed
+spec:
+  crd:
+    spec:
+      names:
+        kind: RequireQuantumAllowed
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package requirequantumallowed
+        violation[{"msg": msg}] {
+          input.review.kind.kind == "Job"
+          not input.review.object.metadata.annotations["quantum.allowed"]
+          msg := "Quantum Job must include annotation 'quantum.allowed=true' to be created"
+        }
+
+---
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: RequireQuantumAllowed
+metadata:
+  name: quantum-allowed-required
+spec:
+  match:
+    kinds:
+      - apiGroups: [""]
+        kinds: ["Job"]
+
*** End Patch
*** Begin Patch
*** Add File:data/quantum_manifest_schema.json
+{
+  "$schema": "http://json-schema.org/draft-07/schema#",
+  "title": "Aegis Quantum Experiment Manifest",
+  "type": "object",
+  "required": ["experiment_id","backend","shots","created_at","manifest_version"],
+  "properties": {
+    "experiment_id": {"type":"string"},
+    "backend": {"type":"string"},
+    "backend_version": {"type":"string"},
+    "shots": {"type":"integer"},
+    "noise_model_id": {"type":"string"},
+    "transpile_seed": {"type":"integer"},
+    "circuit_list": {"type":"array"},
+    "job_queue_time": {"type":"number"},
+    "job_exec_time": {"type":"number"},
+    "metrics": {"type":"object"},
+    "manifest_version": {"type":"string"},
+    "signed_by": {"type":"string"},
+    "signature": {"type":"string"}
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:argo/quantum/nightly_benchmarks.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: quantum-nightly-bench-
+  namespace: aegis
+spec:
+  entrypoint: quantum-bench
+  templates:
+    - name: quantum-bench
+      steps:
+        - - name: run-sim-bench
+            template: sim-bench
+        - - name: run-qpu-bench
+            template: qpu-bench
+        - - name: compare-and-log
+            template: compare-log
+
+    - name: sim-bench
+      container:
+        image: registry.example.com/aegis/qiskit-aer-sim:latest
+        command: [sh, -c]
+        args:
+          - mkdir -p /output && python3 /workspace/run_aer_sim.py --circuits /workspace/bench_circuits.json --out /output || true
+      outputs:
+        artifacts:
+          - name: sim-results
+            path: /output/sim_results.json
+
+    - name: qpu-bench
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install boto3 || true
+            python3 - <<PY
+import boto3, json, os
+print("QPU bench submission stub: submit to Braket/IBM as configured")
+PY
+
+    - name: compare-log
+      inputs:
+        artifacts:
+          - name: sim-results
+            path: /tmp/sim_results.json
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install mlflow || true
+            python3 - <<PY
+import json, os
+try:
+    sim = json.load(open('/tmp/sim_results.json'))
+    print('Sim results sample:', list(sim.keys())[:5])
+except Exception:
+    print('No sim results')
+PY
+
*** End Patch
*** End Patch
