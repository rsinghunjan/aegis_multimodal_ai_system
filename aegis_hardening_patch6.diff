diff --git a/vault/policies/aegis_agents_policy.hcl b/vault/policies/aegis_agents_policy.hcl
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/vault/policies/aegis_agents_policy.hcl
@@ -0,0 +1,42 @@
+# Vault policy for Aegis agents: minimal read access to GitHub App key (KV v2) and dynamic DB creds.
+# Operator: tighten paths per your Vault layout.
+path "secret/data/aegis/github_app" {
+  capabilities = ["read"]
+}
+
+path "secret/data/aegis/postgres" {
+  capabilities = ["read"]
+}
+
+path "secret/data/aegis/cloud/*" {
+  capabilities = ["read"]
+}
+
+# Allow issuing dynamic DB creds from the database secrets engine
+path "database/creds/aegis-role" {
+  capabilities = ["read"]
+}
+
+path "secret/data/aegis/ephemeral/*" {
+  capabilities = ["read","list"]
+}
+
+path "auth/token/renew-self" {
+  capabilities = ["update"]
+}
diff --git a/vault/write_github_app_to_vault.sh b/vault/write_github_app_to_vault.sh
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/vault/write_github_app_to_vault.sh
@@ -0,0 +1,140 @@
+#!/usr/bin/env bash
+#
+# Write GitHub App PEM + metadata into Vault KV v2.
+# Requires VAULT_ADDR & VAULT_TOKEN env vars and `vault` CLI or HTTP available.
+#
+# Usage:
+#   ./vault/write_github_app_to_vault.sh --pem /tmp/github_app.pem --app-id 12345 --installation-id 67890
+
+set -euo pipefail
+
+PEM_FILE=""
+APP_ID=""
+INSTALLATION_ID=""
+VAULT_PATH="${VAULT_PATH:-secret/data/aegis/github_app}"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --pem) PEM_FILE="$2"; shift 2;;
+    --app-id) APP_ID="$2"; shift 2;;
+    --installation-id) INSTALLATION_ID="$2"; shift 2;;
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+if [ -z "$PEM_FILE" ] || [ -z "$APP_ID" ] || [ -z "$INSTALLATION_ID" ]; then
+  echo "Provide --pem, --app-id and --installation-id"
+  exit 1
+fi
+
+if [ -z "${VAULT_ADDR:-}" ] || [ -z "${VAULT_TOKEN:-}" ]; then
+  echo "Set VAULT_ADDR and VAULT_TOKEN in environment"
+  exit 1
+fi
+
+PAYLOAD=$(jq -n --arg pk "$(sed -e ':a' -e 'N' -e '$!ba' -e 's/\n/\\n/g' "$PEM_FILE")" --arg app_id "$APP_ID" --arg inst_id "$INSTALLATION_ID" '{data: {private_key: $pk, app_id: $app_id, installation_id: $inst_id}}')
+
+curl -sS --header "X-Vault-Token: $VAULT_TOKEN" --request POST \
+  --data "$PAYLOAD" \
+  "$VAULT_ADDR/v1/$VAULT_PATH" | jq . || true
+
+echo "Written GitHub App secret to $VAULT_PATH"
+exit 0
diff --git a/vault/setup_dynamic_db.sh b/vault/setup_dynamic_db.sh
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/vault/setup_dynamic_db.sh
@@ -0,0 +1,180 @@
+#!/usr/bin/env bash
+#
+# Configure Vault database secrets engine for dynamic Postgres users.
+# Requires VAULT_ADDR & VAULT_TOKEN and DB admin creds available locally.
+#
+# Usage:
+#   ./vault/setup_dynamic_db.sh --db-host <host> --db-admin-user <user> --db-admin-pass-file ./pg_admin_pass
+
+set -euo pipefail
+
+DB_HOST=""
+DB_NAME="aegis"
+DB_ADMIN_USER=""
+DB_ADMIN_PASS_FILE=""
+VAULT_MOUNT_PATH="${VAULT_MOUNT_PATH:-database}"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --db-host) DB_HOST="$2"; shift 2;;
+    --db-name) DB_NAME="$2"; shift 2;;
+    --db-admin-user) DB_ADMIN_USER="$2"; shift 2;;
+    --db-admin-pass-file) DB_ADMIN_PASS_FILE="$2"; shift 2;;
+    --vault-mount) VAULT_MOUNT_PATH="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+if [ -z "${VAULT_ADDR:-}" ] || [ -z "${VAULT_TOKEN:-}" ]; then
+  echo "Set VAULT_ADDR and VAULT_TOKEN in environment"
+  exit 1
+fi
+
+if [ -z "$DB_HOST" ] || [ -z "$DB_ADMIN_USER" ] || [ -z "$DB_ADMIN_PASS_FILE" ]; then
+  echo "Provide --db-host, --db-admin-user and --db-admin-pass-file"
+  exit 1
+fi
+
+DB_ADMIN_PASS="$(cat "$DB_ADMIN_PASS_FILE")"
+
+vault secrets enable -path="$VAULT_MOUNT_PATH" database || true
+
+vault write "$VAULT_MOUNT_PATH/config/postgresql" \
+  plugin_name="postgresql-database-plugin" \
+  allowed_roles="aegis-role" \
+  connection_url="postgresql://{{username}}:{{password}}@${DB_HOST}/${DB_NAME}?sslmode=disable" \
+  username="$DB_ADMIN_USER" \
+  password="$DB_ADMIN_PASS"
+
+vault write "$VAULT_MOUNT_PATH/roles/aegis-role" \
+  db_name="postgresql" \
+  creation_statements="CREATE ROLE \"{{name}}\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; GRANT CONNECT ON DATABASE ${DB_NAME} TO \"{{name}}\";" \
+  default_ttl="1h" \
+  max_ttl="24h"
+
+echo "Dynamic DB role 'aegis-role' configured."
diff --git a/k8s/manifests/vault-enforcer.sh b/k8s/manifests/vault-enforcer.sh
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/k8s/manifests/vault-enforcer.sh
@@ -0,0 +1,200 @@
+#!/usr/bin/env bash
+#
+# Scan deployments for plaintext/k8s secrets and optionally annotate them for Vault Injector.
+# Dry-run by default. Use --apply to annotate.
+
+set -euo pipefail
+NS="aegis-ml"
+APPLY=false
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --namespace) NS="$2"; shift 2;;
+    --apply) APPLY=true; shift;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+echo "Scanning deployments in $NS..."
+DEPLOYS=$(kubectl -n "$NS" get deployments -o json | jq -r '.items[].metadata.name')
+for d in $DEPLOYS; do
+  echo "Deployment: $d"
+  LITERAL=$(kubectl -n "$NS" get deploy "$d" -o json | jq -r '.spec.template.spec.containers[].env[]?.name' | egrep -i "TOKEN|KEY|PASSWORD|DB_PASS|GITHUB|SECRET" || true)
+  VALUEFROM=$(kubectl -n "$NS" get deploy "$d" -o json | jq -r '.spec.template.spec.containers[].env[]? | select(.valueFrom!=null) | @json' || true)
+  if [ -n "$LITERAL" ] || [ -n "$VALUEFROM" ]; then
+    echo "  Candidate secret usage detected."
+    if [ "$APPLY" = true ]; then
+      echo "  Annotating $d for Vault Injector (operator review required)."
+      kubectl -n "$NS" annotate deploy "$d" vault.hashicorp.com/agent-inject=true --overwrite
+      kubectl -n "$NS" annotate deploy "$d" vault.hashicorp.com/role=aegis-agent --overwrite
+    else
+      echo "  (dry-run) would annotate $d"
+    fi
+  else
+    echo "  No suspicious envs found."
+  fi
+done
+
+echo "Done. If you applied annotations, verify pods have /vault/secrets mounted."
diff --git a/k8s/manifests/remove_plaintext_secrets.sh b/k8s/manifests/remove_plaintext_secrets.sh
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/k8s/manifests/remove_plaintext_secrets.sh
@@ -0,0 +1,120 @@
+#!/usr/bin/env bash
+#
+# Detect and optionally delete literal k8s secrets in namespace.
+#
+NAMESPACE="${1:-aegis-ml}"
+DRY_RUN=true
+if [[ "${2:-}" == "--apply" ]]; then DRY_RUN=false; fi
+
+echo "Scanning secrets in $NAMESPACE (dry-run=${DRY_RUN})..."
+kubectl -n "$NAMESPACE" get secrets -o json | jq -r '.items[].metadata.name' | while read -r s; do
+  if echo "$s" | egrep -i "password|postgres|db|github|token|key|pem|secret" >/dev/null; then
+    echo "Found: $s"
+    if [ "$DRY_RUN" = "false" ]; then
+      kubectl -n "$NAMESPACE" delete secret "$s" || true
+      echo "Deleted secret $s"
+    else
+      echo "(dry-run) would delete $s"
+    fi
+  fi
+done
+
+echo "Done. Ensure Vault injection is configured before deletion."
diff --git a/agents/common/github_app_vault.py b/agents/common/github_app_vault.py
new file mode 100644
index 0000000..6666666
--- /dev/null
+++ b/agents/common/github_app_vault.py
@@ -0,0 +1,220 @@
+#!/usr/bin/env python3
+"""
+Fetch GitHub App installation tokens using PEM stored in Vault.
+Agents should call get_installation_token() instead of using PATs.
+"""
+import os
+import time
+import json
+import requests
+import jwt
+from typing import Optional
+import logging
+
+logger = logging.getLogger("aegis.github_app_vault")
+logging.basicConfig(level=logging.INFO)
+
+VAULT_ADDR = os.environ.get("VAULT_ADDR")
+VAULT_TOKEN = os.environ.get("VAULT_TOKEN")
+GITHUB_APP_VAULT_PATH = os.environ.get("GITHUB_APP_VAULT_PATH", "secret/data/aegis/github_app")
+
+def _read_vault_secret(path: str) -> Optional[dict]:
+    # prefer injector-mounted file
+    if os.path.exists("/vault/secrets/github_app.pem"):
+        try:
+            with open("/vault/secrets/github_app.pem","r") as fh:
+                pk = fh.read()
+            meta = {}
+            if os.path.exists("/vault/secrets/github_app.meta.json"):
+                meta = json.load(open("/vault/secrets/github_app.meta.json"))
+            return {"data": {"private_key": pk, **meta}}
+        except Exception:
+            pass
+    if not VAULT_ADDR or not VAULT_TOKEN:
+        logger.warning("VAULT not configured")
+        return None
+    url = f"{VAULT_ADDR}/v1/{path}"
+    headers = {"X-Vault-Token": VAULT_TOKEN}
+    r = requests.get(url, headers=headers, timeout=10)
+    if r.status_code != 200:
+        logger.error("Vault read failed: %s %s", r.status_code, r.text)
+        return None
+    return r.json()
+
+def _create_jwt(app_id: str, private_key_pem: str) -> str:
+    now = int(time.time())
+    payload = {"iat": now - 60, "exp": now + 600, "iss": app_id}
+    token = jwt.encode(payload, private_key_pem, algorithm="RS256")
+    if isinstance(token, bytes): token = token.decode("utf-8")
+    return token
+
+def get_installation_token(installation_id: Optional[str] = None) -> Optional[str]:
+    sec = _read_vault_secret(GITHUB_APP_VAULT_PATH)
+    if not sec:
+        logger.error("No GH App secret in Vault")
+        return None
+    data = sec.get("data") or sec
+    if "data" in data and isinstance(data["data"], dict):
+        payload = data["data"]
+    else:
+        payload = data
+    private_key = payload.get("private_key")
+    app_id = payload.get("app_id") or os.environ.get("GITHUB_APP_ID")
+    inst = installation_id or payload.get("installation_id") or os.environ.get("GITHUB_INSTALLATION_ID")
+    if not private_key or not app_id or not inst:
+        logger.error("Missing GH App metadata")
+        return None
+    jwt_token = _create_jwt(str(app_id), private_key)
+    headers = {"Authorization": f"Bearer {jwt_token}", "Accept": "application/vnd.github+json"}
+    url = f"https://api.github.com/app/installations/{inst}/access_tokens"
+    resp = requests.post(url, headers=headers, timeout=15)
+    if resp.status_code not in (200,201):
+        logger.error("Token exchange failed: %s %s", resp.status_code, resp.text)
+        return None
+    tok = resp.json().get("token")
+    logger.info("Obtained installation token (expires_at=%s)", resp.json().get("expires_at"))
+    return tok
diff --git a/k8s/manifests/approval-gateway-deployment.yaml b/k8s/manifests/approval-gateway-deployment.yaml
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/k8s/manifests/approval-gateway-deployment.yaml
@@ -0,0 +1,160 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-approval-gateway
+  namespace: aegis-ml
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-approval-gateway
+  template:
+    metadata:
+      labels:
+        app: aegis-approval-gateway
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: gateway
+          image: <REGISTRY>/aegis-approval-gateway:latest
+          env:
+            - name: ORCHESTRATOR_WEBHOOK
+              value: "http://orchestrator.aegis-ml.svc.cluster.local:8082/webhook"
+            - name: GITHUB_REPO
+              value: "<OWNER/REPO>"
+            - name: DEFAULT_REVIEWERS
+              value: "sre,security"
+          ports:
+            - containerPort: 8080
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-approval-gateway
+  namespace: aegis-ml
+spec:
+  selector:
+    app: aegis-approval-gateway
+  ports:
+    - port: 8080
+      targetPort: 8080
diff --git a/scripts/auto_approval_gateway.py b/scripts/auto_approval_gateway.py
new file mode 100644
index 0000000..8888888
--- /dev/null
+++ b/scripts/auto_approval_gateway.py
@@ -0,0 +1,260 @@
+#!/usr/bin/env python3
+"""
+Approval Gateway: receives requests from orchestrator, creates PRs via GitHub App, requests reviewers,
+and notifies orchestrator when PR is merged so approvals can be logged in decision_log.
+"""
+from flask import Flask, request, jsonify
+import os, logging, requests, json
+from typing import List, Optional
+
+try:
+    from agents.common.github_app_vault import get_installation_token
+except Exception:
+    def get_installation_token(*a, **k):
+        return os.environ.get("GITHUB_TOKEN")
+
+GITHUB_API = "https://api.github.com"
+REPO = os.environ.get("GITHUB_REPO","")
+DEFAULT_REVIEWERS = os.environ.get("DEFAULT_REVIEWERS","sre,security").split(",")
+ORCHESTRATOR_WEBHOOK = os.environ.get("ORCHESTRATOR_WEBHOOK","http://orchestrator.aegis-ml.svc.cluster.local:8082/webhook")
+
+logging.basicConfig(level=logging.INFO)
+logger = logging.getLogger("aegis.approval.gateway")
+app = Flask(__name__)
+
+def _headers(token: str):
+    return {"Authorization": f"token {token}", "Accept": "application/vnd.github.v3+json"}
+
+def create_pr(title: str, body: str, head: str, base: str="main", installation_id: Optional[str]=None):
+    token = get_installation_token(installation_id)
+    if not token:
+        raise RuntimeError("No installation token")
+    url = f"{GITHUB_API}/repos/{REPO}/pulls"
+    r = requests.post(url, headers=_headers(token), json={"title": title, "body": body, "head": head, "base": base}, timeout=10)
+    r.raise_for_status()
+    return r.json()
+
+def request_review(pr_number: int, reviewers: List[str], installation_id: Optional[str]=None):
+    token = get_installation_token(installation_id)
+    url = f"{GITHUB_API}/repos/{REPO}/pulls/{pr_number}/requested_reviewers"
+    r = requests.post(url, headers=_headers(token), json={"reviewers": reviewers}, timeout=10)
+    r.raise_for_status()
+    return r.json()
+
+def post_comment(pr_number: int, comment: str, installation_id: Optional[str]=None):
+    token = get_installation_token(installation_id)
+    url = f"{GITHUB_API}/repos/{REPO}/issues/{pr_number}/comments"
+    r = requests.post(url, headers=_headers(token), json={"body": comment}, timeout=10)
+    r.raise_for_status()
+    return r.json()
+
+@app.route("/request-approval", methods=["POST"])
+def request_approval():
+    payload = request.get_json()
+    model = payload.get("model","unknown")
+    reason = payload.get("reason","")
+    branch = payload.get("change_branch", f"aegis/approval-{int(os.getpid())}-{int(os.stat(__file__).st_mtime)}")
+    title = f"[Aegis Approval] Action for model {model}"
+    body = f"Automated request for approval\n\nModel: {model}\nReason: {reason}\n\nDiff:\n```\n{payload.get('diff','')}\n```"
+    try:
+        pr = create_pr(title, body, branch, payload.get("base","main"))
+        pr_no = pr.get("number")
+        try:
+            request_review(pr_no, DEFAULT_REVIEWERS)
+        except Exception:
+            logger.exception("request_review failed")
+        post_comment(pr_no, f"Approval requested by Aegis orchestrator for model {model}")
+        return jsonify({"pr_number": pr_no, "pr_url": pr.get("html_url")}), 201
+    except Exception as e:
+        logger.exception("create_pr failed")
+        return jsonify({"error": str(e)}), 500
+
+@app.route("/webhook/github", methods=["POST"])
+def github_webhook():
+    evt = request.get_json()
+    pr = evt.get("pull_request") or {}
+    merged = pr.get("merged", False)
+    if merged:
+        orchestrator_payload = {"approval": {"pr_url": pr.get("html_url"), "pr_number": pr.get("number"), "merged_by": evt.get("sender",{}).get("login")}}
+        try:
+            r = requests.post(ORCHESTRATOR_WEBHOOK, json=orchestrator_payload, timeout=10)
+            logger.info("Notified orchestrator: %s", r.status_code)
+        except Exception:
+            logger.exception("Failed to notify orchestrator")
+    return jsonify({"status":"ok"}), 200
+
+if __name__=="__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT","8080")))
diff --git a/sql/002_add_indexes_decision_log.sql b/sql/002_add_indexes_decision_log.sql
new file mode 100644
index 0000000..9999999
--- /dev/null
+++ b/sql/002_add_indexes_decision_log.sql
@@ -0,0 +1,64 @@
+-- Add indexes for common audit queries on decision_log
+CREATE INDEX IF NOT EXISTS idx_decision_log_created_at ON decision_log (created_at DESC);
+CREATE INDEX IF NOT EXISTS idx_decision_log_model ON decision_log ((payload->>'model'));
+CREATE INDEX IF NOT EXISTS idx_decision_log_action ON decision_log ((payload->>'action'));
+CREATE INDEX IF NOT EXISTS idx_decision_log_agent ON decision_log (agent);
+CREATE INDEX IF NOT EXISTS idx_decision_log_evidence ON decision_log USING GIN (evidence);
+
+-- Optional: partitioning or retention policy can be added by operator
+-- Example retention: DELETE FROM decision_log WHERE created_at < now() - interval '365 days';
diff --git a/tools/decisionlog_to_elastic.py b/tools/decisionlog_to_elastic.py
new file mode 100644
index 0000000..aaaaaaaa
--- /dev/null
+++ b/tools/decisionlog_to_elastic.py
@@ -0,0 +1,220 @@
+#!/usr/bin/env python3
+"""
+Mirror Decision Log (Postgres) to Elasticsearch for fast audits.
+Requires POSTGRES_URL & ELASTIC_URL environment variables.
+"""
+import os, json, psycopg2, requests
+
+PG_URL = os.environ.get("POSTGRES_URL")
+ES_URL = os.environ.get("ELASTIC_URL")
+
+def fetch_recent(limit=500):
+    conn = psycopg2.connect(PG_URL)
+    cur = conn.cursor()
+    cur.execute("SELECT id, created_at, agent, payload, evidence FROM decision_log ORDER BY created_at DESC LIMIT %s", (limit,))
+    rows = cur.fetchall()
+    cur.close()
+    conn.close()
+    return rows
+
+def index_to_es(rows):
+    for r in rows:
+        doc = {"id": r[0], "created_at": r[1].isoformat(), "agent": r[2], "payload": r[3], "evidence": r[4]}
+        url = f"{ES_URL.rstrip('/')}/decision_log/_doc/{doc['id']}"
+        resp = requests.put(url, json=doc)
+        if resp.status_code not in (200,201):
+            print("Failed to index", doc['id'], resp.status_code, resp.text)
+
+def main():
+    if not PG_URL or not ES_URL:
+        print("POSTGRES_URL and ELASTIC_URL must be set")
+        return
+    rows = fetch_recent()
+    index_to_es(rows)
+
+if __name__ == "__main__":
+    main()
diff --git a/policy/opa/data/models_canonical.json b/policy/opa/data/models_canonical.json
new file mode 100644
index 0000000..bbbbbbbb
--- /dev/null
+++ b/policy/opa/data/models_canonical.json
@@ -0,0 +1,120 @@
+{
+  "models": {
+    "low-demo-model": {
+      "risk": "low",
+      "team": "ads",
+      "budget_usd_per_month": 200.0,
+      "owners": ["alice","bob"]
+    },
+    "fraud-detector-v1": {
+      "risk": "high",
+      "team": "fraud",
+      "budget_usd_per_month": 1000.0,
+      "owners": ["sre","security"]
+    },
+    "default": {
+      "risk": "medium",
+      "team": "ml",
+      "budget_usd_per_month": 500.0,
+      "owners": ["ml-team"]
+    }
+  }
+}
diff --git a/policy/opa/tests/agent_policies_more_tests.rego b/policy/opa/tests/agent_policies_more_tests.rego
new file mode 100644
index 0000000..cccccccc
--- /dev/null
+++ b/policy/opa/tests/agent_policies_more_tests.rego
@@ -0,0 +1,220 @@
+package aegis.policies.tests
+
+import data.aegis.policies
+import data.models
+
+test_retrain_staging_allowed {
+  input := {"action": "retrain", "model": "low-demo-model", "env": "staging", "params": {}}
+  result := data.aegis.policies.result with input as input
+  result.allow == true
+}
+
+test_promote_medium_requires_approval {
+  input := {"action": "promote", "model": "default", "env": "production", "params": {}}
+  result := data.aegis.policies.result with input as input
+  result.allow == false
+}
+
+test_promote_with_approval {
+  input := {"action":"promote","model":"default","env":"production","params":{"approved_by":"sre"}}
+  result := data.aegis.policies.result with input as input
+  result.allow == true
+}
+
+test_high_risk_retrain_denied_in_prod {
+  input := {"action":"retrain","model":"fraud-detector-v1","env":"production","params":{}}
+  result := data.aegis.policies.result with input as input
+  result.allow == false
+}
diff --git a/.github/workflows/policy-ci.yml b/.github/workflows/policy-ci.yml
new file mode 100644
index 0000000..dddddddd
--- /dev/null
+++ b/.github/workflows/policy-ci.yml
@@ -0,0 +1,132 @@
+name: Policy CI
+
+on:
+  push:
+    paths:
+      - "policy/**"
+  pull_request:
+    paths:
+      - "policy/**"
+
+jobs:
+  opa-test:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run OPA unit tests
+        run: |
+          docker run --rm -v "${{ github.workspace }}:/workspace" openpolicyagent/opa:latest test /workspace/policy -v
+  rego-lint:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Lint Rego
+        run: |
+          docker run --rm -v "${{ github.workspace }}:/workspace" openpolicyagent/opa:latest fmt /workspace/policy || true
diff --git a/k8s/manifests/deepspeed-nccl-configmap.yaml b/k8s/manifests/deepspeed-nccl-configmap.yaml
new file mode 100644
index 0000000..eeeeeeee
--- /dev/null
+++ b/k8s/manifests/deepspeed-nccl-configmap.yaml
@@ -0,0 +1,120 @@
+apiVersion: v1
+kind: ConfigMap
+metadata:
+  name: aegis-deepspeed-nccl
+  namespace: aegis-ml
+data:
+  NCCL_IB_DISABLE: "0"
+  NCCL_SOCKET_IFNAME: "eth0"
+  NCCL_P2P_LEVEL: "NVL"
+  NCCL_DEBUG: "WARN"
+  NCCL_MIN_NRINGS: "8"
+
+# Operators must tune values for their infra.
diff --git a/k8s/manifests/feast-online-deploy.yaml b/k8s/manifests/feast-online-deploy.yaml
new file mode 100644
index 0000000..ffffffff
--- /dev/null
+++ b/k8s/manifests/feast-online-deploy.yaml
@@ -0,0 +1,120 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: feast-online-store
+  namespace: aegis-ml
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: feast-online
+  template:
+    metadata:
+      labels:
+        app: feast-online
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: feast-online
+          image: <REGISTRY>/aegis-feast-online:latest
+          env:
+            - name: REDIS_HOST
+              value: "feast-redis.aegis-ml.svc.cluster.local"
+          ports:
+            - containerPort: 6566
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "512Mi"
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: feast-online
+  namespace: aegis-ml
+spec:
+  selector:
+    app: feast-online
+  ports:
+    - port: 6566
+      targetPort: 6566
diff --git a/k8s/manifests/feast-sync-job.yaml b/k8s/manifests/feast-sync-job.yaml
new file mode 100644
index 0000000..10101010
--- /dev/null
+++ b/k8s/manifests/feast-sync-job.yaml
@@ -0,0 +1,120 @@
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: aegis-feast-sync
+  namespace: aegis-ml
+spec:
+  template:
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: feast-sync
+          image: <REGISTRY>/aegis-feast-sync:latest
+          command: ["python", "/app/feast_sync.py"]
+          env:
+            - name: BATCH_FEATURE_PATH
+              value: "s3://<BUCKET>/features/"
+            - name: FEAST_REDIS_HOST
+              value: "feast-redis.aegis-ml.svc.cluster.local"
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+      restartPolicy: OnFailure
diff --git a/k8s/manifests/labeling-queue-deployment.yaml b/k8s/manifests/labeling-queue-deployment.yaml
new file mode 100644
index 0000000..11111111
--- /dev/null
+++ b/k8s/manifests/labeling-queue-deployment.yaml
@@ -0,0 +1,160 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-labeling-queue
+  namespace: aegis-ml
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-labeling-queue
+  template:
+    metadata:
+      labels:
+        app: aegis-labeling-queue
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: labeling-queue
+          image: <REGISTRY>/aegis-labeling-queue:latest
+          env:
+            - name: LABELSTUDIO_URL
+              value: "http://labelstudio.aegis-ml.svc.cluster.local:8080"
+            - name: LAKEFS_API
+              value: "http://lakefs:8000"
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-labeling-queue
+  namespace: aegis-ml
+spec:
+  selector:
+    app: aegis-labeling-queue
+  ports:
+    - port: 8080
+      targetPort: 8080
diff --git a/k8s/manifests/networkpolicy-restrict.yaml b/k8s/manifests/networkpolicy-restrict.yaml
new file mode 100644
index 0000000..12121212
--- /dev/null
+++ b/k8s/manifests/networkpolicy-restrict.yaml
@@ -0,0 +1,120 @@
+apiVersion: networking.k8s.io/v1
+kind: NetworkPolicy
+metadata:
+  name: restrict-aegis-namespace
+  namespace: aegis-ml
+spec:
+  podSelector: {}
+  policyTypes:
+    - Ingress
+    - Egress
+  ingress:
+    - from:
+        - podSelector:
+            matchLabels:
+              app: aegis-agent
+      ports:
+        - protocol: TCP
+          port: 8082
+  egress:
+    - to:
+        - ipBlock:
+            cidr: 0.0.0.0/0
+      ports:
+        - protocol: TCP
+          port: 443
+# Tune before applying in production.
diff --git a/k8s/manifests/agent-serviceaccount-rbac.yaml b/k8s/manifests/agent-serviceaccount-rbac.yaml
new file mode 100644
index 0000000..13131313
--- /dev/null
+++ b/k8s/manifests/agent-serviceaccount-rbac.yaml
@@ -0,0 +1,140 @@
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: aegis-agent-sa
+  namespace: aegis-ml
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: aegis-agent-role
+  namespace: aegis-ml
+rules:
+  - apiGroups: [""]
+    resources: ["pods","configmaps"]
+    verbs: ["get","list","watch"]
+  - apiGroups: [""]
+    resources: ["secrets"]
+    verbs: ["get","list"]
+  - apiGroups: ["apps"]
+    resources: ["deployments"]
+    verbs: ["get","list","patch"]
+  - apiGroups: ["batch"]
+    resources: ["jobs"]
+    verbs: ["create","get","list"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: aegis-agent-rolebinding
+  namespace: aegis-ml
+subjects:
+  - kind: ServiceAccount
+    name: aegis-agent-sa
+roleRef:
+  kind: Role
+  name: aegis-agent-role
+  apiGroup: rbac.authorization.k8s.io
diff --git a/docs/PRODUCTION_HARDENING_RUNBOOK.md b/docs/PRODUCTION_HARDENING_RUNBOOK.md
new file mode 100644
index 0000000..14141414
--- /dev/null
+++ b/docs/PRODUCTION_HARDENING_RUNBOOK.md
@@ -0,0 +1,240 @@
+# Aegis Production Hardening Runbook â€” Secrets, Policy, Approval, Monitoring, DR
+
+Follow these steps to remediate high-impact weaknesses prior to enabling production auto-exec.
+
+1) Vault & Secrets (HIGH)
+ - Write GH App PEM to Vault:
+     ./vault/write_github_app_to_vault.sh --pem /tmp/github_app.pem --app-id 12345 --installation-id 67890
+ - Configure dynamic DB roles:
+     ./vault/setup_dynamic_db.sh --db-host aegis-postgres.aegis-ml.svc.cluster.local --db-admin-user postgres --db-admin-pass-file ./pg_admin_pass
+ - Run dry-run scan and annotate for Vault Injector:
+     ./k8s/manifests/vault-enforcer.sh --namespace aegis-ml
+ - After verifying injection, remove plaintext secrets:
+     ./k8s/manifests/remove_plaintext_secrets.sh aegis-ml --apply
+
+2) Policy (HIGH)
+ - Add canonical model data: policy/opa/data/models_canonical.json
+ - Add rego tests: policy/opa/tests/agent_policies_more_tests.rego
+ - Enable policy CI: .github/workflows/policy-ci.yml
+
+3) GitHub App (HIGH)
+ - Create GH App with least-privilege scopes, store PEM in Vault and use agents/common/github_app_vault.get_installation_token()
+ - Rotate keys and revoke PATs.
+
+4) Approval (HIGH)
+ - Deploy approval gateway (k8s/manifests/approval-gateway-deployment.yaml)
+ - Wire orchestrator to call /request-approval; gateway will create PR and request reviewers.
+ - On PR merge, gateway notifies orchestrator to log approval in decision_log.
+
+5) Decision Log & BI (MEDIUM)
+ - Apply SQL migration: sql/002_add_indexes_decision_log.sql
+ - Optionally schedule tools/decisionlog_to_elastic.py for mirroring to ES
+
+6) Feature Store & Labeling (MEDIUM)
+ - Deploy Feast online & sync job (k8s/manifests/*), labeling queue (k8s/manifests/labeling-queue-deployment.yaml)
+
+7) Monitoring & DR (MEDIUM)
+ - Add Prometheus rules (not included here), schedule cross-region sync (dr/cross_region_sync_cronjob.yaml)
+
+Testing & Validation
+ - Run dry-run cycles, validate Vault injection, run OPA tests, verify PR approval flow and decision_log entries.
+
+Contact SRE/Security/ML for signoff.
