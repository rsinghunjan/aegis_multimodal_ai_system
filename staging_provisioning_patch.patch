*** Begin Patch
*** Add File:infra/secrets/externalsecret_cosign_kms.yaml
+apiVersion: external-secrets.io/v1beta1
+kind: ExternalSecret
+metadata:
+  name: cosign-kms-secrets
+  namespace: aegis
+spec:
+  refreshInterval: "1h"
+  secretStoreRef:
+    name: aws-secrets-manager
+    kind: SecretStore
+  target:
+    name: cosign-kms-secrets
+    creationPolicy: Owner
+  data:
+    - secretKey: COSIGN_KMS_KEY_ARN
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/cosign/kms_key_arn"
+    - secretKey: COSIGN_ACCESS_KEY_ID
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/cosign/access_key_id"
+    - secretKey: COSIGN_SECRET_ACCESS_KEY
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/cosign/secret_access_key"
+    - secretKey: REKOR_URL
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/cosign/rekor_url"
+    - secretKey: REKOR_API_KEY
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/cosign/rekor_api_key"
+
+# Populate your SecretsManager keys under REPLACE_SECRET_PREFIX before applying.
+
*** End Patch
*** Begin Patch
*** Add File:infra/secrets/externalsecret_app_secrets.yaml
+apiVersion: external-secrets.io/v1beta1
+kind: ExternalSecret
+metadata:
+  name: aegis-app-secrets
+  namespace: aegis
+spec:
+  refreshInterval: "1h"
+  secretStoreRef:
+    name: aws-secrets-manager
+    kind: SecretStore
+  target:
+    name: aegis-app-secrets
+    creationPolicy: Owner
+  data:
+    - secretKey: MLFLOW_TRACKING_URI
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/mlflow/tracking_uri"
+    - secretKey: MLFLOW_USERNAME
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/mlflow/username"
+    - secretKey: MLFLOW_PASSWORD
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/mlflow/password"
+    - secretKey: EVIDENCE_BUCKET
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/s3/evidence_bucket"
+    - secretKey: CARBON_GUARD_API_KEY
+      remoteRef:
+        key: "REPLACE_SECRET_PREFIX/carbon/guard_api_key"
+
*** End Patch
*** Begin Patch
*** Add File:infra/kms/create_cosign_kms.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Helper script (operator-run) to create an AWS KMS key for cosign and output guidance to store in SecretsManager.
+#
+# Usage:
+#   ./infra/kms/create_cosign_kms.sh <alias-name> <aws-profile> <aws-region>
+#
+ALIAS=${1:-"alias/aegis-cosign-key"}
+AWS_PROFILE=${2:-""}
+AWS_REGION=${3:-"us-west-2"}
+
+AWS_CLI="aws"
+if [ -n "${AWS_PROFILE}" ]; then
+  AWS_CLI="${AWS_CLI} --profile ${AWS_PROFILE}"
+fi
+
+echo "Creating KMS key with alias ${ALIAS} in ${AWS_REGION}..."
+KEY_ID=$(${AWS_CLI} kms create-key --region ${AWS_REGION} --query KeyMetadata.KeyId --output text)
+echo "KeyId: ${KEY_ID}"
+${AWS_CLI} kms create-alias --region ${AWS_REGION} --alias-name "${ALIAS}" --target-key-id "${KEY_ID}"
+KEY_ARN=$(${AWS_CLI} kms describe-key --key-id "${KEY_ID}" --region ${AWS_REGION} --query KeyMetadata.Arn --output text)
+echo "KMS Key ARN: ${KEY_ARN}"
+
+echo
+echo "Next steps (operator):"
+echo "1) Add a SecretsManager entry at path REPLACE_SECRET_PREFIX/cosign/kms_key_arn with value: ${KEY_ARN}"
+echo "2) Configure IAM permissions so the CI runner and cosign admission have Encrypt/Decrypt/Sign permissions."
+echo "3) Configure cosign to use awskms signer in your CI: cosign sign --key awskms://${KEY_ARN} <artifact>"
+
+exit 0
+
*** End Patch
*** Begin Patch
*** Add File:infra/cert-manager/generate_webhook_ca.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Create a cert-manager Certificate and extract CA bundle for use in ValidatingWebhookConfiguration.
+#
+# Usage:
+#   ./infra/cert-manager/generate_webhook_ca.sh <namespace> <service-name> <issuer-name>
+#
+NAMESPACE=${1:-security}
+SERVICE=${2:-cosign-admission}
+ISSUER=${3:-letsencrypt-prod}  # replace with cluster issuer
+
+echo "Create a Certificate using cert-manager (example manifest)..."
+cat <<EOF | kubectl apply -f -
+apiVersion: cert-manager.io/v1
+kind: Certificate
+metadata:
+  name: ${SERVICE}-tls
+  namespace: ${NAMESPACE}
+spec:
+  dnsNames:
+  - ${SERVICE}.${NAMESPACE}.svc.cluster.local
+  secretName: ${SERVICE}-tls
+  issuerRef:
+    name: ${ISSUER}
+    kind: ClusterIssuer
+EOF
+
+echo "Waiting for secret ${SERVICE}-tls..."
+kubectl wait --for=condition=Ready --timeout=120s certificate/${SERVICE}-tls -n ${NAMESPACE} || true
+
+echo "Extracting CA bundle..."
+kubectl get secret ${SERVICE}-tls -n ${NAMESPACE} -o jsonpath="{.data['ca\.crt']}" | base64 --decode > /tmp/${SERVICE}-ca.crt
+echo "CA bundle saved to /tmp/${SERVICE}-ca.crt"
+echo "Use the base64 of this file to populate the caBundle field in ValidatingWebhookConfiguration."
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/build_push_images.yml
+name: Build & Push Aegis Images
+
+on:
+  workflow_dispatch:
+  push:
+    paths:
+      - 'mcp/**'
+      - 'explainability/**'
+      - 'mcp_context/**'
+      - 'security/**'
+      - 'carbon/**'
+
+jobs:
+  build:
+    runs-on: ubuntu-latest
+    env:
+      REGISTRY: ghcr.io/${{ github.repository_owner }}
+      IMAGE_TAG: ${{ github.sha }}
+    steps:
+      - uses: actions/checkout@v4
+      - name: Set up QEMU
+        uses: docker/setup-qemu-action@v2
+      - name: Set up Docker Buildx
+        uses: docker/setup-buildx-action@v2
+      - name: Login to registry
+        uses: docker/login-action@v2
+        with:
+          registry: ghcr.io
+          username: ${{ github.actor }}
+          password: ${{ secrets.GITHUB_TOKEN }}
+      - name: Build & push MCP image
+        run: |
+          docker build -t $REGISTRY/aegis-mcp:$IMAGE_TAG mcp/api
+          docker push $REGISTRY/aegis-mcp:$IMAGE_TAG
+      - name: Build & push MCP operator image
+        run: |
+          docker build -t $REGISTRY/aegis-mcp-operator:$IMAGE_TAG mcp/operator
+          docker push $REGISTRY/aegis-mcp-operator:$IMAGE_TAG
+      - name: Build & push cosign admission image
+        run: |
+          docker build -t $REGISTRY/aegis-cosign-admission:$IMAGE_TAG security/cosign-admission
+          docker push $REGISTRY/aegis-cosign-admission:$IMAGE_TAG
+      - name: Output images
+        run: |
+          echo "MCP_IMAGE=$REGISTRY/aegis-mcp:$IMAGE_TAG" >> $GITHUB_OUTPUT
+          echo "OPERATOR_IMAGE=$REGISTRY/aegis-mcp-operator:$IMAGE_TAG" >> $GITHUB_OUTPUT
+          echo "ADMISSION_IMAGE=$REGISTRY/aegis-cosign-admission:$IMAGE_TAG" >> $GITHUB_OUTPUT
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/deploy_staging.yml
+name: Deploy to Staging (Helm + Apply Manifests)
+
+on:
+  workflow_dispatch:
+
+jobs:
+  deploy:
+    runs-on: ubuntu-latest
+    env:
+      KUBE_CONTEXT: ${{ secrets.STAGING_KUBE_CONTEXT }}
+      IMAGE_TAG: ${{ github.sha }}
+      REGISTRY: ghcr.io/${{ github.repository_owner }}
+      EVIDENCE_BUCKET: ${{ secrets.EVIDENCE_BUCKET }}
+    steps:
+      - uses: actions/checkout@v4
+      - name: Set kubectl context
+        uses: azure/setup-kubectl@v3
+        with:
+          version: '1.27.3'
+      - name: Setup Kubeconfig
+        run: |
+          echo "${{ secrets.KUBECONFIG_STAGING }}" > kubeconfig && export KUBECONFIG=$(pwd)/kubeconfig
+          kubectl config use-context "${KUBE_CONTEXT}"
+      - name: Apply ExternalSecrets
+        run: |
+          kubectl apply -f infra/secrets/externalsecret_app_secrets.yaml
+          kubectl apply -f infra/secrets/externalsecret_cosign_kms.yaml
+      - name: Deploy cert-manager resources (if not present)
+        run: |
+          # cert-manager should be installed by operators; ensure Certificate manifest is available
+          kubectl apply -f infra/cert-manager/certificate-example.yaml || true
+      - name: Deploy cosign admission
+        env:
+          IMAGE: $REGISTRY/aegis-cosign-admission:${IMAGE_TAG}
+        run: |
+          sed "s|ghcr.io/yourorg/aegis-cosign-admission:latest|${IMAGE}|" security/cosign-admission/deployment.yaml | kubectl apply -f -
+      - name: Deploy MCP & operator
+        env:
+          MCP_IMAGE: $REGISTRY/aegis-mcp:${IMAGE_TAG}
+          OP_IMAGE: $REGISTRY/aegis-mcp-operator:${IMAGE_TAG}
+        run: |
+          sed "s|ghcr.io/yourorg/aegis-mcp:latest|${MCP_IMAGE}|" mcp/manifests/mcp-deployment.yaml | kubectl apply -f -
+          sed "s|ghcr.io/yourorg/aegis-mcp-operator:latest|${OP_IMAGE}|" mcp/manifests/operator-deployment.yaml | kubectl apply -f -
+      - name: Deploy Gatekeeper constraints (staging - audit mode)
+        run: |
+          kubectl apply -f devsecops/gatekeeper/constraint_require_signed_images.yaml
+          # In staging, set Gatekeeper to report-only by creating Constraint with enforcementAction: "dryrun" (operator modify as needed)
+          # Operators should create a Constraint instance with dryrun enforcement.
+      - name: Wait for pods
+        run: |
+          kubectl rollout status deployment/aegis-mcp -n aegis --timeout=120s || true
+          kubectl rollout status deployment/aegis-mcp-operator -n aegis --timeout=120s || true
+
*** End Patch
*** Begin Patch
*** Add File:scripts/run_validations.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run the full validation suite in staging.
+# Expects:
+#  - kubectl context pointed to staging
+#  - EVIDENCE_BUCKET and MLFLOW_TRACKING_URI set in env
+#  - Tools: docker, python with environment for harnesses
+#
+echo "Starting full validation suite..."
+
+ROOT_DIR="$(cd "$(dirname "$0")/.." && pwd)"
+
+echo "1) Run fairness tests (if test dataset present)..."
+if [ -f fairness/test_data/test_preds.csv ]; then
+  python fairness/fairness_eval.py --csv fairness/test_data/test_preds.csv --sensitive sensitive_attr --label label --pred pred --run-id staging-fairness
+else
+  echo "No fairness test data; skipping"
+fi
+
+echo "2) Run hallucination/PII harness (if present)..."
+if [ -f safety/hallucination/pairs.json ]; then
+  # Example: call hallucination service or local harness
+  python safety/hallucination_factuality/hallucination_eval.py --run-id staging-halluc --pairs safety/hallucination/pairs.json --model-url http://aegis-mcp.aegis.svc.cluster.local:8089/predict || true
+else
+  echo "No hallucination dataset; skipping"
+fi
+
+echo "3) Run membership inference monitor (if sample exists in S3)..."
+if [ -n "${EVIDENCE_BUCKET:-}" ]; then
+  # Assumes you have uploaded a sample JSON at s3://$EVIDENCE_BUCKET/mi_samples/staging_samples.json
+  python privacy/membership_inference_monitor.py --endpoint http://aegis-mcp.aegis.svc.cluster.local:8089/predict --s3-key mi_samples/staging_samples.json || true
+else
+  echo "EVIDENCE_BUCKET not set; skipping MI monitor"
+fi
+
+echo "4) Run confinement / red-team tests (best-effort)"
+if [ -d security/confinement_tests ]; then
+  echo "Running confinement tests..."
+  # Placeholder: implement the specific containment tests. For now, run any Python scripts present.
+  for t in security/confinement_tests/*.py; do
+    [ -f "$t" ] || continue
+    python "$t" || echo "Test $t failed (see logs)"
+  done
+else
+  echo "No confinement tests; skipping"
+fi
+
+echo "5) Run scale tests (RAG throughput, Milvus bulk index, Deepspeed smoke)"
+echo "5a) Milvus bulk index (if dataset provided)"
+if [ -f infra/scale/milvus_bulk_index.sh ]; then
+  bash infra/scale/milvus_bulk_index.sh || echo "Milvus bulk index test failed"
+else
+  echo "No Milvus scale script; skipping"
+fi
+
+echo "5b) RAG throughput (Vegeta or similar)"
+if [ -f infra/scale/rag_vegeta.sh ]; then
+  bash infra/scale/rag_vegeta.sh || echo "RAG throughput test failed"
+else
+  echo "No RAG throughput script; skipping"
+fi
+
+echo "5c) Deepspeed smoke"
+if [ -f infra/scale/deepspeed_smoke.sh ]; then
+  bash infra/scale/deepspeed_smoke.sh || echo "Deepspeed smoke failed"
+else
+  echo "No Deepspeed smoke script; skipping"
+fi
+
+echo "Validation suite completed. Inspect MLflow, S3 and Prometheus/Grafana for results."
+
*** End Patch
*** Begin Patch
*** Add File:infra/scale/milvus_bulk_index.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Example Milvus bulk index smoke script (operator must provide dataset and access)
+#
+MILVUS_HOST=${MILVUS_HOST:-"milvus.aegis.svc.cluster.local"}
+MILVUS_PORT=${MILVUS_PORT:-19530}
+SAMPLE_DATA=${SAMPLE_DATA:-"/data/milvus_sample.csv"}
+
+if [ ! -f "${SAMPLE_DATA}" ]; then
+  echo "No sample data at ${SAMPLE_DATA}; skip"
+  exit 0
+fi
+
+python - <<PY
+import pandas as pd
+from pymilvus import connections, FieldSchema, CollectionSchema, Collection
+
+connections.connect(host="${MILVUS_HOST}", port="${MILVUS_PORT}")
+df = pd.read_csv("${SAMPLE_DATA}")
+print("Loaded", len(df), "rows")
+# Placeholder: create collection, insert embeddings (operators must adapt)
+print("Milvus bulk index script is a template; replace with your indexing logic.")
+PY
+
*** End Patch
*** Begin Patch
*** Add File:infra/scale/rag_vegeta.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Simple vegeta-style HTTP load test placeholder for RAG service.
+#
+RAG_ENDPOINT=${RAG_ENDPOINT:-"http://rag-service.aegis.svc.cluster.local/query"}
+LOAD_DURATION=${LOAD_DURATION:-30s}
+RATE=${RATE:-10}
+
+if ! command -v vegeta >/dev/null 2>&1; then
+  echo "vegeta not installed; please install or run alternative load test"
+  exit 0
+fi
+
+echo "GET ${RAG_ENDPOINT}" | vegeta attack -duration=${LOAD_DURATION} -rate=${RATE} | vegeta report
+
*** End Patch
*** Begin Patch
*** Add File:infra/scale/deepspeed_smoke.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Deepspeed smoke runner (example)
+#
+echo "Running Deepspeed smoke job (placeholder)"
+echo "Operator: replace with your actual Deepspeed job submission (Slurm or k8s job)."
+exit 0
+
*** End Patch
*** Begin Patch
*** Add File:infra/gatekeeper/failclosed_constraint.yaml
+apiVersion: templates.gatekeeper.sh/v1beta1
+kind: ConstraintTemplate
+metadata:
+  name: failclosedconstraint
+spec:
+  crd:
+    spec:
+      names:
+        kind: FailClosedConstraint
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package failclosed
+        violation[{"msg": msg}] {
+          input.review.object.kind == "Deployment"
+          annotations := input.review.object.metadata.annotations
+          annotations["aegis.require_signed_images"] == "true"
+          not annotations["aegis.cosign.signature"]
+          msg := "Deployment requires cosign signature annotation; failing admission in fail-closed mode."
+        }
+
+---
+# Example Constraint instance to enforce in production (create in prod namespace with enforcementAction: deny)
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: FailClosedConstraint
+metadata:
+  name: require-signed-prod
+spec:
+  match:
+    namespaces:
+      - "aegis"
+
*** End Patch
*** Begin Patch
*** Add File:infra/falco/falco_rules_tuning.yaml
+# Falco tuning rules (examples) - operators should adapt thresholds to reduce noise
+falco_rules:
+  - rule: Detect high-frequency execs in container
+    desc: "Avoid noisy alerts from heavy CI jobs; tune thresholds"
+    condition: evt.type = execve and proc.name in (python, bash)
+    output: "High-frequency exec in container (user=%user.name container=%container.id image=%container.image)"
+    priority: WARNING
+    tags: [performance, tuning]
+
+  - rule: Suspicious file write to /etc
+    desc: "Monitor writes to /etc but reduce false positives for config management"
+    condition: evt.type = open and fd.name startswith /etc and not proc.name in (systemd, kubelet)
+    output: "Write to /etc by %proc.name in container %container.id"
+    priority: NOTICE
+    tags: [safety]
+
*** End Patch
*** Begin Patch
*** Add File:runbooks/staging_hardening_playbook.md
+# Staging Hardening & Validation Playbook
+
+Purpose: step-by-step instructions and scripts to provision KMS/secrets, TLS, deploy to staging, and run validation suites.
+
+Pre-requisites:
+- AWS CLI configured with operator credentials
+- kubectl configured for staging cluster
+- cert-manager installed on cluster
+- ExternalSecrets/SecretStore configured to use AWS Secrets Manager
+- GitHub Actions secrets configured for CI image push & staging kubeconfig
+
+Steps:
+1) Create/Provision KMS for cosign
+   - Run: infra/kms/create_cosign_kms.sh alias/aegis-cosign-key <aws-profile> <region>
+   - Take the KMS ARN printed and store in SecretsManager at path REPLACE_SECRET_PREFIX/cosign/kms_key_arn
+
+2) Populate SecretsManager entries
+   - Populate MLflow creds, S3 evidence bucket, Rekor URL/API key and COSIGN KMS ARN (use secure procedures)
+   - Example SecretsManager keys:
+     - REPLACE_SECRET_PREFIX/mlflow/tracking_uri
+     - REPLACE_SECRET_PREFIX/s3/evidence_bucket
+     - REPLACE_SECRET_PREFIX/cosign/kms_key_arn
+     - REPLACE_SECRET_PREFIX/cosign/rekor_url
+
+3) Apply ExternalSecrets in cluster
+   - kubectl apply -f infra/secrets/externalsecret_app_secrets.yaml
+   - kubectl apply -f infra/secrets/externalsecret_cosign_kms.yaml
+
+4) Generate TLS certificate for admission webhook
+   - ./infra/cert-manager/generate_webhook_ca.sh security cosign-admission <cluster-issuer>
+   - Base64-encode /tmp/cosign-admission-ca.crt and populate ValidatingWebhookConfiguration caBundle
+
+5) Build & push images via GitHub Action
+   - Trigger .github/workflows/build_push_images.yml via repository_dispatch or push
+   - Confirm images appear in registry and note IMAGE_TAG (sha)
+
+6) Deploy to staging
+   - Trigger .github/workflows/deploy_staging.yml or run scripts/deploy_staging.sh locally
+   - Ensure Gatekeeper constraints are applied in dry-run / audit mode initially
+
+7) Run validations
+   - Run scripts/run_validations.sh to execute fairness, hallucination, MI, confinement and scale tests
+   - Review MLflow tags, S3 evidence and Prometheus/Grafana dashboards for results
+
+8) Harden policies & flip fail-closed
+   - After validation, adjust Gatekeeper Constraint instances to enforcementAction: deny for production namespaces
+   - Update Falco rules via infra/falco/falco_rules_tuning.yaml and tune noise thresholds
+
+9) Final signoff
+   - Execute a full representative flow end-to-end and collect artifacts (cosign signatures, Rekor entries, model_card, run_context S3 pointer)
+   - Store evidence and hand to auditor for signoff
+
*** End Patch
*** End Patch
