diff --git a/scripts/signoff/collect_signoff_artifacts.sh b/scripts/signoff/collect_signoff_artifacts.sh
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/scripts/signoff/collect_signoff_artifacts.sh
@@ -0,0 +1,200 @@
+#!/usr/bin/env bash
+#
+# Collect signoff artifacts for Aegis agent runs:
+# - decision_log export (Postgres)
+# - Argo workflows for timeframe / label
+# - Promotion PR links (GitHub query)
+#
+# Requires:
+# - kubectl configured to staging cluster
+# - argo CLI installed & able to reach Argo server (or use kubectl to fetch workflows)
+# - jq, curl, psql (or kubectl + psql inside pod)
+# - env:
+#     NAMESPACE (default aegis-ml)
+#     ARTIFACT_DIR (default ./artifacts/<timestamp>)
+#     GITHUB_REPO (owner/repo)
+#     GITHUB_TOKEN (installation token or personal token with repo read)
+#
+set -euo pipefail
+
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+TS="$(date -u +%Y%m%dT%H%M%SZ)"
+ARTIFACT_DIR="${ARTIFACT_DIR:-./artifacts/$TS}"
+GITHUB_REPO="${GITHUB_REPO:-}"
+GITHUB_TOKEN="${GITHUB_TOKEN:-}"
+
+mkdir -p "$ARTIFACT_DIR"
+echo "Artifacts will be written to $ARTIFACT_DIR"
+
+echo "1) Export recent decision_log rows from Postgres"
+# Prefer running psql inside the aegis-postgres pod to avoid exposing credentials
+POD="$(kubectl -n "$NAMESPACE" get pods -l app=aegis-postgres -o jsonpath='{.items[0].metadata.name}')"
+if [ -n "$POD" ]; then
+  echo "Found postgres pod: $POD"
+  kubectl -n "$NAMESPACE" exec "$POD" -- bash -lc "psql -U aegis -d aegis -c \"COPY (SELECT id, created_at, agent, model, env, action, payload, evidence, metadata FROM decision_log ORDER BY created_at DESC LIMIT 1000) TO STDOUT WITH CSV HEADER\" " > "$ARTIFACT_DIR/decision_log_recent.csv" || true
+  echo "Wrote decision_log_recent.csv"
+else
+  echo "No aegis-postgres pod found. Skipping DB export."
+fi
+
+echo "2) Collect Argo workflows referencing the orchestrator / retrain runs"
+# Use argo CLI if available; otherwise use kubectl get workflows
+if command -v argo >/dev/null 2>&1; then
+  WF_LIST_FILE="$ARTIFACT_DIR/argo_workflows_list.json"
+  argo list --output json > "$WF_LIST_FILE" || true
+  echo "Saved Argo workflow list to $WF_LIST_FILE"
+  # Optionally export recent workflows
+  jq -r '.[].metadata.name' "$WF_LIST_FILE" | while read -r wf; do
+    echo "Exporting workflow $wf"
+    argo get "$wf" -o yaml > "$ARTIFACT_DIR/argo_workflow_${wf}.yaml" || true
+  done
+else
+  echo "argo CLI not found; using kubectl to list Workflow CRs"
+  kubectl -n "$NAMESPACE" get workflows -o json > "$ARTIFACT_DIR/argo_workflows_kubectl.json" || true
+  jq -r '.items[].metadata.name' "$ARTIFACT_DIR/argo_workflows_kubectl.json" | while read -r wf; do
+    kubectl -n "$NAMESPACE" get workflow "$wf" -o yaml > "$ARTIFACT_DIR/argo_workflow_${wf}.yaml" || true
+  done
+fi
+
+echo "3) Capture orchestrator logs (recent)"
+kubectl -n "$NAMESPACE" logs deploy/aegis-orchestrator --tail=500 > "$ARTIFACT_DIR/orchestrator_logs_tail500.log" || true
+
+echo "4) Collect promotion PRs from GitHub (label=auto-promote or search)"
+if [ -n "$GITHUB_REPO" ] && [ -n "$GITHUB_TOKEN" ]; then
+  GH_API="https://api.github.com/repos/$GITHUB_REPO/pulls?state=all&per_page=100"
+  echo "Querying GitHub PRs for repo $GITHUB_REPO"
+  curl -sS -H "Authorization: token $GITHUB_TOKEN" "$GH_API" | jq '.' > "$ARTIFACT_DIR/github_prs.json" || true
+  # Filter PRs created by bots or with label 'auto-promote'
+  jq '[ .[] | select((.user.login|test("aegis|bot")) or (.labels[]?.name=="auto-promote")) ]' "$ARTIFACT_DIR/github_prs.json" > "$ARTIFACT_DIR/github_auto_promote_prs.json" || true
+  echo "Saved github_auto_promote_prs.json"
+else
+  echo "GITHUB_REPO or GITHUB_TOKEN not set; skipping GitHub PR collection."
+fi
+
+echo "5) Package artifacts"
+tar -czf "${ARTIFACT_DIR}.tgz" -C "$(dirname "$ARTIFACT_DIR")" "$(basename "$ARTIFACT_DIR")"
+echo "Packaged artifacts to ${ARTIFACT_DIR}.tgz"
+
+echo "Signoff artifacts ready at ${ARTIFACT_DIR} and ${ARTIFACT_DIR}.tgz"
+echo "Share securely with product/SRE/Sec for review."
+
diff --git a/vault/setup_dynamic_db.sh b/vault/setup_dynamic_db.sh
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/vault/setup_dynamic_db.sh
@@ -0,0 +1,180 @@
+#!/usr/bin/env bash
+#
+# Configure Vault to issue dynamic Postgres credentials for Aegis agents, and store GitHub App key in KV.
+#
+# This is an operator-level helper. It assumes Vault CLI / VAULT_ADDR / VAULT_TOKEN present.
+#
+# Usage example:
+# ./vault/setup_dynamic_db.sh --db-host aegis-postgres.aegis-ml.svc.cluster.local --db-name aegis --db-admin-user postgres --db-admin-pass-file ./pg_admin_pass
+
+set -euo pipefail
+
+DB_HOST=""
+DB_NAME="aegis"
+DB_ADMIN_USER=""
+DB_ADMIN_PASS_FILE=""
+VAULT_MOUNT_PATH="${VAULT_MOUNT_PATH:-database}"
+VAULT_KV_PATH="${VAULT_KV_PATH:-secret/data/aegis}"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --db-host) DB_HOST="$2"; shift 2;;
+    --db-name) DB_NAME="$2"; shift 2;;
+    --db-admin-user) DB_ADMIN_USER="$2"; shift 2;;
+    --db-admin-pass-file) DB_ADMIN_PASS_FILE="$2"; shift 2;;
+    --vault-mount) VAULT_MOUNT_PATH="$2"; shift 2;;
+    --vault-kv) VAULT_KV_PATH="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+if [ -z "${VAULT_ADDR:-}" ] || [ -z "${VAULT_TOKEN:-}" ]; then
+  echo "Set VAULT_ADDR and VAULT_TOKEN in environment"
+  exit 1
+fi
+
+if [ -z "$DB_HOST" ] || [ -z "$DB_ADMIN_USER" ] || [ -z "$DB_ADMIN_PASS_FILE" ]; then
+  echo "Provide --db-host, --db-admin-user and --db-admin-pass-file"
+  exit 1
+fi
+
+DB_ADMIN_PASS="$(cat "$DB_ADMIN_PASS_FILE")"
+
+echo "1) Enable database secrets engine at: $VAULT_MOUNT_PATH"
+vault secrets enable -path="$VAULT_MOUNT_PATH" database || true
+
+echo "2) Configure Postgres plugin connection in Vault"
+vault write "$VAULT_MOUNT_PATH/config/postgresql" \
+  plugin_name="postgresql-database-plugin" \
+  allowed_roles="aegis-role" \
+  connection_url="postgresql://{{username}}:{{password}}@${DB_HOST}/${DB_NAME}?sslmode=disable" \
+  username="$DB_ADMIN_USER" \
+  password="$DB_ADMIN_PASS"
+
+echo "3) Create a role that maps a creation statement to create DB user with limited TTL"
+vault write "$VAULT_MOUNT_PATH/roles/aegis-role" \
+  db_name="postgresql" \
+  creation_statements="CREATE ROLE \"{{name}}\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; GRANT CONNECT ON DATABASE ${DB_NAME} TO \"{{name}}\";" \
+  default_ttl="1h" \
+  max_ttl="24h"
+
+echo "4) Store GitHub App key in KV (optional) under $VAULT_KV_PATH/github_app"
+echo "To store a PEM file, use:"
+echo "  vault kv put $VAULT_KV_PATH/github_app private_key=@/path/to/github_app.pem app_id=<app_id> installation_id=<installation_id>"
+
+echo "5) Create a Vault policy for agents to read these secrets (example in vault/agents_policy.hcl)."
+echo "  vault policy write aegis-agents vault/agents_policy.hcl"
+
+echo "Vault dynamic DB role setup complete. Agents can request credentials via Vault API or agent injector."
+
diff --git a/vault/agents_policy.hcl b/vault/agents_policy.hcl
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/vault/agents_policy.hcl
@@ -0,0 +1,80 @@
+# Example Vault policy for Aegis agents
+# Allows read of github_app (KVv2) and dynamic DB creds mount path
+path "secret/data/aegis/github_app" {
+  capabilities = ["read"]
+}
+
+# Allow read for other aegis secrets
+path "secret/data/aegis/*" {
+  capabilities = ["read", "list"]
+}
+
+# Allow issuance of dynamic DB credentials from the configured database mount
+path "database/creds/aegis-role" {
+  capabilities = ["read"]
+}
+
+# Allow agents to renew tokens and read their own tokens
+path "auth/token/lookup-self" {
+  capabilities = ["read"]
+}
+
diff --git a/scripts/signoff/run_dry_runs.sh b/scripts/signoff/run_dry_runs.sh
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/scripts/signoff/run_dry_runs.sh
@@ -0,0 +1,160 @@
+#!/usr/bin/env bash
+#
+# Run multiple dry-run cycles of synthetic drift and collect artifacts after each cycle.
+#
+# Usage:
+#   ./scripts/signoff/run_dry_runs.sh --cycles 5 --interval 30
+#
+set -euo pipefail
+
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+CYCLES="${CYCLES:-3}"
+INTERVAL="${INTERVAL:-30}"
+PORT_FORWARD_PID=0
+
+function port_forward_eventsource {
+  echo "Port-forwarding EventSource to localhost:12000 (background)"
+  kubectl -n "$NAMESPACE" port-forward svc/aegis-webhook-es 12000:12000 >/dev/null 2>&1 &
+  PORT_FORWARD_PID=$!
+  sleep 2
+  echo "Port-forward PID: $PORT_FORWARD_PID"
+}
+
+function stop_port_forward {
+  if [ "$PORT_FORWARD_PID" -ne 0 ]; then
+    echo "Stopping port-forward PID $PORT_FORWARD_PID"
+    kill "$PORT_FORWARD_PID" || true
+  fi
+}
+
+function run_cycle {
+  local idx="$1"
+  echo "=== Dry-run cycle $idx ==="
+  python tests/send_synthetic_drift.py --model low-demo-model --url http://localhost:12000/drift || true
+  # Wait a bit for orchestrator to process and write decision
+  sleep 5
+  # Collect artifacts for this cycle
+  ART_DIR="./artifacts/dryrun_cycle_${idx}_$(date -u +%Y%m%dT%H%M%SZ)"
+  mkdir -p "$ART_DIR"
+  echo "Collecting decision_log snapshot for cycle $idx"
+  POD="$(kubectl -n "$NAMESPACE" get pods -l app=aegis-postgres -o jsonpath='{.items[0].metadata.name}')"
+  if [ -n "$POD" ]; then
+    kubectl -n "$NAMESPACE" exec "$POD" -- bash -lc "psql -U aegis -d aegis -c \"COPY (SELECT id, created_at, agent, model, env, action, payload, evidence FROM decision_log ORDER BY created_at DESC LIMIT 20) TO STDOUT WITH CSV HEADER\" " > "$ART_DIR/decision_log_recent.csv" || true
+  fi
+  kubectl -n "$NAMESPACE" logs deploy/aegis-orchestrator --tail=200 > "$ART_DIR/orchestrator_tail.log" || true
+  echo "Saved artifacts to $ART_DIR"
+}
+
+trap stop_port_forward EXIT
+port_forward_eventsource
+
+for i in $(seq 1 "$CYCLES"); do
+  run_cycle "$i"
+  if [ "$i" -lt "$CYCLES" ]; then
+    echo "Sleeping $INTERVAL seconds before next cycle..."
+    sleep "$INTERVAL"
+  fi
+done
+
+stop_port_forward
+echo "Dry-run cycles complete. Review artifacts in ./artifacts/"
+
diff --git a/scripts/signoff/toggle_dry_run.sh b/scripts/signoff/toggle_dry_run.sh
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/scripts/signoff/toggle_dry_run.sh
@@ -0,0 +1,140 @@
+#!/usr/bin/env bash
+#
+# Toggle DRY_RUN env var on the orchestrator deployment and rollout restart to apply.
+#
+# Usage:
+#  ./scripts/signoff/toggle_dry_run.sh --namespace aegis-ml --dry-run false
+#
+set -euo pipefail
+
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+DRY_RUN_VAL="${1:-}"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --namespace) NAMESPACE="$2"; shift 2;;
+    --dry-run) DRY_RUN_VAL="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+if [ -z "$DRY_RUN_VAL" ]; then
+  echo "Provide --dry-run true|false"
+  exit 1
+fi
+
+DEPLOY="aegis-orchestrator"
+
+echo "Patching deployment $DEPLOY in namespace $NAMESPACE to set DRY_RUN=$DRY_RUN_VAL"
+kubectl -n "$NAMESPACE" set env deployment/"$DEPLOY" DRY_RUN="$DRY_RUN_VAL"
+echo "Rolling restart to pick up env change"
+kubectl -n "$NAMESPACE" rollout restart deployment/"$DEPLOY"
+echo "Waiting for rollout to finish..."
+kubectl -n "$NAMESPACE" rollout status deployment/"$DEPLOY" --timeout=120s
+echo "DRY_RUN is now set to $DRY_RUN_VAL and rollout completed."
+
diff --git a/scripts/signoff/chaos_drill_and_capture.sh b/scripts/signoff/chaos_drill_and_capture.sh
new file mode 100644
index 0000000..6666666
--- /dev/null
+++ b/scripts/signoff/chaos_drill_and_capture.sh
@@ -0,0 +1,220 @@
+#!/usr/bin/env bash
+#
+# Run a DR / chaos drill for staging, simulate worker preemption, capture artifacts for signoff.
+#
+# Requirements:
+# - kubectl connected to staging cluster
+# - scripts/signoff/collect_signoff_artifacts.sh present and executable
+# - scripts/signoff/run_dry_runs.sh available for pre-checks
+#
+# Usage:
+#   ./scripts/signoff/chaos_drill_and_capture.sh --namespace aegis-ml --worker-label "app=gpu-worker" --capture-dir ./drill-artifacts
+#
+set -euo pipefail
+
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+WORKER_LABEL="${WORKER_LABEL:-app=gpu-worker}"
+CAPTURE_DIR="${CAPTURE_DIR:-./drill-artifacts/$(date -u +%Y%m%dT%H%M%SZ)}"
+PRECHECK_CYCLES="${PRECHECK_CYCLES:-2}"
+
+mkdir -p "$CAPTURE_DIR"
+
+echo "1) Pre-check: run $PRECHECK_CYCLES dry-run cycles to establish baseline"
+./scripts/signoff/run_dry_runs.sh --cycles "$PRECHECK_CYCLES" --interval 10
+cp -r ./artifacts/* "$CAPTURE_DIR/" || true
+
+echo "2) Capture state before chaos"
+kubectl -n "$NAMESPACE" get pods -o wide > "$CAPTURE_DIR/pods_before.txt"
+kubectl -n "$NAMESPACE" get deployments -o wide > "$CAPTURE_DIR/deployments_before.txt"
+kubectl -n "$NAMESPACE" get svc -o wide > "$CAPTURE_DIR/services_before.txt"
+./scripts/signoff/collect_signoff_artifacts.sh || true
+cp -r ./artifacts/* "$CAPTURE_DIR/" || true
+
+echo "3) Trigger chaos: simulate worker preemption"
+POD=$(kubectl -n "$NAMESPACE" get pods -l "$WORKER_LABEL" -o jsonpath='{.items[0].metadata.name}' || true)
+if [ -z "$POD" ]; then
+  echo "No worker pod found with label $WORKER_LABEL; aborting chaos step"
+else
+  echo "Deleting pod $POD to simulate preemption"
+  kubectl -n "$NAMESPACE" delete pod "$POD" --grace-period=0 --force || true
+  echo "Deleted $POD; waiting for orchestrator / trainers to react"
+  sleep 30
+fi
+
+echo "4) Post-chaos: collect artifacts"
+kubectl -n "$NAMESPACE" get pods -o wide > "$CAPTURE_DIR/pods_after.txt"
+kubectl -n "$NAMESPACE" get deployments -o wide > "$CAPTURE_DIR/deployments_after.txt"
+./scripts/signoff/collect_signoff_artifacts.sh || true
+cp -r ./artifacts/* "$CAPTURE_DIR/" || true
+
+echo "5) Verify checkpoint/resume: check trainer pods logs for S3 checkpoint resume messages"
+kubectl -n "$NAMESPACE" get pods -l app=aegis-trainer -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n' | while read -r tpod; do
+  echo "==== logs for $tpod (tail 200) ====" >> "$CAPTURE_DIR/trainer_logs_after.txt" || true
+  kubectl -n "$NAMESPACE" logs "$tpod" --tail=200 >> "$CAPTURE_DIR/trainer_logs_after.txt" || true
+done
+
+echo "6) Package artifacts for signoff"
+tar -czf "${CAPTURE_DIR}.tgz" -C "$(dirname "$CAPTURE_DIR")" "$(basename "$CAPTURE_DIR")"
+echo "Chaos drill artifacts packaged at ${CAPTURE_DIR}.tgz"
+echo "Please review ${CAPTURE_DIR} and share with SRE/Security for formal signoff."
+
diff --git a/README_SIGNOFF.md b/README_SIGNOFF.md
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/README_SIGNOFF.md
@@ -0,0 +1,240 @@
+# Aegis Signoff & Chaos Drill Artifacts — How to run and what to collect
+
+This set of scripts helps you:
+
+- iterate policies with product/SRE/Sec and collect signoff artifacts (decision logs, Argo workflow JSON, PR links)
+- convert DB creds & GitHub App keys to Vault dynamic secrets (operator scripts & policies)
+- run multiple dry‑run cycles, toggle DRY_RUN and re‑run tests
+- schedule and execute a chaos/DR drill and capture artifacts for formal signoff
+
+Security note: Do NOT commit secrets into git. Use Vault/SealedSecrets and restrict access to the artifacts tarball.
+
+Files & purpose:
+- scripts/signoff/collect_signoff_artifacts.sh — gather decision_log, Argo workflows, orchestrator logs, and GitHub PRs
+- scripts/signoff/run_dry_runs.sh — run synthetic drift multiple times and capture per-cycle artifacts
+- scripts/signoff/toggle_dry_run.sh — patch orchestration deployment env var DRY_RUN and rollout restart
+- scripts/signoff/chaos_drill_and_capture.sh — perform pre-checks, simulate worker preemption, capture artifacts and package them
+- vault/setup_dynamic_db.sh — operator helper to enable Vault DB secrets engine and a role for dynamic Postgres creds
+- vault/agents_policy.hcl — example Vault policy for agents
+
+Recommended signoff workflow (high-level)
+1) Policy iteration & staging validation (collaborative)
+   - Product/SRE/Security review Rego policies: policy/opa/agent_policies_extended.rego and policy/opa/data/models.json
+   - Update data/models.json with authoritative model risk metadata (team, owners, budgets)
+   - Load policy & data into OPA (use k8s/manifests/opa-load.sh or your OPA deployment workflow)
+   - Run a few dry‑run cycles:
+       ./scripts/signoff/run_dry_runs.sh --cycles 3 --interval 30
+   - Review artifacts in ./artifacts/ and iterate policy rules until behavior matches expectations
+
+2) Convert credentials to Vault (operator action)
+   - Use vault/upload_to_vault.sh to put GitHub App key & DB admin credentials into Vault (kv v2)
+   - Configure DB dynamic secrets via vault/setup_dynamic_db.sh (operator must run with appropriate DB admin credentials)
+   - Create and apply a Vault policy for agents (vault/agents_policy.hcl)
+   - Configure Vault Agent Injector or CSI driver to mount secrets into orchestrator/agent pods (see Vault docs)
+   - Remove any staging plaintext secrets from k8s:
+       kubectl -n aegis-ml delete secret aegis-postgres-secret || true
+       kubectl -n aegis-ml delete secret aegis-github || true
+
+3) Dry‑run → enabling executes
+   - After repeated dry‑run cycles and policy tuning, toggle DRY_RUN:
+       ./scripts/signoff/toggle_dry_run.sh --namespace aegis-ml --dry-run false
+   - Re-run synthetic drift tests to confirm actions actually execute and remain safe
+   - Monitor decision_log, Argo workflows, and PR creation; watch Prometheus alerts for budget or deny spikes
+
+4) Chaos drill & artifacts collection (formal signoff)
+   - Run an orchestrated chaos drill and capture artifacts:
+       ./scripts/signoff/chaos_drill_and_capture.sh --namespace aegis-ml --worker-label "app=gpu-worker" --capture-dir ./drill-artifacts
+   - The script will:
+       * run pre-check dry-run cycles
+       * collect pre-chaos state (pods, deployments, services)
+       * delete one worker pod to simulate preemption
+       * collect post-chaos state and logs
+       * capture decision_log, Argo workflows, trainer logs and package them
+   - Share the packaged artifacts tarball with SRE & Security for review and signoff
+
+5) Signoff checklist (for SRE & Security)
+   - decision_log contains expected decisions with evidence (Argo workflow id, MLflow run id, PR link)
+   - At least one synthetic retrain executed end-to-end in staging with artifacts stored in object store
+   - Promotion PRs appear in GitHub with CODEOWNERS requested reviewers
+   - Gatekeeper denies invalid auto-promote manifests and OPA denies unsafe actions
+   - DRY_RUN toggle applied and tested
+   - Kill-switch validated (ConfigMap flip prevents external actions)
+   - Chaos drill shows trainer checkpoint & resume behavior and orchestrator response
+   - Budget guard fired (if configured) and no runaway retrains occurred during tests
+   - SRE & Security sign the signoff document and record date/time + artifact tarball id
+
+Operational notes & troubleshooting tips
+- If decision_log is empty: ensure DB schema initialized (see k8s/manifests/init_db_and_migrate.sh)
+- If PRs are not created: verify GitHub App installation id, private key present in Vault, and orchestrator has permission to exchange JWT for installation token
+- If Argo workflow not submitted: check orchestrator logs and OPA decision result (use opa debug endpoints)
+- If Gatekeeper denies valid manifests: inspect constraint status and Gatekeeper audit logs
+
+Retention & compliance
+- Store signoff artifact tarballs in a secure, long-lived object store (S3/GCS) with proper access control and retention policy
+- Record signoff in team governance system (Confluence / GitHub PR with artifact links)
+
+If you want, I can:
+- A) Open a PR adding these scripts and the README to your repo (provide owner/repo & target branch)
+- B) Customize the Vault & DB dynamic role scripts for your cloud provider (RDS / Cloud SQL / Azure DB)
+- C) Generate a small GitHub Action that runs the dry-run cycles and automatically uploads artifacts as build artifacts
+
+Which would you like next?
+
