*** Begin Patch
*** Add File:pilot/vault/create_vault_roles.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Create Vault policies and roles for pilots (quantum, edge, hpc).
+# This script requires vault CLI logged in as a token with policy write capability.
+#
+# Usage:
+#   VAULT_ADDR=https://vault.vault.svc:8200 VAULT_TOKEN=... ./pilot/vault/create_vault_roles.sh
+
+: "${VAULT_ADDR:?VAULT_ADDR required (e.g. https://vault.vault.svc:8200)}"
+
+echo "Creating policies and Kubernetes auth roles for pilot teams"
+
+cat > /tmp/policy-quantum.hcl <<'HCL'
+path "secret/data/aegis/quantum/*" {
+  capabilities = ["read","list"]
+}
+path "transit/sign/aegis-signing" {
+  capabilities = ["create","read"]
+}
+HCL
+
+cat > /tmp/policy-edge.hcl <<'HCL'
+path "secret/data/aegis/edge/*" {
+  capabilities = ["read","list"]
+}
+path "pki/issue/edge-client" {
+  capabilities = ["create","read"]
+}
+HCL
+
+cat > /tmp/policy-hpc.hcl <<'HCL'
+path "secret/data/aegis/hpc/*" {
+  capabilities = ["read","list"]
+}
+path "ssh/sign/hpc-ssh" {
+  capabilities = ["create","read"]
+}
+HCL
+
+echo "Writing policies into Vault..."
+vault policy write aegis-quantum /tmp/policy-quantum.hcl || true
+vault policy write aegis-edge /tmp/policy-edge.hcl || true
+vault policy write aegis-hpc /tmp/policy-hpc.hcl || true
+
+echo "Enabling kubernetes auth (if not enabled) and creating example roles"
+vault auth enable kubernetes || true
+
+# Note: the following roles assume a Kubernetes ServiceAccount per pilot: quantum-sa, edge-sa, hpc-sa in namespace aegis
+vault write auth/kubernetes/role/aegis-quantum \
+  bound_service_account_names="quantum-sa" \
+  bound_service_account_namespaces="aegis" \
+  policies="aegis-quantum" \
+  ttl="24h" || true
+
+vault write auth/kubernetes/role/aegis-edge \
+  bound_service_account_names="edge-sa" \
+  bound_service_account_namespaces="aegis" \
+  policies="aegis-edge" \
+  ttl="24h" || true
+
+vault write auth/kubernetes/role/aegis-hpc \
+  bound_service_account_names="hpc-sa" \
+  bound_service_account_namespaces="aegis" \
+  policies="aegis-hpc" \
+  ttl="24h" || true
+
+echo "Vault roles and policies created. Please populate secrets at secret/data/aegis/<team>/..."
+echo "Example: vault kv put secret/aegis/quantum/ibm TOKEN=xxx"
+
*** End Patch
*** Begin Patch
*** Add File:pilot/quantum/playbook_quantum.md
+Pilot Playbook: Quantum Pilot (Simulator + Optional Real Backend)
+
+Overview
+- Uses quantum/qiskit/qiskit_runner.py to run experiments on simulator and (optionally) real backends.
+- Captures results, bundles signed evidence and uploads to EVIDENCE_BUCKET.
+
+Prerequisites
+- Vault accessible and pilot policy created (see pilot/vault/create_vault_roles.sh).
+- EVIDENCE_BUCKET configured and cosign KMS key available (COSIGN_KMS_KEY_ARN).
+- Argo workflow (quantum/argo/argo_qiskit_job.yaml) or run locally with Python and qiskit installed.
+
+Steps
+1. Create Vault policy & role:
+   VAULT_ADDR=... VAULT_TOKEN=... ./pilot/vault/create_vault_roles.sh
+
+2. Inject provider credentials (for real backend) into Vault (operator):
+   vault kv put secret/aegis/quantum/ibm TOKEN="REPLACE_IBM_TOKEN"
+
+3. Run job via Argo:
+   argo submit -n aegis quantum/argo/argo_qiskit_job.yaml --watch
+
+4. Or run locally for quick test:
+   EVIDENCE_BUCKET=<bucket> ./quantum/qiskit/qiskit_runner.py --shots 512 --backend simulator
+
+5. Validate evidence in S3:
+   aws s3 ls s3://<EVIDENCE_BUCKET>/quantum/
+
+Notes
+- For pilot, start with simulator backend. Only enable real provider after credential injection and cost/quota checks.
+- Ensure output evidence includes backend metadata and cosign/Rekor attestation as per registry contract.
+
*** End Patch
*** Begin Patch
*** Add File:pilot/edge/playbook_edge.md
+Edge Pilot Playbook (Single Device)
+
+Overview
+- Deploy edge/agent/edge_agent.py on a test device or container to validate model verification, redaction, local signing & evidence upload.
+- Use pilot/edge/tuf_sign_and_publish.sh to publish a signed model bundle to S3 for OTA.
+
+Prerequisites
+- Device or VM with Python3, cosign, and awscli available.
+- EVIDENCE_BUCKET and COSIGN_KMS_KEY_ARN provisioned.
+- Device provisioning: place a local key at /etc/edge/key.pem for PoC (production use TPM).
+
+Steps
+1. Prepare example model package (on operator machine):
+   mkdir -p /tmp/artifacts && echo "demo model" > /tmp/artifacts/model.onnx
+   EVIDENCE_BUCKET=<bucket> COSIGN_KMS_KEY_ARN=<arn> ./edge/ota/tuf_sign_and_publish.sh /tmp/artifacts
+
+2. On device: install agent and configure env:
+   export EVIDENCE_BUCKET=<bucket>
+   export COSIGN_KMS_KEY_ARN=<arn>  # optional for verification with KMS
+   export EDGE_LOCAL_KEY=/etc/edge/key.pem
+   python3 edge/agent/edge_agent.py
+
+3. Inspect evidence in S3:
+   aws s3 ls s3://<EVIDENCE_BUCKET>/edge/
+
+Notes
+- For TPM-based PoC, use pilot/edge/agent_tpm_poc.py which demonstrates using a TPM-protected key (requires tpm2-tools & python-tss).
+- For fleet OTA, integrate the TUF pipeline into Argo workflows for staged rollout.
+
*** End Patch
*** Begin Patch
*** Add File:pilot/hpc/playbook_hpc.md
+HPC Pilot Playbook (Slurm Job)
+
+Overview
+- Submit a small Slurm job from Argo or bastion using hpc/argo/submit_slurm_job.py, fetch output, upload to S3 and sign evidence.
+
+Prerequisites
+- SSH access to HPC head node, SSH key injected into Vault or accessible to runner.
+- EVIDENCE_BUCKET available for evidence uploads.
+- Slurm cluster with sbatch and squeue.
+
+Steps
+1. Store SSH private key in Vault or make available to runner (operator must handle securely).
+
+2. Create a sample Slurm script (job.sh):
+   #!/bin/bash
+   #SBATCH --time=00:05:00
+   echo "Hello HPC" > slurm-$SLURM_JOB_ID.out
+
+3. Run from bastion:
+   python3 hpc/argo/submit_slurm_job.py --host <hpc-head> --user <user> --script job.sh --s3-bucket <EVIDENCE_BUCKET>
+
+4. Verify artifact & evidence:
+   aws s3 ls s3://<EVIDENCE_BUCKET>/hpc/
+
+Notes
+- For production, use Vault to issue ephemeral SSH certs and rotate keys regularly.
+- Ensure Slurm output includes job node metadata and environment capture for reproducibility.
+
*** End Patch
*** Begin Patch
*** Add File:edge/agent/agent_tpm_poc.py
+#!/usr/bin/env python3
+"""
+TPM PoC for edge agent:
+- Demonstrates generating an RSA key in TPM, signing a trace and exporting signature.
+Requires tpm2-tools and python tpm2-pytss (TPM2-TSS) installed.
+This is a PoC – do not use as-is in production without audit.
+"""
+import json, tempfile, subprocess, os
+from tpm2_pytss import *
+
+def generate_tpm_key():
+    with ESYS_CONTEXT() as ctx:
+        in_sensitive = TPM2B_SENSITIVE_CREATE()
+        rsa_public = TPM2B_PUBLIC.parse(
+            "rsa 2048 fixedtpm fixedparent restricted decrypt userwithauth"
+        )
+        primary = ctx.create_primary(TPM2_RH_OWNER, in_sensitive, rsa_public)
+        handle = primary[0]
+        # persist or use handle as needed
+        return handle
+
+def sign_with_tpm(data_path):
+    # For PoC, shell out to tpm2_sign if available
+    sig_path = data_path + ".sig"
+    try:
+        subprocess.run(["tpm2_sign", "-c", "0x81010001", "-g", "sha256", "-o", sig_path, data_path], check=True)
+        return sig_path
+    except Exception as e:
+        print("tpm2_sign failed or not available:", e)
+        return None
+
+def main():
+    # create a simple trace
+    tmp = tempfile.mkdtemp()
+    trace = {"req":"hello","res":"hi","ts":int(time.time())}
+    trace_path = os.path.join(tmp,"trace.json")
+    with open(trace_path,"w") as f:
+        json.dump(trace,f)
+    sig = sign_with_tpm(trace_path)
+    if sig:
+        print("Signed trace at", sig)
+    else:
+        print("TPM signing not available; install tpm2-tools and provision persistent key 0x81010001 for PoC")
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:pilot/scripts/run_quantum_pilot.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run the quantum pilot locally (simulator) or via Argo.
+
+: "${EVIDENCE_BUCKET:?EVIDENCE_BUCKET required}"
+
+echo "Running local quantum pilot (simulator)"
+EVIDENCE_BUCKET=${EVIDENCE_BUCKET} python3 quantum/qiskit/qiskit_runner.py --shots 512 --backend simulator
+
+echo "List evidence artifacts:"
+aws s3 ls s3://${EVIDENCE_BUCKET}/quantum/ || true
+
*** End Patch
*** Begin Patch
*** Add File:pilot/scripts/run_edge_pilot.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run edge pilot locally in a container-like environment (simulated device).
+
+: "${EVIDENCE_BUCKET:?EVIDENCE_BUCKET required}"
+
+echo "Preparing demo model and publishing via TUF-ish script"
+mkdir -p /tmp/artifacts && echo "demo model for edge" > /tmp/artifacts/model.onnx
+EVIDENCE_BUCKET=${EVIDENCE_BUCKET} COSIGN_KMS_KEY_ARN=${COSIGN_KMS_KEY_ARN:-} ./edge/ota/tuf_sign_and_publish.sh /tmp/artifacts
+
+echo "Starting edge agent (PoC) to process model and upload evidence (runs once)"
+EDGE_LOCAL_KEY=${EDGE_LOCAL_KEY:-/etc/edge/key.pem}
+EVIDENCE_BUCKET=${EVIDENCE_BUCKET} COSIGN_KMS_KEY_ARN=${COSIGN_KMS_KEY_ARN:-} EDGE_LOCAL_KEY=${EDGE_LOCAL_KEY} python3 edge/agent/edge_agent.py &
+sleep 5
+pkill -f edge_agent.py || true
+
+echo "Edge evidence artifacts:"
+aws s3 ls s3://${EVIDENCE_BUCKET}/edge/ || true
+
*** End Patch
*** Begin Patch
*** Add File:pilot/scripts/run_hpc_pilot.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run a small HPC pilot by submitting a Slurm script via SSH (requires SSH key setup).
+
+: "${EVIDENCE_BUCKET:?EVIDENCE_BUCKET required}"
+
+TMPJOB=/tmp/hpc_job.sh
+cat > ${TMPJOB} <<'BASH'
+#!/bin/bash
+#SBATCH --time=00:02:00
+echo "Hello from HPC" > slurm-$SLURM_JOB_ID.out
+hostname > hostinfo-$SLURM_JOB_ID.txt
+BASH
+
+echo "Submit and poll via submit_slurm_job.py (operator must set HPC_HEADNODE and HPC_USER env)"
+if [ -z "${HPC_HEADNODE:-}" ] || [ -z "${HPC_USER:-}" ]; then
+  echo "Set HPC_HEADNODE and HPC_USER to run this pilot (e.g. export HPC_HEADNODE=head.example.com HPC_USER=hpcuser)"
+  exit 2
+fi
+
+python3 hpc/argo/submit_slurm_job.py --host ${HPC_HEADNODE} --user ${HPC_USER} --script ${TMPJOB} --s3-bucket ${EVIDENCE_BUCKET}
+
+echo "Check evidence in S3:"
+aws s3 ls s3://${EVIDENCE_BUCKET}/hpc/ || true
+
*** End Patch
*** Begin Patch
*** Add File:pilot/README.md
+# Aegis Pilot Suite — Quantum, Edge, HPC
+
+This folder contains scripts and playbooks to run pilots across domains. Each pilot is designed to:
+- use Vault for secrets (roles & policies created by pilot/vault/create_vault_roles.sh)
+- run a small workload (simulator or simple job)
+- bundle signed evidence and upload to EVIDENCE_BUCKET
+
+Quick start (operator)
+1. Create Vault roles/policies:
+   VAULT_ADDR=https://vault.vault.svc:8200 VAULT_TOKEN=... ./pilot/vault/create_vault_roles.sh
+
+2. Configure env (example):
+   export EVIDENCE_BUCKET=my-evidence-bucket
+   export COSIGN_KMS_KEY_ARN=arn:aws:kms:...
+
+3. Run pilots:
+   ./pilot/scripts/run_quantum_pilot.sh
+   ./pilot/scripts/run_edge_pilot.sh
+   export HPC_HEADNODE=head.example.com HPC_USER=hpcuser
+   ./pilot/scripts/run_hpc_pilot.sh
+
+Notes & security
+- Do NOT commit real secrets. Use Vault/SealedSecrets to inject tokens and keys.
+- Edge TPM PoC requires tpm2-tools and python tpm2-pytss; follow vendor docs to provision TPM keys.
+- HPC SSH key management should rely on Vault or short-lived certificates.
+
*** End Patch
*** End Patch
