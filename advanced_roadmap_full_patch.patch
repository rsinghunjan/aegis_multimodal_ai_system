*** Begin Patch
*** Add File: provider/Dockerfile
+FROM python:3.10-slim
+WORKDIR /app
+COPY provider/requirements.txt /app/
+RUN pip install --no-cache-dir -r requirements.txt
+COPY provider/broker_service.py /app/
+EXPOSE 8080
+CMD ["python", "broker_service.py"]
+
*** End Patch
*** Begin Patch
*** Add File: provider/requirements.txt
+flask==2.2.5
+requests==2.31.0
+
*** End Patch
*** Begin Patch
*** Add File: provider/broker_service_v2.py
+#!/usr/bin/env python3
+"""
+Enhanced Provider Broker Service with Prometheus metrics and simple online learner.
+Endpoints:
+ - POST /select  {candidates:[{name,meta}], config?}  -> selected provider + scores
+ - POST /ingest  {provider, success, cost, latency, fidelity} -> store telemetry + adapt weights
+ - GET  /state   -> current weights & recent history
+ - GET  /metrics -> Prometheus metrics
+"""
+import json, os
+from datetime import datetime
+from flask import Flask, request, jsonify, Response
+from prometheus_client import Counter, Gauge, generate_latest, CONTENT_TYPE_LATEST
+
+STATE_PATH = "/data/provider_broker_state.json"
+DEFAULT_WEIGHTS = {"cost": -0.5, "latency": -0.2, "carbon": -0.1, "fidelity": 1.0}
+
+app = Flask("provider-broker-v2")
+ingest_counter = Counter("aegis_provider_ingest_total", "Telemetry ingested by provider broker", ["provider", "success"])
+select_counter = Counter("aegis_provider_select_total", "Selections made by the broker", ["selected"])
+current_weights_g = Gauge("aegis_provider_weights", "Current learned weights", list(DEFAULT_WEIGHTS.keys()))
+
+def load_state(path=STATE_PATH):
+    if os.path.exists(path):
+        return json.load(open(path))
+    return {"weights": DEFAULT_WEIGHTS.copy(), "history": []}
+
+def save_state(state, path=STATE_PATH):
+    os.makedirs(os.path.dirname(path), exist_ok=True)
+    with open(path, "w") as fh:
+        json.dump(state, fh, indent=2)
+
+def score_candidate(meta, weights):
+    cost = meta.get("cost_per_job", 1.0)
+    latency = meta.get("latency_ms", 100)
+    carbon = meta.get("carbon_g_per_kwh", 300)
+    fidelity = meta.get("avg_fidelity", 0.5)
+    score = (weights.get("cost",0.0) * (1.0 / max(0.001, cost))
+             + weights.get("latency",0.0) * (1.0 / max(1.0, latency))
+             + weights.get("carbon",0.0) * (1.0 / max(1.0, carbon))
+             + weights.get("fidelity",0.0) * fidelity)
+    return score
+
+@app.route("/select", methods=["POST"])
+def select():
+    payload = request.json or {}
+    candidates = payload.get("candidates", [])
+    config = payload.get("config", {})
+    state = load_state()
+    weights = state.get("weights", DEFAULT_WEIGHTS.copy())
+    weights.update(config.get("weights", {}))
+    details = {}
+    best = None
+    best_score = -1e18
+    for c in candidates:
+        name = c.get("name") or c.get("meta",{}).get("provider") or str(c)
+        meta = c.get("meta", {})
+        s = score_candidate(meta, weights)
+        details[name] = {"score": s, "meta": meta}
+        if s > best_score:
+            best_score = s
+            best = name
+    select_counter.labels(selected=best or "none").inc()
+    return jsonify({"timestamp": datetime.utcnow().isoformat(), "selected": best, "scores": details})
+
+@app.route("/ingest", methods=["POST"])
+def ingest():
+    rec = request.json or {}
+    state = load_state()
+    state["history"].append({"ts": datetime.utcnow().isoformat(), **rec})
+    w = state.get("weights", DEFAULT_WEIGHTS.copy())
+    lr = 0.01
+    # update fidelity weight slightly toward successes/failures
+    if "success" in rec:
+        delta = lr * (rec.get("success",0) - 0.5)
+        w["fidelity"] = max(-5.0, min(5.0, w.get("fidelity",1.0) + delta))
+    # emit metrics
+    try:
+        ingest_counter.labels(provider=rec.get("provider","unknown"), success=str(int(rec.get("success",0)))).inc()
+    except Exception:
+        pass
+    state["weights"] = w
+    save_state(state)
+    # update gauge
+    for k, v in w.items():
+        try:
+            current_weights_g.labels(k).set(v)
+        except Exception:
+            pass
+    return jsonify({"ok": True, "weights": state["weights"]})
+
+@app.route("/state", methods=["GET"])
+def state_get():
+    return jsonify(load_state())
+
+@app.route("/metrics")
+def metrics():
+    return Response(generate_latest(), mimetype=CONTENT_TYPE_LATEST)
+
+if __name__ == "__main__":
+    from argparse import ArgumentParser
+    p = ArgumentParser()
+    p.add_argument("--host", default="0.0.0.0")
+    p.add_argument("--port", type=int, default=8080)
+    args = p.parse_args()
+    app.run(host=args.host, port=args.port)
+
*** End Patch
*** Begin Patch
*** Add File: provider/k8s/provider-broker-deployment-v2.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: provider-broker-v2
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: provider-broker-v2
+  template:
+    metadata:
+      labels:
+        app: provider-broker-v2
+    spec:
+      containers:
+        - name: broker
+          image: aegis/provider-broker:latest # build from provider/Dockerfile
+          ports:
+            - containerPort: 8080
+          livenessProbe:
+            httpGet:
+              path: /state
+              port: 8080
+            initialDelaySeconds: 10
+            periodSeconds: 30
+          readinessProbe:
+            httpGet:
+              path: /state
+              port: 8080
+            initialDelaySeconds: 5
+            periodSeconds: 15
+          resources:
+            limits:
+              cpu: "500m"
+              memory: "512Mi"
+            requests:
+              cpu: "100m"
+              memory: "128Mi"
+      restartPolicy: Always
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: provider-broker-v2
+  namespace: aegis
+spec:
+  selector:
+    app: provider-broker-v2
+  ports:
+    - port: 80
+      targetPort: 8080
+
*** End Patch
*** Begin Patch
*** Add File: quantum/mitigation_operator.py
+#!/usr/bin/env python3
+"""
+Mitigation Operator (controller-lite).
+ - Reads suggestions from MLflow or S3/local file and decides via MITIGATION_MIN_IMPROVEMENT threshold
+ - Writes a ConfigMap with per-device mitigation toggles consumed by adapters
+ - Emits a Prometheus metric for number of applied mitigations
+"""
+import json, os, subprocess
+from datetime import datetime
+from prometheus_client import Counter, generate_latest, CONTENT_TYPE_LATEST
+from flask import Flask, Response
+
+SUG_FILE = os.environ.get("MIT_SUG_FILE", "/tmp/mitigation_suggestions.json")
+THRESHOLD = float(os.environ.get("MITIGATION_MIN_IMPROVEMENT", "0.02"))
+APPLIED_COUNTER = Counter("aegis_mitigation_applied_total", "Mitigations applied by operator")
+
+app = Flask("mitigation-operator")
+
+def load_suggestions(path=SUG_FILE):
+    if not os.path.exists(path):
+        return []
+    return json.load(open(path))
+
+def decide_and_apply():
+    sugg = load_suggestions()
+    mapping = {}
+    for s in sugg:
+        dev = s.get("device")
+        gain = s.get("expected_gain", 0.0)
+        if gain >= THRESHOLD and s.get("risk",0.01) < 0.05:
+            mapping[dev] = s.get("suggestion", {})
+            APPLIED_COUNTER.inc()
+        else:
+            mapping[dev] = {"apply": False}
+    cm = {
+        "apiVersion": "v1",
+        "kind": "ConfigMap",
+        "metadata": {"name": "aegis-mitigation-config", "namespace": "aegis"},
+        "data": {"mitigation": json.dumps(mapping)}
+    }
+    p = subprocess.run(["kubectl", "apply", "-f", "-"], input=json.dumps(cm).encode())
+    return p.returncode == 0
+
+@app.route("/run")
+def run_op():
+    ok = decide_and_apply()
+    return {"applied": ok, "ts": datetime.utcnow().isoformat()}
+
+@app.route("/metrics")
+def metrics():
+    return Response(generate_latest(), mimetype=CONTENT_TYPE_LATEST)
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", "8081")))
+
*** End Patch
*** Begin Patch
*** Add File: quantum/k8s/mitigation-operator-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: mitigation-operator
+  namespace: aegis
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: mitigation-operator
+  template:
+    metadata:
+      labels:
+        app: mitigation-operator
+    spec:
+      containers:
+        - name: operator
+          image: aegis/mitigation-operator:latest
+          env:
+            - name: MIT_SUG_FILE
+              value: "/tmp/mitigation_suggestions.json"
+            - name: MITIGATION_MIN_IMPROVEMENT
+              value: "0.02"
+          ports:
+            - containerPort: 8081
+          livenessProbe:
+            httpGet:
+              path: /run
+              port: 8081
+            initialDelaySeconds: 15
+            periodSeconds: 30
+      volumes:
+        - name: tmp
+          emptyDir: {}
+
*** End Patch
*** Begin Patch
*** Add File: quantum/k8s/mitigation-grafana-panel.json
+{
+  "panels": [
+    {
+      "type": "graph",
+      "title": "Mitigation Applied",
+      "targets": [
+        {
+          "expr": "aegis_mitigation_applied_total",
+          "legendFormat": "applied"
+        }
+      ]
+    }
+  ]
+}
+
*** End Patch
*** Begin Patch
*** Add File: federated/k8s/orchestrator_job.yaml
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: federated-orchestrator
+  namespace: aegis
+spec:
+  template:
+    spec:
+      containers:
+        - name: orchestrator
+          image: aegis/federated-orchestrator:latest
+          command: ["python","federated/orchestrator.py","--round","1","--mlflow-uri","http://mlflow:5000"]
+      restartPolicy: Never
+  backoffLimit: 1
+
*** End Patch
*** Begin Patch
*** Add File: ansible/provision/federated_client_deploy.yml
+- name: Deploy federated client to Jetson runners (prototype)
+  hosts: runners
+  become: true
+  vars:
+    remote_path: /opt/aegis/federated
+  tasks:
+    - name: Ensure python3 present
+      apt:
+        name: python3
+        state: present
+      become: true
+
+    - name: Create directory for federated client
+      file:
+        path: "{{ remote_path }}"
+        state: directory
+        owner: root
+        mode: '0755'
+
+    - name: Upload client runner
+      copy:
+        src: federated/client_runner.py
+        dest: "{{ remote_path }}/client_runner.py"
+        mode: '0755'
+
+    - name: Run federated client (example)
+      shell: "python3 {{ remote_path }}/client_runner.py --client-id {{ inventory_hostname }} --round 1"
+      register: fed_run
+      ignore_errors: yes
+
+    - name: Show result
+      debug:
+        var: fed_run.stdout_lines
+
*** End Patch
*** Begin Patch
*** Add File: ansible/inventory_federated_example.ini
+[runners]
+device-a ansible_host=10.0.0.10
+device-b ansible_host=10.0.0.11
+device-c ansible_host=10.0.0.12
+
*** End Patch
*** Begin Patch
*** Add File: zero_trust/.github/workflows/tpm_attestation_check.yml
+name: TPM Attestation Check (CI)
+on:
+  workflow_dispatch:
+
+jobs:
+  tpm-check:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install tpm2-tools (Linux runner must support)
+        run: sudo apt-get update && sudo apt-get install -y tpm2-tools || true
+      - name: Run local attestation script (dry-run)
+        run: |
+          chmod +x zero_trust/generate_certs.sh || true
+          ./zero_trust/generate_certs.sh aegis aegis-service-certs || true
+      - name: Run Ansible TPM enrollment playbook (operator must provide inventory)
+        run: |
+          echo "To run full TPM enrollment, run ansible-playbook -i inventory_federated_example.ini ansible/provision/federated_client_deploy.yml"
+          echo "CI cannot run remote enrollment in this demo."
+
*** End Patch
*** Begin Patch
*** Add File: zero_trust/helm/mtls-demo/Chart.yaml
+apiVersion: v2
+name: aegis-mtls-demo
+description: Demo mTLS chart (minimal)
+type: application
+version: 0.1.0
+
*** End Patch
*** Begin Patch
*** Add File: zero_trust/helm/mtls-demo/templates/service.yaml
+apiVersion: v1
+kind: Service
+metadata:
+  name: mtls-demo
+spec:
+  ports:
+    - port: 80
+      targetPort: 8080
+  selector:
+    app: mtls-demo
+
*** End Patch
*** Begin Patch
*** Add File: zero_trust/helm/mtls-demo/templates/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: mtls-demo
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: mtls-demo
+  template:
+    metadata:
+      labels:
+        app: mtls-demo
+    spec:
+      containers:
+        - name: app
+          image: alpine:3.18
+          command: ["sh","-c","while true; do sleep 3600; done"]
+          ports:
+            - containerPort: 8080
+      # In production, enable Istio sidecar injection and mTLS PeerAuthentication
+
*** End Patch
*** Begin Patch
*** Add File: docs/30_60_90_action_plan.md
+# Aegis 30/60/90 Day Action Plan (Provider Broker, Mitigation Operator, Federated Pilot, Zero-Trust)
+
+Owners: Platform Lead (platform@example.com), SRE Lead (sre@example.com), Security Lead (security@example.com), ML Research (ml@example.com)
+
+30-Day (Goals & Commands)
+- Deploy provider-broker-v2 (Platform/SRE)
+  - Build image: docker build -t aegis/provider-broker:latest -f provider/Dockerfile provider/
+  - Push & deploy: kubectl apply -f provider/k8s/provider-broker-deployment-v2.yaml
+  - Smoke: curl http://<broker-service>/select -X POST -d '{"candidates":[{"name":"braket","meta":{"cost_per_job":1.0,"latency_ms":120}}]}' -H "Content-Type: application/json"
+- Deploy mitigation-operator (Quantum)
+  - Build image and kubectl apply quantum/k8s/mitigation-operator-deployment.yaml
+  - Trigger run: curl http://<mitigation-operator>/run
+- Nightly verification enabled (QA)
+  - Inspect GH Action .github/workflows/nightly_verification.yml runs
+
+60-Day (Goals & Commands)
+- Instrument broker telemetry ingestion:
+  - POST telemetry to /ingest with provider success/cost/latency/fidelity
+  - Observe metrics: kubectl port-forward svc/provider-broker-v2 8080:80 && curl http://127.0.0.1:8080/metrics
+- Federated pilot (ML Research/Platform)
+  - Run Ansible deploy: ansible-playbook -i ansible/inventory_federated_example.ini ansible/provision/federated_client_deploy.yml
+  - Run orchestrator job: kubectl apply -f federated/k8s/orchestrator_job.yaml
+
+90-Day (Goals & Commands)
+- Replace heuristic with learned policy:
+  - Export broker history, train offline policy on telemetry, test in shadow mode by using /select results for canary runs.
+- Zeroâ€‘trust automation:
+  - Run ansible/zero_trust/tpm_enroll.yml against sample runners and verify attestation server receives quotes.
+  - Enforce Istio PeerAuthentication: kubectl apply -f zero_trust/k8s/istio_peer_authentication.yaml
+
+Notes:
+- Each task should have an owner assigned and a runbook (PR/issue) tracking progress. Use the nightly verification GH Action to catch regressions.
+
*** End Patch
*** End Patch
