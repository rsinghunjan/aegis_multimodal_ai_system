diff --git a/vault/write_github_app_to_vault.sh b/vault/write_github_app_to_vault.sh
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/vault/write_github_app_to_vault.sh
@@ -0,0 +1,140 @@
+#!/usr/bin/env bash
+#
+# Operator helper: write GitHub App PEM and metadata into Vault KV v2.
+# Requires VAULT_ADDR & VAULT_TOKEN env vars and `vault` CLI installed.
+#
+# Usage:
+#   ./vault/write_github_app_to_vault.sh --pem /tmp/github_app.pem --app-id 12345 --installation-id 67890
+
+set -euo pipefail
+
+PEM_FILE=""
+APP_ID=""
+INSTALLATION_ID=""
+VAULT_PATH="${VAULT_PATH:-secret/data/aegis/github_app}"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --pem) PEM_FILE="$2"; shift 2;;
+    --app-id) APP_ID="$2"; shift 2;;
+    --installation-id) INSTALLATION_ID="$2"; shift 2;;
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+if [ -z "$PEM_FILE" ] || [ -z "$APP_ID" ] || [ -z "$INSTALLATION_ID" ]; then
+  echo "Provide --pem, --app-id and --installation-id"
+  exit 1
+fi
+
+if [ -z "${VAULT_ADDR:-}" ] || [ -z "${VAULT_TOKEN:-}" ]; then
+  echo "Set VAULT_ADDR and VAULT_TOKEN in environment"
+  exit 1
+fi
+
+echo "Writing GitHub App PEM to Vault at $VAULT_PATH"
+# Use KV v2 write format: data: {...}
+PAYLOAD=$(jq -n --arg pk "$(sed -e ':a' -e 'N' -e '$!ba' -e 's/\n/\\n/g' "$PEM_FILE")" --arg app_id "$APP_ID" --arg inst_id "$INSTALLATION_ID" '{data: {private_key: $pk, app_id: $app_id, installation_id: $inst_id}}')
+
+curl -sS --header "X-Vault-Token: $VAULT_TOKEN" --request POST \
+  --data "$PAYLOAD" \
+  "$VAULT_ADDR/v1/$VAULT_PATH" | jq . || true
+
+echo "Done. Ensure Vault policy allows the aegis-agent role to read $VAULT_PATH"
+
+exit 0
+
diff --git a/vault/setup_dynamic_db.sh b/vault/setup_dynamic_db.sh
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/vault/setup_dynamic_db.sh
@@ -0,0 +1,180 @@
+#!/usr/bin/env bash
+#
+# Configure Vault database secrets engine for dynamic Postgres users for Aegis.
+# Requires VAULT_ADDR & VAULT_TOKEN and DB admin creds.
+#
+# Usage:
+# ./vault/setup_dynamic_db.sh --db-host aegis-postgres.aegis-ml.svc.cluster.local --db-admin-user postgres --db-admin-pass-file ./pg_admin_pass
+
+set -euo pipefail
+
+DB_HOST=""
+DB_NAME="aegis"
+DB_ADMIN_USER=""
+DB_ADMIN_PASS_FILE=""
+VAULT_MOUNT_PATH="${VAULT_MOUNT_PATH:-database}"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --db-host) DB_HOST="$2"; shift 2;;
+    --db-name) DB_NAME="$2"; shift 2;;
+    --db-admin-user) DB_ADMIN_USER="$2"; shift 2;;
+    --db-admin-pass-file) DB_ADMIN_PASS_FILE="$2"; shift 2;;
+    --vault-mount) VAULT_MOUNT_PATH="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+if [ -z "${VAULT_ADDR:-}" ] || [ -z "${VAULT_TOKEN:-}" ]; then
+  echo "Set VAULT_ADDR and VAULT_TOKEN in environment"
+  exit 1
+fi
+
+if [ -z "$DB_HOST" ] || [ -z "$DB_ADMIN_USER" ] || [ -z "$DB_ADMIN_PASS_FILE" ]; then
+  echo "Provide --db-host, --db-admin-user and --db-admin-pass-file"
+  exit 1
+fi
+
+DB_ADMIN_PASS="$(cat "$DB_ADMIN_PASS_FILE")"
+
+echo "Enabling database secrets engine at: $VAULT_MOUNT_PATH"
+vault secrets enable -path="$VAULT_MOUNT_PATH" database || true
+
+echo "Configuring Postgres connection in Vault"
+vault write "$VAULT_MOUNT_PATH/config/postgresql" \
+  plugin_name="postgresql-database-plugin" \
+  allowed_roles="aegis-role" \
+  connection_url="postgresql://{{username}}:{{password}}@${DB_HOST}/${DB_NAME}?sslmode=disable" \
+  username="$DB_ADMIN_USER" \
+  password="$DB_ADMIN_PASS"
+
+echo "Creating role aegis-role (short TTL)"
+vault write "$VAULT_MOUNT_PATH/roles/aegis-role" \
+  db_name="postgresql" \
+  creation_statements="CREATE ROLE \"{{name}}\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; GRANT CONNECT ON DATABASE ${DB_NAME} TO \"{{name}}\";" \
+  default_ttl="1h" \
+  max_ttl="24h"
+
+echo "Dynamic DB role created. Agents can now request credentials at $VAULT_MOUNT_PATH/creds/aegis-role"
+echo "Remember to create a Vault policy for agents and bind k8s SA to it."
+
diff --git a/k8s/manifests/vault-enforcer.sh b/k8s/manifests/vault-enforcer.sh
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/k8s/manifests/vault-enforcer.sh
@@ -0,0 +1,200 @@
+#!/usr/bin/env bash
+#
+# Scans deployments in a namespace for secret env vars and optionally annotates them
+# to use Vault Injector (vault.hashicorp.com annotations). This is a best-effort helper;
+# operators should review changes before applying in production.
+#
+# Usage:
+#  ./k8s/manifests/vault-enforcer.sh --namespace aegis-ml [--apply]
+
+set -euo pipefail
+
+NS="aegis-ml"
+APPLY=false
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --namespace) NS="$2"; shift 2;;
+    --apply) APPLY=true; shift 1;;
+    *) echo "Unknown arg $1"; exit 1;;
+  esac
+done
+
+echo "Scanning deployments in namespace $NS for secret envs..."
+
+DEPLOYS=$(kubectl -n "$NS" get deployments -o json | jq -r '.items[].metadata.name')
+
+for d in $DEPLOYS; do
+  echo "Checking deployment: $d"
+  SECRETS=$(kubectl -n "$NS" get deploy "$d" -o json | jq -r '.spec.template.spec.containers[].env[]? | select(.valueFrom!=null) | @json' || true)
+  if [ -z "$SECRETS" ]; then
+    echo "  No valueFrom env entries; checking for literal secret-like env names..."
+    LITERAL=$(kubectl -n "$NS" get deploy "$d" -o json | jq -r '.spec.template.spec.containers[].env[]?.name' | egrep -i "TOKEN|KEY|PASSWORD|DB_PASS|GITHUB|SECRET" || true)
+    if [ -n "$LITERAL" ]; then
+      echo "  Found literal secret-like env names: $LITERAL"
+      if [ "$APPLY" = true ]; then
+        echo "  Annotating deployment $d for Vault Injector"
+        kubectl -n "$NS" annotate deployment "$d" vault.hashicorp.com/agent-inject=true --overwrite
+        kubectl -n "$NS" annotate deployment "$d" vault.hashicorp.com/role=aegis-agent --overwrite
+        echo "  (operator) Please add vault.hashicorp.com/agent-inject-secret-<name> annotations as needed"
+      else
+        echo "  (dry-run) would annotate: $d"
+      fi
+    fi
+  else
+    echo "  Has valueFrom envs (likely k8s secrets); recommend replacing with Vault Injector annotations"
+    echo "$SECRETS" | sed 's/^/    /'
+    if [ "$APPLY" = true ]; then
+      echo "  Annotating deployment $d for Vault Injector"
+      kubectl -n "$NS" annotate deployment "$d" vault.hashicorp.com/agent-inject=true --overwrite
+      kubectl -n "$NS" annotate deployment "$d" vault.hashicorp.com/role=aegis-agent --overwrite
+      echo "  (operator) Add specific secret mapping annotations manually."
+    fi
+  fi
+done
+
+echo "Scan complete. If you applied annotations, wait for rollout and verify /vault/secrets presence in pods."
+
diff --git a/k8s/manifests/remove_plaintext_secrets.sh b/k8s/manifests/remove_plaintext_secrets.sh
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/k8s/manifests/remove_plaintext_secrets.sh
@@ -0,0 +1,120 @@
+#!/usr/bin/env bash
+#
+# Helper to detect and optionally remove plaintext Kubernetes secrets in the aegis-ml namespace.
+# Use with caution. This script lists secrets that look like credentials and optionally deletes them.
+
+NAMESPACE="${1:-aegis-ml}"
+DRY_RUN=true
+
+if [[ "${2:-}" == "--apply" ]]; then
+  DRY_RUN=false
+fi
+
+echo "Scanning namespace $NAMESPACE for suspicious secrets (dry-run=$DRY_RUN)..."
+SECRETS=$(kubectl -n "$NAMESPACE" get secrets -o json | jq -r '.items[].metadata.name')
+for s in $SECRETS; do
+  if echo "$s" | egrep -i "password|postgres|db|github|token|key|pem|secret" >/dev/null; then
+    echo "Found candidate secret: $s"
+    if [ "$DRY_RUN" = "false" ]; then
+      echo "Deleting secret $s"
+      kubectl -n "$NAMESPACE" delete secret "$s" || true
+    else
+      echo "(dry-run) would delete: $s"
+    fi
+  fi
+done
+
+echo "Scan complete. If you removed secrets, ensure Vault Injector annotations are present on deployments and that Vault policies/roles are configured."
+
diff --git a/policy/opa/data/models_canonical.json b/policy/opa/data/models_canonical.json
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/policy/opa/data/models_canonical.json
@@ -0,0 +1,120 @@
+{
+  "models": {
+    "low-demo-model": {
+      "risk": "low",
+      "team": "ads",
+      "budget_usd_per_month": 200.0,
+      "owners": ["alice","bob"],
+      "approved_installations": []
+    },
+    "fraud-detector-v1": {
+      "risk": "high",
+      "team": "fraud",
+      "budget_usd_per_month": 1000.0,
+      "owners": ["sre","security"],
+      "approved_installations": []
+    },
+    "default": {
+      "risk": "medium",
+      "team": "ml",
+      "budget_usd_per_month": 500.0,
+      "owners": ["ml-team"],
+      "approved_installations": []
+    }
+  }
+}
+
diff --git a/policy/opa/tests/agent_policies_more_tests.rego b/policy/opa/tests/agent_policies_more_tests.rego
new file mode 100644
index 0000000..6666666
--- /dev/null
+++ b/policy/opa/tests/agent_policies_more_tests.rego
@@ -0,0 +1,220 @@
+package aegis.policies.tests
+
+import data.aegis.policies
+import data.models
+
+# Test a variety of action types and risk levels
+test_retrain_staging_allowed {
+  input := {"action": "retrain", "model": "low-demo-model", "env": "staging", "params": {}}
+  result := data.aegis.policies.result with input as input
+  result.allow == true
+}
+
+test_promote_medium_requires_approval {
+  input := {"action": "promote", "model": "default", "env": "production", "params": {}}
+  result := data.aegis.policies.result with input as input
+  result.allow == false
+}
+
+test_promote_medium_with_approval {
+  input := {"action": "promote", "model": "default", "env": "production", "params": {"approved_by": "sre"}}
+  result := data.aegis.policies.result with input as input
+  result.allow == true
+}
+
+test_high_risk_retrain_denied_in_prod {
+  input := {"action":"retrain","model":"fraud-detector-v1","env":"production","params":{}}
+  result := data.aegis.policies.result with input as input
+  result.allow == false
+}
+
+test_create_pr_allowed_in_prod_for_high_risk {
+  input := {"action":"create_pr","model":"fraud-detector-v1","env":"production","params":{}}
+  result := data.aegis.policies.result with input as input
+  result.allow == true
+}
+
+test_unknown_model_uses_default_medium {
+  input := {"action":"retrain","model":"some-unknown-model","env":"production","params":{}}
+  result := data.aegis.policies.result with input as input
+  result.allow == false
+}
+
diff --git a/.github/workflows/policy-ci.yml b/.github/workflows/policy-ci.yml
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/.github/workflows/policy-ci.yml
@@ -0,0 +1,132 @@
+name: Policy CI
+
+on:
+  push:
+    paths:
+      - "policy/**"
+  pull_request:
+    paths:
+      - "policy/**"
+
+jobs:
+  opa-test:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run OPA unit tests
+        run: |
+          docker run --rm -v "${{ github.workspace }}:/workspace" openpolicyagent/opa:latest test /workspace/policy -v
+
+  rego-lint:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Lint Rego (opa fmt)
+        run: |
+          docker run --rm -v "${{ github.workspace }}:/workspace" openpolicyagent/opa:latest fmt /workspace/policy || true
+
diff --git a/agents/common/github_app_vault.py b/agents/common/github_app_vault.py
new file mode 100644
index 0000000..8888888
--- /dev/null
+++ b/agents/common/github_app_vault.py
@@ -0,0 +1,220 @@
+#!/usr/bin/env python3
+"""
+Helper to obtain GitHub App installation tokens using a private key stored in Vault (KV v2).
+Intended to be used by agents to avoid PAT usage.
+"""
+import os
+import time
+import json
+import requests
+import jwt
+from typing import Optional
+import logging
+
+logger = logging.getLogger("aegis.github_app_vault")
+logging.basicConfig(level=logging.INFO)
+
+VAULT_ADDR = os.environ.get("VAULT_ADDR")
+VAULT_TOKEN = os.environ.get("VAULT_TOKEN")
+GITHUB_APP_VAULT_PATH = os.environ.get("VAULT_SECRET_GITHUB_APP_PATH", "secret/data/aegis/github_app")
+
+def _read_vault_secret(path: str) -> Optional[dict]:
+    if os.path.exists("/vault/secrets/github_app.pem"):
+        try:
+            with open("/vault/secrets/github_app.pem", "r") as fh:
+                content = fh.read()
+            meta = {}
+            try:
+                with open("/vault/secrets/github_app.meta.json", "r") as mh:
+                    meta = json.load(mh)
+            except Exception:
+                meta = {}
+            return {"data": {"private_key": content, **meta}}
+        except Exception:
+            pass
+
+    if not VAULT_ADDR or not VAULT_TOKEN:
+        logger.warning("VAULT_ADDR or VAULT_TOKEN not set; cannot read Vault secret")
+        return None
+
+    url = f"{VAULT_ADDR}/v1/{path}"
+    headers = {"X-Vault-Token": VAULT_TOKEN}
+    resp = requests.get(url, headers=headers, timeout=10)
+    if resp.status_code != 200:
+        logger.error("Vault read failed %s: %s", resp.status_code, resp.text)
+        return None
+    try:
+        return resp.json()
+    except Exception:
+        logger.exception("Failed to parse Vault response")
+        return None
+
+def _create_jwt(app_id: str, private_key_pem: str) -> str:
+    now = int(time.time())
+    payload = {
+        "iat": now - 60,
+        "exp": now + (10 * 60),
+        "iss": app_id
+    }
+    token = jwt.encode(payload, private_key_pem, algorithm="RS256")
+    if isinstance(token, bytes):
+        token = token.decode("utf-8")
+    return token
+
+def get_installation_token(installation_id: Optional[str] = None) -> Optional[str]:
+    sec = _read_vault_secret(GITHUB_APP_VAULT_PATH)
+    if not sec:
+        logger.error("Failed to read GitHub App secret from Vault")
+        return None
+
+    data = sec.get("data") or sec
+    if "data" in data and isinstance(data["data"], dict):
+        payload = data["data"]
+    else:
+        payload = data
+
+    private_key = payload.get("private_key")
+    app_id = payload.get("app_id") or payload.get("appId") or os.environ.get("GITHUB_APP_ID")
+    installation = installation_id or payload.get("installation_id") or payload.get("installationId") or os.environ.get("GITHUB_INSTALLATION_ID")
+    if not private_key or not app_id or not installation:
+        logger.error("Missing private_key/app_id/installation_id in Vault secret")
+        return None
+
+    jwt_token = _create_jwt(str(app_id), private_key)
+
+    headers = {"Authorization": f"Bearer {jwt_token}", "Accept": "application/vnd.github+json"}
+    url = f"https://api.github.com/app/installations/{installation}/access_tokens"
+    resp = requests.post(url, headers=headers, timeout=15)
+    if resp.status_code not in (200,201):
+        logger.error("GitHub installation token exchange failed: %s %s", resp.status_code, resp.text)
+        return None
+    j = resp.json()
+    token = j.get("token")
+    logger.info("Obtained installation token, expires_at=%s", j.get("expires_at"))
+    return token
+
diff --git a/k8s/manifests/approval-gateway-deployment.yaml b/k8s/manifests/approval-gateway-deployment.yaml
new file mode 100644
index 0000000..9999999
--- /dev/null
+++ b/k8s/manifests/approval-gateway-deployment.yaml
@@ -0,0 +1,160 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-approval-gateway
+  namespace: aegis-ml
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-approval-gateway
+  template:
+    metadata:
+      labels:
+        app: aegis-approval-gateway
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: gateway
+          image: <REGISTRY>/aegis-approval-gateway:latest
+          env:
+            - name: ORCHESTRATOR_WEBHOOK
+              value: "http://orchestrator.aegis-ml.svc.cluster.local:8082/webhook"
+            - name: GITHUB_REPO
+              value: "<OWNER/REPO>"
+            - name: DEFAULT_REVIEWERS
+              value: "sre,security"
+          ports:
+            - containerPort: 8080
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-approval-gateway
+  namespace: aegis-ml
+spec:
+  selector:
+    app: aegis-approval-gateway
+  ports:
+    - port: 8080
+      targetPort: 8080
+
diff --git a/scripts/auto_approval_gateway.py b/scripts/auto_approval_gateway.py
new file mode 100644
index 0000000..aaaaaaaa
--- /dev/null
+++ b/scripts/auto_approval_gateway.py
@@ -0,0 +1,260 @@
+#!/usr/bin/env python3
+"""
+Lightweight Approval Gateway (Flask). See k8s/manifests/approval-gateway-deployment.yaml
+"""
+from flask import Flask, request, jsonify
+import os, logging, requests, json
+from typing import List, Optional
+
+try:
+    from agents.common.github_app_vault import get_installation_token
+except Exception:
+    def get_installation_token(*a, **k):
+        return os.environ.get("GITHUB_TOKEN")
+
+GITHUB_API = "https://api.github.com"
+REPO = os.environ.get("GITHUB_REPO", "")
+DEFAULT_REVIEWERS = os.environ.get("DEFAULT_REVIEWERS", "sre,security").split(",")
+ORCHESTRATOR_WEBHOOK = os.environ.get("ORCHESTRATOR_WEBHOOK", "http://orchestrator.aegis-ml.svc.cluster.local:8082/webhook")
+
+logging.basicConfig(level=logging.INFO)
+logger = logging.getLogger("aegis.approval.gateway")
+app = Flask(__name__)
+
+def _headers(token: str):
+    return {"Authorization": f"token {token}", "Accept": "application/vnd.github.v3+json"}
+
+def create_pr(title: str, body: str, head: str, base: str = "main", installation_id: Optional[str] = None):
+    token = get_installation_token(installation_id)
+    if not token:
+        raise RuntimeError("No GitHub installation token available")
+    url = f"{GITHUB_API}/repos/{REPO}/pulls"
+    r = requests.post(url, headers=_headers(token), json={"title": title, "body": body, "head": head, "base": base}, timeout=10)
+    r.raise_for_status()
+    return r.json()
+
+def request_review(pr_number: int, reviewers: List[str], installation_id: Optional[str] = None):
+    token = get_installation_token(installation_id)
+    url = f"{GITHUB_API}/repos/{REPO}/pulls/{pr_number}/requested_reviewers"
+    r = requests.post(url, headers=_headers(token), json={"reviewers": reviewers}, timeout=10)
+    r.raise_for_status()
+    return r.json()
+
+def post_comment(pr_number: int, comment: str, installation_id: Optional[str] = None):
+    token = get_installation_token(installation_id)
+    url = f"{GITHUB_API}/repos/{REPO}/issues/{pr_number}/comments"
+    r = requests.post(url, headers=_headers(token), json={"body": comment}, timeout=10)
+    r.raise_for_status()
+    return r.json()
+
+@app.route("/request-approval", methods=["POST"])
+def request_approval():
+    payload = request.get_json()
+    model = payload.get("model", "unknown")
+    reason = payload.get("reason", "")
+    branch = payload.get("change_branch", f"aegis/approval-{int(os.getpid())}-{int(os.stat(__file__).st_mtime)}")
+    title = f"[Aegis Approval] Auto-action for model {model}"
+    body = f"Automated approval request for model `{model}`\n\nReason: {reason}\n\nDiff:\n```\n{payload.get('diff','')}\n```"
+    try:
+        pr = create_pr(title=title, body=body, head=branch, base=payload.get("base","main"))
+        pr_number = pr.get("number")
+        try:
+            request_review(pr_number, DEFAULT_REVIEWERS)
+        except Exception:
+            logger.exception("Failed to request reviewers")
+        post_comment(pr_number, f"Approval requested by orchestrator for model {model}")
+        return jsonify({"pr_number": pr_number, "pr_url": pr.get("html_url")}), 201
+    except Exception as e:
+        logger.exception("Failed to create PR")
+        return jsonify({"error": str(e)}), 500
+
+@app.route("/webhook/github", methods=["POST"])
+def github_webhook():
+    evt = request.get_json()
+    pr = evt.get("pull_request") or {}
+    merged = pr.get("merged", False)
+    if merged:
+        orchestrator_payload = {"approval": {"pr_url": pr.get("html_url"), "pr_number": pr.get("number"), "merged_by": evt.get("sender", {}).get("login")}}
+        try:
+            r = requests.post(ORCHESTRATOR_WEBHOOK, json=orchestrator_payload, timeout=10)
+            logger.info("Notified orchestrator of approval: %s", r.status_code)
+        except Exception:
+            logger.exception("Failed to notify orchestrator")
+    return jsonify({"status":"ok"}), 200
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT","8080")))
+
diff --git a/sql/002_add_indexes_decision_log.sql b/sql/002_add_indexes_decision_log.sql
new file mode 100644
index 0000000..bbbbbbbb
--- /dev/null
+++ b/sql/002_add_indexes_decision_log.sql
@@ -0,0 +1,64 @@
+-- Add indexes for common audit queries on decision_log
+CREATE INDEX IF NOT EXISTS idx_decision_log_created_at ON decision_log (created_at DESC);
+CREATE INDEX IF NOT EXISTS idx_decision_log_model ON decision_log ((payload->>'model'));
+CREATE INDEX IF NOT EXISTS idx_decision_log_action ON decision_log ((payload->>'action'));
+CREATE INDEX IF NOT EXISTS idx_decision_log_agent ON decision_log (agent);
+CREATE INDEX IF NOT EXISTS idx_decision_log_evidence ON decision_log USING GIN (evidence);
+
+-- Optional: retention example
+-- DELETE FROM decision_log WHERE created_at < now() - interval '365 days';
+
diff --git a/tools/decisionlog_to_elastic.py b/tools/decisionlog_to_elastic.py
new file mode 100644
index 0000000..cccccccc
--- /dev/null
+++ b/tools/decisionlog_to_elastic.py
@@ -0,0 +1,220 @@
+#!/usr/bin/env python3
+"""
+Mirror Postgres decision_log -> Elasticsearch for fast audit search.
+Requires POSTGRES_URL & ELASTIC_URL env vars.
+"""
+import os, json, time, psycopg2, requests
+
+PG_URL = os.environ.get("POSTGRES_URL")
+ES_URL = os.environ.get("ELASTIC_URL")
+
+def fetch_recent(limit=500):
+    conn = psycopg2.connect(PG_URL)
+    cur = conn.cursor()
+    cur.execute("SELECT id, created_at, agent, payload, evidence FROM decision_log ORDER BY created_at DESC LIMIT %s", (limit,))
+    rows = cur.fetchall()
+    cur.close()
+    conn.close()
+    return rows
+
+def index_to_es(rows):
+    for r in rows:
+        doc = {"id": r[0], "created_at": r[1].isoformat(), "agent": r[2], "payload": r[3], "evidence": r[4]}
+        url = f"{ES_URL.rstrip('/')}/decision_log/_doc/{doc['id']}"
+        resp = requests.put(url, json=doc)
+        if resp.status_code not in (200,201):
+            print("Failed to index", doc['id'], resp.status_code, resp.text)
+
+def main():
+    if not PG_URL or not ES_URL:
+        print("POSTGRES_URL and ELASTIC_URL required")
+        return
+    rows = fetch_recent()
+    index_to_es(rows)
+
+if __name__ == "__main__":
+    main()
+
diff --git a/k8s/manifests/deepspeed-nccl-configmap.yaml b/k8s/manifests/deepspeed-nccl-configmap.yaml
new file mode 100644
index 0000000..dddddddd
--- /dev/null
+++ b/k8s/manifests/deepspeed-nccl-configmap.yaml
@@ -0,0 +1,120 @@
+apiVersion: v1
+kind: ConfigMap
+metadata:
+  name: aegis-deepspeed-nccl
+  namespace: aegis-ml
+data:
+  NCCL_IB_DISABLE: "0"
+  NCCL_SOCKET_IFNAME: "eth0"
+  NCCL_P2P_LEVEL: "NVL"
+  NCCL_DEBUG: "WARN"
+  NCCL_MIN_NRINGS: "8"
+
+---
+# Example CLI usage: kubectl create configmap aegis-deepspeed-nccl --from-literal=NCCL_IB_DISABLE=0 -n aegis-ml
+
diff --git a/k8s/manifests/feast-online-deploy.yaml b/k8s/manifests/feast-online-deploy.yaml
new file mode 100644
index 0000000..eeeeeeee
--- /dev/null
+++ b/k8s/manifests/feast-online-deploy.yaml
@@ -0,0 +1,120 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: feast-online-store
+  namespace: aegis-ml
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: feast-online
+  template:
+    metadata:
+      labels:
+        app: feast-online
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: feast-online
+          image: <REGISTRY>/aegis-feast-online:latest
+          env:
+            - name: REDIS_HOST
+              value: "feast-redis.aegis-ml.svc.cluster.local"
+          ports:
+            - containerPort: 6566
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "512Mi"
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: feast-online
+  namespace: aegis-ml
+spec:
+  selector:
+    app: feast-online
+  ports:
+    - port: 6566
+      targetPort: 6566
+
diff --git a/k8s/manifests/feast-sync-job.yaml b/k8s/manifests/feast-sync-job.yaml
new file mode 100644
index 0000000..fffffff
--- /dev/null
+++ b/k8s/manifests/feast-sync-job.yaml
@@ -0,0 +1,120 @@
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: aegis-feast-sync
+  namespace: aegis-ml
+spec:
+  template:
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: feast-sync
+          image: <REGISTRY>/aegis-feast-sync:latest
+          command: ["python", "/app/feast_sync.py"]
+          env:
+            - name: BATCH_FEATURE_PATH
+              value: "s3://<BUCKET>/features/"
+            - name: FEAST_REDIS_HOST
+              value: "feast-redis.aegis-ml.svc.cluster.local"
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+      restartPolicy: OnFailure
+
diff --git a/k8s/manifests/labeling-queue-deployment.yaml b/k8s/manifests/labeling-queue-deployment.yaml
new file mode 100644
index 0000000..12121212
--- /dev/null
+++ b/k8s/manifests/labeling-queue-deployment.yaml
@@ -0,0 +1,160 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-labeling-queue
+  namespace: aegis-ml
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-labeling-queue
+  template:
+    metadata:
+      labels:
+        app: aegis-labeling-queue
+    spec:
+      serviceAccountName: aegis-agent-sa
+      containers:
+        - name: labeling-queue
+          image: <REGISTRY>/aegis-labeling-queue:latest
+          env:
+            - name: LABELSTUDIO_URL
+              value: "http://labelstudio.aegis-ml.svc.cluster.local:8080"
+            - name: LAKEFS_API
+              value: "http://lakefs:8000"
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-labeling-queue
+  namespace: aegis-ml
+spec:
+  selector:
+    app: aegis-labeling-queue
+  ports:
+    - port: 8080
+      targetPort: 8080
+
diff --git a/monitoring/prometheus/model_slo_rules_additional.yaml b/monitoring/prometheus/model_slo_rules_additional.yaml
new file mode 100644
index 0000000..13131313
--- /dev/null
+++ b/monitoring/prometheus/model_slo_rules_additional.yaml
@@ -0,0 +1,120 @@
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: aegis-model-slo-rules-additional
+  namespace: aegis-ml
+spec:
+  groups:
+    - name: aegis-model-slo.additional
+      rules:
+        - alert: ModelDecisionErrorBudgetExceeded
+          expr: increase(aegis_autoexec_errors_total[1h]) > 5
+          for: 10m
+          labels:
+            severity: critical
+          annotations:
+            summary: "Model auto-exec error budget exceeded"
+
+        - alert: FeatureStoreSyncLag
+          expr: increase(feast_sync_lag_seconds[5m]) > 300
+          for: 10m
+          labels:
+            severity: warning
+          annotations:
+            summary: "Feast online store sync lag is high"
+
diff --git a/dr/cross_region_sync_cronjob.yaml b/dr/cross_region_sync_cronjob.yaml
new file mode 100644
index 0000000..14141414
--- /dev/null
+++ b/dr/cross_region_sync_cronjob.yaml
@@ -0,0 +1,120 @@
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: aegis-cross-region-sync
+  namespace: aegis-ml
+spec:
+  schedule: "0 2 * * *"  # daily at 02:00
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          serviceAccountName: aegis-agent-sa
+          containers:
+            - name: cr-sync
+              image: <REGISTRY>/aegis-dr-tools:latest
+              command: ["/bin/sh","-c"]
+              args:
+                - |
+                  ./dr/cross_region_sync.sh --src s3://<BUCKET>/models --dst s3://<BACKUP_BUCKET>/models --region us-west-2 --dst-region eu-west-1
+          restartPolicy: OnFailure
+
diff --git a/k8s/manifests/networkpolicy-restrict.yaml b/k8s/manifests/networkpolicy-restrict.yaml
new file mode 100644
index 0000000..15151515
--- /dev/null
+++ b/k8s/manifests/networkpolicy-restrict.yaml
@@ -0,0 +1,120 @@
+apiVersion: networking.k8s.io/v1
+kind: NetworkPolicy
+metadata:
+  name: restrict-aegis-namespace
+  namespace: aegis-ml
+spec:
+  podSelector: {}
+  policyTypes:
+    - Ingress
+    - Egress
+  ingress:
+    - from:
+        - podSelector:
+            matchLabels:
+              app: aegis-agent
+      ports:
+        - protocol: TCP
+          port: 8082
+  egress:
+    - to:
+        - ipBlock:
+            cidr: 0.0.0.0/0
+      ports:
+        - protocol: TCP
+          port: 443
+  # Note: tune rules to your cluster. This example is conservative; review before applying.
+
diff --git a/k8s/manifests/agent-serviceaccount-rbac.yaml b/k8s/manifests/agent-serviceaccount-rbac.yaml
new file mode 100644
index 0000000..16161616
--- /dev/null
+++ b/k8s/manifests/agent-serviceaccount-rbac.yaml
@@ -0,0 +1,140 @@
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: aegis-agent-sa
+  namespace: aegis-ml
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: aegis-agent-role
+  namespace: aegis-ml
+rules:
+  - apiGroups: [""]
+    resources: ["pods", "configmaps"]
+    verbs: ["get","list","watch"]
+  - apiGroups: [""]
+    resources: ["secrets"]
+    verbs: ["get","list"]
+  - apiGroups: ["apps"]
+    resources: ["deployments"]
+    verbs: ["get","list","patch"]
+  - apiGroups: ["batch"]
+    resources: ["jobs"]
+    verbs: ["create","get","list"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: aegis-agent-rolebinding
+  namespace: aegis-ml
+subjects:
+  - kind: ServiceAccount
+    name: aegis-agent-sa
+roleRef:
+  kind: Role
+  name: aegis-agent-role
+  apiGroup: rbac.authorization.k8s.io
+
diff --git a/docs/PRODUCTION_HARDENING_RUNBOOK.md b/docs/PRODUCTION_HARDENING_RUNBOOK.md
new file mode 100644
index 0000000..17171717
--- /dev/null
+++ b/docs/PRODUCTION_HARDENING_RUNBOOK.md
@@ -0,0 +1,240 @@
+# Aegis Production Hardening Runbook (secrets, policy, approvals, monitoring, DR)
+
+This runbook bundles concrete steps to remediate high-impact gaps before enabling production auto-exec.
+
+1) Vault & Secrets Migration (HIGH)
+ - Write GH App PEM to Vault:
+     ./vault/write_github_app_to_vault.sh --pem /tmp/github_app.pem --app-id 12345 --installation-id=67890
+ - Configure dynamic DB roles with:
+     ./vault/setup_dynamic_db.sh --db-host aegis-postgres.aegis-ml.svc.cluster.local --db-admin-user postgres --db-admin-pass-file ./pg_admin_pass
+ - Use k8s/manifests/vault-enforcer.sh to identify deployments needing Vault injector annotations (dry-run first).
+ - Annotate orchestrator and critical deployments with Vault Injector and verify injected files in /vault/secrets.
+ - Remove plaintext secrets from cluster after injector verification:
+     ./k8s/manifests/remove_plaintext_secrets.sh aegis-ml  (first dry-run; then --apply)
+
+2) OPA Policy Hardening & CI (HIGH)
+ - Place authoritative model metadata: policy/opa/data/models_canonical.json
+ - Add Rego unit tests in policy/opa/tests (agent_policies_more_tests.rego)
+ - Enable policy CI (.github/workflows/policy-ci.yml) to block PRs that break policy tests
+ - Run local policy smoke:
+     docker run --rm -v "$PWD:/workspace" openpolicyagent/opa:latest test /workspace/policy -v
+
+3) GitHub App Production Integration (HIGH)
+ - Create GH App with minimal perms. Store PEM in Vault (step 1), configure agents to call agents.common.github_app_vault.get_installation_token()
+ - Replace any PAT usage in CI with short-lived installation tokens and audit token use.
+
+4) Auto-exec Approval Flows (HIGH)
+ - Deploy approval gateway (k8s/manifests/approval-gateway-deployment.yaml)
+ - Wire orchestrator to call the gateway when OPA denies auto-exec; gateway will create PR via GitHub App and request reviewers.
+ - Ensure CODEOWNERS + branch protection and required reviewers are configured. On PR merge, gateway notifies orchestrator to log approval.
+
+5) Decision Log Indexing & BI (MEDIUM)
+ - Apply DB index migration:
+     kubectl -n aegis-ml exec deploy/aegis-postgres -- psql -U aegis -d aegis -f /sql/002_add_indexes_decision_log.sql
+ - Optionally run tools/decisionlog_to_elastic.py with POSTGRES_URL & ELASTIC_URL to mirror for fast search
+
+6) Feature Store & Labeling (MEDIUM)
+ - Deploy Feast online store and sync job (k8s/manifests/feast-online-deploy.yaml and feast-sync-job.yaml)
+ - Deploy labeling queue (k8s/manifests/labeling-queue-deployment.yaml) and integrate with LakeFS
+
+7) Monitoring & SLOs (MEDIUM)
+ - Apply PrometheusRule manifests in monitoring/prometheus/*.yaml (model_slo_rules, additional rules)
+ - Create runbooks for alerts and tune thresholds
+
+8) DR & Cross-region (MEDIUM)
+ - Deploy cross-region cronjob (dr/cross_region_sync_cronjob.yaml) to mirror model repos nightly
+ - Periodically run chaos drills and verify restores (use scripts in dr/)
+
+Testing & Validation
+ - Run multiple dry-run cycles (scripts/signoff/run_dry_runs.sh)
+ - Validate OPA policy behavior using policy tests
+ - Verify that Vault injector mounts secrets into pods and that no plaintext secrets remain
+ - Create a non-production PR via approval gateway and ensure CODEOWNERS requested reviewers
+
+Contact
+ - SRE, Security, and ML leadership should coordinate signoff. Attach artifacts produced by scripts/signoff/collect_signoff_artifacts.sh
+
