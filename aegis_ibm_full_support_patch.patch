*** Begin Patch
*** Add File:terraform/ibm/provider_wrapper.tf
+// Terraform wrapper that delegates IBM resource creation to the ibmcloud CLI
+// (This avoids brittle provider resource names across tenancy variants.)
+terraform {
+  required_version = ">= 1.0"
+}
+
+provider "local" {}
+
*** End Patch
*** Begin Patch
*** Add File:terraform/ibm/main.tf
+// Null resource that runs the CLI-based IBM resource creation script.
+// The script will create:
+//  - IAM service-id
+//  - service API key
+//  - optional Cloud Object Storage (COS) bucket
+//
+// After running, the operator should run the Vault helper to push secrets into Vault.
+resource "null_resource" "create_ibm_resources" {
+  triggers = {
+    name           = var.name
+    region         = var.region
+    resource_group = var.resource_group
+    create_cos     = tostring(var.create_cos)
+  }
+
+  provisioner "local-exec" {
+    command = <<EOT
+      set -eux
+      mkdir -p ${path.module}/../scripts/ibm/out
+      ${path.module}/../scripts/ibm/create_ibm_resources.sh --name "${var.name}" ${var.create_cos ? "--create-cos" : ""} --region "${var.region}" --resource-group "${var.resource_group}" --output "${path.module}/../scripts/ibm/out/ibm_resources.json"
+EOT
+    interpreter = ["/bin/bash", "-c"]
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:terraform/ibm/variables.tf
+variable "name" {
+  description = "Friendly name for created IBM resources (prefix)"
+  type        = string
+  default     = "aegis-ibm"
+}
+
+variable "region" {
+  description = "IBM Cloud region"
+  type        = string
+  default     = "us-south"
+}
+
+variable "resource_group" {
+  description = "IBM Cloud resource group name"
+  type        = string
+  default     = "default"
+}
+
+variable "create_cos" {
+  description = "Whether to attempt COS bucket creation (requires COS plugin & entitlement)"
+  type        = bool
+  default     = false
+}
+
*** End Patch
*** Begin Patch
*** Add File:terraform/ibm/outputs.tf
+output "ibm_resources_file" {
+  description = "Path to the JSON file created by the CLI script with resource metadata (contains API key - remove after use)."
+  value       = "${path.module}/../scripts/ibm/out/ibm_resources.json"
+}
+
*** End Patch
*** Begin Patch
*** Add File:terraform/ibm/terraform.tfvars.template
+name = "REPLACE_WITH_NAME_PREFIX"
+region = "REPLACE_WITH_IBM_REGION"
+resource_group = "REPLACE_WITH_RESOURCE_GROUP"
+create_cos = false
+
+# After applying, operator must run: ./scripts/ibm/store_ibm_secrets_to_vault.sh --input scripts/ibm/out/ibm_resources.json
+
*** End Patch
*** Begin Patch
*** Add File:scripts/ibm/create_ibm_resources.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Create IBM Cloud resources using ibmcloud CLI (safe, operator-run).
+# Produces a JSON file with service-id, api key (secret), and optional COS bucket.
+#
+OUT_DIR=${OUT_DIR:-./scripts/ibm/out}
+mkdir -p "$OUT_DIR"
+
+usage() {
+  cat <<EOF
+Usage: $0 --name <friendly-name> [--create-cos] [--region <region>] [--resource-group <rg>] [--output <out.json>]
+
+Creates:
+ - IBM Cloud service-id
+ - API key for the service-id
+ - (optional) COS bucket (best-effort)
+
+Writes JSON metadata (including API key) to the output file. Do NOT commit that file.
+EOF
+}
+
+NAME=""
+CREATE_COS=false
+REGION="us-south"
+RESOURCE_GROUP="default"
+OUT="${OUT_DIR}/ibm_resources.json"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --name) NAME="$2"; shift 2;;
+    --create-cos) CREATE_COS=true; shift ;;
+    --region) REGION="$2"; shift 2;;
+    --resource-group) RESOURCE_GROUP="$2"; shift 2;;
+    --output) OUT="$2"; shift 2;;
+    -h|--help) usage; exit 0;;
+    *) echo "Unknown arg: $1"; usage; exit 2;;
+  esac
+done
+
+if [ -z "$NAME" ]; then
+  echo "Missing --name"
+  usage
+  exit 2
+fi
+
+echo "Operator note: ensure you are logged in to ibmcloud CLI before running this script."
+ibmcloud target >/dev/null 2>&1 || { echo "Please run: ibmcloud login --sso or ibmcloud login"; exit 2; }
+
+echo "Creating service-id..."
+SID_JSON=$(ibmcloud iam service-id-create "$NAME" -d "Aegis generated service-id for $NAME" --output json)
+SID=$(echo "$SID_JSON" | jq -r '.id // empty')
+SID_NAME=$(echo "$SID_JSON" | jq -r '.name // empty')
+echo "Service ID: $SID ($SID_NAME)"
+
+echo "Creating API key for service-id..."
+AK_JSON=$(ibmcloud iam service-id-api-key-create "$SID" "${NAME}-key" -d "Aegis key for $SID_NAME" --output json)
+APIKEY=$(echo "$AK_JSON" | jq -r '.apikey // empty')
+APIKEY_ID=$(echo "$AK_JSON" | jq -r '.id // empty')
+echo "API key id: $APIKEY_ID"
+
+COS_BUCKET=""
+if [ "$CREATE_COS" = true ]; then
+  echo "Attempting to create COS bucket (best-effort)..."
+  if ! ibmcloud cos version >/dev/null 2>&1; then
+    echo "COS plugin not installed or not configured. Skipping COS creation. Install plugin with 'ibmcloud plugin install cloud-object-storage -f' and configure."
+  else
+    BUCKET_NAME="${NAME}-${REGION}"
+    echo "Creating bucket: $BUCKET_NAME"
+    ibmcloud cos create-bucket --bucket "$BUCKET_NAME" --region "$REGION" || echo "Bucket creation may require manual steps; please verify"
+    COS_BUCKET="$BUCKET_NAME"
+  fi
+fi
+
+cat > "$OUT" <<JSON
+{
+  "service_id": "$SID",
+  "service_id_name": "$SID_NAME",
+  "api_key_id": "$APIKEY_ID",
+  "api_key": "$APIKEY",
+  "cos_bucket": "$COS_BUCKET",
+  "region": "$REGION",
+  "resource_group": "$RESOURCE_GROUP"
+}
+JSON
+
+echo "Wrote resources metadata to $OUT"
+echo "IMPORTANT: Move the API key into Vault immediately using scripts/ibm/store_ibm_secrets_to_vault.sh and then delete this file."
+
*** End Patch
*** Begin Patch
*** Add File:scripts/ibm/store_ibm_secrets_to_vault.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Store IBM API key & metadata into Vault KV v2 at secret/data/ibm/
+#
+INPUT=""
+VAULT_PATH=${VAULT_PATH:-secret/data/ibm}
+VAULT_CLI=${VAULT_CLI:-vault}
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --input) INPUT="$2"; shift 2;;
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    *) echo "Unknown arg: $1"; exit 2;;
+  esac
+done
+
+if [ -z "$INPUT" ]; then
+  echo "Usage: $0 --input <json-file> [--vault-path secret/data/ibm]"
+  exit 2
+fi
+
+if [ ! -f "$INPUT" ]; then
+  echo "Input file not found: $INPUT"
+  exit 2
+fi
+
+if ! command -v "$VAULT_CLI" >/dev/null 2>&1; then
+  echo "Vault CLI ($VAULT_CLI) not found. Install it and ensure VAULT_ADDR and VAULT_TOKEN are set."
+  exit 2
+fi
+
+JSON=$(cat "$INPUT")
+APIKEY=$(echo "$JSON" | jq -r '.api_key')
+APIKEY_ID=$(echo "$JSON" | jq -r '.api_key_id')
+SID=$(echo "$JSON" | jq -r '.service_id')
+REGION=$(echo "$JSON" | jq -r '.region')
+COS_BUCKET=$(echo "$JSON" | jq -r '.cos_bucket')
+
+echo "Writing IBM secret into Vault at ${VAULT_PATH} (KV v2)"
+$VAULT_CLI kv put "${VAULT_PATH#secret/data/}" api_key="$APIKEY" api_key_id="$APIKEY_ID" service_id="$SID" region="$REGION" cos_bucket="$COS_BUCKET"
+
+echo "Secret written. Verify with: vault kv get ${VAULT_PATH#secret/data/}"
+echo "REMINDER: Remove the local JSON file containing the API key after verification: rm -f $INPUT"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/ibm/complete_ibm_setup.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# High-level operator orchestration to:
+#  - Run terraform wrapper (which invokes CLI script)
+#  - Push secrets to Vault
+#  - Configure Vault transit (scaffold)
+#  - Create Vault policy & role examples for GitHub OIDC and k8s
+#
+TF_DIR=${1:-terraform/ibm}
+RES_JSON=${2:-scripts/ibm/out/ibm_resources.json}
+
+echo "1) Running terraform apply (this will call the CLI script to create IBM resources)"
+pushd "$TF_DIR"
+terraform init
+terraform apply -auto-approve
+popd
+
+echo "2) Move API key into Vault (operator must have VAULT_ADDR and VAULT_TOKEN set)"
+if [ ! -f "$RES_JSON" ]; then
+  echo "Resource file not found: $RES_JSON - aborting"
+  exit 2
+fi
+./scripts/ibm/store_ibm_secrets_to_vault.sh --input "$RES_JSON"
+
+echo "3) Configure Vault (enable KV v2 + create policies/roles). Edit scripts/vault/*.sh before running."
+./scripts/vault/enable_kv_and_policies.sh
+./scripts/vault/configure_vault_for_github_oidc.sh
+./scripts/vault/create_ibm_policy_and_role.sh
+./scripts/vault/vault_transit_setup.sh
+
+echo "Operator NOTE: review outputs and remove the local resource JSON file: rm -f $RES_JSON"
+echo "Complete. Next: deploy quantum workers that read IBM creds from Vault (see examples/vault/ibm/...)"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/vault/enable_kv_and_policies.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Enable KV v2 and create a minimal policy for Aegis to read IBM secrets
+VAULT_CLI=${VAULT_CLI:-vault}
+POLICY_NAME=${POLICY_NAME:-aegis-ibm-read}
+
+if ! command -v "$VAULT_CLI" >/dev/null 2>&1; then
+  echo "Vault CLI not found; please install and set VAULT_ADDR & VAULT_TOKEN"
+  exit 2
+fi
+
+echo "Enabling KV v2 at secret/ if not already enabled"
+if ! $VAULT_CLI secrets list -format=json | jq -r 'keys[]' | grep -q '^secret/'; then
+  $VAULT_CLI secrets enable -version=2 -path=secret kv || true
+fi
+
+cat > /tmp/${POLICY_NAME}.hcl <<EOF
+path "secret/data/ibm" {
+  capabilities = ["read","list"]
+}
+EOF
+
+echo "Writing policy ${POLICY_NAME}"
+$VAULT_CLI policy write "${POLICY_NAME}" /tmp/${POLICY_NAME}.hcl
+rm -f /tmp/${POLICY_NAME}.hcl
+echo "Policy ${POLICY_NAME} created. Adjust as needed."
+
*** End Patch
*** Begin Patch
*** Add File:scripts/vault/configure_vault_for_github_oidc.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Template script to configure GitHub OIDC auth in Vault.
+# Edit variables below with your GH organization/repo and desired role/policies.
+#
+VAULT=${VAULT:-vault}
+GH_OIDC_DISCOVERY_URL=${GH_OIDC_DISCOVERY_URL:-"https://token.actions.githubusercontent.com"}
+GITHUB_ORG=${GITHUB_ORG:-"REPLACE_WITH_ORG"}
+GITHUB_REPO=${GITHUB_REPO:-"REPLACE_WITH_REPO"}
+VAULT_ROLE_NAME=${VAULT_ROLE_NAME:-"aegis-github-oidc-role"}
+POLICY_NAME=${POLICY_NAME:-"aegis-ibm-read"}
+
+echo "Enable JWT auth method if not present"
+if ! $VAULT auth list -format=json | jq -r 'keys[]' | grep -q '^oidc/'; then
+  $VAULT auth enable oidc || true
+fi
+
+echo "Configure OIDC issuer for GitHub Actions (operator must set client_id/client_secret if required by your Vault)"
+$VAULT write auth/oidc/config \
+  oidc_discovery_url="$GH_OIDC_DISCOVERY_URL" \
+  default_role="$VAULT_ROLE_NAME" || true
+
+cat > /tmp/role_cfg.json <<JSON
+{
+  "role_name": "$VAULT_ROLE_NAME",
+  "bound_audiences": ["sts.amazonaws.com", "sigstore"],
+  "user_claim": "sub",
+  "allowed_redirect_uris": [],
+  "token_policies": ["$POLICY_NAME"],
+  "claim_mappings": {}
+}
+JSON
+
+echo "Create role $VAULT_ROLE_NAME with policy $POLICY_NAME (adjust audience/claims per your GH OIDC setup)"
+# Operator should adapt this to the specific Vault OIDC method being used (the above is illustrative)
+echo "Operator: edit this file /tmp/role_cfg.json if needed, then use vault CLI to configure role manually."
+
*** End Patch
*** Begin Patch
*** Add File:scripts/vault/create_ibm_policy_and_role.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Create a Kubernetes or GitHub role bound to aegis-ibm-read policy.
+# This script is a template - operator must adapt role binding and selectors.
+VAULT_CLI=${VAULT_CLI:-vault}
+ROLE_NAME=${ROLE_NAME:-aegis-ibm-k8s-role}
+POLICY_NAME=${POLICY_NAME:-aegis-ibm-read}
+K8S_SA=${K8S_SA:-aegis-quantum-sa}
+K8S_NAMESPACE=${K8S_NAMESPACE:-staging}
+
+echo "Creating Kubernetes auth role for service account ${K8S_SA} in namespace ${K8S_NAMESPACE}"
+$VAULT_CLI auth enable kubernetes || true
+
+# Operator: ensure Kubernetes auth is configured (token reviewer, kubernetes_host etc.)
+
+$VAULT_CLI write auth/kubernetes/role/${ROLE_NAME} \
+  bound_service_account_names=${K8S_SA} \
+  bound_service_account_namespaces=${K8S_NAMESPACE} \
+  policies=${POLICY_NAME} \
+  ttl=1h || true
+
+echo "Created role ${ROLE_NAME} bound to policy ${POLICY_NAME}"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/vault/vault_transit_setup.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Setup Vault transit key & policies for signing circuit snapshots using Vault transit.
+# This allows workers to sign artifacts via Vault and record provenance without exposing private keys.
+#
+VAULT_CLI=${VAULT_CLI:-vault}
+TRANSIT_KEY_NAME=${TRANSIT_KEY_NAME:-aegis-quantum-signing}
+POLICY_NAME=${POLICY_NAME:-aegis-transit-sign}
+
+echo "Enable transit engine if not enabled"
+if ! $VAULT_CLI secrets list -format=json | jq -r 'keys[]' | grep -q '^transit/'; then
+  $VAULT_CLI secrets enable transit || true
+fi
+
+echo "Create transit key: $TRANSIT_KEY_NAME"
+$VAULT_CLI write -f transit/keys/$TRANSIT_KEY_NAME || true
+
+cat > /tmp/${POLICY_NAME}.hcl <<EOF
+path "transit/sign/${TRANSIT_KEY_NAME}" {
+  capabilities = ["update"]
+}
+path "transit/verify/${TRANSIT_KEY_NAME}" {
+  capabilities = ["read"]
+}
+EOF
+
+echo "Write policy ${POLICY_NAME}"
+$VAULT_CLI policy write ${POLICY_NAME} /tmp/${POLICY_NAME}.hcl
+rm -f /tmp/${POLICY_NAME}.hcl
+
+echo "Transit key and policy created. Use scripts/ibm/vault_transit_cosign_wrapper.sh as a signing wrapper in workers/CI."
+
*** End Patch
*** Begin Patch
*** Add File:scripts/ibm/vault_transit_cosign_wrapper.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Sign a file using Vault transit sign endpoint and output a cosign-compatible signature file (base64).
+# Requires VAULT_ADDR and VAULT_TOKEN or Vault Agent injected token in environment.
+#
+FILE=${1:-}
+KEY=${KEY:-aegis-quantum-signing}
+VAULT_ADDR=${VAULT_ADDR:-http://127.0.0.1:8200}
+
+if [ -z "$FILE" ]; then
+  echo "Usage: $0 <file-to-sign>"
+  exit 2
+fi
+
+if [ ! -f "$FILE" ]; then
+  echo "File not found: $FILE"
+  exit 2
+fi
+
+DATA_B64=$(base64 -w 0 "$FILE")
+RESP=$(curl -sS --header "X-Vault-Token: $VAULT_TOKEN" --request POST --data '{"input":"'"$DATA_B64"'"}' $VAULT_ADDR/v1/transit/sign/$KEY)
+SIG=$(echo "$RESP" | jq -r '.data.signature')
+echo "Vault signature: $SIG"
+# Write minimal artifact for Rekor or other uses
+echo "$SIG" > "$FILE.vault.sig"
+echo "Signature written to $FILE.vault.sig"
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/ci_ibm_vault_oidc.yml
+name: CI: IBMQ job (Vault OIDC fetch)
+on:
+  workflow_dispatch:
+
+permissions:
+  id-token: write
+  contents: read
+
+jobs:
+  run-ibmq-job:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Configure short-lived Vault token via OIDC (operator must configure Vault OIDC role)
+        env:
+          VAULT_ADDR: ${{ secrets.VAULT_ADDR }}
+        run: |
+          set -eux
+          # The exact method to exchange OIDC for Vault token depends on your Vault OIDC configuration.
+          # This is an illustrative placeholder. Operator: replace with real vault login command.
+          echo "Operator: configure vault login via OIDC here"
+      - name: Fetch IBM API key from Vault
+        env:
+          VAULT_ADDR: ${{ secrets.VAULT_ADDR }}
+          VAULT_TOKEN: ${{ secrets.VAULT_TOKEN }} # If using OIDC this should be the short-lived token acquired above
+        run: |
+          set -eux
+          vault kv get -format=json secret/ibm | jq -r '.data.data.api_key' > ibm_api_key.txt
+          echo "Fetched IBM API key (do not echo to logs)"
+      - name: Run Qiskit sample with injected API key
+        env:
+          IBM_API_TOKEN: $(cat ibm_api_key.txt)
+        run: |
+          python3 examples/qiskit/sample_qiskit_script.py
+
*** End Patch
*** Begin Patch
*** Add File:README_IBM_FULL.md
+# Aegis: Full IBM Cloud Support (operator-run, safe defaults)
+
+This patch adds a full, operator-driven integration path to support IBM Cloud for Aegis:
+- CLI-first Terraform wrapper that runs scripts/ibm/create_ibm_resources.sh (creates service-id, API key, optional COS).
+- Vault integration helpers to store secrets, enable KV v2, configure policies and roles, and setup Vault transit for signing.
+- A signing wrapper that uses Vault transit to sign artifacts (works as a cosign/Vault bridge).
+- CI example showing Vault OIDC consumption pattern (illustrative; operator must adapt).
+
+Security-first approach
+- No secrets stored in Git. The resource creation script writes a JSON file with the created API key — move it into Vault immediately via scripts/ibm/store_ibm_secrets_to_vault.sh, then delete the JSON file.
+- Vault admin/ops must review and run scripts/vault/*.sh; they contain templates and placeholders.
+
+Operator runbook (high-level)
+1. Review scripts carefully with IBM Cloud & Security teams.
+2. Login to IBM Cloud: `ibmcloud login --sso` (or interactive).
+3. Run Terraform wrapper:
+   cd terraform/ibm
+   terraform init && terraform apply -auto-approve
+   (this will call scripts/ibm/create_ibm_resources.sh)
+4. Immediately store secrets in Vault:
+   ./scripts/ibm/store_ibm_secrets_to_vault.sh --input scripts/ibm/out/ibm_resources.json
+   rm -f scripts/ibm/out/ibm_resources.json
+5. Configure Vault (KV v2, policies, roles, transit):
+   ./scripts/vault/enable_kv_and_policies.sh
+   ./scripts/vault/configure_vault_for_github_oidc.sh   # edit placeholders first
+   ./scripts/vault/create_ibm_policy_and_role.sh       # edit placeholders if needed
+   ./scripts/vault/vault_transit_setup.sh
+6. Deploy quantum workers to read IBM creds from Vault Agent injector (see examples/vault/ibm/vault-k8s-vault-agent-inject-ibm-secret.yaml).
+7. Use scripts/ibm/vault_transit_cosign_wrapper.sh in CI/worker signing flows to sign circuit snapshots and record provenance.
+
+Notes and caveats
+- Terraform wrapper delegates to ibmcloud CLI for portability. Once validated in tenancy you can convert CLI steps into native Terraform resources if desired.
+- Vault transit key is created in Vault; optionally you may configure Key Protect as an HSM backing or use PKCS#11 adapters — this requires account-level review and is not automated here.
+- The CI workflow included is templated and requires operator customization to exchange GitHub OIDC for a Vault token, or to configure short-lived tokens.
+
+If you want, I can now:
+- Generate a PR in your GitHub repo with this patch (I will not apply any resources).
+- Convert the CLI steps into best-effort native Terraform resources for IBM (I will mark manual-review sections).
+- Scaffold a Vault ⇄ IBM Key Protect PKCS#11 integration (notes + sample configs) — this is advanced and requires access to your Key Protect / HSM details.
+
+Choose next step or apply the patch locally and follow the runbook.
+
*** End Patch
*** End Patch
