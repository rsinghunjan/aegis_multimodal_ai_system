*** Begin Patch
*** Add File:ops/provision_validate_hsm_end_to_end.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# End-to-end HSM provisioning & validation orchestrator
+# - Optionally runs Terraform to provision CloudHSM
+# - Installs vendor PKCS#11 module (calls vendor install script)
+# - Publishes config & public keys to Vault
+# - Runs sign & rotation tests and verifies S3 audit forwarding + SIEM sample forward
+# - Produces a JSON report at the end
+#
+# Usage:
+#   ./provision_validate_hsm_end_to_end.sh \
+#     --hsm-tfvars ./cloud/hsm/terraform.tfvars \
+#     --pkcs11-module /opt/vendor/lib/vendor_pkcs11.so \
+#     --pkcs11-slot 0 \
+#     --pkcs11-pin 1234 \
+#     --key-label pqkey \
+#     --vault-path secret/data/hsm/config \
+#     --s3-audit-bucket my-hsm-audit-bucket \
+#     --siem-endpoint https://siem.example.com/ingest
+#
+OUT=/tmp/aegis_hsm_full_run_$(date -u +"%Y%m%dT%H%M%SZ")
+mkdir -p "$OUT"
+TFVARS=""
+PKCS11_MODULE=""
+PKCS11_SLOT="0"
+PKCS11_PIN=""
+KEY_LABEL="pqkey"
+VAULT_PATH="secret/data/hsm/config"
+S3_AUDIT_BUCKET=""
+SIEM_ENDPOINT=""
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --hsm-tfvars) TFVARS="$2"; shift 2;;
+    --pkcs11-module) PKCS11_MODULE="$2"; shift 2;;
+    --pkcs11-slot) PKCS11_SLOT="$2"; shift 2;;
+    --pkcs11-pin) PKCS11_PIN="$2"; shift 2;;
+    --key-label) KEY_LABEL="$2"; shift 2;;
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    --s3-audit-bucket) S3_AUDIT_BUCKET="$2"; shift 2;;
+    --siem-endpoint) SIEM_ENDPOINT="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 2;;
+  esac
+done
+
+log() { echo "[$(date -u +"%Y-%m-%dT%H:%M:%SZ")] $*"; }
+report_file="${OUT}/report.json"
+report='{"steps":{}}'
+
+log "Start HSM full run; logs & artifacts in ${OUT}"
+
+if [ -n "$TFVARS" ]; then
+  log "Provisioning CloudHSM via Terraform..."
+  pushd cloud/hsm >/dev/null
+  terraform init -input=false
+  terraform apply -auto-approve -var-file="${TFVARS}" | tee "${OUT}/terraform_apply.log"
+  popd >/dev/null
+  report=$(jq --arg t "terraform:ok" '.steps.terraform=$t' <<<"$report")
+else
+  log "Skipping Terraform provisioning (no tfvars provided)."
+  report=$(jq --arg t "terraform:skipped" '.steps.terraform=$t' <<<"$report")
+fi
+
+if [ -n "$PKCS11_MODULE" ]; then
+  log "Installing PKCS#11 & audit forwarders on host(s)..."
+  sudo bash quantum/hsm/vendor_integration/install_vendor_pkcs11.sh --module "${PKCS11_MODULE}" --s3-audit-bucket "${S3_AUDIT_BUCKET}" --siem-endpoint "${SIEM_ENDPOINT}" 2>&1 | tee "${OUT}/install_pkcs11.log"
+  report=$(jq --arg t "pkcs11:installed" '.steps.pkcs11=$t' <<<"$report")
+else
+  log "No PKCS#11 module provided; skipping install."
+  report=$(jq --arg t "pkcs11:skipped" '.steps.pkcs11=$t' <<<"$report")
+fi
+
+log "Publishing HSM config & (if present) public key to Vault..."
+if command -v vault >/dev/null 2>&1; then
+  if [ -f "/tmp/${KEY_LABEL}.pub" ]; then
+    vault kv put "${VAULT_PATH}" pkcs11_module="${PKCS11_MODULE}" slot="${PKCS11_SLOT}" public_key=@"/tmp/${KEY_LABEL}.pub" | tee "${OUT}/vault_put.log"
+    report=$(jq --arg t "vault:updated" '.steps.vault=$t' <<<"$report")
+  else
+    log "Warning: /tmp/${KEY_LABEL}.pub not present; operator must export vendor public key to /tmp/${KEY_LABEL}.pub and re-run write if desired."
+    report=$(jq --arg t "vault:pubkey_missing" '.steps.vault=$t' <<<"$report")
+  fi
+else
+  log "Vault CLI not available; skipping Vault publish."
+  report=$(jq --arg t "vault:missing_cli" '.steps.vault=$t' <<<"$report")
+fi
+
+log "Running validation sign operation..."
+ART="${OUT}/test-artifact.bin"
+echo "aegis-hsm-test" > "${ART}"
+set +e
+bash quantum/hsm/validate_hsm_end_to_end.sh --artifact "${ART}" --pkcs11-lib "${PKCS11_MODULE}" --pkcs11-slot "${PKCS11_SLOT}" --pkcs11-pin "${PKCS11_PIN}" --pkcs11-keylabel "${KEY_LABEL}" --s3-bucket "${S3_AUDIT_BUCKET}" 2>&1 | tee "${OUT}/hsm_validation.log"
+RC=$?
+set -e
+report=$(jq --arg t "validate:${RC}" '.steps.validate=$t' <<<"$report")
+
+log "Rotation test (operator: create new key in vendor HSM now)..."
+echo "Please create new key labelled ${KEY_LABEL}-v2 using vendor CLI and place public key at /tmp/${KEY_LABEL}-v2.pub"
+read -p "Press Enter to continue or Ctrl-C to abort..."
+if [ -f "/tmp/${KEY_LABEL}-v2.pub" ]; then
+  bash quantum/hsm/vendor_rotation_test.sh --vault-path "${VAULT_PATH}" --new-label "${KEY_LABEL}-v2" --pubkey "/tmp/${KEY_LABEL}-v2.pub" --pkcs11-lib "${PKCS11_MODULE}" --slot "${PKCS11_SLOT}" --pin "${PKCS11_PIN}" --artifact "${ART}" --s3-bucket "${S3_AUDIT_BUCKET}" 2>&1 | tee "${OUT}/hsm_rotation.log"
+  report=$(jq --arg t "rotation:ran" '.steps.rotation=$t' <<<"$report")
+else
+  log "Rotation public key missing; skipping."
+  report=$(jq --arg t "rotation:skipped" '.steps.rotation=$t' <<<"$report")
+fi
+
+log "Verifying audit objects in S3..."
+if [ -n "${S3_AUDIT_BUCKET}" ]; then
+  python3 quantum/hsm/vendor_validation/verify_hsm_audit.py --s3-bucket "${S3_AUDIT_BUCKET}" --prefix hsm-audit/ --timeout 300 2>&1 | tee "${OUT}/verify_hsm_audit.log" || true
+  if [ -n "${SIEM_ENDPOINT}" ]; then
+    python3 quantum/hsm/verify_audit_to_siem.py --s3-bucket "${S3_AUDIT_BUCKET}" --prefix hsm-audit/ --timeout 60 --siem-endpoint "${SIEM_ENDPOINT}" 2>&1 | tee "${OUT}/verify_hsm_siem.log" || true
+  fi
+  report=$(jq --arg t "s3:checked" '.steps.s3=$t' <<<"$report")
+else
+  report=$(jq --arg t "s3:skipped" '.steps.s3=$t' <<<"$report")
+fi
+
+echo "$report" | jq . > "$report_file"
+log "HSM full run complete. Report: ${report_file}. Logs: ${OUT}"
+exit 0
+
*** End Patch
*** Begin Patch
*** Add File:quantum/pilot/run_credentialed_pilots.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Script to write provider credentials into Vault, run pilots for multiple vendors,
+# collect artifacts, and produce a verification summary.
+#
+# Usage:
+#  ./run_credentialed_pilots.sh --vault-path secret/data/quantum/providers --braket-device arn:aws:braket:... --ibm-token <token> --program /tmp/demo.qasm --s3-bucket my-bucket
+
+VAULT_PATH=""
+BRAKET_DEVICE=""
+IBM_TOKEN=""
+PROGRAM=""
+S3_BUCKET=""
+MLFLOW_URL=""
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    --braket-device) BRAKET_DEVICE="$2"; shift 2;;
+    --ibm-token) IBM_TOKEN="$2"; shift 2;;
+    --program) PROGRAM="$2"; shift 2;;
+    --s3-bucket) S3_BUCKET="$2"; shift 2;;
+    --mlflow-url) MLFLOW_URL="$2"; shift 2;;
+    *) echo "Unknown $1"; exit 1;;
+  esac
+done
+
+: "${VAULT_PATH:?--vault-path required}"
+: "${PROGRAM:?--program required}"
+: "${S3_BUCKET:?--s3-bucket required}"
+
+report="/tmp/aegis_pilots_$(date -u +"%Y%m%dT%H%M%SZ").json"
+echo '{"runs":[]}' > "$report"
+
+if [ -n "$BRAKET_DEVICE" ]; then
+  echo "Writing Braket device to Vault..."
+  vault kv put "${VAULT_PATH}" braket_device="${BRAKET_DEVICE}" || true
+  echo "Running Braket pilot..."
+  python3 quantum/pilot/credentialed_pilot_runner.py --vault-path "${VAULT_PATH}" --braket-device "${BRAKET_DEVICE}" --program "${PROGRAM}" --s3-bucket "${S3_BUCKET}" --mlflow-url "${MLFLOW_URL:-}" | tee /tmp/braket_pilot.log || true
+  jq --arg f "/tmp/braket_pilot.log" '.runs += [{"provider":"braket","log":$f}]' "$report" > "${report}.tmp" && mv "${report}.tmp" "$report"
+fi
+
+if [ -n "$IBM_TOKEN" ]; then
+  echo "Writing IBM token to Vault..."
+  vault kv put "${VAULT_PATH}" ibm_token="${IBM_TOKEN}" || true
+  echo "Running IBM pilot..."
+  python3 quantum/pilot/credentialed_pilot_runner.py --vault-path "${VAULT_PATH}" --ibm-token "${IBM_TOKEN}" --program "${PROGRAM}" --s3-bucket "${S3_BUCKET}" --mlflow-url "${MLFLOW_URL:-}" | tee /tmp/ibm_pilot.log || true
+  jq --arg f "/tmp/ibm_pilot.log" '.runs += [{"provider":"ibm","log":$f}]' "$report" > "${report}.tmp" && mv "${report}.tmp" "$report"
+fi
+
+echo "Collected pilot logs. Report at ${report}"
+cat "$report"
+
*** End Patch
*** Begin Patch
*** Add File:feature_store/externalsecret_feast_db.yaml
+apiVersion: kubernetes-client.io/v1
+kind: ExternalSecret
+metadata:
+  name: feast-db-secret
+  namespace: feast
+spec:
+  backendType: vault
+  vaultMountPoint: "secret"
+  vaultRole: "aegis-feast-role"
+  data:
+    - key: "secret/data/feast/db"
+      name: DATABASE_URL
+
*** End Patch
*** Begin Patch
*** Add File:feature_store/feast_prod_helper.sh
+#!/usr/bin/env bash
+set -euo pipefail
+NS=${1:-feast}
+RELEASE=${2:-aegis-feast}
+
+echo "Ensure ExternalSecret feast-db-secret is applied (feature_store/externalsecret_feast_db.yaml)"
+kubectl apply -n "${NS}" -f feature_store/externalsecret_feast_db.yaml
+echo "Install Feast dependencies (postgres/redis) via Helm..."
+bash feature_store/deploy_feast_prod.sh "${RELEASE}" "${NS}"
+echo "Create PVCs for batch reads and AI ops reports if not present (operator action)."
+echo "Deploy CronJob to run ingestion (feature_store/k8s/feast-ingest-cronjob.yaml)"
+kubectl apply -n "${NS}" -f feature_store/k8s/feast-ingest-cronjob.yaml
+echo "Feast prod helper run complete; monitor pods in namespace ${NS}"
+
*** End Patch
*** Begin Patch
*** Add File:ci/serving/promote_and_verify.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# Promote model image and verify SLI (latency / error rate) via Prometheus queries.
+IMAGE="${1:?image required (registry/name:tag)}"
+DEPLOYMENT="${2:-aegis-model}"
+NAMESPACE="${3:-aegis}"
+PROM_URL="${PROM_URL:-http://prometheus.aegis:9090}"
+MAX_LATENCY="${MAX_LATENCY:-1.0}"  # seconds
+MAX_ERROR_RATE="${MAX_ERROR_RATE:-0.01}" # fraction
+
+old_image=$(kubectl -n "${NAMESPACE}" get deployment "${DEPLOYMENT}" -o jsonpath='{.spec.template.spec.containers[0].image}')
+echo "Promoting ${IMAGE} -> ${DEPLOYMENT} (was ${old_image})"
+kubectl -n "${NAMESPACE}" set image deployment/"${DEPLOYMENT}" "${DEPLOYMENT}"="${IMAGE}"
+kubectl -n "${NAMESPACE}" rollout status deployment/"${DEPLOYMENT}" --timeout=120s
+
+echo "Wait 30s for metrics to collect..."
+sleep 30
+
+lat=$(curl -sG "${PROM_URL}/api/v1/query" --data-urlencode "query=job:inference_latency:avg" | jq -r '.data.result[0].value[1]' 2>/dev/null || echo "0")
+err=$(curl -sG "${PROM_URL}/api/v1/query" --data-urlencode "query=rate(aegis_model_errors_total[5m])" | jq -r '.data.result[0].value[1]' 2>/dev/null || echo "0")
+lat=${lat:-0}
+err=${err:-0}
+echo "Observed latency=${lat}s error_rate=${err}"
+lat_ok=$(awk "BEGIN{print (${lat} <= ${MAX_LATENCY}) ? 1 : 0}")
+err_ok=$(awk "BEGIN{print (${err} <= ${MAX_ERROR_RATE}) ? 1 : 0}")
+if [ "${lat_ok}" -eq 1 ] && [ "${err_ok}" -eq 1 ]; then
+  echo "SLI check passed. Promotion complete."
+  exit 0
+else
+  echo "SLI check failed. Rolling back to ${old_image}"
+  kubectl -n "${NAMESPACE}" set image deployment/"${DEPLOYMENT}" "${DEPLOYMENT}"="${old_image}"
+  kubectl -n "${NAMESPACE}" rollout status deployment/"${DEPLOYMENT}" --timeout=120s
+  echo "Rollback complete."
+  exit 2
+fi
+
*** End Patch
*** Begin Patch
*** Add File:ops/vault_k8s_setup.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# Create Vault policy and k8s auth role for external-secrets / agents
+VAULT_ADDR=${VAULT_ADDR:-http://127.0.0.1:8200}
+ROLE_NAME=${1:-aegis-k8s-role}
+POLICY_NAME=${2:-aegis-agent-policy}
+
+echo "Ensure VAULT_TOKEN is set and points to an admin-capable token."
+vault policy write "${POLICY_NAME}" - <<EOF
+path "secret/data/*" {
+  capabilities = ["read","list"]
+}
+path "secret/data/job_database" {
+  capabilities = ["read"]
+}
+EOF
+
+vault auth enable -path=kubernetes kubernetes || true
+vault write auth/kubernetes/role/"${ROLE_NAME}" \
+  bound_service_account_names="aegis-agent" \
+  bound_service_account_namespaces="aegis" \
+  policies="${POLICY_NAME}" \
+  ttl="24h"
+
+echo "Vault k8s role ${ROLE_NAME} and policy ${POLICY_NAME} created."
+
*** End Patch
*** Begin Patch
*** Add File:ops/smoke_and_load_runbook.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# High level smoke & load runbook:
+echo "1) Ensure cluster context is correct:"
+kubectl config current-context
+echo "2) Run broker smoke tests:"
+bash broker/scripts/smoke_tests.sh aegis
+echo "3) Run HPA autoscale load test (requires BROKER_JWT env):"
+if [ -z "${BROKER_JWT:-}" ]; then
+  echo "BROKER_JWT not set; please set and re-run HPA test."
+else
+  ./broker/runbooks/load_test_hpa.sh "http://aegis-quantum-broker.aegis.svc.cluster.local/submit" "${BROKER_JWT}" 200
+fi
+echo "4) Run model serving canary & SLI verification:"
+echo "Use ci/serving/promote_and_verify.sh <image> [deployment]"
+
*** End Patch
*** Begin Patch
*** Add File:governance/legal/contract_finalization_checklist.md
+Vendor contract & SOC2 finalization checklist
+
+Steps to complete legal & auditor acceptance:
+1. Consolidate vendor contract templates: compliance/vendor_contracts/COUNTERSIGN_TEMPLATE.md and compliance/legal/contract_signoff_template.md
+2. Provide evidence bundle: run compliance/generate_evidence_bundle_enhanced.py with env HSM_AUDIT_BUCKET, MLFLOW_URL and COSIGN_KEY set.
+3. Email draft: ops/compliance/auto_email_attach_and_notify.sh will prepare draft for legal with evidence attached.
+4. Export-control: provide architecture docs, HSM crypto description and QPU usage details to legal for export-control review.
+5. SOC2: engage auditor and submit evidence bundle. Have auditor confirm Rekor/cosign process is acceptable; add any procedural steps to docs/compliance.
+
*** End Patch
*** Begin Patch
*** Add File:billing/scale/cur_scale_test_runner.sh
+#!/usr/bin/env bash
+set -euo pipefail
+OUTCSV=${1:-/tmp/cur_test.csv}
+DBURL=${2:-postgresql://feast:feastpass@postgres:5432/feast}
+THRESHOLD=${3:-10000}
+FALLBACK_URL=${4:-http://aegis-quantum-broker.aegis.svc.cluster.local/admin/trigger-fallback}
+
+echo "Generating synthetic CUR CSV..."
+python3 billing/cur/stress_test_cur_generator.py --out "${OUTCSV}" --rows 20000 --jobs 2000
+echo "Ingesting CSV into billing connector..."
+python3 billing/chargeback/cur_to_billing.py "${OUTCSV}" --dburl "${DBURL}" --threshold "${THRESHOLD}" --fallback-url "${FALLBACK_URL}"
+echo "Waiting 30s and checking broker fallback state..."
+sleep 30
+curl -s "${FALLBACK_URL}" || true
+
*** End Patch
*** Begin Patch
*** Add File:ui/.github/workflows/model_card_publish.yml
+name: Publish Model Card
+on:
+  workflow_dispatch:
+    inputs:
+      model_id:
+        required: true
+      model_card_file:
+        required: true
+jobs:
+  publish:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Publish model card to Aegis UI
+        run: |
+          curl -s -X POST "${{ secrets.AEGIS_API_URL }}/api/model-cards/" -H "Authorization: Bearer ${{ secrets.AEGIS_API_TOKEN }}" -H "Content-Type: application/json" --data-binary @"${{ github.event.inputs.model_card_file }}"
+
*** End Patch
*** Begin Patch
*** Add File:ci/serving/explainability_step.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# CI step: run SHAP explainability script and upload artifact to MLflow and model card store
+MODEL_PATH=${1:-/tmp/model.joblib}
+DATA_CSV=${2:-/tmp/val.csv}
+MLFLOW_URL=${MLFLOW_URL:-${MLFLOW_URL}}
+
+python3 explainability/shap/run_shap.py "${MODEL_PATH}" "${DATA_CSV}"
+# assume run_shap logs artifact to MLflow; optionally upload model card to UI if present
+if [ -n "${AEGIS_API:-}" ]; then
+  echo "Posting model card to UI (if present)"
+  # model card must be prepared by pipeline (placeholder)
+fi
+
*** End Patch
*** End Patch
