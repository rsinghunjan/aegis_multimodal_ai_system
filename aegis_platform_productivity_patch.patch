*** Begin Patch
*** Add File:product/backlog.yaml
+---
+project: aegis-platform
+version: 1
+areas:
+  - name: Factory
+    owner: platform-factory
+    description: "Build, package, SBOM, SCA, sign, artifact manifest and CI flows."
+    priorities:
+      - id: FACT-001
+        title: "Enforce build -> SBOM -> sign pipeline in CI"
+        effort: 3
+      - id: FACT-002
+        title: "Produce standardized manifest on every build"
+        effort: 2
+      - id: FACT-003
+        title: "Developer CLI: train -> package -> sign -> promote"
+        effort: 5
+
+  - name: Lab
+    owner: platform-lab
+    description: "Verification pipelines (SIL, PIL, HIL), simulation harness, off-policy evaluation."
+    priorities:
+      - id: LAB-001
+        title: "Digital twin scenario library integration"
+        effort: 5
+      - id: LAB-002
+        title: "Automate evidence capture for verification runs"
+        effort: 3
+
+  - name: Vault
+    owner: platform-security
+    description: "Secrets, PKI, signing trust, audit logs and HSM integration."
+    priorities:
+      - id: VAULT-001
+        title: "Vault PKI for ephemeral CI certs"
+        effort: 3
+      - id: VAULT-002
+        title: "Automate audit log archival to EVIDENCE_BUCKET"
+        effort: 2
+
+  - name: Control Tower
+    owner: platform-control
+    description: "Gatekeeper policies, runtime safety, canaries, monitoring, cost controls."
+    priorities:
+      - id: CT-001
+        title: "Gatekeeper dry-run harness and promotion workflow"
+        effort: 3
+      - id: CT-002
+        title: "KPI-first dashboards and alerts (lead-time, SBOM coverage, drift)"
+        effort: 4
+
+guidelines:
+  - "Prioritize ML-facing deliverables first (Factory -> Lab) in each sprint."
+  - "Keep Platform UX thin: provide CLI + API + template per developer flow."
+  - "All promotions must generate an evidence bundle and a registry entry (automated)."
+
*** End Patch
*** Begin Patch
*** Add File:dev/cli/aegis_cli.py
+#!/usr/bin/env python3
+"""
+Simple Aegis developer CLI to train, package, sign and promote models.
+Usage:
+  aegis_cli.py train --out out/model.bin
+  aegis_cli.py package --model out/model.bin --out out
+  aegis_cli.py sign --manifest out/manifest.json
+  aegis_cli.py promote --manifest-s3 s3://.../artifacts/manifest.json
+
+This CLI is intentionally minimal — meant to be used locally or in CI as a lightweight DX layer.
+"""
+import argparse, os, json, hashlib, subprocess, time
+
+def train(args):
+    os.makedirs(args.out, exist_ok=True)
+    path = os.path.join(args.out, "model.bin")
+    with open(path, "wb") as f:
+        f.write(b"TRAINED_MODEL_PLACEHOLDER")
+    print("wrote", path)
+
+def package(args):
+    mpath = os.path.join(args.out, "model.bin")
+    if not os.path.exists(mpath):
+        raise SystemExit("model not found, run train first")
+    sha = hashlib.sha256(open(mpath,"rb").read()).hexdigest()
+    manifest = {
+        "artifact": os.path.basename(mpath),
+        "version": args.version or "0.0.0",
+        "sha256": sha,
+        "provenance": {"builder":"aegis-cli","time": time.time()},
+        "sbom": "sbom.spdx.json",
+        "trivy_report": "trivy_report.json",
+        "acceptance_criteria": args.acceptance_criteria or {}
+    }
+    with open(os.path.join(args.out,"manifest.json"), "w") as f:
+        json.dump(manifest, f, indent=2)
+    print("wrote manifest", os.path.join(args.out,"manifest.json"))
+
+def sign(args):
+    manifest = args.manifest
+    if not os.path.exists(manifest):
+        raise SystemExit("manifest not found")
+    kms = os.environ.get("COSIGN_KMS_KEY_ARN")
+    rekor = os.environ.get("REKOR_URL")
+    if not kms:
+        print("COSIGN_KMS_KEY_ARN not set — skipping cosign; create evidence bundle locally")
+        return
+    cmd = ["cosign","sign","--key",f"awskms://{kms}"]
+    if rekor:
+        cmd += ["--rekor-url", rekor]
+    cmd.append(manifest)
+    print("running:", " ".join(cmd))
+    subprocess.check_call(cmd)
+
+def promote(args):
+    # Simple promotion: upload manifest and evidence, then call Argo promotion via kubectl (or REST)
+    manifest = args.manifest
+    if manifest.startswith("s3://"):
+        manifest_s3 = manifest
+    else:
+        # upload to MODEL_ARTIFACT_BUCKET
+        bucket = os.environ.get("MODEL_ARTIFACT_BUCKET")
+        if not bucket:
+            raise SystemExit("MODEL_ARTIFACT_BUCKET not set")
+        key = f"artifacts/{os.path.basename(manifest)}"
+        subprocess.check_call(["aws","s3","cp",manifest,f"s3://{bucket}/{key}"])
+        manifest_s3 = f"s3://{bucket}/{key}"
+    # kick off Argo promotion workflow
+    print("Triggering Argo promotion for", manifest_s3)
+    # argo: using kubectl to create a Workflow object might be platform-dependent; here we'll just POST to Argo Server if available
+    argo_server = os.environ.get("ARGO_SERVER")
+    if argo_server:
+        import requests
+        wf = {
+          "apiVersion":"argoproj.io/v1alpha1",
+          "kind":"Workflow",
+          "metadata":{"generateName":"promotion-"},
+          "spec":{"entrypoint":"promote-artifact","arguments":{"parameters":[{"name":"manifest-s3","value":manifest_s3}]}}
+        }
+        r = requests.post(f"{argo_server}/api/v1/workflows/aegis", json=wf, timeout=10, headers={"Content-Type":"application/json"})
+        print("Argo response:", r.status_code, r.text)
+    else:
+        print("No ARGO_SERVER set — please trigger Argo promotion manually. Manifest at", manifest_s3)
+
+def main():
+    p = argparse.ArgumentParser(prog="aegis")
+    sub = p.add_subparsers(dest="cmd")
+    t = sub.add_parser("train")
+    t.add_argument("--out", default="out")
+    pk = sub.add_parser("package")
+    pk.add_argument("--model", default=None)
+    pk.add_argument("--out", default="out")
+    pk.add_argument("--version", default=None)
+    pk.add_argument("--acceptance-criteria", dest="acceptance_criteria", default={})
+    s = sub.add_parser("sign")
+    s.add_argument("--manifest", required=True)
+    pr = sub.add_parser("promote")
+    pr.add_argument("--manifest", required=True)
+    args = p.parse_args()
+    if args.cmd=="train":
+        train(args)
+    elif args.cmd=="package":
+        package(args)
+    elif args.cmd=="sign":
+        sign(args)
+    elif args.cmd=="promote":
+        promote(args)
+    else:
+        p.print_help()
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:dev/templates/serving/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: model-serving-{{ .name }}
+  namespace: {{ .namespace | default "aegis" }}
+  labels:
+    app: model-serving
+    model: "{{ .name }}"
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: model-serving
+      model: "{{ .name }}"
+  template:
+    metadata:
+      labels:
+        app: model-serving
+        model: "{{ .name }}"
+      annotations:
+        prometheus.io/scrape: "true"
+        prometheus.io/port: "8080"
+    spec:
+      containers:
+        - name: model-server
+          image: "{{ .image }}"
+          ports:
+            - containerPort: 8080
+          env:
+            - name: MONGO_URI
+              valueFrom:
+                secretKeyRef:
+                  name: mongodb-connection
+                  key: MONGO_URI
+            - name: COUCHBASE_HOST
+              value: "{{ .couchbase_host | default \"\" }}"
+            - name: SAFETY_MONITOR_URL
+              value: "{{ .safety_monitor_url | default \"http://safety-monitor.aegis.svc:8080/evaluate\" }}"
+          readinessProbe:
+            httpGet:
+              path: /health
+              port: 8080
+            initialDelaySeconds: 5
+            periodSeconds: 10
+
*** End Patch
*** Begin Patch
*** Add File:dev/templates/serving/flagger_canary.yaml
+apiVersion: flagger.app/v1beta1
+kind: Canary
+metadata:
+  name: "{{ .name }}-canary"
+  namespace: {{ .namespace | default "aegis" }}
+spec:
+  targetRef:
+    apiVersion: apps/v1
+    kind: Deployment
+    name: model-serving-{{ .name }}
+  service:
+    port: 80
+  analysis:
+    interval: 1m
+    threshold: 10
+    iterations: 10
+    metrics:
+      - name: request-success-rate
+        template: success-rate
+      - name: request-duration
+        template: request-duration
+  webhooks:
+    - name: safety-check
+      type: pre-rollout
+      url: "{{ .safety_monitor_check_url | default \"http://safety-monitor.aegis.svc:8080/evaluate\" }}"
+      timeout: 10s
+
*** End Patch
*** Begin Patch
*** Add File:argo/promotion/evidence_and_register_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: promotion-evidence-
+  namespace: aegis
+spec:
+  entrypoint: promote-and-register
+  templates:
+    - name: promote-and-register
+      inputs:
+        parameters:
+          - name: manifest-s3
+      steps:
+        - - name: download-manifest
+            template: download-manifest
+            arguments:
+              parameters:
+                - name: manifest-s3
+                  value: "{{inputs.parameters.manifest-s3}}"
+        - - name: verify-signature
+            template: verify-signature
+            arguments:
+              parameters:
+                - name: manifest
+                  value: "{{steps.download-manifest.outputs.parameters.manifest}}"
+        - - name: bundle-evidence
+            template: bundle-evidence
+            arguments:
+              parameters:
+                - name: manifest
+                  value: "{{steps.download-manifest.outputs.parameters.manifest}}"
+        - - name: register-artifact
+            template: register-artifact
+            arguments:
+              parameters:
+                - name: manifest
+                  value: "{{steps.download-manifest.outputs.parameters.manifest}}"
+
+    - name: download-manifest
+      inputs:
+        parameters:
+          - name: manifest-s3
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install boto3 || true; python3 - <<PY
+import boto3,sys,json,os
+src="{{inputs.parameters.manifest-s3}}"
+parts=src[5:].split('/',1)
+bucket,key=parts[0],parts[1]
+boto3.client('s3').download_file(bucket,key,'/tmp/manifest.json')
+print('/tmp/manifest.json')
+PY
+      outputs:
+        parameters:
+          - name: manifest
+            valueFrom:
+              path: /tmp/manifest.json
+
+    - name: verify-signature
+      inputs:
+        parameters:
+          - name: manifest
+      container:
+        image: sigstore/cosign:latest
+        command: [sh,-c]
+        args:
+          - echo "Verifying signature for {{inputs.parameters.manifest}}"; sleep 1
+
+    - name: bundle-evidence
+      inputs:
+        parameters:
+          - name: manifest
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install boto3 || true; python3 scripts/evidence/attach_and_sign.py --manifest "{{inputs.parameters.manifest}}" --out /tmp/evidence.tgz || true; ls -l /tmp/evidence.tgz
+
+    - name: register-artifact
+      inputs:
+        parameters:
+          - name: manifest
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install pymongo boto3 || true; python3 scripts/register/register_artifact.py --manifest "{{inputs.parameters.manifest}}"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/register/register_artifact.py
+#!/usr/bin/env python3
+"""
+Register artifact metadata and lineage into MongoDB.
+Expected env: MONGO_URI, EVIDENCE_BUCKET
+"""
+import argparse, json, os, time
+from pymongo import MongoClient
+
+def register(manifest_path):
+    m = json.load(open(manifest_path))
+    mongo = os.environ.get("MONGO_URI","mongodb://localhost:27017")
+    client = MongoClient(mongo)
+    db = client['aegis']
+    artifact = {
+        "artifact_id": m.get("artifact")+"-"+str(int(time.time())),
+        "manifest": m,
+        "signed": False,
+        "registered_at": time.time(),
+        "evidence": []
+    }
+    # best-effort check for cosign signature by presence of .sig or Rekor (this is a stub)
+    artifact["signed"] = True if os.environ.get("COSIGN_KMS_KEY_ARN") else False
+    # attach evidence location if EVIDENCE_BUCKET present (attach_and_sign pushes)
+    eb = os.environ.get("EVIDENCE_BUCKET")
+    if eb:
+        artifact["evidence"].append(f"s3://{eb}/evidence/")
+    db.artifacts.insert_one(artifact)
+    print("Registered artifact", artifact["artifact_id"])
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--manifest", required=True)
+    args = p.parse_args()
+    register(args.manifest)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:gatekeeper/constraints/deny_direct_couchbase_writes_template.yaml
+apiVersion: templates.gatekeeper.sh/v1beta1
+kind: ConstraintTemplate
+metadata:
+  name: k8sdeny_direct_couchbase_writes
+spec:
+  crd:
+    spec:
+      names:
+        kind: DenyDirectCouchbaseWrites
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package k8sdeny_direct_couchbase_writes
+
+        violation[{"msg": msg}] {
+          input.review.object.kind == "Pod"
+          containers := input.review.object.spec.containers
+          some i
+          c := containers[i]
+          # deny if container env contains COUCHBASE_WRITE=true unless pod has label allow-couchbase-write=true
+          has_env := c.env[_].name == "COUCHBASE_WRITE"
+          has_env
+          c.env[_].value == "true"
+          not input.review.object.metadata.labels["allow-couchbase-write"] == "true"
+          msg := sprintf("Direct writes to Couchbase are disallowed for pod %v", [input.review.object.metadata.name])
+        }
+
*** End Patch
*** Begin Patch
*** Add File:gatekeeper/constraints/deny_direct_couchbase_writes.yaml
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: DenyDirectCouchbaseWrites
+metadata:
+  name: deny-couchbase-writes
+spec:
+  enforcementAction: dryrun
+  match:
+    kinds:
+      - apiGroups: [""]
+        kinds: ["Pod"]
+    namespaces:
+      - "aegis"
+  parameters: {}
+
+#
+# NOTE: enforcementAction is set to dryrun initially. After reviewing Gatekeeper audit results,
+# change enforcementAction to "deny" to enforce canonical ownership.
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/kpi_exporter/app.py
+#!/usr/bin/env python3
+"""
+Simple KPI exporter that reads MongoDB and S3 evidence to expose Prometheus metrics:
+- aegis_lead_time_seconds (histogram/summary)
+- aegis_percent_signed (gauge 0..1)
+- aegis_model_drift_rate (gauge placeholder)
+- aegis_canary_rollback_rate (gauge placeholder)
+- aegis_time_to_restore_seconds (gauge)
+
+This is a minimal example — adapt to your data schemas.
+"""
+from prometheus_client import start_http_server, Gauge, Summary
+import time, os, json
+from pymongo import MongoClient
+import boto3
+
+MONGO_URI = os.environ.get("MONGO_URI", "mongodb://localhost:27017")
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+
+lead_time = Summary('aegis_lead_time_seconds', 'Time from build to register')
+percent_signed = Gauge('aegis_percent_signed', 'Percent artifacts with signature (0..1)')
+model_drift = Gauge('aegis_model_drift_rate', 'Model drift rate (fraction recent models flagged drift)')
+canary_rollbacks = Gauge('aegis_canary_rollback_rate', 'Canary rollback rate per day')
+time_to_restore = Gauge('aegis_time_to_restore_seconds', 'Time to restore measured from evidence')
+
+def compute_metrics():
+    client = MongoClient(MONGO_URI)
+    db = client['aegis']
+    artifacts = list(db.artifacts.find({"registered_at":{"$exists":True}}))
+    if not artifacts:
+        percent_signed.set(0.0)
+        model_drift.set(0.0)
+        canary_rollbacks.set(0.0)
+        time_to_restore.set(0.0)
+        return
+    total = len(artifacts)
+    signed = len([a for a in artifacts if a.get("signed")])
+    percent_signed.set(float(signed)/total)
+    # lead time: placeholder use registered_at - manifest.provenance.build_time
+    times = []
+    for a in artifacts:
+        m = a.get("manifest") or a.get("manifest",{})
+        btime = m.get("provenance",{}).get("build_time")
+        rtime = a.get("registered_at")
+        if btime and rtime:
+            times.append(float(rtime)-float(btime))
+    if times:
+        avg = sum(times)/len(times)
+        lead_time.observe(avg)
+    # drift: count entries in collection 'drift' if present indicating drift events
+    drift_count = db.get_collection("drift").count_documents({"flagged":True}) if "drift" in db.list_collection_names() else 0
+    recent_count = db.get_collection("drift").count_documents({"timestamp":{"$gt": time.time()-7*24*3600}}) if "drift" in db.list_collection_names() else 0
+    model_drift.set(float(recent_count)/(total if total>0 else 1))
+    # canary rollback rate: look at 'canary_events' collection
+    rollbacks = db.get_collection("canary_events").count_documents({"event":"rollback","timestamp":{"$gt": time.time()-24*3600}}) if "canary_events" in db.list_collection_names() else 0
+    canary_rollbacks.set(rollbacks)
+    # time_to_restore: parse evidence proofs from S3 (simplified)
+    if EVIDENCE_BUCKET:
+        s3 = boto3.client("s3")
+        objs = s3.list_objects_v2(Bucket=EVIDENCE_BUCKET, Prefix="restore-proofs/")
+        if objs.get("Contents"):
+            # use latest proof (placeholder)
+            latest = sorted(objs["Contents"], key=lambda x: x["LastModified"])[-1]
+            # For demo, set time_to_restore to a configured placeholder (real computation requires parsing stored proofs)
+            time_to_restore.set(3600.0)
+        else:
+            time_to_restore.set(0.0)
+    else:
+        time_to_restore.set(0.0)
+
+def main():
+    port = int(os.environ.get("METRICS_PORT", "9102"))
+    start_http_server(port)
+    print("KPI exporter listening on", port)
+    while True:
+        try:
+            compute_metrics()
+        except Exception as e:
+            print("metric compute error:", e)
+        time.sleep(30)
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/kpi_exporter/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-kpi-exporter
+  namespace: monitoring
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-kpi-exporter
+  template:
+    metadata:
+      labels:
+        app: aegis-kpi-exporter
+    spec:
+      containers:
+        - name: exporter
+          image: registry.example.com/aegis/kpi-exporter:latest
+          env:
+            - name: MONGO_URI
+              valueFrom:
+                secretKeyRef:
+                  name: mongodb-connection
+                  key: MONGO_URI
+            - name: EVIDENCE_BUCKET
+              value: "{{ EVIDENCE_BUCKET }}"
+          ports:
+            - containerPort: 9102
+
*** End Patch
*** Begin Patch
*** Add File:dashboards/grafana/kpi_dashboard.json
+{
+  "dashboard": {
+    "id": null,
+    "title": "Aegis KPIs",
+    "panels": [
+      {
+        "type": "graph",
+        "title": "Lead Time (model -> register)",
+        "targets": [{"expr": "aegis_lead_time_seconds"}],
+        "gridPos": {"x":0,"y":0,"w":12,"h":6}
+      },
+      {
+        "type": "gauge",
+        "title": "% Artifacts Signed",
+        "targets": [{"expr": "aegis_percent_signed"}],
+        "gridPos": {"x":12,"y":0,"w":12,"h":4}
+      },
+      {
+        "type": "stat",
+        "title": "Model Drift Rate",
+        "targets": [{"expr": "aegis_model_drift_rate"}],
+        "gridPos": {"x":12,"y":4,"w":6,"h":4}
+      },
+      {
+        "type": "stat",
+        "title": "Canary Rollbacks (24h)",
+        "targets": [{"expr": "aegis_canary_rollback_rate"}],
+        "gridPos": {"x":18,"y":4,"w":6,"h":4}
+      }
+    ]
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:docs/DEVELOPER_EXPERIENCE.md
+# Developer Experience (DX) - Thin layer for data scientists
+
+Principles
+- Keep CLI & APIs minimal and opinionated: train -> package -> sign -> promote.
+- Provide templates for serving, canary, metrics and dashboards that "just work".
+- Automate evidence & lineage capture in the promotion workflow.
+
+What to use immediately
+- dev/cli/aegis_cli.py: local CLI for dev flows. Add to PATH or turn into a GitHub Action step.
+- dev/templates/serving/: Turnkey serving + Flagger canary templates. Fill image and name values and apply.
+- Argo promotion: argo/promotion/evidence_and_register_workflow.yaml automatically bundles evidence and writes a registry entry in MongoDB.
+- Registry: registry/api exposes artifacts and evidence pointers for developers and auditors.
+
+Best practices
+- Use MongoDB (MONGO_URI) as canonical metadata source. Only the change-stream consumer or controlled services should write to Couchbase.
+- Use Gatekeeper constraint deny_direct_couchbase_writes (dryrun initially) to monitor potential violations.
+- Add a small CI step to call aegis_cli.py sign and aegis_cli.py promote after build to keep flow simple for teams.
+
*** End Patch
*** Begin Patch
*** Add File:docs/MANAGED_SERVICES_DECISION.md
+# Managed Services Decision & Migration Paths
+
+Recommendation
+- Favor managed services for high-op-ex components: MongoDB Atlas, Amazon RDS (for Rekor), Amazon MSK / Confluent for Kafka, Couchbase Capella for Couchbase.
+
+Migration patterns
+- Dual-write or ETL: during migration, run dual writes for a period and validate parity.
+- VPC peering & Private endpoints: ensure private networking and IP allowlists.
+- Backup parity: export managed backups into EVIDENCE_BUCKET periodically to preserve immutable audit trail.
+
+Automation
+- Use Terraform modules (examples provided) to provision managed resources and capture outputs into Kubernetes Secrets or Vault.
+
*** End Patch
*** End Patch
