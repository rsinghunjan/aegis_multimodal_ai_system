*** Begin Patch
*** Add File:mcp/README.md
+# Model Control Plane (MCP) for Aegis
+
+This directory implements a three-tier Model Control Plane:
+
+- Option A (Lightweight MCP API + UI): FastAPI service to inspect MLflow models, trigger promotions, run safety/sign checks, request human approvals, and create ModelDeployment CRD objects to kick off rollouts.
+- Option B (Rollout Controller): Kubernetes operator (Kopf-based) that watches ModelDeployment CRD and performs staged canary rollouts, automatic verification, and rollback on failures.
+- Option C (Retrain Automation): The operator can also trigger retrain jobs when drift is detected (or on schedule) and create new model versions, then open approval requests.
+
+This patch adds:
+- MCP API service (mcp/api)
+- Lightweight web UI (mcp/ui) — static single-page app
+- ModelDeployment CRD and Kopf operator (mcp/operator)
+- Kubernetes manifests for service and operator
+- Runbook with operator steps for deploying and wiring to MLflow, cosign, human approval API, Gatekeeper, and audit.
+
+Notes:
+- No secrets are included. Use ExternalSecrets / SecretsManager to inject MLFLOW_TRACKING_URI, COSIGN_KMS_ARN, HUMAN_APPROVAL_URL, K8S access credentials, etc.
+- The code is intentionally pragmatic and contains placeholders where you must wire your specific enforcement and verification logic (e.g., exact eval scripts, cosign KMS usage, S3 evidence keys).
+
*** End Patch
*** Begin Patch
*** Add File:mcp/api/requirements.txt
+fastapi
+uvicorn[standard]
+mlflow
+boto3
+requests
+pydantic
+python-dotenv
*** End Patch
*** Begin Patch
*** Add File:mcp/api/mcp_service.py
+#!/usr/bin/env python3
+"""
+MCP API service (FastAPI)
+
+Endpoints:
+ - GET /models : list MLflow registered models
+ - GET /models/{name} : model details & model_card link if present
+ - POST /promote : request promotion of a model version to a target namespace (creates ModelDeployment CRD)
+ - POST /verify-signature : best-effort cosign verify wrapper (exec cosign CLI; placeholder)
+ - POST /trigger-eval : run safety/eval harness externally (placeholder to call CI or local script)
+ - POST /request-approval : call Human Approval API to create approval and return request_id
+
+The promote flow orchestrates:
+ 1) verify signature (cosign)
+ 2) run eval harness (hallucination/fairness/PII)
+ 3) request human approval (if required)
+ 4) create ModelDeployment CRD to instruct the operator to rollout
+"""
+import os
+import subprocess
+import json
+import time
+from typing import Optional
+from pydantic import BaseModel
+from fastapi import FastAPI, HTTPException
+import mlflow
+import requests
+import kubernetes
+from kubernetes import client, config
+
+MLFLOW_TRACKING_URI = os.environ.get("MLFLOW_TRACKING_URI", "")
+HUMAN_APPROVAL_URL = os.environ.get("HUMAN_APPROVAL_URL", "http://human-approval.aegis.svc.cluster.local")
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "REPLACE_WITH_EVIDENCE_BUCKET")
+COSIGN_VERIFY_CMD = os.environ.get("COSIGN_VERIFY_CMD", "cosign verify")  # placeholder
+
+if MLFLOW_TRACKING_URI:
+    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
+
+app = FastAPI(title="Aegis Model Control Plane (MCP)")
+
+def k8s_client():
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    return client.CustomObjectsApi()
+
+class PromoteReq(BaseModel):
+    model_name: str
+    model_version: str
+    target_namespace: str = "aegis"
+    rollout_strategy: Optional[str] = "canary"  # canary / bluegreen / immediate
+    canary_percent: Optional[int] = 10
+    require_approval: Optional[bool] = True
+    run_id: Optional[str] = None
+
+@app.get("/models")
+def list_models():
+    try:
+        client = mlflow.tracking.MlflowClient()
+        res = client.list_registered_models()
+        out = []
+        for m in res:
+            out.append({"name": m.name, "latest_versions": [v.version for v in m.latest_versions]})
+        return out
+    except Exception as e:
+        raise HTTPException(status_code=500, detail=str(e))
+
+@app.get("/models/{name}")
+def get_model(name: str):
+    try:
+        client = mlflow.tracking.MlflowClient()
+        models = client.get_registered_model(name)
+        return models.to_json()
+    except Exception as e:
+        raise HTTPException(status_code=404, detail=str(e))
+
+@app.post("/verify-signature")
+def verify_signature(artifact_uri: str):
+    """
+    Best-effort cosign verify. artifact_uri can be a local path or OCI reference.
+    Operators should replace this with KMS-backed cosign verification.
+    """
+    # Placeholder: call cosign verify and return output
+    try:
+        cmd = f"{COSIGN_VERIFY_CMD} {artifact_uri}"
+        proc = subprocess.run(cmd.split(), capture_output=True, text=True, check=False)
+        return {"returncode": proc.returncode, "stdout": proc.stdout, "stderr": proc.stderr}
+    except Exception as e:
+        raise HTTPException(status_code=500, detail=str(e))
+
+@app.post("/trigger-eval")
+def trigger_eval(run_id: str, eval_suite: str = "hallucination"):
+    """
+    Trigger an eval harness. In production, this would invoke CI job or a job runner.
+    Here we call a configured HTTP evaluation endpoint or run a local script (placeholder).
+    """
+    eval_url = os.environ.get("EVAL_SERVICE_URL", "")
+    if eval_url:
+        r = requests.post(f"{eval_url}/run", json={"run_id": run_id, "suite": eval_suite}, timeout=60)
+        return {"status": r.status_code, "resp": r.text}
+    # fallback: pretend success
+    time.sleep(1)
+    return {"status": "ok", "note": "eval_stub"}
+
+@app.post("/request-approval")
+def request_approval(payload: dict):
+    """
+    Proxy to Human Approval API. Returns request_id.
+    """
+    try:
+        r = requests.post(f"{HUMAN_APPROVAL_URL}/request", json=payload, timeout=10)
+        r.raise_for_status()
+        return r.json()
+    except Exception as e:
+        raise HTTPException(status_code=500, detail=str(e))
+
+@app.post("/promote")
+def promote(req: PromoteReq):
+    """
+    High-level promotion orchestration:
+     1) Verify artifact signature (if model has artifact_uri in MLflow)
+     2) Run eval(s) — hallucination/fairness/PII
+     3) If require_approval -> create approval request
+     4) Create a ModelDeployment CRD describing the rollout for the operator
+    """
+    client_ml = mlflow.tracking.MlflowClient()
+    try:
+        rm = client_ml.get_registered_model(req.model_name)
+    except Exception as e:
+        raise HTTPException(status_code=404, detail=f"model not found: {e}")
+    # Resolve model version run info
+    try:
+        mv = client_ml.get_model_version(req.model_name, req.model_version)
+    except Exception as e:
+        raise HTTPException(status_code=404, detail=f"model version not found: {e}")
+    artifact_uri = mv.source
+    # 1) Verify signature (best-effort)
+    sig_res = verify_signature(artifact_uri)
+    if sig_res.get("returncode", 1) != 0:
+        # In production you'd fail; here we warn
+        return {"status": "signature_failed", "details": sig_res}
+    # 2) Trigger eval suite(s)
+    if req.run_id:
+        eval_res = trigger_eval(req.run_id)
+    else:
+        eval_res = {"note": "no run_id provided; eval skipped"}
+    # 3) Request human approval if required
+    approval = None
+    if req.require_approval:
+        app_payload = {"model_name": req.model_name, "model_version": req.model_version, "details": {"eval": eval_res}}
+        approval = request_approval(app_payload)
+        # Here we expect approval to be created; operator/UI will wait for approval to be granted before proceeding
+    # 4) Create ModelDeployment CRD for operator
+    body = {
+        "apiVersion": "mcp.aegis/v1",
+        "kind": "ModelDeployment",
+        "metadata": {
+            "name": f"{req.model_name.replace('/', '-')}-{req.model_version}",
+            "namespace": req.target_namespace,
+            "labels": {"aegis.model": req.model_name, "aegis.version": req.model_version}
+        },
+        "spec": {
+            "model_name": req.model_name,
+            "model_version": req.model_version,
+            "artifact_uri": artifact_uri,
+            "rolloutStrategy": req.rollout_strategy,
+            "canaryPercent": req.canary_percent,
+            "approvalRequest": approval
+        }
+    }
+    try:
+        api = k8s_client()
+        api.create_namespaced_custom_object(group="mcp.aegis", version="v1", namespace=req.target_namespace, plural="modeldeployments", body=body)
+        return {"status": "created", "crd": body}
+    except Exception as e:
+        raise HTTPException(status_code=500, detail=str(e))
+
+if __name__ == "__main__":
+    import uvicorn
+    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("MCP_PORT", "8089")))
+
*** End Patch
*** Begin Patch
*** Add File:mcp/ui/index.html
+<!doctype html>
+<html>
+<head>
+  <meta charset="utf-8"/>
+  <title>Aegis MCP UI (Demo)</title>
+  <style>body{font-family:Arial,Helvetica,sans-serif;margin:24px}pre{background:#f7f7f7;padding:8px}</style>
+</head>
+<body>
+  <h1>Aegis Model Control Plane (Demo UI)</h1>
+  <div>
+    <button onclick="loadModels()">Refresh Models</button>
+    <div id="models"></div>
+  </div>
+  <script>
+    const API = window.__MCP_API__ || "http://localhost:8089";
+    async function loadModels(){
+      const r = await fetch(`${API}/models`);
+      const json = await r.json();
+      const div = document.getElementById('models');
+      div.innerHTML = '';
+      json.forEach(m => {
+        const el = document.createElement('div');
+        el.innerHTML = `<h3>${m.name}</h3><pre>${JSON.stringify(m.latest_versions,null,2)}</pre>
+          <button onclick="promote('${m.name}','1')">Promote v1 (demo)</button>`;
+        div.appendChild(el);
+      })
+    }
+    async function promote(name, version){
+      const payload = {model_name: name, model_version: version, require_approval: true, run_id: "demo-run-001"};
+      const r = await fetch(`${API}/promote`, {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload)});
+      const j = await r.json();
+      alert(JSON.stringify(j));
+    }
+    loadModels();
+  </script>
+</body>
+</html>
*** End Patch
*** Begin Patch
*** Add File:mcp/crds/modeldeployment.yaml
+apiVersion: apiextensions.k8s.io/v1
+kind: CustomResourceDefinition
+metadata:
+  name: modeldeployments.mcp.aegis
+spec:
+  group: mcp.aegis
+  names:
+    kind: ModelDeployment
+    plural: modeldeployments
+    singular: modeldeployment
+  scope: Namespaced
+  versions:
+    - name: v1
+      served: true
+      storage: true
+      schema:
+        openAPIV3Schema:
+          type: object
+          properties:
+            spec:
+              type: object
+              properties:
+                model_name:
+                  type: string
+                model_version:
+                  type: string
+                artifact_uri:
+                  type: string
+                rolloutStrategy:
+                  type: string
+                canaryPercent:
+                  type: integer
+                approvalRequest:
+                  type: object
+                retrainOnDrift:
+                  type: boolean
+      subresources:
+        status: {}
+
*** End Patch
*** Begin Patch
*** Add File:mcp/operator/requirements.txt
+kopf
+kubernetes
+requests
+mlflow
+boto3
+python-dotenv
*** End Patch
*** Begin Patch
*** Add File:mcp/operator/operator.py
+#!/usr/bin/env python3
+"""
+Kopf-based operator for ModelDeployment CRD
+
+Responsibilities:
+ - Watch ModelDeployment objects and perform staged rollouts (canary -> promote)
+ - Verify post-rollout health via optional verification hooks (call evaluator or check metrics)
+ - Rollback on verification failure
+ - Optionally trigger retrain jobs when drift detected (placeholder)
+
+This is intentionally simple: adapt to your rollout platform (Istio/Flagger/KNativeRollout) for production.
+"""
+import os
+import time
+import kopf
+import kubernetes
+import requests
+import mlflow
+from kubernetes import client, config
+
+MLFLOW_TRACKING_URI = os.environ.get("MLFLOW_TRACKING_URI", "")
+VERIFY_ENDPOINT = os.environ.get("MCP_VERIFY_ENDPOINT", "http://carbon-guard.aegis.svc.cluster.local/verify")  # placeholder
+
+if MLFLOW_TRACKING_URI:
+    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
+
+def k8s_apps_client():
+    try:
+        config.load_incluster_config()
+    except:
+        config.load_kube_config()
+    return client.AppsV1Api()
+
+@kopf.on.create('mcp.aegis', 'v1', 'modeldeployments')
+def create_fn(spec, name, namespace, logger, **kwargs):
+    """
+    On creation, perform rollout according to spec
+    """
+    model_name = spec.get('model_name')
+    model_version = spec.get('model_version')
+    artifact_uri = spec.get('artifact_uri')
+    strategy = spec.get('rolloutStrategy', 'canary')
+    canary_pct = int(spec.get('canaryPercent', 10))
+    logger.info(f"Starting rollout for {model_name}:{model_version} strategy={strategy}")
+
+    # This operator assumes a Deployment named after model_name exists in target namespace.
+    deploy_name = model_name.replace('/', '-')
+    apps = k8s_apps_client()
+    try:
+        dep = apps.read_namespaced_deployment(name=deploy_name, namespace=namespace)
+    except client.exceptions.ApiException as e:
+        logger.error(f"Deployment {deploy_name} not found in {namespace}: {e}")
+        raise kopf.TemporaryError(f"Deployment not found: {deploy_name}", delay=30)
+
+    # Determine new image from artifact_uri (user must store image or model->serving mapping)
+    # Placeholder: artifact_uri contains image tag: e.g., docker.io/org/model:version
+    new_image = artifact_uri  # operators should map artifact to serving image
+
+    if strategy == "immediate":
+        # Patch deployment image and finish
+        for c in dep.spec.template.spec.containers:
+            c.image = new_image
+        apps.patch_namespaced_deployment(name=deploy_name, namespace=namespace, body=dep)
+        logger.info("Immediate rollout applied")
+        return {"status": "rolled_out"}
+
+    if strategy == "canary":
+        # Implement a simple canary by scaling up an extra Deployment or using a label-based pod.
+        # For simplicity, we will patch image and scale gradually by adjusting replicas proportionally.
+        current_replicas = dep.spec.replicas or 1
+        canary_replicas = max(1, int((canary_pct/100.0) * current_replicas))
+        logger.info(f"Performing canary: setting canary replicas={canary_replicas} of total {current_replicas}")
+
+        # Create a temporary canary deployment
+        canary_name = f"{deploy_name}-canary-{int(time.time())}"
+        canary_dep = client.V1Deployment(
+            metadata=client.V1ObjectMeta(name=canary_name, namespace=namespace, labels={"aegis.canary": "true"}),
+            spec=client.V1DeploymentSpec(
+                replicas=canary_replicas,
+                selector=dep.spec.selector,
+                template=dep.spec.template
+            )
+        )
+        # set canary image
+        for c in canary_dep.spec.template.spec.containers:
+            c.image = new_image
+        apps.create_namespaced_deployment(namespace=namespace, body=canary_dep)
+        logger.info(f"Canary {canary_name} created")
+
+        # Wait and verify (placeholder: call external verify endpoint)
+        verify_ok = False
+        try:
+            for attempt in range(6):
+                logger.info("Waiting for canary to stabilize...")
+                time.sleep(10)
+                # Call verification endpoint with canary id (operator-specific)
+                try:
+                    r = requests.post(VERIFY_ENDPOINT, json={"canary": canary_name}, timeout=5)
+                    if r.status_code == 200 and r.json().get("ok", True):
+                        verify_ok = True
+                        break
+                except Exception:
+                    pass
+            if not verify_ok:
+                raise Exception("canary verification failed")
+        except Exception as e:
+            logger.error(f"Canary failed: {e}. Rolling back and deleting canary")
+            try:
+                apps.delete_namespaced_deployment(name=canary_name, namespace=namespace)
+            except Exception:
+                pass
+            raise kopf.PermanentError("Canary failed; rolled back")
+
+        # Promote: patch main deployment image to new_image
+        logger.info("Canary OK. Promoting new image to main deployment.")
+        for c in dep.spec.template.spec.containers:
+            c.image = new_image
+        apps.patch_namespaced_deployment(name=deploy_name, namespace=namespace, body=dep)
+        # Delete canary
+        try:
+            apps.delete_namespaced_deployment(name=canary_name, namespace=namespace)
+        except Exception:
+            logger.warn("Failed to delete canary deployment; manual cleanup may be needed")
+        logger.info("Promotion complete")
+        return {"status": "promoted"}
+
+    # fallback
+    logger.warn("Unknown rollout strategy; no action taken")
+    return {"status": "no_action"}
+
+@kopf.timer('mcp.aegis', 'v1', 'modeldeployments', interval=300)
+def monitor_deployments(spec, name, namespace, status, logger, **kwargs):
+    # Periodic checks: e.g., detect drift via metrics or log anomalies
+    # Placeholder: if spec.retrainOnDrift true and some condition met, create a retrain Job.
+    retrain = spec.get("retrainOnDrift", False)
+    if retrain:
+        logger.info(f"Drift configured for {name}; operator would trigger retrain flow (placeholder).")
+
*** End Patch
*** Begin Patch
*** Add File:mcp/manifests/mcp-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-mcp
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: aegis-mcp
+  template:
+    metadata:
+      labels:
+        app: aegis-mcp
+    spec:
+      serviceAccountName: aegis-mcp-sa
+      containers:
+        - name: mcp
+          image: ghcr.io/yourorg/aegis-mcp:latest
+          env:
+            - name: MLFLOW_TRACKING_URI
+              value: "REPLACE_MLFLOW_TRACKING_URI"
+            - name: HUMAN_APPROVAL_URL
+              value: "REPLACE_HUMAN_APPROVAL_URL"
+            - name: EVIDENCE_BUCKET
+              value: "REPLACE_EVIDENCE_BUCKET"
+          ports:
+            - containerPort: 8089
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-mcp
+  namespace: aegis
+spec:
+  selector:
+    app: aegis-mcp
+  ports:
+    - port: 8089
+      targetPort: 8089
+
*** End Patch
*** Begin Patch
*** Add File:mcp/manifests/operator-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-mcp-operator
+  namespace: aegis
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-mcp-operator
+  template:
+    metadata:
+      labels:
+        app: aegis-mcp-operator
+    spec:
+      serviceAccountName: aegis-mcp-operator-sa
+      containers:
+        - name: operator
+          image: ghcr.io/yourorg/aegis-mcp-operator:latest
+          env:
+            - name: MLFLOW_TRACKING_URI
+              value: "REPLACE_MLFLOW_TRACKING_URI"
+            - name: MCP_VERIFY_ENDPOINT
+              value: "REPLACE_VERIFY_ENDPOINT"
+          securityContext:
+            runAsUser: 1000
+            runAsNonRoot: true
+---
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: aegis-mcp-operator-sa
+  namespace: aegis
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: aegis-mcp-operator-role
+rules:
+  - apiGroups: ["", "apps", "batch"]
+    resources: ["pods", "deployments", "services", "jobs"]
+    verbs: ["get", "list", "watch", "create", "delete", "patch", "update"]
+  - apiGroups: ["mcp.aegis"]
+    resources: ["modeldeployments"]
+    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRoleBinding
+metadata:
+  name: aegis-mcp-operator-binding
+roleRef:
+  apiGroup: rbac.authorization.k8s.io
+  kind: ClusterRole
+  name: aegis-mcp-operator-role
+subjects:
+  - kind: ServiceAccount
+    name: aegis-mcp-operator-sa
+    namespace: aegis
+
*** End Patch
*** Begin Patch
*** Add File:mcp/runbooks/mcp_runbook.md
+# MCP Runbook (Aegis) — deploy & operate
+
+Prereqs:
+- MLflow server reachable and populated with models/versions.
+- Human Approval API deployed (see governance/human_approval).
+- Cosign KMS and Rekor configured (COSIGN_KMS_ARN, REKOR_URL) and available via ExternalSecrets.
+- Namespace `aegis` exists and operator has cluster-level RBAC above.
+
+Deploy steps:
+1. Apply CRD:
+   kubectl apply -f mcp/crds/modeldeployment.yaml
+
+2. Deploy MCP service:
+   - Build & push image for mcp/api/mcp_service.py (image ghcr.io/yourorg/aegis-mcp:latest)
+   - kubectl apply -f mcp/manifests/mcp-deployment.yaml
+
+3. Deploy operator:
+   - Build & push image for mcp/operator/operator.py with Kopf entrypoint (ghcr.io/yourorg/aegis-mcp-operator:latest)
+   - kubectl apply -f mcp/manifests/operator-deployment.yaml
+
+4. Wire secrets:
+   - Use ExternalSecrets to inject MLFLOW_TRACKING_URI, HUMAN_APPROVAL_URL, COSIGN KMS ARNs, EVIDENCE_BUCKET
+
+5. Test promote flow:
+   - Use MCP UI (mcp/ui/index.html) or call POST /promote to create a ModelDeployment CRD.
+   - Operator will perform canary, call verification endpoint, promote or rollback.
+
+6. Post-deploy verification:
+   - Check operator logs (kubectl logs -n aegis deployment/aegis-mcp-operator)
+   - Check CRD status: kubectl get modeldeployments -n aegis -o yaml
+   - Validate promoted deployment image & rollout via kubectl rollout status
+
+Notes on production hardening:
+- Replace placeholder verification with a robust eval pipeline or integration with Flagger/Istio for traffic splitting.
+- Integrate Gatekeeper constraints to ensure only cosign-signed artifacts and model_card annotations are used.
+- Add metrics & Prometheus hooks in operator to emit rollout success/fail counts.
+- Secure MCP API with authentication (OIDC) and network policies to restrict access.
+
*** End Patch
*** End Patch
