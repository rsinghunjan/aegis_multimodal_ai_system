*** Begin Patch
*** Add File:mcp/schema.json
+{
+  "$schema": "http://json-schema.org/draft-07/schema#",
+  "title": "Model Context Protocol (MCP) Schema",
+  "description": "Canonical MCP document recording model context, provenance, governance and operational metadata.",
+  "type": "object",
+  "required": ["model_id","model_version","artifact_uri","mlflow_run_id","signed_by","signature","rekor_entry","approved_by","approved_at"],
+  "properties": {
+    "model_id": {"type":"string"},
+    "model_version": {"type":"string"},
+    "artifact_uri": {"type":"string", "format":"uri"},
+    "image_uri": {"type":"string", "format":"uri"},
+    "mlflow_run_id": {"type":"string"},
+    "dataset_snapshot_id": {"type":"string"},
+    "training_commit": {"type":"string"},
+    "environment": {
+      "type":"object",
+      "properties": {
+        "container_image": {"type":"string"},
+        "deps_hash": {"type":"string"},
+        "runtime": {"type":"string"}
+      }
+    },
+    "features": {
+      "type":"object",
+      "description":"Links to feature store snapshots / lineage"
+    },
+    "validation": {
+      "type":"object",
+      "properties": {
+        "metrics": {"type":"object"},
+        "thresholds": {"type":"object"},
+        "validation_time": {"type":"string", "format":"date-time"}
+      }
+    },
+    "explainability": {
+      "type":"object",
+      "properties": {
+        "model_card_uri": {"type":"string"},
+        "shap_uri": {"type":"string"}
+      }
+    },
+    "governance": {
+      "type":"object",
+      "properties": {
+        "approved_by": {"type":"string"},
+        "approved_at": {"type":"string", "format":"date-time"},
+        "approval_notes": {"type":"string"}
+      }
+    },
+    "operational": {
+      "type":"object",
+      "properties": {
+        "sli": {"type":"object"},
+        "canary_policy": {"type":"object"}
+      }
+    },
+    "compliance": {
+      "type":"object",
+      "properties": {
+        "export_control": {"type":"string"},
+        "vendor_contract_id": {"type":"string"}
+      }
+    },
+    "signed_by": {"type":"string"},
+    "signature": {"type":"string"},
+    "rekor_entry": {"type":"string"}
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:production/policy/mcp_issue.py
+#!/usr/bin/env python3
+"""
+MCP issuer:
+ - Collects model context from MLflow, model-card API, validation output and artifact metadata
+ - Builds MCP JSON, validates against schema, signs it (HSM via robust_sign or cosign fallback),
+   uploads MCP JSON to S3 and registers Rekor entry if available.
+
+Usage:
+  python3 production/policy/mcp_issue.py --model-id mymodel --model-version v1 --artifact /path/to/model.pkl --mlflow-run <run_id> --out /tmp/mcp.json
+"""
+import argparse, json, os, subprocess, tempfile, boto3
+from jsonschema import validate, ValidationError
+
+SCHEMA_PATH = "mcp/schema.json"
+
+def load_schema():
+    with open(SCHEMA_PATH) as f:
+        return json.load(f)
+
+def collect_context(args):
+    m = {
+        "model_id": args.model_id,
+        "model_version": args.model_version,
+        "artifact_uri": args.artifact_s3_uri or args.artifact,
+        "image_uri": args.image_uri or "",
+        "mlflow_run_id": args.mlflow_run_id or "",
+        "dataset_snapshot_id": args.dataset_snapshot_id or "",
+        "training_commit": args.training_commit or "",
+        "environment": {"container_image": args.image_uri or "", "deps_hash": args.deps_hash or "", "runtime": "python"},
+        "features": {},
+        "validation": args.validation or {},
+        "explainability": args.explainability or {},
+        "governance": {"approved_by": args.approved_by or "", "approved_at": args.approved_at or "", "approval_notes": args.approval_notes or ""},
+        "operational": args.operational or {},
+        "compliance": args.compliance or {},
+    }
+    return m
+
+def sign_payload_hsm(payload_bytes):
+    # Try HSM helper
+    try:
+        from quantum.crypto.hsm_helper_vendor import robust_sign
+        sig_b64 = robust_sign(os.environ.get("PKCS11_MODULE","/opt/vendor/lib/pkcs11.so"), os.environ.get("PKCS11_SLOT","0"), os.environ.get("PKCS11_PIN",""), os.environ.get("PKCS11_KEYLABEL","pqkey"), payload_bytes)
+        return sig_b64
+    except Exception:
+        return None
+
+def sign_with_cosign(blob_path, signature_out):
+    cosign_key = os.environ.get("COSIGN_KEY")
+    if not cosign_key:
+        raise RuntimeError("COSIGN_KEY not set for cosign fallback signing")
+    subprocess.check_call(["cosign","sign-blob","--key",cosign_key,"--output-signature",signature_out,blob_path])
+    with open(signature_out,"rb") as f:
+        return f.read().hex()
+
+def upload_s3(local_path, bucket, key):
+    s3 = boto3.client("s3")
+    s3.upload_file(local_path, bucket, key)
+    return f"s3://{bucket}/{key}"
+
+def register_rekor(artifact_path, signature_path, rekor_server):
+    try:
+        subprocess.check_call(["rekor-cli","upload","--artifact",artifact_path,"--signature",signature_path,"--rekor-server",rekor_server])
+    except Exception:
+        pass
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--model-id", required=True)
+    p.add_argument("--model-version", required=True)
+    p.add_argument("--artifact", required=True)
+    p.add_argument("--artifact-s3-uri", default=None)
+    p.add_argument("--image-uri", default=None)
+    p.add_argument("--mlflow-run-id", default=None)
+    p.add_argument("--validation", type=json.loads, default=None)
+    p.add_argument("--explainability", type=json.loads, default=None)
+    p.add_argument("--approved-by", default=None)
+    p.add_argument("--approved-at", default=None)
+    p.add_argument("--approval-notes", default=None)
+    p.add_argument("--out", default="/tmp/mcp.json")
+    p.add_argument("--s3-bucket", default=os.environ.get("MODEL_ARTIFACT_BUCKET"))
+    p.add_argument("--rekor-server", default=os.environ.get("REKOR_URL",""))
+    args = p.parse_args()
+
+    schema = load_schema()
+    ctx = collect_context(args)
+    # Validation might be json string already
+    try:
+        validate(instance=ctx, schema=schema)
+    except ValidationError as e:
+        print("MCP document validation failed:", e)
+        raise
+
+    payload_bytes = json.dumps(ctx, sort_keys=True, indent=2).encode("utf-8")
+    sig = sign_payload_hsm(payload_bytes)
+    signature_file = None
+    if sig:
+        ctx["signed_by"] = os.environ.get("PKCS11_KEYLABEL","pqkey")
+        ctx["signature"] = sig if isinstance(sig, str) else sig.decode("utf-8")
+    else:
+        # write payload to temp file and sign with cosign
+        tf = tempfile.NamedTemporaryFile(delete=False)
+        tf.write(payload_bytes); tf.flush(); tf.close()
+        signature_file = tf.name + ".sig"
+        sighex = sign_with_cosign(tf.name, signature_file)
+        ctx["signed_by"] = "cosign-fallback"
+        ctx["signature"] = sighex
+
+    # Upload MCP JSON to S3 if bucket set
+    if args.s3_bucket:
+        local_out = args.out
+        with open(local_out, "w") as f:
+            json.dump(ctx, f, indent=2)
+        key = f"mcp/{ctx['model_id']}-{ctx['model_version']}.json"
+        s3uri = upload_s3(local_out, args.s3_bucket, key)
+        ctx["_mcp_s3_uri"] = s3uri
+
+    # Register rekor for artifact + mcp if server provided
+    if args.rekor_server:
+        try:
+            # register MCP itself as artifact
+            register_rekor(args.out if os.path.exists(args.out) else args.artifact, signature_file or args.out + ".sig", args.rekor_server)
+            ctx["rekor_entry"] = "registered"
+        except Exception:
+            ctx["rekor_entry"] = "failed"
+    # write output
+    with open(args.out,"w") as f:
+        json.dump(ctx, f, indent=2)
+    print("MCP issued to", args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ui/backend/mcp_api.py
+from flask import Blueprint, jsonify, request
+import os, json
+
+bp = Blueprint("mcp", __name__, url_prefix="/api/mcp")
+MCP_STORE_DIR = os.environ.get("MCP_STORE_DIR", "/var/aegis/mcp")
+os.makedirs(MCP_STORE_DIR, exist_ok=True)
+
+@bp.route("/", methods=["POST"])
+def create_mcp():
+    payload = request.json or {}
+    model_id = payload.get("model_id")
+    model_version = payload.get("model_version")
+    if not model_id or not model_version:
+        return jsonify({"error":"model_id and model_version required"}), 400
+    fname = os.path.join(MCP_STORE_DIR, f"{model_id}-{model_version}.json")
+    with open(fname,"w") as f:
+        json.dump(payload, f, indent=2)
+    return jsonify({"status":"created","path":fname})
+
+@bp.route("/<model_id>/<model_version>", methods=["GET"])
+def get_mcp(model_id, model_version):
+    fname = os.path.join(MCP_STORE_DIR, f"{model_id}-{model_version}.json")
+    if not os.path.exists(fname):
+        return jsonify({"error":"not found"}), 404
+    return jsonify(json.load(open(fname)))
+
+@bp.route("/list", methods=["GET"])
+def list_mcps():
+    files = [f for f in os.listdir(MCP_STORE_DIR) if f.endswith(".json")]
+    out = []
+    for f in files:
+        out.append(f)
+    return jsonify({"mcps": out})
+
*** End Patch
*** Begin Patch
*** Add File:sdk/cli/aegis_cli/mcp_commands.py
+import click, subprocess, os, json
+
+@click.group()
+def mcp():
+    "Model Context Protocol (MCP) helper commands"
+    pass
+
+@mcp.command()
+@click.option("--model-id", required=True)
+@click.option("--model-version", required=True)
+@click.option("--artifact", required=True)
+@click.option("--mlflow-run-id", default="")
+@click.option("--out", default="/tmp/mcp.json")
+@click.option("--s3-bucket", default="")
+@click.option("--rekor-server", default="")
+def issue(model_id, model_version, artifact, mlflow_run_id, out, s3_bucket, rekor_server):
+    cmd = ["python3","production/policy/mcp_issue.py","--model-id",model_id,"--model-version",model_version,"--artifact",artifact,"--mlflow-run-id",mlflow_run_id,"--out",out]
+    if s3_bucket:
+        cmd += ["--s3-bucket",s3_bucket]
+    if rekor_server:
+        cmd += ["--rekor-server",rekor_server]
+    subprocess.check_call(cmd)
+    click.echo("MCP issued at " + out)
+
+@mcp.command()
+@click.option("--api", default=os.environ.get("AEGIS_API","http://localhost:8081/api"))
+@click.option("--model-id", required=True)
+@click.option("--model-version", required=True)
+def get(api, model_id, model_version):
+    import requests
+    r = requests.get(f"{api}/mcp/{model_id}/{model_version}")
+    click.echo(r.status_code)
+    click.echo(r.text)
+
*** End Patch
*** Begin Patch
*** Add File:production/pipeline/argo_model_lifecycle.yaml
*** End Patch
*** Begin Patch
*** Update File:production/pipeline/argo_model_lifecycle.yaml
@@
   - - name: sign-and-notarize
       template: run-script
       arguments:
         parameters:
           - name: script
-            value: "python3 production/pipeline/sign/sign_with_hsm.py --artifact /workspace/artifacts/model-latest.pkl --s3-bucket ${MODEL_ARTIFACT_BUCKET} --vault-path ${VAULT_PATH} --rekor-server ${REKOR_URL}"
+            value: "python3 production/pipeline/sign/sign_with_hsm.py --artifact /workspace/artifacts/model-latest.pkl --s3-bucket ${MODEL_ARTIFACT_BUCKET} --vault-path ${VAULT_PATH} --rekor-server ${REKOR_URL} && python3 production/policy/mcp_issue.py --model-id ${MODEL_ID:-mymodel} --model-version ${MODEL_VERSION:-v1} --artifact /workspace/artifacts/model-latest.pkl --mlflow-run-id ${MLFLOW_RUN_ID:-} --out /tmp/mcp.json --s3-bucket ${MODEL_ARTIFACT_BUCKET} --rekor-server ${REKOR_URL}"
*** End Patch
*** Begin Patch
*** Add File:compliance/include_mcp_in_evidence.py
+#!/usr/bin/env python3
+"""
+Helper to ensure MCP artifacts are included in evidence bundle.
+Scans S3 bucket or local /var/aegis/mcp and pulls MCP JSON files into evidence dir.
+"""
+import os, boto3, shutil
+
+def collect_local_mcp(outdir):
+    src = os.environ.get("MCP_STORE_DIR","/var/aegis/mcp")
+    if os.path.isdir(src):
+        os.makedirs(outdir, exist_ok=True)
+        for f in os.listdir(src):
+            if f.endswith(".json"):
+                shutil.copy(os.path.join(src,f), os.path.join(outdir,f))
+
+def collect_from_s3(bucket, prefix="mcp/", outdir="/tmp/aegis_evidence/mcp"):
+    s3 = boto3.client("s3")
+    resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
+    os.makedirs(outdir, exist_ok=True)
+    for o in resp.get("Contents", []):
+        key = o["Key"]
+        fn = key.split("/")[-1]
+        s3.download_file(bucket, key, os.path.join(outdir, fn))
+
+if __name__ == "__main__":
+    out = os.environ.get("EVIDENCE_OUT","/tmp/aegis_evidence")
+    collect_local_mcp(out)
+    # optionally collect from S3 if configured
+    if os.environ.get("MODEL_ARTIFACT_BUCKET"):
+        collect_from_s3(os.environ.get("MODEL_ARTIFACT_BUCKET"), outdir=os.path.join(out,"mcp"))
+    print("MCP collection done")
+
*** End Patch
*** Begin Patch
*** Update File:compliance/generate_evidence_bundle_enhanced.py
@@
 def collect_broker_logs(out=OUTDIR):
     os.makedirs(out, exist_ok=True)
     try:
         subprocess.check_call(["kubectl","logs","-n","aegis","deployment/aegis-quantum-broker"], stdout=open(os.path.join(out,"broker.log"),"w"))
     except Exception:
         pass
+
+def include_mcp(out=OUTDIR):
+    try:
+        import compliance.include_mcp_in_evidence as inc
+        inc.collect_local_mcp(out)
+    except Exception:
+        pass
+
@@
 def main():
     out = OUTDIR
     os.makedirs(out, exist_ok=True)
     collect_broker_logs(out)
     collect_mlflow(out)
     collect_hsm_audit(out)
+    include_mcp(out)
     package(out)
*** End Patch
*** Begin Patch
*** Add File:k8s/crd/modelcontext_crd.yaml
+apiVersion: apiextensions.k8s.io/v1
+kind: CustomResourceDefinition
+metadata:
+  name: modelcontexts.aegis.ai
+spec:
+  group: aegis.ai
+  names:
+    kind: ModelContext
+    plural: modelcontexts
+    singular: modelcontext
+    shortNames:
+      - mcp
+  scope: Namespaced
+  versions:
+    - name: v1
+      served: true
+      storage: true
+      schema:
+        openAPIV3Schema:
+          type: object
+          properties:
+            spec:
+              type: object
+              properties:
+                model_id:
+                  type: string
+                model_version:
+                  type: string
+                mcp_s3_uri:
+                  type: string
+                approved:
+                  type: boolean
+                approver:
+                  type: string
+            status:
+              type: object
+              properties:
+                state:
+                  type: string
+                message:
+                  type: string
+      subresources:
+        status: {}
+
*** End Patch
*** Begin Patch
*** Add File:controllers/modelcontext_controller.py
+#!/usr/bin/env python3
+"""
+Simple Kubernetes controller for ModelContext CRD.
+ - Watches ModelContext resources and, when spec.approved is true, updates status.state to "Certified"
+ - Optionally invokes the MCP issuer if spec.mcp_s3_uri is missing
+
+Note: This controller is a minimal reference implementation. For production, use controller-runtime or Kopf-based operator.
+"""
+import os, time, json
+from kubernetes import client, config, watch, utils
+import subprocess
+
+def ensure_mcp(ctx):
+    # If spec.mcp_s3_uri missing, attempt to build MCP using local heuristics (this is a convenience)
+    ns = ctx['metadata']['namespace']
+    name = ctx['metadata']['name']
+    spec = ctx.get('spec', {})
+    model_id = spec.get('model_id')
+    model_version = spec.get('model_version')
+    mcp_out = f"/tmp/mcp-{model_id}-{model_version}.json"
+    artifact = spec.get('artifact','/tmp/model.pkl')
+    if not spec.get('mcp_s3_uri'):
+        cmd = ["python3","production/policy/mcp_issue.py","--model-id",model_id,"--model-version",model_version,"--artifact",artifact,"--out",mcp_out,"--s3-bucket", os.environ.get("MODEL_ARTIFACT_BUCKET","")]
+        try:
+            subprocess.check_call(cmd)
+            # pretend we uploaded and update CRD with mcp_s3_uri if available
+            return mcp_out
+        except Exception as e:
+            print("mcp_issue failed:", e)
+            return None
+    return spec.get('mcp_s3_uri')
+
+def main():
+    config.load_incluster_config() if os.environ.get("KUBERNETES_SERVICE_HOST") else config.load_kube_config()
+    api = client.CustomObjectsApi()
+    w = watch.Watch()
+    group = "aegis.ai"
+    version = "v1"
+    plural = "modelcontexts"
+    ns = os.environ.get("WATCH_NAMESPACE","aegis")
+    print("Starting ModelContext controller in namespace", ns)
+    for event in w.stream(api.list_namespaced_custom_object, group, version, ns, plural, timeout_seconds=0):
+        obj = event['object']
+        typ = event['type']
+        name = obj['metadata']['name']
+        spec = obj.get('spec',{})
+        print("Event", typ, name)
+        try:
+            if spec.get('approved') is True:
+                # ensure MCP exists
+                mcp_uri = ensure_mcp(obj)
+                # update status to certified
+                body = {"status": {"state": "Certified", "message": f"Certified; mcp:{mcp_uri}"}}
+                api.patch_namespaced_custom_object_status(group, version, ns, plural, name, body)
+        except Exception as e:
+            print("controller error:", e)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:k8s/modelcontext_rbac.yaml
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: modelcontext-controller
+  namespace: aegis
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: modelcontext-role
+  namespace: aegis
+rules:
+  - apiGroups: ["aegis.ai"]
+    resources: ["modelcontexts"]
+    verbs: ["get","list","watch","create","update","patch"]
+  - apiGroups: [""]
+    resources: ["pods","pods/log"]
+    verbs: ["get","list"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: modelcontext-rb
+  namespace: aegis
+subjects:
+  - kind: ServiceAccount
+    name: modelcontext-controller
+    namespace: aegis
+roleRef:
+  kind: Role
+  name: modelcontext-role
+  apiGroup: rbac.authorization.k8s.io
+
*** End Patch
*** Begin Patch
*** Add File:controllers/Dockerfile
+FROM python:3.10-slim
+RUN pip install kubernetes
+WORKDIR /app
+COPY controllers/modelcontext_controller.py /app/
+CMD ["python3","/app/modelcontext_controller.py"]
+
*** End Patch
*** Begin Patch
*** Add File:production/policy/README_MCP.md
+# Model Context Protocol (MCP) — Implementation Notes
+
+This folder implements Option A (lightweight MCP issuer) and Option B (ModelContext CRD + controller).
+
+Option A:
+- mcp/schema.json — MCP JSON Schema
+- production/policy/mcp_issue.py — collector & signer; produces signed MCP JSON and uploads to S3 / Rekor
+- ui/backend/mcp_api.py — REST endpoints to store and retrieve MCP JSON (simple store)
+- sdk/cli/aegis_cli/mcp_commands.py — CLI commands to issue MCP and query API
+- production/pipeline/argo_model_lifecycle.yaml was extended to call mcp_issue after signing step
+- compliance/include_mcp_in_evidence.py and compliance/generate_evidence_bundle_enhanced.py were updated to collect MCP artifacts into evidence
+
+Option B:
+- k8s/crd/modelcontext_crd.yaml — CRD definition for ModelContext
+- controllers/modelcontext_controller.py — minimal controller that watches ModelContext resources and runs MCP issuer if needed; updates status to Certified
+- k8s/modelcontext_rbac.yaml — serviceaccount & RBAC for controller
+- controllers/Dockerfile — to build controller container
+
+How to use:
+1) Option A quick path:
+   - Call the issuer directly via CLI or build a CI step that runs production/policy/mcp_issue.py and stores the resulting MCP in S3.
+   - Ensure COSIGN_KEY or HSM is available for signing.
+2) Option B path (Kubernetes-native):
+   - Apply CRD: kubectl apply -f k8s/crd/modelcontext_crd.yaml
+   - Apply RBAC: kubectl apply -f k8s/modelcontext_rbac.yaml
+   - Build and deploy controller image from controllers/Dockerfile; ensure serviceaccount has Vault access (if issuing uses Vault)
+   - Create ModelContext CR: it will be observed and moved to status.Certified once approved
+
+Acceptance:
+- MCP JSON exists per promoted model and is included in evidence bundle
+- Rekor entry is created for MCP or signed artifact
+- ModelContext CR (if used) reflects certification status and is readable via kubectl
+
*** End Patch
*** End Patch
