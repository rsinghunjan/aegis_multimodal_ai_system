*** Begin Patch
*** Add File:quantum/hsm/provision_cloudhsm.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Operator helper: provision AWS CloudHSM (via Terraform) and print next steps.
+# This is a wrapper that assumes terraform files exist in cloud/hsm/ (cloud provider specifics).
+#
+# Usage:
+#   ./provision_cloudhsm.sh --tf-vars ./cloud/hsm/terraform.tfvars
+#
+TFVARS=""
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --tf-vars) TFVARS="$2"; shift 2;;
+    *) echo "Unknown $1"; exit 1;;
+  esac
+done
+
+: "${TFVARS:?--tf-vars required (point to a terraform.tfvars file)}"
+
+echo "Initializing Terraform in cloud/hsm..."
+pushd cloud/hsm >/dev/null
+terraform init -input=false
+terraform apply -input=false -auto-approve -var-file="${TFVARS}"
+popd >/dev/null
+
+echo "Provisioning triggered. After provisioning:"
+echo " - Retrieve CloudHSM cluster id and details from Terraform outputs."
+echo " - Configure network connectivity (client ENIs), install PKCS#11 module on signing hosts."
+echo " - Follow vendor instructions to initialize HSM cluster and create partitions/keys."
+
*** End Patch
*** Begin Patch
*** Add File:quantum/hsm/validate_hsm_end_to_end.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run full HSM validation:
+# 1) Sign artifact using hybrid_signer_hsm (PKCS#11)
+# 2) Verify hybrid metadata and (optional) upload to Rekor
+# 3) Verify audit logs appear in configured S3 bucket
+#
+usage() {
+  cat <<EOF
+Usage: $0 --artifact /tmp/foo.bin --pkcs11-lib /path/to/lib --pkcs11-slot 0 --pkcs11-pin 1234 --pkcs11-keylabel pqkey --s3-bucket <audit-bucket>
+EOF
+}
+
+ART=""
+PKCS11_LIB=""
+PKCS11_SLOT=""
+PKCS11_PIN=""
+PKCS11_KEYLABEL=""
+S3_BUCKET=""
+REKOR=false
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --artifact) ART="$2"; shift 2;;
+    --pkcs11-lib) PKCS11_LIB="$2"; shift 2;;
+    --pkcs11-slot) PKCS11_SLOT="$2"; shift 2;;
+    --pkcs11-pin) PKCS11_PIN="$2"; shift 2;;
+    --pkcs11-keylabel) PKCS11_KEYLABEL="$2"; shift 2;;
+    --s3-bucket) S3_BUCKET="$2"; shift 2;;
+    --rekor) REKOR=true; shift 1;;
+    *) echo "Unknown $1"; usage; exit 1;;
+  esac
+done
+
+: "${ART:?--artifact required}"
+: "${PKCS11_LIB:?--pkcs11-lib required}"
+: "${PKCS11_SLOT:?--pkcs11-slot required}"
+: "${PKCS11_PIN:?--pkcs11-pin required}"
+: "${PKCS11_KEYLABEL:?--pkcs11-keylabel required}"
+
+OUTDIR="$(mktemp -d /tmp/aegis_hsm_validate.XXXX)"
+echo "OUTDIR: $OUTDIR"
+
+echo "Signing artifact with hybrid_signer_hsm.py (PKCS#11)..."
+python3 quantum/crypto/hybrid_signer_hsm.py sign --artifact "${ART}" --outdir "${OUTDIR}" --use-pkcs11 --pkcs11-lib "${PKCS11_LIB}" --pkcs11-slot "${PKCS11_SLOT}" --pkcs11-pin "${PKCS11_PIN}" --pkcs11-keylabel "${PKCS11_KEYLABEL}" $( $REKOR && echo "--rekor" || echo "")
+
+echo "Hybrid metadata:"
+cat "${OUTDIR}/hybrid-signature.json" || true
+
+if [ -n "${S3_BUCKET}" ]; then
+  echo "Polling S3 for HSM audit objects (s3://${S3_BUCKET}/hsm-audit/) for up to 180s..."
+  python3 quantum/hsm/vendor_validation/verify_hsm_audit.py --s3-bucket "${S3_BUCKET}" --prefix hsm-audit/ --timeout 180 || echo "Audit objects not found yet - check vendor audit config"
+fi
+
+echo "Validation completed. Keep OUTDIR for evidence: ${OUTDIR}"
+
*** End Patch
*** Begin Patch
*** Add File:quantum/vault/write_hsm_config_and_pubkey.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Writes HSM PKCS#11 config and public key into Vault KV (v2)
+# Usage:
+#  ./write_hsm_config_and_pubkey.sh --vault-path secret/data/hsm/config --pkcs11-lib /usr/lib/your_hsm.so --slot 0 --token-label mytoken --pubkey /tmp/pq.pub
+VAULT_PATH=""
+PKCS11_LIB=""
+SLOT=""
+TOKEN_LABEL=""
+PUBKEY_FILE=""
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    --pkcs11-lib) PKCS11_LIB="$2"; shift 2;;
+    --slot) SLOT="$2"; shift 2;;
+    --token-label) TOKEN_LABEL="$2"; shift 2;;
+    --pubkey) PUBKEY_FILE="$2"; shift 2;;
+    *) echo "Unknown $1"; exit 1;;
+  esac
+done
+
+: "${VAULT_PATH:?--vault-path required}"
+: "${PKCS11_LIB:?--pkcs11-lib required}"
+
+echo "Writing PKCS#11 config to Vault path: ${VAULT_PATH}"
+vault kv put "${VAULT_PATH}" pkcs11_module="${PKCS11_LIB}" slot="${SLOT:-}" token_label="${TOKEN_LABEL:-}"
+
+if [ -n "${PUBKEY_FILE:-}" ]; then
+  echo "Uploading public key ${PUBKEY_FILE} to Vault path ${VAULT_PATH}"
+  vault kv put "${VAULT_PATH}" public_key=@${PUBKEY_FILE}
+fi
+
+echo "Vault write complete. Ensure Vault policies restrict access to signing service and compliance."
+
*** End Patch
*** Begin Patch
*** Add File:providers/pilot/run_pilots_and_verify.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run credential-backed pilots (Braket + IBM), capture metadata, run playback, and verify Rekor+MLflow tags.
+# Usage:
+#  ./run_pilots_and_verify.sh --vault-path secret/data/quantum/providers --program demo.qasm --s3-bucket my-staging-bucket --ibm-backend ibmq_qasm_simulator
+VAULT_PATH=""
+PROGRAM=""
+S3_BUCKET=""
+IBM_BACKEND=""
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    --program) PROGRAM="$2"; shift 2;;
+    --s3-bucket) S3_BUCKET="$2"; shift 2;;
+    --ibm-backend) IBM_BACKEND="$2"; shift 2;;
+    *) echo "Unknown $1"; exit 1;;
+  esac
+done
+
+: "${VAULT_PATH:?--vault-path required}"
+: "${PROGRAM:?--program required}"
+: "${S3_BUCKET:?--s3-bucket required}"
+
+echo "Running Braket pilot (credentials loaded from Vault)..."
+python3 providers/pilot/orchestrator.py --provider braket --vault-path "${VAULT_PATH}" --program "${PROGRAM}" --s3-bucket "${S3_BUCKET}"
+
+if [ -n "${IBM_BACKEND}" ]; then
+  echo "Running IBM pilot..."
+  python3 providers/pilot/orchestrator.py --provider ibm --vault-path "${VAULT_PATH}" --program "${PROGRAM}" --s3-bucket "${S3_BUCKET}" --backend "${IBM_BACKEND}"
+fi
+
+echo "Pilots submitted. Now attempt to verify MLflow + Rekor linkage for recent runs."
+python3 quantum/rekor/check_mlflow_rekor.py --mlflow-url "${MLFLOW_URL:-http://mlflow:5000}" --experiment quantum-pilots --threshold 10 || true
+
+echo "Find produced meta files in /tmp or S3 and run simulator playback using repro/simulator_playback.py if noise snapshots included."
+
*** End Patch
*** Begin Patch
*** Add File:broker/scripts/deploy_broker_prod.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Deploy Broker to production/staging: provision RDS via Terraform (operator), deploy Helm chart, install cert-manager (if needed).
+# Usage:
+#  ./deploy_broker_prod.sh --tf-vars ./broker/terraform/prod.tfvars --namespace aegis --helm-release aegis-quantum-broker
+TFVARS=""
+NS="aegis"
+RELEASE="aegis-quantum-broker"
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --tf-vars) TFVARS="$2"; shift 2;;
+    --namespace) NS="$2"; shift 2;;
+    --helm-release) RELEASE="$2"; shift 2;;
+    *) echo "Unknown $1"; exit 1;;
+  esac
+done
+
+: "${TFVARS:?--tf-vars required (points to Terraform vars)}"
+
+echo "Apply Terraform (RDS & infra) in broker/terraform..."
+pushd broker/terraform >/dev/null
+terraform init -input=false
+terraform apply -input=false -auto-approve -var-file="${TFVARS}"
+popd >/dev/null
+
+echo "Ensure cert-manager is installed on the cluster; apply issuer manifest:"
+kubectl apply -f broker/k8s/cert-manager-issuer.yaml || true
+
+echo "Create namespace and secrets (populate JOB_DATABASE_URL and BROKER_API_JWT_SECRET via Vault or external-secrets prior)"
+kubectl create ns "${NS}" --dry-run=client -o yaml | kubectl apply -f -
+
+echo "Install/upgrade Helm chart"
+helm upgrade --install "${RELEASE}" broker/helm -n "${NS}" --set image.tag=production --values broker/helm/values-production.yaml
+
+echo "Deploy worker deployment (autoscaled). Ensure HPA is created and monitoring is configured."
+
*** End Patch
*** Begin Patch
*** Add File:broker/scripts/validate_broker_prod.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Validate broker production deployment: mTLS check + JWT rotation test + HPA status
+#
+NAMESPACE=${1:-aegis}
+SERVICE=${2:-aegis-quantum-broker}
+INGRESS_HOST=${3:-aegis-quantum-broker.aegis.svc.cluster.local}
+
+echo "Check pods in namespace ${NAMESPACE}"
+kubectl get pods -n "${NAMESPACE}"
+
+echo "Check HPA status"
+kubectl get hpa -n "${NAMESPACE}" || true
+
+echo "Check certificate secret"
+kubectl get secret aegis-broker-tls-secret -n "${NAMESPACE}" || echo "TLS secret not found"
+
+echo "JWT rotation test: run jwt_rotate.sh and ensure broker still responds"
+./quantum/job_broker/jwt_rotate.sh "${NAMESPACE}" aegis-broker-secret || true
+
+echo "mTLS validation (operator must provide client cert/key/ca for test):"
+echo "Run broker/k8s/validate_mtls.sh with proper certs (manual step)."
+
+echo "Broker validation script completed. Address any errors above."
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/rekor_auditor_report.yml
+name: Rekor Auditor Report
+on:
+  workflow_dispatch:
+jobs:
+  rekor-audit:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install tooling
+        run: |
+          sudo apt-get update && sudo apt-get install -y jq
+          curl -sSL https://github.com/sigstore/cosign/releases/download/v2.0.0/cosign-linux-amd64 -o cosign && chmod +x cosign && sudo mv cosign /usr/local/bin/
+          curl -sSL https://github.com/sigstore/rekor/releases/download/v0.10.0/rekor-cli_linux_amd64 -o rekor-cli && chmod +x rekor-cli && sudo mv rekor-cli /usr/local/bin/
+      - name: Fetch recent artifact list (placeholder)
+        run: |
+          echo "This job assumes build artifacts or metadata are available. For auditing, operator will supply artifact list."
+      - name: Query Rekor for artifacts (example)
+        run: |
+          # Placeholder: iterate over artifact hashes provided via artifact input; here we show example usage
+          true
+      - name: Produce auditor note
+        run: |
+          echo "If Rekor entries are present for required artifacts, collect their JSON outputs and attach to auditor package."
+
*** End Patch
*** Begin Patch
*** Add File:observability/cur/ingest_cur.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Simple CUR ingestion helper:
+# - Downloads latest AWS CUR CSV/Parquet from S3 (operator ensures CUR is delivered to bucket)
+# - Converts to simplified CSV with columns: job,cost
+# - Calls chargeback_connector.py to ingest into billing table
+#
+S3_PATH=${1:-}
+LOCAL_DIR=${2:-/tmp/aws_cur}
+TENANT=${3:-default}
+
+if [ -z "$S3_PATH" ]; then
+  echo "Usage: ingest_cur.sh s3://bucket/path/cur-YYYYMMDD/ local_dir [tenant]"; exit 2
+fi
+mkdir -p "$LOCAL_DIR"
+echo "Downloading CUR files from $S3_PATH to $LOCAL_DIR"
+aws s3 cp "$S3_PATH" "$LOCAL_DIR" --recursive
+
+echo "Converting CUR to simplified billing CSV (placeholder). Operator must map CUR fields to job IDs/tags."
+# Placeholder transform: produce a CSV with header job,cost
+echo "job,cost" > "${LOCAL_DIR}/simple_billing.csv"
+# In real deployment, parse CUR files and sum cost per job tag
+
+echo "Ingesting simplified billing CSV into billing DB"
+python3 broker/quotas/chargeback_connector.py "${LOCAL_DIR}/simple_billing.csv" "${TENANT}"
+
+echo "CUR ingestion complete."
+
*** End Patch
*** Begin Patch
*** Add File:observability/test_cost_spike.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Simulate ingestion of a large billing row to trigger cost_enforcer fallback logic.
+#
+CSV=${1:-/tmp/fake_billing.csv}
+TENANT=${2:-default}
+cat > "${CSV}" <<CSV
+job,cost
+fake-job-1,2000.00
+CSV
+python3 broker/quotas/chargeback_connector.py "${CSV}" "${TENANT}"
+echo "Fake billing ingested. Wait up to 5 minutes for cost_enforcer to detect and set fallback."
+
*** End Patch
*** Begin Patch
*** Add File:compliance/vendor_contracts/COUNTERSIGN_TEMPLATE.md
+Vendor Counter-sign Template for HSM / QPU Providers
+---------------------------------------------------
+Key sections to include for countersigning:
+- Scope of Services: explicit HSM features (PKCS#11), audit log export, access to key lifecycle ops.
+- Security & Certifications: SOC2/ISO evidence to be provided by vendor.
+- Data Residency & Export Controls: geofencing clauses and export obligations.
+- Incident Response: vendor obligations for key compromise, audit, and notifications.
+- SLAs & Support: availability, maintenance windows, and escalation.
+- Pricing & Quotas: cost per QPU minute, cancellation, and overage handling.
+
+Operators: use legal counsel to finalize and attach to compliance/evidence.
+
*** End Patch
*** Begin Patch
*** Add File:compliance/soc2/audit_request_template.md
+SOC2 Audit Request â€” PQ/HSM & Quantum Pilots
+-------------------------------------------
+Provide to auditor:
+- Inventory of PKCS#11/HSM vendors, module versions and deployment architecture.
+- Evidence of signing flows: artifact hashes, cosign signature output, Rekor entries and MLflow links.
+- HSM audit logs (S3) covering pilot runs and key rotation events.
+- Broker deployment manifests and secrets handling description (Vault policies).
+- Pilot job artifacts: raw shots, noise snapshots, MLflow runs and Rekor entries.
+
+Attach deliverables (tar.gz) produced by compliance/packager.py
+
*** End Patch
*** End Patch
