*** Begin Patch
*** Add File:helm/feast/Chart.yaml
+apiVersion: v2
+name: aegis-feast
+description: "Feast deployment (offline+online) tailored for Aegis (staging/production values)"
+type: application
+version: 0.1.0
+appVersion: "0.1.0"
+
*** End Patch
*** Begin Patch
*** Add File:helm/feast/values.yaml
+# Default values for Aegis Feast Helm chart (production-ready defaults - override per-env)
+image:
+  repository: registry.example.com/aegis/feast
+  tag: latest
+offlineStore:
+  s3:
+    bucket: {{ .Values.global.modelArtifactBucket | default "your-bucket" }}
+    prefix: feast/offline
+onlineStore:
+  redis:
+    host: redis-headless.aegis.svc
+    port: 6379
+resources:
+  job:
+    requests:
+      cpu: "500m"
+      memory: "1Gi"
+    limits:
+      cpu: "2"
+      memory: "4Gi"
+serviceAccount:
+  create: true
+prometheus:
+  enabled: true
+  serviceMonitor:
+    enabled: true
+    interval: "30s"
+rbac:
+  create: true
+
*** End Patch
*** Begin Patch
*** Add File:helm/feast/templates/deployment-job.yaml
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: feast-ingest-job
+  labels:
+    app: aegis-feast
+spec:
+  template:
+    spec:
+      serviceAccountName: {{ .Values.serviceAccount.name | default "feast-sa" }}
+      containers:
+        - name: feast-offline-ingest
+          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
+          command: ["sh","-c"]
+          args: ["python3 /app/feast_ingest.py"]
+          resources:
+{{ toYaml .Values.resources.job | indent 12 }}
+      restartPolicy: OnFailure
+
*** End Patch
*** Begin Patch
*** Add File:helm/feast/templates/servicemonitor.yaml
+{{- if .Values.prometheus.serviceMonitor.enabled }}
+apiVersion: monitoring.coreos.com/v1
+kind: ServiceMonitor
+metadata:
+  name: feast-servicemonitor
+  labels:
+    app: aegis-feast
+spec:
+  selector:
+    matchLabels:
+      app: aegis-feast
+  endpoints:
+    - port: metrics
+      interval: {{ .Values.prometheus.serviceMonitor.interval }}
+{{- end }}
+
*** End Patch
*** Begin Patch
*** Add File:redis/redis-cluster-helm-values-production.yaml
+# Production-ready values for Redis Helm chart (bitnami/redis or other operator)
+global:
+  redis:
+    passwordSecret: redis-creds
+cluster:
+  enabled: true
+  replicaCount: 3
+  persistence:
+    enabled: true
+    size: 50Gi
+metrics:
+  enabled: true
+  serviceMonitor:
+    enabled: true
+resources:
+  master:
+    requests:
+      cpu: "500m"
+      memory: "1Gi"
+    limits:
+      cpu: "2000m"
+      memory: "4Gi"
+  replica:
+    requests:
+      cpu: "500m"
+      memory: "1Gi"
+    limits:
+      cpu: "2000m"
+      memory: "4Gi"
+
*** End Patch
*** Begin Patch
*** Add File:kafka/strimzi/kafka-cluster.yaml
+apiVersion: kafka.strimzi.io/v1beta2
+kind: Kafka
+metadata:
+  name: aegis-kafka
+  namespace: aegis
+spec:
+  kafka:
+    version: 3.4.0
+    replicas: 3
+    listeners:
+      - name: plain
+        plaintext: {}
+    config:
+      offsets.topic.replication.factor: 3
+      transaction.state.log.replication.factor: 3
+      transaction.state.log.min.isr: 2
+      log.retention.hours: 168
+    storage:
+      type: persistent-claim
+      size: 200Gi
+      deleteClaim: false
+  zookeeper:
+    replicas: 3
+    storage:
+      type: persistent-claim
+      size: 50Gi
+      deleteClaim: false
+  entityOperator:
+    topicOperator: {}
+    userOperator: {}
+
*** End Patch
*** Begin Patch
*** Add File:streaming/kafka-connect/http-sink-connector.json
+{
+  "name": "feast-http-sink",
+  "connector.class": "com.github.jcustenborder.kafka.connect.http.HttpSinkConnector",
+  "tasks.max": "3",
+  "topics": "feast-features",
+  "http.api.url": "http://feast-stream-processor.aegis.svc:9100/events",
+  "policy": "EXACTLY_ONCE",
+  "headers": "Content-Type:application/json",
+  "key.converter.schemas.enable": "false",
+  "value.converter.schemas.enable": "false"
+}
+
*** End Patch
*** Begin Patch
*** Add File:streaming/feast_stream_processor_ha.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: feast-stream-processor
+  namespace: aegis
+spec:
+  replicas: 3
+  selector:
+    matchLabels:
+      app: feast-stream-processor
+  template:
+    metadata:
+      labels:
+        app: feast-stream-processor
+    spec:
+      serviceAccountName: aegis-agent
+      containers:
+        - name: feast-stream-processor
+          image: registry.example.com/aegis/feast-stream-processor:latest
+          ports:
+            - containerPort: 9100
+          readinessProbe:
+            httpGet:
+              path: /healthz
+              port: 9100
+            initialDelaySeconds: 10
+            periodSeconds: 10
+          resources:
+            requests:
+              cpu: "300m"
+              memory: "512Mi"
+            limits:
+              cpu: "1500m"
+              memory: "2Gi"
+
*** End Patch
*** Begin Patch
*** Add File:marquez/deployment/marquez-deploy.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: marquez
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: marquez
+  template:
+    metadata:
+      labels:
+        app: marquez
+    spec:
+      containers:
+        - name: marquez
+          image: marquezproject/marquez:0.35.0
+          env:
+            - name: SPRING_PROFILES_ACTIVE
+              value: prod
+            - name: MARQUEZ_DB_HOST
+              value: postgres.aegis.svc
+          ports:
+            - containerPort: 8080
+          resources:
+            requests:
+              cpu: "500m"
+              memory: "1Gi"
+            limits:
+              cpu: "2"
+              memory: "4Gi"
+
*** End Patch
*** Begin Patch
*** Add File:catalog/marquez-connector-cronjob.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: marquez-connector
+  namespace: aegis
+spec:
+  schedule: "*/5 * * * *"
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          serviceAccountName: aegis-agent
+          containers:
+            - name: connector
+              image: registry.example.com/aegis/marquez-connector:latest
+              env:
+                - name: MARQUEZ_URL
+                  value: "http://marquez.aegis.svc:8080"
+                - name: LINEAGE_DIR
+                  value: "/var/aegis/lineage"
+              volumeMounts:
+                - name: lineage
+                  mountPath: /var/aegis/lineage
+          restartPolicy: OnFailure
+          volumes:
+            - name: lineage
+              hostPath:
+                path: /var/aegis/lineage
+                type: DirectoryOrCreate
+
*** End Patch
*** Begin Patch
*** Add File:amundsen/deploy/deploy-amundsen.yaml
+# Minimal Amundsen deployment (metadata service + frontend)
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: amundsen-frontend
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: amundsen-frontend
+  template:
+    metadata:
+      labels:
+        app: amundsen-frontend
+    spec:
+      containers:
+        - name: amundsen-frontend
+          image: amundsendev/amundsen-frontend:latest
+          env:
+            - name: SEARCH_SERVICE_BASE
+              value: http://amundsen-search.aegis.svc:5001
+          ports:
+            - containerPort: 5000
+
*** End Patch
*** Begin Patch
*** Add File:dp/secure_inference/crypten_example.py
+"""
+CrypTen secure inference example (minimal)
+ - Demonstrates how to load a PyTorch model and run one encrypted inference using CrypTen.
+ - Requires crypten installation and appropriate setup.
+ - This file is an example scaffold. Evaluate performance & security before production use.
+"""
+try:
+    import torch
+    import crypten
+    crypten.init()
+except Exception as e:
+    raise RuntimeError("Crypten not installed or not configured: " + str(e))
+
+def demo():
+    # simple model
+    import torch.nn as nn
+    model = nn.Sequential(nn.Linear(10, 16), nn.ReLU(), nn.Linear(16, 2))
+    model.eval()
+    # crypten: encrypt model
+    crypten_model = crypten.nn.from_pytorch(model, torch.zeros(1,10))
+    crypten_model.encrypt()
+    # create encrypted input
+    x = torch.randn(1,10)
+    enc_x = crypten.cryptensor(x)
+    out = crypten_model(enc_x)
+    # decrypt result
+    res = out.get_plain_text()
+    print("Decrypted result:", res)
+
+if __name__ == "__main__":
+    demo()
+
*** End Patch
*** Begin Patch
*** Add File:dp/secure_inference/tf_encrypted_example.py
+"""
+TF-Encrypted example (placeholder)
+ - Demonstrates concept: convert a TF model and run a secure inference using TF-Encrypted primitives.
+ - TF-Encrypted has specific runtime and dependency requirements; this is an integration scaffold.
+"""
+def notes():
+    print("TF-Encrypted integration requires installing tf-encrypted and evaluating performance. See docs to integrate.")
+
+if __name__ == "__main__":
+    notes()
+
*** End Patch
*** Begin Patch
*** Add File:zero_trust/linkerd_install_and_spire.sh
+#!/usr/bin/env bash
+set -euo pipefail
+echo "Install Linkerd and SPIRE (staging quickstart). Review and adapt for production HA."
+# Install Linkerd
+curl -sL https://run.linkerd.io/install | sh
+linkerd check --pre
+linkerd install | kubectl apply -f -
+linkerd check
+
+# Install SPIRE (example manifest)
+kubectl apply -f https://raw.githubusercontent.com/spiffe/spire/main/examples/k8s/manifests/spire-all.yaml
+
+echo "Linkerd and SPIRE applied. Register a workload using spire/register_workload.sh"
+
*** End Patch
*** Begin Patch
*** Add File:vault/ekstemplate_vault_agent_example.yaml
+# Example Vault Agent Injector annotation for dynamic secret injection (Kubernetes)
+apiVersion: v1
+kind: Pod
+metadata:
+  name: example-vault-inject
+  namespace: aegis
+  annotations:
+    vault.hashicorp.com/agent-inject: "true"
+    vault.hashicorp.com/role: "aegis-role"
+    vault.hashicorp.com/agent-inject-secret-redis: "secret/data/redis#password"
+spec:
+  serviceAccountName: aegis-agent
+  containers:
+    - name: app
+      image: busybox
+      command: ["sh","-c","sleep 3600"]
+      env:
+        - name: REDIS_PASSWORD_FILE
+          value: /vault/secrets/redis
+
*** End Patch
*** Begin Patch
*** Add File:ops/dr/restore_and_verify.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Restore automation script for DR validation
+# - Expects backup tarball path as argument
+# - Restores Postgres DB (pg_restore), uploads MinIO artifacts, validates Redis RDB presence
+
+TARBALL=${1:-}
+if [ -z "$TARBALL" ]; then
+  echo "Usage: $0 <backup-tarball>"
+  exit 2
+fi
+WORKDIR=$(mktemp -d)
+tar xzf "$TARBALL" -C "$WORKDIR"
+echo "Extracted backup to $WORKDIR"
+
+# Restore Postgres
+if [ -f "$WORKDIR/mlflow_db.dump" ]; then
+  echo "Restoring Postgres dump (manual step may be required for credentials)"
+  # Example: pg_restore -d <db> -U <user> -h <host> "$WORKDIR/mlflow_db.dump"
+fi
+
+# Restore MinIO artifacts
+if [ -d "$WORKDIR/minio" ]; then
+  echo "Restoring MinIO artifacts (requires aws CLI endpoint configured)"
+  # Example: aws --endpoint-url ${MINIO_ENDPOINT:-} s3 sync "$WORKDIR/minio/" "s3://${MINIO_BUCKET:-}"
+fi
+
+# Validate Redis rdb
+echo "Check Redis persistence (operator dependent)."
+
+echo "Post-restore validation: run smoke tests against MLflow API and sample model inference."
+
*** End Patch
*** Begin Patch
*** Add File:ui/modelcards/frontend_template.html
+<!doctype html>
+<html>
+  <head>
+    <meta charset="utf-8"/>
+    <title>Aegis Model Cards</title>
+    <style>
+      body { font-family: Arial, sans-serif; margin: 20px; }
+      .card { border: 1px solid #ddd; padding: 12px; margin-bottom: 10px; }
+      .meta { color: #555; font-size: 12px; }
+    </style>
+  </head>
+  <body>
+    <h1>Model Cards</h1>
+    <div id="cards"></div>
+    <script>
+      async function load(page=1) {
+        const res = await fetch('/api/modelcards?page=' + page);
+        const j = await res.json();
+        const el = document.getElementById('cards');
+        el.innerHTML = '';
+        j.cards.forEach(c => {
+          const d = document.createElement('div'); d.className='card';
+          d.innerHTML = `<h2>${c.model_id} v${c.model_version}</h2>
+                         <div class="meta">Signed: ${c.signed_by} â€” Created: ${new Date(c.created_at*1000).toLocaleString()}</div>
+                         <pre>${JSON.stringify(c, null, 2)}</pre>`;
+          el.appendChild(d);
+        });
+        if (j.next_page) {
+          const btn = document.createElement('button'); btn.innerText='Next'; btn.onclick=()=>load(j.next_page); el.appendChild(btn);
+        }
+      }
+      load();
+    </script>
+  </body>
+</html>
+
*** End Patch
*** Begin Patch
*** Add File:ui/approvals_api_improvements.py
+#!/usr/bin/env python3
+"""
+Enhance approvals endpoints: pagination, filtering, and role-based check placeholder.
+Used alongside approvals_app_enhanced.py (same SQLite DB).
+"""
+from flask import Flask, request, jsonify
+import sqlite3, os
+
+DB = os.environ.get("APPROVAL_DB","/tmp/aegis_approvals.db")
+app = Flask(__name__)
+
+def query_db(q, params=()):
+    conn = sqlite3.connect(DB)
+    cur = conn.cursor()
+    cur.execute(q, params)
+    rows = cur.fetchall()
+    cols = [d[0] for d in cur.description] if cur.description else []
+    conn.close()
+    return [dict(zip(cols, r)) for r in rows]
+
+@app.route("/api/modelcards")
+def list_modelcards():
+    page = int(request.args.get("page", "1"))
+    per = int(request.args.get("per", "10"))
+    offset = (page-1)*per
+    files = query_db("SELECT id, entity, entity_id, status, requested_by, reviewer, reviewed_at FROM approvals ORDER BY id DESC LIMIT ? OFFSET ?", (per, offset))
+    # next_page indicator (quick)
+    next_page = page+1 if len(files)==per else None
+    return jsonify({"cards": files, "next_page": next_page})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=8089)
+
*** End Patch
*** Begin Patch
*** Add File:observability/prometheus/remote_write_thanos.yaml
+# Example Prometheus remote_write config to send metrics to Thanos/Long-term store
+remote_write:
+- url: "http://thanos-receive.aegis.svc:19291/api/v1/receive"
+  remote_timeout: 30s
+  queue_config:
+    max_samples_per_send: 1000
+    capacity: 2500
+  write_relabel_configs:
+    # drop high-cardinality label 'request_id' before sending long-term
+    - source_labels: [request_id]
+      regex: ".*"
+      action: drop
+  basic_auth:
+    username: "__token__"
+    password:
+      name: prometheus-remote-write-secret
+      key: token
+
*** End Patch
*** Begin Patch
*** Add File:observability/prometheus/relabeling_example.yaml
+# Example scrape_config relabeling snippet to reduce cardinality at scrape time
+relabel_configs:
+- source_labels: [__meta_kubernetes_pod_label_model_id]
+  regex: "(.*)"
+  target_label: "model_id"
+  action: replace
+- source_labels: [model_id]
+  regex: ".*"
+  action: keep
+- source_labels: [user_id]
+  regex: ".*"
+  action: labelmap
+# Drop request_id label to reduce cardinality
+- source_labels: [request_id]
+  regex: ".*"
+  action: labeldrop
+
*** End Patch
*** Begin Patch
*** Add File:docs/PRODUCTIONIZE_FEAST_README.md
+# Feast productionization checklist for Aegis
+
+1) Install helm chart (helm/feast) with values-production.yaml after filling MODEL_ARTIFACT_BUCKET and redis creds.
+2) Provision Redis cluster (bitnami or managed), create redis-creds secret.
+3) Install Kafka (Strimzi) and Kafka Connect (with HTTP sink plugin for feast-stream).
+4) Deploy feast-stream-processor with replicas and readiness probes; use ServiceMonitor to collect metrics.
+5) Configure Prometheus recording rules and SLOs:
+   - P95 lookup latency < 50ms
+   - Error rate < 0.1%
+6) Add Prometheus alerts and ServiceLevel objects; integrate to PagerDuty.
+7) Run load test (benchmarks/redis_latency_bench.py) and iterate sizing.
+
*** End Patch
*** Begin Patch
*** Add File:docs/SECURE_INFERENCE_GUIDE.md
+# Secure inference roadmap and guidance (Aegis)
+
+1) Evaluate libraries: CrypTen (PyTorch), TF-Encrypted (TensorFlow), Microsoft SEAL (HE), TenSEAL, OpenMined stacks.
+2) Replace PoC wrappers with vetted library pipelines and CI tests:
+   - Add unit/integration tests that measure latency & accuracy on representative payloads.
+3) For HE/MPC: pre-evaluate model size & latency tradeoffs. Consider hybrid approach:
+   - Use CrypTen or TF-Encrypted for low-latency models where supported.
+   - Use HE for very small models or aggregate-only queries.
+4) Add attestation and secure channel: require SPIRE-issued identities and Vault short-lived keys for clients that request secure inference.
+
*** End Patch
*** Begin Patch
*** Add File:docs/DR_RUNBOOK.md
+# DR Runbook (Aegis)
+
+1) Backup schedule:
+   - Postgres dump: daily
+   - MinIO snapshots: daily incremental, weekly full
+   - Redis RDB/AOF: periodic snapshot + replication
+2) Restore drill:
+   - Run ops/dr/restore_and_verify.sh with latest tarball
+   - Validate MLflow API, sample model artifact load, and run a sample inference
+3) Run monthly DR drill: automate via Argo (ops/dr/argo_dr_test.yaml)
+4) Acceptance: RTO < configured SLA, and evidence of verification saved in EVIDENCE_BUCKET
+
*** End Patch
*** Begin Patch
*** Add File:ci/production_full_checks.yml
+name: Aegis Full Production Checks
+on:
+  workflow_dispatch:
+jobs:
+  infra-checks:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run Redis & Feast bench
+        run: |
+          pip install redis
+          python3 benchmarks/redis_latency_bench.py --host redis-headless.aegis.svc --port 6379 --duration 30 --qps 200
+      - name: Submit Argo DR test
+        run: |
+          argo submit ops/dr/argo_dr_test.yaml -n aegis --watch
+
*** End Patch
*** End Patch
