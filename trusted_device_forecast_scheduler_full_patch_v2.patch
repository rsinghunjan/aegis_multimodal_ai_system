*** Begin Patch
*** Add File: provider/onboarding/operator_playbook.md
+```markdown
+# Provider Onboarding Operator Playbook
+
+Purpose:
+- Guide operators through onboarding a new provider that will supply signed energy attestations.
+
+Steps:
+1. Pre-engagement
+  - Share `provider/onboarding/PROVIDER_CONTRACT_TEMPLATE.md` with procurement/legal.
+  - Agree S3 path or HTTPS POST endpoint, signing method (cosign), Rekor server and public key exchange.
+
+2. Technical onboarding
+  - Ask provider to publish a signed attestation sample (see `provider/onboarding/provider_attestation_example.json`).
+  - Provider should run: `provider/onboarding/provider_sign_attestation.sh provider_attestation_example.json s3://<bucket>/provider/`
+
+3. Operator ingestion test
+  - On operator side, run ingestion test:
+    - Ensure provider ingestion service (`provider/attestations_service.py`) is reachable.
+    - Run `python provider/onboarding/ingestion_test.py` against ingestion endpoint.
+  - Verify returned `attestation_id`, Rekor evidence and DB record.
+
+4. Reconciliation validation
+  - After ingest, run reconciliation script (see `provider/onboarding/reconcile_attestation_with_ledger.py`) to compare attested energy vs measured ledger.
+  - Review discrepancies and follow up with provider.
+
+5. SLA & monitoring
+  - Ensure monitoring alerts trigger if provider attestation not received within SLA window (15 minutes).
+  - Record contact info in trusted-source registry.
+
+6. Go-live
+  - After a 2-week pilot and reconciliation sign-off, mark provider as "trusted" in `trusted-source-registry`.
+
+Notes:
+- Keep provider signing keys out of CI. Verify Rekor entries for auditability.
+```
+
*** End Patch
*** Begin Patch
*** Add File: provider/onboarding/email_template.md
+```markdown
+Subject: Aegis Provider Onboarding — Energy Attestation Integration
+
+Hi <Provider Contact>,
+
+We're preparing to onboard your energy attestation feed into Aegis for carbon accounting.
+Please provide:
+- JSON attestation format (see sample attached)
+- Method of delivery: S3 path or HTTPS POST endpoint
+- Signing mechanism: cosign-signed blobs and Rekor entries (preferred)
+- Contact details for incident response
+
+We require hourly attestations signed with cosign and published within 5 minutes of period_end. Please confirm and provide a test attestation.
+
+Thanks,
+<Operator>
+```
+
*** End Patch
*** Begin Patch
*** Add File: provider/onboarding/reconcile_attestation_with_ledger.py
+#!/usr/bin/env python3
+"""
+Reconcile a provider attestation (S3 key or attestation_id) with job ledger measured energy.
+Usage: python reconcile_attestation_with_ledger.py --attestation-id 123
+"""
+import os, json, argparse
+from sqlalchemy import create_engine, text
+import boto3
+
+DB_URL = os.environ.get("DATABASE_URL", "postgresql://aegis:aegis@localhost:5432/aegis")
+S3_BUCKET = os.environ.get("ATTEST_S3_BUCKET", "aegis-provider-attestations")
+engine = create_engine(DB_URL)
+
+def fetch_attestation(att_id):
+    with engine.connect() as conn:
+        row = conn.execute(text("SELECT * FROM provider_attestations WHERE id=:id"), {"id": att_id}).first()
+        return dict(row._mapping) if row else None
+
+def reconcile(att):
+    # Very simple reconciliation: sum measured job kWh in the attestation time window
+    meta = att.get("metadata",{})
+    period_start = meta.get("raw",{}).get("period_start")
+    period_end = meta.get("raw",{}).get("period_end")
+    provider = att.get("provider")
+    if not period_start or not period_end:
+        print("No period metadata; cannot reconcile")
+        return
+    with engine.connect() as conn:
+        q = text("SELECT job_id, SUM((payload->>'kwh')::float) as measured_kwh FROM job_events WHERE event='measured' AND ts >= :start AND ts <= :end GROUP BY job_id")
+        rows = conn.execute(q, {"start": period_start, "end": period_end}).fetchall()
+        total_measured = sum([r.measured_kwh for r in rows]) if rows else 0.0
+    att_kwh = meta.get("raw",{}).get("energy_kwh")
+    print("Attestation kWh:", att_kwh, "Measured kWh (sum):", total_measured)
+    print("Discrepancy (attested - measured):", (att_kwh or 0.0) - total_measured)
+
+if __name__=="__main__":
+    p=argparse.ArgumentParser()
+    p.add_argument("--attestation-id", type=int, required=True)
+    args=p.parse_args()
+    att = fetch_attestation(args.attestation_id)
+    if not att:
+        print("No attestation found"); raise SystemExit(2)
+    reconcile(att)
+
*** End Patch
*** Begin Patch
*** Add File: provider/onboarding/procurement_checklist.md
+```markdown
+# Provider Procurement Checklist
+
+Before contract:
+- Confirm required fields & JSON schema (sample provided).
+- Agree on S3 path or HTTPS POST endpoint and credentials.
+- Agree on signing method: cosign + Rekor preferred.
+- Define SLA: max_age_minutes=15, availability=99.9%, latency requirement.
+- Define support/incident contacts and rotation policy for signing keys.
+
+Operational checks:
+- Ensure provider can sign sample and upload to agreed path.
+- Run ingestion test and reconciliation with pilot data.
+- Verify Rekor evidence for signed blobs.
+- Confirm monthly reconciliation reporting cadence.
+
+Security:
+- Confirm provider will not publish private keys; exchange public keys out-of-band.
+- Agree on key rotation notice period.
+
+Audit:
+- Provider will supply raw meter logs on request for auditors (within 90 days) or agree to impersonation tests.
+```
+
*** End Patch
*** Begin Patch
*** Add File: helm/device-rollout/Chart.yaml
+apiVersion: v2
+name: aegis-device-rollout
+description: Umbrella chart for PDU exporter, device registry and calibration job
+type: application
+version: 0.1.0
+appVersion: "1.0"
+
*** End Patch
*** Begin Patch
*** Add File: helm/device-rollout/values.yaml
+pduExporter:
+  image:
+    repository: aegis/pdu-exporter
+    tag: latest
+  mapping: |
+    {
+      "device-1": {"node":"node-1","rack":"rack-a","ipmi_host":"10.0.0.1"}
+    }
+deviceRegistry:
+  image:
+    repository: aegis/device-registry
+    tag: latest
+calibration:
+  image:
+    repository: aegis/calibration
+    tag: latest
+serviceMonitor:
+  enabled: true
+  namespace: monitoring
+
*** End Patch
*** Begin Patch
*** Add File: helm/device-rollout/templates/pdu-daemonset.yaml
+apiVersion: apps/v1
+kind: DaemonSet
+metadata:
+  name: aegis-pdu-exporter
+spec:
+  selector:
+    matchLabels:
+      app: aegis-pdu-exporter
+  template:
+    metadata:
+      labels:
+        app: aegis-pdu-exporter
+    spec:
+      containers:
+        - name: pdu-exporter
+          image: "{{ .Values.pduExporter.image.repository }}:{{ .Values.pduExporter.image.tag }}"
+          args: ["--mapping-file=/etc/aegis/device_mapping.json", "--interval=15"]
+          volumeMounts:
+            - name: mapping
+              mountPath: /etc/aegis
+      volumes:
+        - name: mapping
+          configMap:
+            name: aegis-device-mapping
+
*** End Patch
*** Begin Patch
*** Add File: helm/device-rollout/templates/device-registry-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-device-registry
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-device-registry
+  template:
+    metadata:
+      labels:
+        app: aegis-device-registry
+    spec:
+      containers:
+        - name: device-registry
+          image: "{{ .Values.deviceRegistry.image.repository }}:{{ .Values.deviceRegistry.image.tag }}"
+          ports:
+            - containerPort: 8123
+
*** End Patch
*** Begin Patch
*** Add File: helm/device-rollout/templates/calibration-job.yaml
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: aegis-calibration-job
+spec:
+  template:
+    spec:
+      containers:
+        - name: calibrate
+          image: "{{ .Values.calibration.image.repository }}:{{ .Values.calibration.image.tag }}"
+          command: ["/bin/sh","-c"]
+          args: ["python /opt/scripts/calibrate_and_validate.py"]
+      restartPolicy: Never
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/device_rollout_ci.yml
+name: Device Rollout CI (deploy + calibrate + coverage)
+on:
+  workflow_dispatch:
+
+jobs:
+  deploy-and-calibrate:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Setup Helm & Kubectl
+        run: |
+          curl -fsSL https://get.helm.sh/helm-v3.8.0-linux-amd64.tar.gz -o /tmp/helm.tgz
+          tar -xzf /tmp/helm.tgz -C /tmp && sudo mv /tmp/linux-amd64/helm /usr/local/bin/helm
+          curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
+          chmod +x kubectl; sudo mv kubectl /usr/local/bin/
+      - name: Deploy helm chart
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG }}
+        run: |
+          helm upgrade --install aegis-device-rollout helm/device-rollout -n aegis --create-namespace
+      - name: Wait for calibration job and run coverage report
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG }}
+          DATABASE_URL: ${{ secrets.DATABASE_URL }}
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+        run: |
+          kubectl wait --for=condition=complete job/aegis-calibration-job -n aegis --timeout=300s || true
+          # run coverage report (requires DB access)
+          python measurement/coverage_report.py || true
+
*** End Patch
*** Begin Patch
*** Add File: forecast/retrain_pipeline_ci.py
+#!/usr/bin/env python3
+"""
+CI wrapper to retrain Prophet model, backtest and gate promotion.
+ - Retrain model for region
+ - Run backtest via backtest_calibrate.py
+ - If backtest PI coverage and MAE meet thresholds, save model and register in model_registry
+ - Otherwise, abort and upload report
+"""
+import os, subprocess, json
+from forecast.prophet_pipeline import train_and_backtest, save_model
+from forecast.model_registry import register_model
+from datetime import datetime
+
+REGION = os.environ.get("REGION", "US")
+MAE_THRESHOLD = float(os.environ.get("MAE_THRESHOLD", "10.0"))
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+
+def run():
+    res = train_and_backtest(REGION)
+    if not res:
+        print("no history; abort")
+        raise SystemExit(2)
+    mae = res.get("mae")
+    print("Backtest MAE:", mae)
+    if mae is None or mae > MAE_THRESHOLD:
+        print("MAE too high; abort and upload report")
+        # assume backtest_calibrate wrote report
+        raise SystemExit(2)
+    model_path = save_model(res["model"], REGION)
+    model_id = register_model(model_path, REGION, mae)
+    print("Registered model", model_id, "path", model_path)
+    # operator may run deployment using model_id
+
+if __name__=="__main__":
+    run()
+
*** End Patch
*** Begin Patch
*** Add File: forecast/rollback_on_increase.py
+#!/usr/bin/env python3
+"""
+Check active model performance and rollback if MAE increased after promotion.
+ - Compare latest monitor MAE to previous active model MAE in registry
+ - If degradation beyond threshold, mark previous model active (rollback)
+"""
+import os, json
+from forecast.model_registry import list_models, rollback_to
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+REGION = os.environ.get("REGION", "US")
+MAE_DELTA_THRESHOLD = float(os.environ.get("MAE_DELTA_THRESHOLD", "1.2"))  # multiplicative
+
+def latest_active():
+    models = list_models(REGION)
+    for m in models:
+        if m.get("active")=="true":
+            return m
+    return None
+
+def main():
+    # read latest monitor from compliance bucket (best effort)
+    # Here we simply compare registry entries: active vs previous
+    models = list_models(REGION)
+    if len(models) < 2:
+        print("not enough models to compare"); return
+    active = models[0]
+    previous = models[1]
+    try:
+        active_mae = float(active.get("mae") or 0.0)
+        prev_mae = float(previous.get("mae") or 0.0)
+    except Exception:
+        print("missing mae info"); return
+    if active_mae > prev_mae * MAE_DELTA_THRESHOLD:
+        print("Degradation detected: rolling back to previous model", previous.get("id"))
+        rollback_to(previous.get("id"))
+    else:
+        print("No rollback necessary")
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/prophet_retrain_and_gate.yml
+name: Prophet Retrain & Gate
+on:
+  schedule:
+    - cron: "0 3 * * *" # daily
+  workflow_dispatch:
+
+jobs:
+  retrain:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup
+        run: |
+          python -m pip install --upgrade pip
+          pip install -r requirements.txt || true
+      - name: Run retrain and gate
+        env:
+          REGION: "US"
+          MAE_THRESHOLD: "10.0"
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+        run: |
+          python forecast/retrain_pipeline_ci.py
+      - name: On success, notify operator to deploy model
+        if: success()
+        run: echo "Retrain passed. Operator to deploy model via model_registry."
+
*** End Patch
*** Begin Patch
*** Add File: forecast/grafana_mae_panel.json
+{
+  "title": "Forecast MAE (by region)",
+  "panels": [
+    {
+      "type": "stat",
+      "title": "MAE US",
+      "targets": [{"expr": "forecast_mae{region=\"US\"}"}]
+    }
+  ]
+}
+
*** End Patch
*** Begin Patch
*** Add File: scheduler/redis_queue.py
+#!/usr/bin/env python3
+"""
+Redis-backed sorted set queue for delayed retries and backoff.
+Uses ZADD for scheduling next_try timestamp and ZPOPMIN to pop due items.
+Each item is JSON: {job, attempts}
+"""
+import os, json, time
+import redis
+from datetime import datetime
+
+REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
+r = redis.from_url(REDIS_URL)
+ZSET = "aegis:queue:zset"
+
+def push(job, score=None):
+    payload = json.dumps({"job": job, "attempts": 0})
+    ts = score or time.time()
+    r.zadd(ZSET, {payload: ts})
+
+def pop_due():
+    now = time.time()
+    res = r.zrangebyscore(ZSET, 0, now, start=0, num=1)
+    if not res:
+        return None
+    item = res[0]
+    # attempt to remove atomically
+    removed = r.zrem(ZSET, item)
+    if removed:
+        return json.loads(item)
+    return None
+
+def requeue_with_backoff(item, backoff_seconds):
+    item["attempts"] = item.get("attempts",0) + 1
+    next_ts = time.time() + backoff_seconds
+    r.zadd(ZSET, {json.dumps(item): next_ts})
+
+if __name__=="__main__":
+    # simple worker loop
+    while True:
+        it = pop_due()
+        if not it:
+            time.sleep(1); continue
+        job = it["job"]
+        # call scheduler adapter
+        import requests
+        try:
+            resp = requests.post(os.environ.get("SCHEDULER_ADAPTER_URL","http://localhost:8200/schedule"), json=job, timeout=10)
+            if resp.status_code == 200:
+                print("Scheduled", job.get("job_id"))
+            else:
+                print("Throttled or failed, requeueing")
+                requeue_with_backoff(it, min(60*(2**it.get("attempts",0)), 3600))
+        except Exception as e:
+            requeue_with_backoff(it, 60)
+
*** End Patch
*** Begin Patch
*** Add File: scheduler/load_test_scenarios.py
+#!/usr/bin/env python3
+"""
+Generate heavy load scenarios for scheduler testing and produce a replay file.
+"""
+import json, random, os
+
+def gen_jobs(n=1000):
+    tenants = ["alpha","beta","gamma","delta"]
+    jobs=[]
+    for i in range(n):
+        jobs.append({"job_id": f"job-{i}", "tenant": random.choice(tenants), "kg": round(random.uniform(0.01, 2.0),3)})
+    return jobs
+
+if __name__=="__main__":
+    jobs = gen_jobs(int(os.environ.get("NUM_JOBS", "1000")))
+    out="/tmp/replay_jobs.json"
+    open(out,"w").write(json.dumps(jobs))
+    print("Wrote", out)
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/scheduler_load_test.yml
+name: Scheduler Load Test
+on:
+  workflow_dispatch:
+
+jobs:
+  generate-and-run:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Generate jobs
+        run: |
+          python scheduler/load_test_scenarios.py
+      - name: Run replay (concurrency=50)
+        env:
+          REPLAY_JOBS_FILE: /tmp/replay_jobs.json
+          ADMISSION_URL: ${{ secrets.ADMISSION_URL }}
+        run: |
+          pip install requests >/dev/null 2>&1 || true
+          python scheduler/replay_test.py
+      - name: Upload results
+        uses: actions/upload-artifact@v4
+        with:
+          name: replay-jobs
+          path: /tmp/replay_jobs.json
+
*** End Patch
*** Begin Patch
*** Add File: scheduler/backpressure_policy.md
+```markdown
+# Scheduler Backpressure & Soft-Throttle Policy
+
+Design:
+- Soft-throttle: when admission returns recommended throttle, scheduler enqueues job into Redis sorted-set queue with exponential backoff.
+- Hard-deny: admission returns denied -> job rejected and user notified.
+
+Backoff:
+- attempts 0 -> delay 30s
+- attempts 1 -> delay 60s
+- attempts 2 -> delay 120s
+- max delay 3600s
+
+Observability:
+- Track queue length, avg wait time, throttle counts per tenant.
+- Emit Prometheus metrics from queue worker.
+
+Recovery:
+- On throttle refill cron (monthly or dynamic) tokens are replenished in throttle_db; queue worker will resume scheduling.
+```
+
*** End Patch
*** Begin Patch
*** Add File: experiments/ab_audit.py
+#!/usr/bin/env python3
+"""
+Ensure A/B experiments include provenance and required metadata before promotion.
+This script verifies presence of sample-size, snapshot_id and attestation_ids and uploads audit note.
+"""
+import os, json, boto3
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+
+def run():
+    in_dir = "experiments/ab_inputs"
+    if not os.path.isdir(in_dir):
+        print("No AB inputs"); return
+    meta_path = os.path.join(in_dir,"meta.json")
+    if not os.path.exists(meta_path):
+        print("Missing meta.json with sample size and snapshot_id"); raise SystemExit(2)
+    meta = json.load(open(meta_path))
+    required = ["snapshot_id","min_sample_size"]
+    for r in required:
+        if r not in meta:
+            print("Missing", r); raise SystemExit(2)
+    # archive meta to compliance
+    out="/tmp/ab_meta_"+meta.get("model_id","manual")+".json"
+    open(out,"w").write(json.dumps(meta, indent=2))
+    if COMPLIANCE_BUCKET:
+        s3=boto3.client("s3"); s3.upload_file(out, COMPLIANCE_BUCKET, f"ab_meta/{os.path.basename(out)}")
+    print("AB audit archive created")
+
+if __name__=="__main__":
+    run()
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/package.json
+{
+  "name": "aegis-tenant-ui",
+  "version": "0.2.0",
+  "private": true,
+  "dependencies": {
+    "react": "^18.2.0",
+    "react-dom": "^18.2.0",
+    "axios": "^1.4.0",
+    "chart.js": "^4.3.0",
+    "react-chartjs-2": "^5.2.0"
+  },
+  "scripts": {
+    "start": "react-scripts start",
+    "build": "react-scripts build"
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/src/Auth.js
+import React, {useState} from 'react';
+
+function Auth({onAuth}) {
+  const [user,setUser] = useState('');
+  const [pw,setPw] = useState('');
+  const login = () => {
+    // simple fake auth for demo: store tenant in localStorage
+    localStorage.setItem('aegis_tenant', user || 'alice');
+    onAuth(localStorage.getItem('aegis_tenant'));
+  };
+  return (
+    <div style={{marginBottom:10}}>
+      <label>User: <input value={user} onChange={e=>setUser(e.target.value)} /></label>
+      <label> PW: <input type="password" value={pw} onChange={e=>setPw(e.target.value)} /></label>
+      <button onClick={login}>Login</button>
+    </div>
+  );
+}
+
+export default Auth;
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/src/TradeoffChart.js
+import React, {useEffect, useRef} from 'react';
+import { Chart, registerables } from 'chart.js';
+Chart.register(...registerables);
+
+function TradeoffChart({tenant}) {
+  const ref = useRef();
+  useEffect(()=>{
+    async function fetchData(){
+      const resp = await fetch(`/tenant/${tenant}/tradeoff`);
+      const j = await resp.json();
+      const ctx = ref.current.getContext('2d');
+      new Chart(ctx, {
+        type: 'bar',
+        data: {
+          labels: ['Cost (30d)', 'Carbon (30d kg)'],
+          datasets: [{label: tenant, data: [j.total_cost || 0, j.total_kg || 0], backgroundColor: ['#4caf50','#f44336']}]
+        }
+      });
+    }
+    fetchData();
+  },[tenant]);
+  return <canvas ref={ref} width={400} height={150}></canvas>
+}
+
+export default TradeoffChart;
+
*** End Patch
*** Begin Patch
*** Modify File: tenant-ui/src/App.js
@@
-import React, {useState, useEffect} from 'react';
-import WhatIf from './WhatIf';
-
-function App(){
-  const [tenant, setTenant] = useState('alice');
-  const [summary, setSummary] = useState(null);
-  const [jobId, setJobId] = useState('');
-  const [decision, setDecision] = useState(null);
-
-  useEffect(()=>{
-    fetch(`/tenant/${tenant}/tradeoff`).then(r=>r.json()).then(setSummary).catch(()=>setSummary(null));
-  },[tenant]);
-
-  const fetchDecision = () => {
-    if(!jobId) return;
-    fetch(`/decision/${jobId}`).then(r=>r.json()).then(setDecision).catch(()=>setDecision(null));
-  };
-
-  return (
-    <div style={{padding:20,fontFamily:'Arial'}}>
-      <h2>Aegis Tenant Showback & What‑If</h2>
-      <label>Tenant: <input value={tenant} onChange={e=>setTenant(e.target.value)} /></label>
-      <div style={{marginTop:10}}>
-        <h3>Summary</h3>
-        {summary ? (
-          <div>
-            <div>Cost (30d): {summary.total_cost}</div>
-            <div>Carbon (30d): {summary.total_kg}</div>
-            <div>Most used snapshot: {summary.most_used_snapshot}</div>
-          </div>
-        ) : <div>Loading...</div>}
-      </div>
-      <div style={{marginTop:20}}>
-        <h3>Decision Explainability</h3>
-        <label>Job ID: <input value={jobId} onChange={e=>setJobId(e.target.value)} /></label>
-        <button onClick={fetchDecision}>Fetch Decision</button>
-        {decision && <pre>{JSON.stringify(decision, null, 2)}</pre>}
-      </div>
-      <WhatIf tenant={tenant} />
-    </div>
-  );
-}
-
-export default App;
+import React, {useState, useEffect} from 'react';
+import WhatIf from './WhatIf';
+import TradeoffChart from './TradeoffChart';
+import Auth from './Auth';
+
+function App(){
+  const [tenant, setTenant] = useState(localStorage.getItem('aegis_tenant') || 'alice');
+  const [summary, setSummary] = useState(null);
+  const [jobId, setJobId] = useState('');
+  const [decision, setDecision] = useState(null);
+
+  useEffect(()=>{
+    fetch(`/tenant/${tenant}/tradeoff`).then(r=>r.json()).then(setSummary).catch(()=>setSummary(null));
+  },[tenant]);
+
+  const fetchDecision = () => {
+    if(!jobId) return;
+    fetch(`/decision/${jobId}`).then(r=>r.json()).then(setDecision).catch(()=>setDecision(null));
+  };
+
+  return (
+    <div style={{padding:20,fontFamily:'Arial'}}>
+      <h2>Aegis Tenant Showback & What‑If</h2>
+      <Auth onAuth={t=>setTenant(t)} />
+      <label>Tenant: <input value={tenant} onChange={e=>setTenant(e.target.value)} /></label>
+      <div style={{marginTop:10}}>
+        <h3>Summary</h3>
+        {summary ? (
+          <div>
+            <div>Cost (30d): {summary.total_cost}</div>
+            <div>Carbon (30d): {summary.total_kg}</div>
+            <div>Most used snapshot: {summary.most_used_snapshot}</div>
+            <h4>Tradeoff Chart</h4>
+            <TradeoffChart tenant={tenant} />
+          </div>
+        ) : <div>Loading...</div>}
+      </div>
+      <div style={{marginTop:20}}>
+        <h3>Decision Explainability</h3>
+        <label>Job ID: <input value={jobId} onChange={e=>setJobId(e.target.value)} /></label>
+        <button onClick={fetchDecision}>Fetch Decision</button>
+        {decision && <pre>{JSON.stringify(decision, null, 2)}</pre>}
+      </div>
+      <WhatIf tenant={tenant} />
+    </div>
+  );
+}
+
+export default App;
*** End Patch
