*** Begin Patch
*** Add File:helm/trino/values.yaml
+# Helm values for Trino (production-ready defaults; adapt to your infra)
+coordinator:
+  replicaCount: 2
+  resources:
+    requests:
+      cpu: 1000m
+      memory: 2Gi
+    limits:
+      cpu: 2000m
+      memory: 4Gi
+  env:
+    - name: JVM_EXTRA_OPTS
+      value: "-Xmx1g -Xms1g -XX:+UseG1GC"
+worker:
+  replicaCount: 3
+  resources:
+    requests:
+      cpu: 2000m
+      memory: 4Gi
+    limits:
+      cpu: 4000m
+      memory: 8Gi
+persistence:
+  enabled: true
+  storageClass: gp3
+  size: 50Gi
+service:
+  type: ClusterIP
+ingress:
+  enabled: false
+  annotations: {}
+# Catalogs are managed as files in /etc/trino/catalog. Mount secrets or use a ConfigMap.
+extraVolumes: []
+extraVolumeMounts: []
+# JVM and Trino tuning knobs
+config:
+  jvm:
+    extra_java_options: "-XX:+UseG1GC -Xms1g -Xmx2g"
+  coordinator:
+    http-server.http.port: 8080
+  discovery:
+    server: "http://trino-coordinator.aegis.svc.cluster.local:8080"
+
*** End Patch
*** Begin Patch
*** Add File:helm/superset/values.yaml
+# Helm values for Superset (production-ready suggestions)
+replicaCount: 3
+image:
+  repository: apache/superset
+  tag: latest
+service:
+  type: ClusterIP
+  port: 8088
+ingress:
+  enabled: false
+persistence:
+  enabled: true
+  storageClass: gp3
+  accessMode: ReadWriteOnce
+  size: 20Gi
+database:
+  # Use an external Postgres for production (set via secrets)
+  uriSecretName: superset-db-uri
+  uriSecretKey: DATABASE_URL
+resources:
+  requests:
+    cpu: 500m
+    memory: 1Gi
+  limits:
+    cpu: 2000m
+    memory: 4Gi
+worker:
+  enabled: true
+  replicas: 2
+  resources:
+    requests:
+      cpu: 500m
+      memory: 1Gi
+celery:
+  enabled: true
+  resources:
+    requests:
+      cpu: 200m
+      memory: 256Mi
+
*** End Patch
*** Begin Patch
*** Add File:helm/datahub/values.yaml
+# Helm values for DataHub GMS + MAE (production-ready)
+gms:
+  replicaCount: 2
+  resources:
+    requests:
+      cpu: 500m
+      memory: 1Gi
+    limits:
+      cpu: 2000m
+      memory: 4Gi
+mae:
+  enabled: true
+  replicas: 2
+  resources:
+    requests:
+      cpu: 500m
+      memory: 1Gi
+    limits:
+      cpu: 2000m
+      memory: 4Gi
+postgresql:
+  enabled: false
+  # For production, provide external Postgres DB via secrets
+ingestion:
+  # Kafka is recommended for large ingestion; you can use an S3 based ingestion pipeline too.
+  kafka:
+    enabled: false
+persistence:
+  enabled: true
+  storageClass: gp3
+  size: 50Gi
+service:
+  type: ClusterIP
+ingress:
+  enabled: false
+
*** End Patch
*** Begin Patch
*** Add File:trino/catalog/lakefs.properties
+# Trino catalog for lakeFS + S3
+# Place this file under /etc/trino/catalog/lakefs.properties in the Trino coordinator.
+# This example uses the Hive connector pointing at S3. For production prefer Glue metastore or Hive metastore.
+
+connector.name=hive-hadoop2
+# If you manage a Hive metastore (Glue): set metastore to AWS Glue (recommended)
+# hive.metastore=glue
+
+# If using an S3-backed Hive metastore (no Glue), ensure the catalog points to the data paths:
+hive.s3.aws-access-key=REPLACE_IF_NOT_USING_IRSA
+hive.s3.aws-secret-key=REPLACE_IF_NOT_USING_IRSA
+# Prefer IRSA or instance role; if so, remove the above keys.
+
+# The S3 endpoint prefix (optional, set when using lakeFS gateway)
+hive.s3.endpoint=https://s3.amazonaws.com
+
+# Set the warehouse location (lakeFS repo path or S3 prefix)
+hive.metastore.warehouse.dir=s3://REPLACE_EVIDENCE_BUCKET/lakefs-repo/
+
+# Optimize read path (Parquet)
+hive.parquet-predicate-pushdown=true
+hive.orc-predicate-pushdown=true
+
+# Recommended: throttle large queries by using resource groups / query queue outside this file.
+
*** End Patch
*** Begin Patch
*** Add File:superset/dashboards/sales_funnel_dashboard.json
+{
+  "dashboard_title": "Sales Funnel Overview",
+  "description": "Basic funnel: Visits -> Signups -> Purchases. Use Trino catalog to query partitioned Parquet.",
+  "charts": [
+    {
+      "slice_name": "Funnel Metrics",
+      "viz_type": "big_number_total",
+      "params": {
+        "metric": {"label": "visits", "expressionType": "SIMPLE"}
+      },
+      "query": {
+        "sql": "SELECT count(*) as visits FROM analytics.events WHERE event_date = current_date"
+      }
+    },
+    {
+      "slice_name": "Conversion Rate Over Time",
+      "viz_type": "line",
+      "query": {
+        "sql": "SELECT event_date, sum(case when event='purchase' then 1 else 0 end) as purchases, sum(case when event='visit' then 1 else 0 end) as visits FROM analytics.events WHERE event_date >= current_date - interval '30' day GROUP BY event_date ORDER BY event_date"
+      }
+    }
+  ],
+  "position_json": "{}"
+}
+
*** End Patch
*** Begin Patch
*** Add File:superset/dashboards/top_cooccurrences_chart.json
+{
+  "dashboard_title": "Top Co-occurring Items",
+  "description": "Shows top item pairs from transactions using Trino FP-growth output.",
+  "charts": [
+    {
+      "slice_name": "Top Pairs Table",
+      "viz_type": "table",
+      "query": {
+        "sql": "SELECT item_a, item_b, freq FROM mining.fp_rules ORDER BY freq DESC LIMIT 100"
+      },
+      "params": {
+        "page_length": 25
+      }
+    }
+  ],
+  "position_json": "{}"
+}
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/trino_query_cost_limit.yml
+name: Trino Query Cost Scan (PR check)
+
+on:
+  pull_request:
+    types: [opened, synchronize]
+
+jobs:
+  scan-sql:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Find changed SQL files
+        id: sql
+        run: |
+          git fetch origin main:main
+          CHANGED=$(git diff --name-only HEAD origin/main | grep -E '\.sql$' || true)
+          echo "changed_sql<<EOF" >> $GITHUB_OUTPUT
+          echo "$CHANGED" >> $GITHUB_OUTPUT
+          echo "EOF" >> $GITHUB_OUTPUT
+      - name: Scan SQL heuristics
+        if: steps.sql.outputs.changed_sql != ''
+        run: |
+          set -euo pipefail
+          CHANGED="${{ steps.sql.outputs.changed_sql }}"
+          echo "$CHANGED"
+          FAIL=0
+          for f in $CHANGED; do
+            echo "Analyzing $f"
+            if grep -Eiq "select \*|join .* on|cross join|full join|left join .* on" "$f"; then
+              echo "Warning: $f contains broad operations (SELECT * or JOINs). Ensure LIMIT / proper filters."
+            fi
+            if ! grep -Eiq "limit [0-9]+" "$f"; then
+              echo "Potential risk: $f does not include a LIMIT clause (no LIMIT found)"
+            fi
+            # Heuristic: if query mentions large tables, warn
+            if grep -Eiq "analytics\.events|transactions|raw_" "$f"; then
+              echo "Note: $f touches large tables; please add filters or sample in CI."
+            fi
+          done
+          if [ $FAIL -ne 0 ]; then
+            echo "SQL heuristics failed"
+            exit 2
+          fi
+
*** End Patch
*** Begin Patch
*** Add File:k8s/jobs/trino_query_limiter.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: trino-query-limiter
+  namespace: aegis
+spec:
+  schedule: "*/5 * * * *" # every 5 minutes
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          serviceAccountName: trino-admin
+          containers:
+            - name: trino-killer
+              image: ghcr.io/yourorg/trino-tools:latest
+              command: [ "/bin/bash", "/opt/scripts/trino_kill_long_queries.sh" ]
+              env:
+                - name: TRINO_COORDINATOR
+                  value: "http://trino-coordinator.aegis.svc.cluster.local:8080"
+                - name: TRINO_USER
+                  value: "query-killer"
+                - name: MAX_SECONDS
+                  value: "600" # kill queries running longer than 10 minutes
+              resources:
+                limits:
+                  cpu: "200m"
+                  memory: "200Mi"
+                requests:
+                  cpu: "100m"
+                  memory: "100Mi"
+          restartPolicy: OnFailure
+
*** End Patch
*** Begin Patch
*** Add File:scripts/trino_kill_long_queries.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Script to cancel Trino queries running longer than MAX_SECONDS.
+# Requires TRINO_COORDINATOR (http://host:8080) and a user with cancel privileges.
+#
+TRINO=${TRINO_COORDINATOR:-http://localhost:8080}
+USER=${TRINO_USER:-admin}
+MAX_SECS=${MAX_SECONDS:-600}
+
+echo "Querying Trino for running queries at $TRINO"
+# Trino has an endpoint /v1/query?id=... - some versions expose /v1/query for queries list via coordinator; adjust per version.
+# We'll use the /v1/query API to list queries. If not available, adapt to your Trino version (or use the EventListener plugin).
+QUERIES_JSON=$(curl -s "${TRINO}/v1/query" || echo "[]")
+if [ -z "$QUERIES_JSON" ] || [ "$QUERIES_JSON" = "[]" ]; then
+  echo "No running queries or cannot list queries via /v1/query. Exiting."
+  exit 0
+fi
+
+echo "$QUERIES_JSON" | jq -c '.[]' | while read -r q; do
+  id=$(echo "$q" | jq -r '.queryId')
+  state=$(echo "$q" | jq -r '.state')
+  elapsed=$(echo "$q" | jq -r '.elapsedTimeSeconds // 0')
+  user=$(echo "$q" | jq -r '.user // "unknown"')
+  if [ "$state" = "RUNNING" ] && [ "$elapsed" -ge "$MAX_SECS" ]; then
+    echo "Cancelling query $id (user=$user elapsed=${elapsed}s)"
+    curl -s -X DELETE "${TRINO}/v1/query/${id}"
+  fi
+done
+
+echo "Trino long-query killer run complete."
+
*** End Patch
*** Begin Patch
*** Add File:docker/spark/Dockerfile
+FROM openjdk:11-jre-slim
+ARG PYTHON_VERSION=3.10
+RUN apt-get update && apt-get install -y curl python${PYTHON_VERSION} python3-pip python3-dev netcat && rm -rf /var/lib/apt/lists/*
+RUN pip3 install pyspark boto3 mlflow pandas pyarrow
+# Copy Spark job artifacts
+COPY spark/ /opt/spark/jobs/
+# Entrypoint is flexible; image used for spark-submit driver/submit
+WORKDIR /opt/spark
+CMD ["bash"]
+
*** End Patch
*** Begin Patch
*** Add File:docker/flink/Dockerfile
+FROM python:3.10-slim
+RUN apt-get update && apt-get install -y curl wget && rm -rf /var/lib/apt/lists/*
+RUN pip install apache-flink pyflink boto3
+COPY flink/ /opt/flink/jobs/
+WORKDIR /opt/flink
+CMD ["bash"]
+
*** End Patch
*** Begin Patch
*** Add File:Makefile
+# Makefile to build and push job images for analysts/operators
+REGISTRY ?= ghcr.io/yourorg
+TAG ?= latest
+
+.PHONY: all spark flink
+all: spark flink
+
+spark:
+	docker build -t $(REGISTRY)/aegis-spark:$(TAG) -f docker/spark/Dockerfile docker
+	docker push $(REGISTRY)/aegis-spark:$(TAG)
+
+flink:
+	docker build -t $(REGISTRY)/aegis-flink:$(TAG) -f docker/flink/Dockerfile docker
+	docker push $(REGISTRY)/aegis-flink:$(TAG)
+
*** End Patch
*** End Patch
