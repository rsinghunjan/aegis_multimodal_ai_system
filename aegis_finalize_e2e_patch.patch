*** Begin Patch
*** Add File: scripts/e2e_run_and_verify.sh
+#!/usr/bin/env bash
+#
+# Run an Argo workflow (training) and verify produced artifact evidence end-to-end:
+# - submit provided Argo workflow YAML (or use an existing running workflow)
+# - wait for completion (or a short timeout)
+# - pull latest artifact from S3 prefix and ensure presence of:
+#   artifact.tar.gz, artifact.tar.gz.sig.json, artifact.tar.gz.attestation.json, artifact.tar.gz.sbom.json
+# - run cosign verify-blob (keyless if available) against artifact
+# - run verify_rekor_inclusion.sh against attestation.json
+#
+# Usage:
+#   export OBJECT_STORE_BUCKET=...
+#   export REKOR_URL=...
+#   export KUBECONFIG=...
+#   ./scripts/e2e_run_and_verify.sh path/to/argo_workflow.yaml
+set -euo pipefail
+
+WF_YAML="${1:-}"
+ARGO_NS="${ARGO_NS:-aegis}"
+BUCKET="${OBJECT_STORE_BUCKET:-}"
+REKOR_URL="${REKOR_URL:-}"
+TIMEOUT="${TIMEOUT:-600}"  # seconds to wait for workflow completion
+
+if [ -z "$BUCKET" ]; then
+  echo "OBJECT_STORE_BUCKET must be set" >&2
+  exit 2
+fi
+
+if [ -n "$WF_YAML" ]; then
+  echo "Submitting Argo workflow: $WF_YAML"
+  kubectl apply -f "$WF_YAML" -n "$ARGO_NS"
+  sleep 5
+fi
+
+# Find the most recent workflow in the namespace
+echo "Locating latest workflow in namespace $ARGO_NS"
+WF=$(kubectl get wf -n "$ARGO_NS" --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1:].metadata.name}' 2>/dev/null || true)
+if [ -z "$WF" ]; then
+  echo "No workflow found in namespace $ARGO_NS" >&2
+  exit 3
+fi
+echo "Found workflow: $WF"
+
+echo "Waiting for workflow to complete (timeout ${TIMEOUT}s)..."
+kubectl wait --for=condition=Completed "workflow/$WF" -n "$ARGO_NS" --timeout="${TIMEOUT}s" || {
+  echo "Workflow did not complete within timeout; fetching logs..." >&2
+  kubectl logs -n "$ARGO_NS" wf/"$WF" --all-containers || true
+  exit 4
+}
+
+echo "Workflow completed. Inspecting S3 for produced artifacts..."
+PREFIX="${ARTIFACT_PREFIX:-model-archives/}"
+OBJ=$(aws s3 ls "s3://${BUCKET}/${PREFIX}" --recursive | sort | tail -n 1 | awk '{print $4}')
+if [ -z "$OBJ" ]; then
+  echo "No artifacts found under s3://${BUCKET}/${PREFIX}" >&2
+  exit 5
+fi
+echo "Latest artifact key: ${OBJ}"
+
+ART_BASE="./e2e_artifact"
+mkdir -p "$ART_BASE"
+aws s3 cp "s3://${BUCKET}/${OBJ}" "$ART_BASE/artifact.tar.gz"
+for ext in ".sig.json" ".attestation.json" ".sbom.json"; do
+  KEY="${OBJ}${ext}"
+  if aws s3 ls "s3://${BUCKET}/${KEY}" >/dev/null 2>&1; then
+    aws s3 cp "s3://${BUCKET}/${KEY}" "$ART_BASE/$(basename ${KEY})"
+    echo "Downloaded evidence: ${KEY}"
+  else
+    echo "Missing evidence file: ${KEY}" >&2
+    exit 6
+  fi
+done
+
+echo "Running cosign verification (best-effort)"
+if command -v cosign >/dev/null 2>&1; then
+  SIG_B64="$(jq -r '.data.signature // empty' "$ART_BASE/$(basename ${OBJ}).sig.json" || true)"
+  if [ -n "$SIG_B64" ]; then
+    echo "$SIG_B64" | base64 -d > "$ART_BASE/sig.bin"
+    cosign verify-blob --keyless --signature "$ART_BASE/sig.bin" "$ART_BASE/artifact.tar.gz" || {
+      echo "cosign verification failed (non-zero). Check cosign environment or use --key pub.pem method](#)
î€€
