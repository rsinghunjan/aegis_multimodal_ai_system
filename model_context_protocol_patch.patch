*** Begin Patch
*** Add File:mcp_context/schema/mcp_context_v1.json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Aegis Model Context Protocol v1",
  "type": "object",
  "required": ["meta","model","input","generation","outputs","provenance"],
  "properties": {
    "meta": {
      "type": "object",
      "properties": {
        "run_id": { "type": "string" },
        "timestamp_utc": { "type": "string", "format": "date-time" },
        "tenant_id": { "type": ["string","null"] },
        "user_id": { "type": ["string","null"] },
        "request_id": { "type": "string" },
        "request_purpose": { "type": "string" }
      }
    },
    "model": {
      "type": "object",
      "properties": {
        "model_name": { "type": "string" },
        "model_version": { "type": "string" },
        "model_card_s3": { "type": ["string","null"] },
        "model_signature": { "type": ["string","null"] }
      }
    },
    "input": {
      "type": "object",
      "properties": {
        "input_pointer": { "type": ["string","null"] },
        "input_hash": { "type": ["string","null"] },
        "sanitized": { "type": "boolean" }
      }
    },
    "retrieval": {
      "type": "object",
      "properties": {
        "retrieved_docs": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "doc_id": { "type": "string" },
              "source": { "type": "string" },
              "snippet_pointer": { "type": ["string","null"] },
              "score": { "type": "number" }
            },
            "required": ["doc_id","source"]
          }
        },
        "retrieval_params": { "type": "object" }
      }
    },
    "generation": {
      "type": "object",
      "properties": {
        "prompt_template": { "type": ["string","null"] },
        "prompt_filled_pointer": { "type": ["string","null"] },
        "chain_of_thought_pointer": { "type": ["string","null"] },
        "tokens_generated": { "type": "integer" },
        "temperature": { "type": "number" },
        "top_p": { "type": "number" }
      }
    },
    "outputs": {
      "type": "object",
      "properties": {
        "output_pointer": { "type": ["string","null"] },
        "output_hash": { "type": ["string","null"] },
        "summary": { "type": ["string","null"] },
        "confidence": { "type": ["number","null"] }
      }
    },
    "tools": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "tool_name": { "type": "string" },
          "args_pointer": { "type": ["string","null"] },
          "result_pointer": { "type": ["string","null"] },
          "status": { "type": "string" }
        }
      }
    },
    "cost_and_carbon": {
      "type": "object",
      "properties": {
        "energy_wh": { "type": "number" },
        "co2e_kg": { "type": "number" },
        "compute_cost_usd": { "type": "number" },
        "metrics_source": { "type": ["string","null"] }
      }
    },
    "governance": {
      "type": "object",
      "properties": {
        "approval": {
          "type": "object",
          "properties": {
            "required": { "type": "boolean" },
            "request_id": { "type": ["string","null"] },
            "approved": { "type": ["boolean","null"] },
            "approver": { "type": ["string","null"] }
          }
        },
        "policy_checks": {
          "type": "array",
          "items": { "type": "object" }
        }
      }
    },
    "provenance": {
      "type": "object",
      "properties": {
        "training_data_snapshot": { "type": ["string","null"] },
        "mlflow_run_id": { "type": ["string","null"] },
        "audit_s3_key": { "type": ["string","null"] },
        "context_signature_s3": { "type": ["string","null"] }
      }
    },
    "diagnostics": {
      "type": "object",
      "properties": {
        "latency_ms": { "type": "number" },
        "warnings": { "type": "array", "items": { "type": "string" } },
        "fallback_used": { "type": "boolean" },
        "fallback_reason": { "type": ["string","null"] }
      }
    },
    "retention": {
      "type": "object",
      "properties": {
        "pii_mask_applied": { "type": "boolean" },
        "retention_ttl_days": { "type": "integer" },
        "encryption_kms_arn": { "type": ["string","null"] }
      }
    }
  }
}
*** End Patch
*** Begin Patch
*** Add File:mcp_context/middleware/requirements.txt
boto3
mlflow
requests
python-dateutil
python-multipart
*** End Patch
*** Begin Patch
*** Add File:mcp_context/middleware/context_middleware.py
#!/usr/bin/env python3
"""
Model Context Protocol middleware.

Usage:
 - Import MCPMiddleware into your inference service and call mcp = MCPMiddleware()
 - Wrap handler by calling mcp.capture_and_respond(request_meta, model_meta, input_payload, output_payload)
 - The middleware will:
    - generate run_id and timestamp
    - build a context JSON according to schema
    - upload context.json to S3 under audit/<run_id>/context.json (EVIDENCE_BUCKET)
    - sign the uploaded file with cosign if COSIGN_KEY present (awskms or file)
    - optionally post to model context registry (MODEL_CONTEXT_REGISTRY_URL)
    - tag MLflow run (if MLFLOW_TRACKING_URI set)
    - return the s3 pointer so calling service can include header "Run-Context-S3"
Notes:
 - This is best-effort: uploading/signing is performed in background thread to avoid added latency.
 - Do not include raw PII inline; provide input_pointer to a secure S3 location or redact.
"""
import os
import json
import uuid
import time
import threading
import tempfile
import subprocess
from datetime import datetime, timezone
from urllib.parse import urljoin
import boto3
import requests
import mlflow

EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "REPLACE_WITH_EVIDENCE_BUCKET")
AWS_REGION = os.environ.get("AWS_REGION", "us-west-2")
MODEL_CONTEXT_REGISTRY_URL = os.environ.get("MODEL_CONTEXT_REGISTRY_URL", "")
MLFLOW_TRACKING_URI = os.environ.get("MLFLOW_TRACKING_URI", "")
COSIGN_KEY = os.environ.get("COSIGN_KEY", "")  # awskms://... or path to key
REKOR_URL = os.environ.get("REKOR_URL", "")

if MLFLOW_TRACKING_URI:
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

s3 = boto3.client("s3", region_name=AWS_REGION)

def _sign_and_upload(local_path, s3_bucket, s3_key):
    """Signs local_path with cosign, uploads .sig to s3 and (best-effort) posts Rekor entry."""
    sig_local = local_path + ".sig"
    result = {"signed": False, "sig_s3": None, "rekor": None}
    if not COSIGN_KEY:
        return result
    try:
        cmd = ["cosign", "sign", "--key", COSIGN_KEY, local_path]
        proc = subprocess.run(cmd, capture_output=True, text=True, check=False)
        if proc.returncode != 0:
            # cosign failed; return without blocking
            result["error"] = proc.stderr
            return result
        if os.path.exists(sig_local):
            sig_s3_key = s3_key + ".sig"
            s3.upload_file(sig_local, s3_bucket, sig_s3_key)
            result["signed"] = True
            result["sig_s3"] = f"s3://{s3_bucket}/{sig_s3_key}"
            # best-effort Rekor post (operator should use Rekor CLI for canonical entries)
            if REKOR_URL:
                try:
                    payload = {"context": f"s3://{s3_bucket}/{s3_key}", "signature": result["sig_s3"]}
                    r = requests.post(urljoin(REKOR_URL, "/api/v1/log/entries"), json=payload, timeout=5)
                    if r.status_code in (200,201):
                        result["rekor"] = r.json()
                except Exception:
                    pass
    except Exception as e:
        result["error"] = str(e)
    return result

def _upload_context_and_process(ctx, s3_bucket, s3_key):
    # write local temp
    tmp = tempfile.mktemp(suffix=".json")
    with open(tmp, "w") as f:
        json.dump(ctx, f)
    # upload
    s3.upload_file(tmp, s3_bucket, s3_key)
    # sign and upload signature (best-effort)
    sig_res = _sign_and_upload(tmp, s3_bucket, s3_key)
    return {"s3": f"s3://{s3_bucket}/{s3_key}", "signature": sig_res}

class MCPMiddleware:
    def __init__(self, evidence_bucket=None, region=None, registry_url=None):
        self.evidence_bucket = evidence_bucket or EVIDENCE_BUCKET
        self.region = region or AWS_REGION
        self.registry_url = registry_url or MODEL_CONTEXT_REGISTRY_URL

    def _build_base_meta(self, tenant_id=None, user_id=None, request_id=None, purpose="inference"):
        return {
            "run_id": str(uuid.uuid4()),
            "timestamp_utc": datetime.now(timezone.utc).isoformat(),
            "tenant_id": tenant_id,
            "user_id": user_id,
            "request_id": request_id or str(uuid.uuid4()),
            "request_purpose": purpose
        }

    def _try_register(self, run_id, s3_key, model_name, model_version, signed=False, cosign_key=None, rekor_entry=None, metadata=None):
        if not self.registry_url:
            return None
        try:
            resp = requests.post(urljoin(self.registry_url, "/register"), json={
                "model_name": model_name,
                "version": model_version,
                "s3_key": s3_key,
                "signed": signed,
                "cosign_key": cosign_key,
                "rekor_entry": rekor_entry,
                "metadata": metadata or {}
            }, timeout=5)
            return resp.json()
        except Exception:
            return None

    def capture_and_respond(self, *,
                            tenant_id=None,
                            user_id=None,
                            request_id=None,
                            purpose="inference",
                            model_name=None,
                            model_version=None,
                            input_pointer=None,
                            input_hash=None,
                            sanitized=False,
                            retrieval=None,
                            prompt_template=None,
                            prompt_filled_pointer=None,
                            chain_of_thought_pointer=None,
                            tokens_generated=0,
                            temperature=None,
                            top_p=None,
                            output_pointer=None,
                            output_hash=None,
                            output_summary=None,
                            confidence=None,
                            tools=None,
                            cost_and_carbon=None,
                            approval=None,
                            mlflow_run_id=None,
                            diagnostics=None,
                            retention=None
                            ):
        """
        Build context JSON and upload async. Returns run_context_s3 pointer immediately (pointing to where the file will be).
        """
        meta = self._build_base_meta(tenant_id, user_id, request_id, purpose)
        ctx = {
            "meta": meta,
            "model": {
                "model_name": model_name,
                "model_version": model_version,
                "model_card_s3": None,
                "model_signature": None
            },
            "input": {
                "input_pointer": input_pointer,
                "input_hash": input_hash,
                "sanitized": bool(sanitized)
            },
            "retrieval": retrieval or {},
            "generation": {
                "prompt_template": prompt_template,
                "prompt_filled_pointer": prompt_filled_pointer,
                "chain_of_thought_pointer": chain_of_thought_pointer,
                "tokens_generated": tokens_generated,
                "temperature": temperature,
                "top_p": top_p
            },
            "outputs": {
                "output_pointer": output_pointer,
                "output_hash": output_hash,
                "summary": output_summary,
                "confidence": confidence
            },
            "tools": tools or [],
            "cost_and_carbon": cost_and_carbon or {},
            "governance": approval or {},
            "provenance": {
                "mlflow_run_id": mlflow_run_id
            },
            "diagnostics": diagnostics or {},
            "retention": retention or {}
        }
        run_id = meta["run_id"]
        s3_key = f"audit/{run_id}/context.json"
        s3_pointer = f"s3://{self.evidence_bucket}/{s3_key}"

        # perform background upload and signing
        def bg():
            try:
                res = _upload_context_and_process(ctx, self.evidence_bucket, s3_key)
                # update ctx provenance with signature reference if available
                ctx["provenance"]["audit_s3_key"] = res.get("s3")
                sig = res.get("signature", {})
                if sig.get("signed"):
                    ctx["provenance"]["context_signature_s3"] = sig.get("sig_s3")
                # final: re-upload enriched context to include provenance.signature
                tmp2 = tempfile.mktemp(suffix=".json")
                with open(tmp2, "w") as f:
                    json.dump(ctx, f)
                s3.upload_file(tmp2, self.evidence_bucket, s3_key)
                # register in registry (best-effort)
                self._try_register(run_id, f"s3://{self.evidence_bucket}/{s3_key}", model_name, model_version, signed=sig.get("signed", False), cosign_key=COSIGN_KEY, rekor_entry=sig.get("rekor"))
                # tag mlflow run if provided
                if mlflow and mlflow_run_id:
                    try:
                        client = mlflow.tracking.MlflowClient()
                        client.set_tag(mlflow_run_id, "run_context_s3", f"s3://{self.evidence_bucket}/{s3_key}")
                        if sig.get("signed"):
                            client.set_tag(mlflow_run_id, "run_context_signed", "true")
                    except Exception:
                        pass
            except Exception:
                # background best-effort; don't raise
                pass

        t = threading.Thread(target=bg, daemon=True)
        t.start()

        # return pointer immediately; calling service should include header or body field
        return {"run_id": run_id, "run_context_s3": s3_pointer}
*** End Patch
*** Begin Patch
*** Add File:mcp_context/registry/requirements.txt
fastapi
uvicorn[standard]
boto3
pydantic
jinja2
sqlalchemy
python-dotenv
*** End Patch
*** Begin Patch
*** Add File:mcp_context/registry/app.py
#!/usr/bin/env python3
"""
Model Context Registry - indexes run_id -> s3 key and provides search / retrieval APIs.

Lightweight sqlite-backed registry. Context JSON remains in S3 (EVIDENCE_BUCKET).
"""
import os
import sqlite3
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from datetime import datetime
import json
import boto3

DB_PATH = os.environ.get("MODEL_CONTEXT_REG_DB", "/data/model_context.db")
EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "REPLACE_WITH_EVIDENCE_BUCKET")
AWS_REGION = os.environ.get("AWS_REGION", "us-west-2")
s3 = boto3.client("s3", region_name=AWS_REGION)

def init_db():
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("""
    CREATE TABLE IF NOT EXISTS contexts (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      run_id TEXT UNIQUE,
      s3_key TEXT,
      model_name TEXT,
      model_version TEXT,
      tenant_id TEXT,
      created_at TEXT,
      metadata TEXT
    )""")
    conn.commit()
    conn.close()

init_db()
app = FastAPI(title="Aegis Model Context Registry")

class RegisterReq(BaseModel):
    run_id: str
    s3_key: str
    model_name: str = None
    model_version: str = None
    tenant_id: str = None
    metadata: dict = {}

@app.post("/register")
def register(req: RegisterReq):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    now = datetime.utcnow().isoformat() + "Z"
    try:
        c.execute("INSERT OR REPLACE INTO contexts (run_id,s3_key,model_name,model_version,tenant_id,created_at,metadata) VALUES(?,?,?,?,?,?,?)",
                  (req.run_id, req.s3_key, req.model_name, req.model_version, req.tenant_id, now, json.dumps(req.metadata or {})))
        conn.commit()
    finally:
        conn.close()
    return {"ok": True, "run_id": req.run_id, "s3_key": req.s3_key}

@app.get("/contexts/{run_id}")
def get_context(run_id: str):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    row = c.execute("SELECT run_id,s3_key,model_name,model_version,tenant_id,created_at,metadata FROM contexts WHERE run_id=?", (run_id,)).fetchone()
    conn.close()
    if not row:
        raise HTTPException(status_code=404, detail="not found")
    return {
        "run_id": row[0],
        "s3_key": row[1],
        "model_name": row[2],
        "model_version": row[3],
        "tenant_id": row[4],
        "created_at": row[5],
        "metadata": json.loads(row[6] or "{}")
    }

@app.get("/search")
def search(model_name: str = None, tenant_id: str = None, limit: int = 50):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    q = "SELECT run_id,s3_key,model_name,model_version,tenant_id,created_at FROM contexts WHERE 1=1"
    params = []
    if model_name:
        q += " AND model_name = ?"
        params.append(model_name)
    if tenant_id:
        q += " AND tenant_id = ?"
        params.append(tenant_id)
    q += " ORDER BY created_at DESC LIMIT ?"
    params.append(limit)
    rows = c.execute(q, params).fetchall()
    conn.close()
    out = []
    for r in rows:
        out.append({"run_id": r[0], "s3_key": r[1], "model_name": r[2], "model_version": r[3], "tenant_id": r[4], "created_at": r[5]})
    return out

@app.get("/contexts/{run_id}/download")
def download_context(run_id: str):
    rec = get_context(run_id)
    s3_key = rec["s3_key"]
    parsed = s3_key.replace("s3://","").split("/",1)
    bucket = parsed[0] if len(parsed)>1 else EVIDENCE_BUCKET
    key = parsed[1] if len(parsed)>1 else parsed[0]
    try:
        obj = s3.get_object(Bucket=bucket, Key=key)
        data = obj["Body"].read()
        return data.decode()
    except Exception as e:
        raise HTTPException(status_code=404, detail="context not found in s3")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=int(os.environ.get("MODEL_CONTEXT_REG_PORT", "8096")))
*** End Patch
*** Begin Patch
*** Add File:mcp_context/registry/ui/index.html
<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Aegis Model Context Registry</title>
  <style>body{font-family:Arial;margin:20px}pre{background:#f3f3f3;padding:10px}</style>
</head>
<body>
  <h1>Aegis Model Context Registry (Demo)</h1>
  <div>
    <label>Model name: <input id="model" /></label>
    <label>Tenant: <input id="tenant" /></label>
    <button onclick="search()">Search</button>
    <div id="results"></div>
  </div>
  <script>
    const API = window.__MODEL_CONTEXT_REG__ || "http://localhost:8096";
    async function search(){
      const model = document.getElementById('model').value;
      const tenant = document.getElementById('tenant').value;
      const q = new URLSearchParams();
      if(model) q.append('model_name', model);
      if(tenant) q.append('tenant_id', tenant);
      const r = await fetch(API + "/search?" + q.toString());
      const j = await r.json();
      const out = document.getElementById('results');
      out.innerHTML = '';
      j.forEach(row => {
        const d = document.createElement('div');
        d.innerHTML = `<h3>${row.model_name || 'unknown'} ${row.model_version || ''}</h3>
          <p>run_id: ${row.run_id}</p>
          <p>created: ${row.created_at}</p>
          <a href="${API}/contexts/${row.run_id}/download" target="_blank">View context</a>`;
        out.appendChild(d);
      });
    }
  </script>
</body>
</html>
*** End Patch
*** Begin Patch
*** Add File:mcp_context/gatekeeper/constraint_require_run_context.yaml
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: requireruncontext
spec:
  crd:
    spec:
      names:
        kind: RequireRunContext
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package requireruncontext
        violation[{"msg": msg}] {
          input.review.object.kind == "Deployment"
          containers := input.review.object.spec.template.spec.containers
          # If the deployment is labeled as inference service, require annotation linking run context
          labels := input.review.object.metadata.labels
          labels["aegis.role"] == "inference"
          not input.review.object.metadata.annotations["aegis.run_context_required"]
          msg := "Inference Deployment must include annotation 'aegis.run_context_required' to indicate run context pointer is enforced"
        }
*** End Patch
*** Begin Patch
*** Add File:mcp_context/runbooks/README.md
# Model Context Protocol (MCPx) Runbook

This folder contains middleware, a registry and gating templates to add Model Context Protocol capabilities to Aegis.

Quick operator checklist:
1. Configure environment variables:
   - EVIDENCE_BUCKET (S3)
   - AWS_REGION
   - MODEL_CONTEXT_REGISTRY_URL (optional)
   - MLFLOW_TRACKING_URI (optional)
   - COSIGN_KEY (optional for signing run contexts)
   - REKOR_URL (optional)
2. Deploy Model Context Registry:
   - Build/push image for mcp_context/registry/app.py and deploy to aegis namespace (port 8096).
   - Expose via internal ingress or service.
3. Integrate middleware:
   - Add mcp_context/middleware/context_middleware.py to inference and agent runtimes.
   - Use mcp = MCPMiddleware() and call mcp.capture_and_respond(...) after inference generation to get run_context pointer.
   - Include the returned run_context_s3 pointer in API response headers: `Run-Context-S3: s3://...`
4. Ensure S3 path permissions:
   - Create s3 prefix audit/ and ensure the inference service role can put objects there.
5. Gatekeeper:
   - Apply requireruncontext ConstraintTemplate and create a Constraint instance in Gatekeeper to enforce annotation for your inference namespace.
6. Verify:
   - Run an inference and check Model Context Registry for registration and S3 content.
   - Confirm cosign signature uploaded (if COSIGN_KEY provided).
7. Retention & privacy:
   - Configure retention TTL and ensure sensitive data is redacted before storing.
8. Audit & UI:
   - Use registry UI (mcp_context/registry/ui) to browse contexts for audits and investigations.

Notes:
- The middleware performs upload and signing asynchronously; it returns the pointer immediately to avoid latency impacts.
- Do not store raw PII in the context JSON; provide pointers to redacted artifacts or store only hashes when required.
*** End Patch
*** End Patch
