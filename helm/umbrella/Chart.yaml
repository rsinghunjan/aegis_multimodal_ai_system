*** Begin Patch
*** Add File: helm/umbrella/Chart.yaml
+apiVersion: v2
+name: aegis-umbrella
+description: Umbrella chart that deploys PDU exporter, device registry and calibration job for staging
+type: application
+version: 0.1.0
+appVersion: "1.0"
+dependencies:
+  - name: aegis-pdu-exporter
+    version: "0.1.0"
+    repository: "file://../pdu-exporter"
+  - name: aegis-device-rollout
+    version: "0.1.0"
+    repository: "file://../device-rollout"
+
*** End Patch
*** Begin Patch
*** Add File: helm/umbrella/values.yaml
+pduExporter:
+  image:
+    repository: aegis/pdu-exporter
+    tag: latest
+
+deviceRegistry:
+  image:
+    repository: aegis/device-registry
+    tag: latest
+
+calibration:
+  image:
+    repository: aegis/calibration
+    tag: latest
+
+serviceMonitor:
+  enabled: true
+  namespace: monitoring
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/staging_deploy_and_validate.yml
+name: Deploy Device Rollout to Staging & Run Calibration
+on:
+  workflow_dispatch:
+
+jobs:
+  deploy-and-validate:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Setup Helm & Kubectl
+        run: |
+          curl -fsSL https://get.helm.sh/helm-v3.8.0-linux-amd64.tar.gz -o /tmp/helm.tgz
+          tar -xzf /tmp/helm.tgz -C /tmp && sudo mv /tmp/linux-amd64/helm /usr/local/bin/helm
+          curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
+          chmod +x kubectl; sudo mv kubectl /usr/local/bin/
+
+      - name: Helm dependency update
+        run: helm dependency update helm/umbrella
+
+      - name: Deploy umbrella chart to staging
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG_STAGING }}
+        run: |
+          helm upgrade --install aegis-umbrella helm/umbrella -n aegis-staging --create-namespace
+          kubectl rollout status deployment/aegis-device-registry -n aegis-staging --timeout=120s || true
+
+      - name: Wait for calibration job to complete
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG_STAGING }}
+        run: |
+          kubectl wait --for=condition=complete job/aegis-calibration-job -n aegis-staging --timeout=300s || true
+
+      - name: Run coverage & calibration reports (CI-run)
+        env:
+          DATABASE_URL: ${{ secrets.DATABASE_URL_STAGING }}
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+        run: |
+          python measurement/coverage_report.py
+          python telemetry/calibration_runner.py
+
+      - name: Upload reports as artifacts
+        uses: actions/upload-artifact@v4
+        with:
+          name: calibration-reports
+          path: /tmp/calibration_full_report.json
+
*** End Patch
*** Begin Patch
*** Add File: model/model_registry_api.py
+#!/usr/bin/env python3
+"""
+HTTP API for model registry actions: list, register, activate, rollback.
+Wraps forecast.model_registry functions for operator automation/CI.
+"""
+import os, json
+from flask import Flask, request, jsonify
+from forecast.model_registry import register_model, list_models, mark_active, rollback_to
+from datetime import datetime
+
+app = Flask("model-registry-api")
+
+@app.route("/models/register", methods=["POST"])
+def api_register():
+    j = request.json or {}
+    s3 = j.get("s3_path")
+    region = j.get("region")
+    mae = j.get("mae")
+    if not s3 or not region:
+        return jsonify({"error":"s3_path and region required"}), 400
+    mid = register_model(s3, region, mae)
+    return jsonify({"model_id": mid})
+
+@app.route("/models/list/<region>", methods=["GET"])
+def api_list(region):
+    return jsonify(list_models(region))
+
+@app.route("/models/activate", methods=["POST"])
+def api_activate():
+    j = request.json or {}
+    mid = j.get("model_id")
+    if not mid:
+        return jsonify({"error":"model_id required"}), 400
+    mark_active(mid)
+    return jsonify({"ok": True})
+
+@app.route("/models/rollback/<int:model_id>", methods=["POST"])
+def api_rollback(model_id):
+    rollback_to(model_id)
+    return jsonify({"rolled_back_to": model_id})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT","8202")))
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/model_promotion_monitor.yml
+name: Model Promotion Monitor & Auto-Rollback
+on:
+  workflow_dispatch:
+    inputs:
+      region:
+        required: true
+      monitor_minutes:
+        required: true
+        default: 30
+      mae_threshold:
+        required: true
+        default: 1.2
+
+jobs:
+  monitor:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install deps
+        run: pip install boto3 requests
+      - name: Run promotion monitor
+        env:
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+          MODEL_REGISTRY_API: ${{ secrets.MODEL_REGISTRY_API }}
+        run: |
+          python model/model_promotion_monitor.py --region "${{ github.event.inputs.region }}" --minutes "${{ github.event.inputs.monitor_minutes }}" --mae-mult "${{ github.event.inputs.mae_threshold }}"
+
*** End Patch
*** Begin Patch
*** Add File: model/model_promotion_monitor.py
+#!/usr/bin/env python3
+"""
+Poll live forecast monitor for a short window after promotion. If live MAE exceeds threshold ratio vs prior MAE, trigger rollback via model_registry_api.
+"""
+import os, time, argparse, json, requests, boto3
+from datetime import datetime
+
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+MODEL_REGISTRY_API = os.environ.get("MODEL_REGISTRY_API")  # e.g. https://model-registry.svc
+
+def fetch_live_mae(region):
+    s3 = boto3.client("s3")
+    key = f"forecast_monitor/prophet_monitor_{region}.json"
+    tmp = f"/tmp/prophet_monitor_{region}.json"
+    try:
+        s3.download_file(COMPLIANCE_BUCKET, key, tmp)
+        j = json.load(open(tmp))
+        return j.get("mae")
+    except Exception:
+        return None
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--region", required=True)
+    p.add_argument("--minutes", type=int, default=30)
+    p.add_argument("--mae-mult", type=float, default=1.2)
+    args = p.parse_args()
+    end = time.time() + args.minutes * 60
+    last_mae = None
+    while time.time() < end:
+        mae = fetch_live_mae(args.region)
+        if mae:
+            last_mae = mae
+            print("live mae:", mae)
+            break
+        time.sleep(30)
+    if not last_mae:
+        print("no live mae; exiting")
+        return
+    # get previous model MAE via registry
+    r = requests.get(f"{MODEL_REGISTRY_API}/models/list/{args.region}")
+    if r.status_code != 200:
+        print("failed to query registry"); return
+    models = r.json()
+    if len(models) < 2:
+        print("not enough models"); return
+    prev = models[1]
+    prev_mae = float(prev.get("mae") or 0.0)
+    print("prev_mae:", prev_mae, "live:", last_mae)
+    if last_mae > prev_mae * args.mae_mult:
+        print("Triggering rollback to previous model id", prev.get("id"))
+        rb = requests.post(f"{MODEL_REGISTRY_API}/models/rollback/{prev.get('id')}")
+        print("rollback response:", rb.status_code, rb.text)
+    else:
+        print("No rollback necessary")
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: scheduler/redis_queue_consumer.py
+#!/usr/bin/env python3
+"""
+Redis-backed sorted-set consumer with Prometheus metrics.
+Pops due items, calls scheduler adapter, and requeues with exponential backoff on throttle.
+"""
+import os, json, time, redis, requests
+from prometheus_client import start_http_server, Counter, Gauge
+from datetime import datetime
+
+REDIS_URL = os.environ.get("REDIS_URL", "redis://redis:6379/0")
+ZSET = "aegis:queue:zset"
+r = redis.from_url(REDIS_URL)
+ADAPTER = os.environ.get("SCHEDULER_ADAPTER_URL","http://scheduler-adapter.aegis.svc:8200/schedule")
+
+# Prometheus metrics
+PROCESSED = Counter("aegis_queue_processed_total", "Total jobs processed")
+REQUEUED = Counter("aegis_queue_requeued_total", "Total jobs requeued")
+THROTTLED = Counter("aegis_queue_throttled_total", "Total throttle events")
+QUEUE_LEN = Gauge("aegis_queue_length", "Current queue length")
+
+def pop_due():
+    now = int(time.time())
+    items = r.zrangebyscore(ZSET, 0, now, start=0, num=1)
+    if not items:
+        return None
+    item = items[0]
+    if r.zrem(ZSET, item):
+        return json.loads(item)
+    return None
+
+def requeue(item, delay):
+    item["attempts"] = item.get("attempts",0) + 1
+    r.zadd(ZSET, {json.dumps(item): int(time.time()) + delay})
+    REQUEUED.inc()
+
+def update_queue_len():
+    try:
+        QUEUE_LEN.set(r.zcard(ZSET))
+    except Exception:
+        pass
+
+def main():
+    start_http_server(int(os.environ.get("METRICS_PORT", "9103")))
+    while True:
+        update_queue_len()
+        it = pop_due()
+        if not it:
+            time.sleep(1); continue
+        job = it
+        try:
+            resp = requests.post(ADAPTER, json=job, timeout=10)
+            if resp.status_code == 200:
+                PROCESSED.inc()
+                print("Scheduled", job.get("job_id"))
+            elif resp.status_code == 429:
+                THROTTLED.inc()
+                print("Adapter throttled, requeue")
+                requeue(job, min(60*(2**job.get("attempts",0)), 3600))
+            else:
+                print("Adapter error", resp.status_code)
+        except Exception as e:
+            print("Exception", e)
+            requeue(job, 60)
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: grafana/redis_queue_dashboard.json
+{
+  "title": "Aegis Scheduler Queue (Redis ZSET)",
+  "panels": [
+    {
+      "type": "stat",
+      "title": "Queue Length",
+      "targets": [{"expr": "aegis_queue_length"}]
+    },
+    {
+      "type": "graph",
+      "title": "Processed / Requeued",
+      "targets": [
+        {"expr": "increase(aegis_queue_processed_total[5m])", "legendFormat": "processed"},
+        {"expr": "increase(aegis_queue_requeued_total[5m])", "legendFormat": "requeued"}
+      ]
+    },
+    {
+      "type": "graph",
+      "title": "Throttle events",
+      "targets": [{"expr": "increase(aegis_queue_throttled_total[5m])"}]
+    }
+  ]
+}
+
*** End Patch
*** Begin Patch
*** Add File: docs/load_test_report_template.md
+# Scheduler Load Test Report
+
+Test metadata:
+- Test name:
+- Date:
+- Cluster / environment:
+- Number of jobs generated:
+- Concurrency:
+- Duration:
+
+Key metrics:
+- Total requests:
+- Successful schedules:
+- Throttles (429):
+- Average latency (ms):
+- P95 latency (ms):
+- Max queue length:
+- Average queue delay:
+
+Observations:
+- Any failures / error messages
+- Resource utilization (CPU, memory) of admission, scheduler adapter, redis
+- Recommendations and tuning notes
+
+Attachments:
+- /tmp/stress_results.json
+- Grafana dashboard snapshots
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/scheduler_load_test_and_report.yml
+name: Scheduler Load Test & Report
+on:
+  workflow_dispatch:
+    inputs:
+      num_jobs:
+        default: "500"
+      concurrency:
+        default: "50"
+
+jobs:
+  run-load-test:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install deps
+        run: pip install requests redis
+      - name: Generate load and run stress test
+        env:
+          NUM_JOBS: ${{ github.event.inputs.num_jobs }}
+          CONCURRENCY: ${{ github.event.inputs.concurrency }}
+          ADMISSION_URL: ${{ secrets.ADMISSION_URL }}
+          SCHEDULER_SUBMIT: ${{ secrets.SCHEDULER_SUBMIT }}
+        run: |
+          python scheduler/load_test_scenarios.py
+          python scheduler/stress_test_runner.py
+      - name: Upload raw results
+        uses: actions/upload-artifact@v4
+        with:
+          name: stress-results
+          path: /tmp/stress_results.json
+      - name: Add load test report template
+        uses: actions/upload-artifact@v4
+        with:
+          name: load-test-report-template
+          path: docs/load_test_report_template.md
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/src/TimeSeriesChart.js
+import React, {useEffect, useRef} from 'react';
+import { Line } from 'react-chartjs-2';
+import 'chartjs-adapter-date-fns';
+
+function TimeSeriesChart({region='US', hours=48}) {
+  const [data, setData] = React.useState(null);
+
+  useEffect(()=>{
+    fetch(`/forecast?region=${region}&hours=${hours}`).then(r=>r.json()).then(j=>{
+      const fc = j.forecast || [];
+      const labels = fc.map(e=>e.ts);
+      const pred = fc.map(e=>e.pred);
+      const lower = fc.map(e=>e.lower);
+      const upper = fc.map(e=>e.upper);
+      setData({
+        labels,
+        datasets: [
+          { label: 'Prediction', data: pred, borderColor: '#1976d2', fill: false },
+          { label: 'Lower', data: lower, borderColor: '#90caf9', borderDash: [5,5], fill: '+1' },
+          { label: 'Upper', data: upper, borderColor: '#f48fb1', borderDash: [5,5], fill: false }
+        ]
+      });
+    }).catch(()=>setData(null));
+  },[region,hours]);
+
+  if(!data) return <div>Loading forecast...</div>;
+  return <div style={{width: '100%', height: 300}}><Line data={data} /></div>;
+}
+
+export default TimeSeriesChart;
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/src/WhatIf.js
+import React, {useState} from 'react';
+import axios from 'axios';
+
+function WhatIf({tenant}) {
+  const [estKg, setEstKg] = useState(1.0);
+  const [options, setOptions] = useState(null);
+  const [token, setToken] = useState(localStorage.getItem('aegis_token'));
+
+  const simulate = async () => {
+    try {
+      const resp = await axios.post(`/recommend/${tenant}`, {estimated_kgco2e: estKg, flexible: true}, {headers: token ? {Authorization: 'Bearer '+token} : {}});
+      setOptions(resp.data.recommendation ? [resp.data.recommendation] : []);
+    } catch(e) {
+      setOptions([{error: e.message}]);
+    }
+  };
+
+  return (
+    <div style={{marginTop:20}}>
+      <h3>Whatâ€‘If: Defer Simulation</h3>
+      <div>
+        <label>Estimated kgCO2e: <input type="number" value={estKg} onChange={e=>setEstKg(parseFloat(e.target.value))} /></label>
+        <button onClick={simulate}>Simulate</button>
+      </div>
+      <div>
+        {options && options.map((o,i)=>(<pre key={i}>{JSON.stringify(o,null,2)}</pre>))}
+      </div>
+    </div>
+  );
+}
+
+export default WhatIf;
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/src/Login.js
+import React, {useState} from 'react';
+import axios from 'axios';
+
+function Login({onAuth}) {
+  const [user,setUser] = useState('');
+  const [error,setError] = useState(null);
+  async function login(){
+    try {
+      const r = await axios.post('/auth/login',{user});
+      const token = r.data.token;
+      localStorage.setItem('aegis_token', token);
+      onAuth(user);
+    } catch(e){
+      setError(e.message);
+    }
+  }
+  return (
+    <div>
+      <input placeholder="username" value={user} onChange={e=>setUser(e.target.value)} />
+      <button onClick={login}>Login</button>
+      {error && <div style={{color:'red'}}>{error}</div>}
+    </div>
+  );
+}
+export default Login;
+
*** End Patch
*** Begin Patch
*** Update File: tenant-ui/src/App.js
@@
-import React, {useState, useEffect} from 'react';
-import WhatIf from './WhatIf';
-import TradeoffChart from './TradeoffChart';
-import Auth from './Auth';
+import React, {useState, useEffect} from 'react';
+import WhatIf from './WhatIf';
+import TradeoffChart from './TradeoffChart';
+import Login from './Login';
+import TimeSeriesChart from './TimeSeriesChart';
@@
-      <Auth onAuth={t=>setTenant(t)} />
+      <Login onAuth={t=>setTenant(t)} />
@@
-            <h4>Tradeoff Chart</h4>
-            <TradeoffChart tenant={tenant} />
+            <h4>Tradeoff Chart</h4>
+            <TradeoffChart tenant={tenant} />
+            <h4>Forecast (next 48h)</h4>
+            <TimeSeriesChart region="US" hours={48} />
*** End Patch
