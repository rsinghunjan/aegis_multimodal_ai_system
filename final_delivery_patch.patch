*** Begin Patch
*** Add File: scripts/run_full_gate_and_deploy.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# run_full_gate_and_deploy.sh
+# Operator script that:
+#  - dispatches the orchestrator GH workflow (Agentic chaos 3× → Edge rotation → Quantum reconcile → RLHF pilot)
+#  - downloads artifacts, validates key reports
+#  - deploys a small device cohort via Ansible and triggers enroll
+#  - triggers quantum reconcile after operator submits provider jobs
+#  - downloads and uploads artifacts to COMPLIANCE_BUCKET
+#
+# Usage:
+#   COMPLIANCE_BUCKET=my-bucket KUBECONFIG=~/.kube/staging \
+#     ANSIBLE_INVENTORY=inventory/devices.ini DEVICE_SSH_USER=ubuntu \
+#     ./scripts/run_full_gate_and_deploy.sh
+
+COMPLIANCE_BUCKET=${COMPLIANCE_BUCKET:-}
+KUBECONFIG=${KUBECONFIG:-$HOME/.kube/config}
+ANSIBLE_INVENTORY=${ANSIBLE_INVENTORY:-inventory/devices.ini}
+DEVICE_SSH_USER=${DEVICE_SSH_USER:-root}
+BRANCH=${BRANCH:-main}
+ANSIBLE_PLAYBOOK=edge/device_deploy/ansible/deploy_tpm2_tools.yml
+
+info(){ echo; echo "=== $*"; echo; }
+err(){ echo "ERROR: $*" >&2; exit 2; }
+
+for cmd in gh aws kubectl ansible-playbook jq; do
+  if ! command -v "$cmd" >/dev/null 2>&1; then
+    err "$cmd CLI required but not installed"
+  fi
+done
+
+if [ -z "$COMPLIANCE_BUCKET" ]; then
+  echo "WARNING: COMPLIANCE_BUCKET not set — artifact upload will be skipped."
+fi
+
+info "1) Dispatching Run Production Orchestrator workflow"
+gh workflow run run_production_orchestrator.yml --ref "${BRANCH}" -f branch="${BRANCH}"
+sleep 4
+
+RUN_ID=$(gh run list --workflow run_production_orchestrator.yml --limit 1 --json database --jq '.[0].database' 2>/dev/null || true)
+if [ -z "$RUN_ID" ]; then
+  RUN_ID=$(gh run list --workflow run_production_orchestrator.yml --limit 1 | awk 'NR==1{print $1}' || true)
+fi
+[ -n "$RUN_ID" ] || err "Cannot determine orchestrator run id"
+
+info "Watching orchestrator run id=${RUN_ID} (this will block)"
+if ! gh run watch "$RUN_ID" --exit-status; then
+  echo "Orchestrator run finished with non-zero conclusion; continue to download artifacts for triage."
+fi
+
+TMP_ORCH=$(mktemp -d /tmp/orch_artifacts_XXXX)
+info "Downloading orchestrator artifacts to $TMP_ORCH"
+gh run download "$RUN_ID" -D "$TMP_ORCH" || true
+
+info "Check for chaos summary and reconcile reports"
+find "$TMP_ORCH" -type f -iname '*chaos*summary*.json' -print -quit || true
+find "$TMP_ORCH" -type f -iname '*reconcile*.json' -print -quit || true
+
+orch_conclusion=$(gh run view "$RUN_ID" --json conclusion --jq .conclusion 2>/dev/null || echo "unknown")
+if echo "$orch_conclusion" | grep -Eiq "failure|cancelled|timed_out"; then
+  err "Orchestrator concluded with issues (${orch_conclusion}). Inspect artifacts in ${TMP_ORCH} and S3://$COMPLIANCE_BUCKET/"
+fi
+
+info "2) Deploying device cohort (Ansible)"
+[ -f "$ANSIBLE_INVENTORY" ] || err "Ansible inventory not found at $ANSIBLE_INVENTORY"
+info "Running Ansible playbook: ${ANSIBLE_PLAYBOOK}"
+ansible-playbook -i "${ANSIBLE_INVENTORY}" "${ANSIBLE_PLAYBOOK}"
+
+info "Triggering enroll_ondevice.py on devices via Ansible ad-hoc (group: devices)"
+ansible -i "${ANSIBLE_INVENTORY}" devices -m shell -a "sudo python3 /opt/device_agent/enroll_ondevice.py" || echo "Enroll step had partial failures; inspect output"
+
+info "Allow time for devices to upload attestations (sleep 30s)"
+sleep 30
+
+if [ -n "$COMPLIANCE_BUCKET" ]; then
+  info "Listing attestation evidence in s3://${COMPLIANCE_BUCKET}/attestations and s3://${COMPLIANCE_BUCKET}/hsm/"
+  aws s3 ls "s3://${COMPLIANCE_BUCKET}/attestations/" --recursive || echo "No attestations prefix found"
+  aws s3 ls "s3://${COMPLIANCE_BUCKET}/hsm/" --recursive || echo "No hsm prefix found"
+fi
+
+info "3) Operator: please submit one real QPU job per provider now (press ENTER when done)"
+echo "Examples (operator):"
+echo "  python3 quantum/staging/submit_and_wait.py --backend ibm --qasm /path/sample.qasm --tenant staging"
+echo "  # Or use your provider submit scripts as required"
+read -p "Press ENTER after submitting provider jobs"
+
+info "4) Dispatch quantum_full_prod_reconcile.yml to ingest receipts and reconcile"
+gh workflow run quantum_full_prod_reconcile.yml --ref "${BRANCH}"
+sleep 3
+QR_RUN_ID=$(gh run list --workflow quantum_full_prod_reconcile.yml --limit 1 --json database --jq '.[0].database' 2>/dev/null || true)
+if [ -z "$QR_RUN_ID" ]; then
+  QR_RUN_ID=$(gh run list --workflow quantum_full_prod_reconcile.yml --limit 1 | awk 'NR==1{print $1}' || true)
+fi
+[ -n "$QR_RUN_ID" ] || err "Cannot determine quantum reconcile run id"
+info "Watching quantum reconcile run id=${QR_RUN_ID}"
+if ! gh run watch "$QR_RUN_ID" --exit-status; then
+  echo "Quantum reconcile finished with non-zero conclusion; fetch artifacts."
+fi
+Q_TMP=$(mktemp -d /tmp/quantum_artifacts_XXXX)
+gh run download "$QR_RUN_ID" -D "$Q_TMP" || true
+info "Downloaded quantum artifacts to $Q_TMP"
+
+ANOMALIES=$(find "$Q_TMP" -type f -iname '*reconcile*.json' -exec jq '.anomalies | length' {} + 2>/dev/null | awk '{s+=$1}END{print s+0}')
+if [ -n "$ANOMALIES" ] && [ "$ANOMALIES" -gt 0 ]; then
+  err "Quantum reconcile reported anomalies (count=${ANOMALIES}). Inspect ${Q_TMP} and s3://$COMPLIANCE_BUCKET/quantum/reconcile/"
+fi
+
+info "5) Dispatch RLHF production pilot (requires previous steps OK)"
+gh workflow run rlhf_prod_pilot.yml --ref "${BRANCH}" -f profile=pilot_medium
+sleep 3
+RLHF_RUN_ID=$(gh run list --workflow rlhf_prod_pilot.yml --limit 1 --json database --jq '.[0].database' 2>/dev/null || true)
+if [ -z "$RLHF_RUN_ID" ]; then
+  RLHF_RUN_ID=$(gh run list --workflow rlhf_prod_pilot.yml --limit 1 | awk 'NR==1{print $1}' || true)
+fi
+[ -n "$RLHF_RUN_ID" ] || err "Cannot determine RLHF run id"
+info "Watching RLHF run id=${RLHF_RUN_ID}"
+if ! gh run watch "$RLHF_RUN_ID" --exit-status; then
+  echo "RLHF run completed with non-zero conclusion; download artifacts for inspection."
+fi
+R_TMP=$(mktemp -d /tmp/rlhf_artifacts_XXXX)
+gh run download "$RLHF_RUN_ID" -D "$R_TMP" || true
+info "Downloaded RLHF artifacts to $R_TMP"
+
+CKPT=$(find "$R_TMP" -type f -iname '*.tar.gz' -print -quit || true)
+if [ -n "$CKPT" ]; then
+  info "Running checkpoint restore test on $CKPT"
+  python3 rl/checkpoint_restore_test.py --ckpt "$CKPT" || err "Checkpoint restore test failed"
+fi
+
+if [ -f "scripts/adversarial_harness_enhanced.py" ]; then
+  info "Running adversarial harness check"
+  python3 scripts/adversarial_harness_enhanced.py || err "Adversarial harness failed"
+fi
+
+info "Uploading artifacts to S3 (if COMPLIANCE_BUCKET configured)"
+if [ -n "$COMPLIANCE_BUCKET" ]; then
+  aws s3 cp "$TMP_ORCH" "s3://${COMPLIANCE_BUCKET}/orchestrator/${RUN_ID}/" --recursive || true
+  aws s3 cp "$Q_TMP" "s3://${COMPLIANCE_BUCKET}/quantum/${QR_RUN_ID}/" --recursive || true
+  aws s3 cp "$R_TMP" "s3://${COMPLIANCE_BUCKET}/rlhf/${RLHF_RUN_ID}/" --recursive || true
+  info "Artifacts uploaded to s3://${COMPLIANCE_BUCKET}/"
+else
+  echo "No COMPLIANCE_BUCKET set; skipping uploads."
+fi
+
+info "Full gate and device cohort deploy complete."
+echo "Artifacts (local): $TMP_ORCH, $Q_TMP, $R_TMP"
+echo "If any step failed, inspect those directories and s3://$COMPLIANCE_BUCKET/ for details."
+
*** End Patch
*** Begin Patch
*** Add File: docs/pr_and_git_commands.md
+## PR + Git Commands to push the orchestrator branch and open the PR
+
+Use these exact commands from your local repo root to create a branch, stage the orchestrator and autonomy files, push them, and open a PR.
+
+1) Create branch and stage files
+
+```bash
+git checkout -b feat/prod-orchestrator
+
+# If you generated files via patch apply, they should exist already.
+# Stage the orchestrator + scripts + docs files added by the patch:
+git add orchestrator/production_orchestrator.py .github/workflows/run_production_orchestrator.yml orchestrator/README.md \
+    scripts/run_full_gate_and_deploy.sh docs/pr_and_git_commands.md runbooks/one_page_checklist.md \
+    ml/anomaly ml remediation governance k8s || true
+
+git commit -m "chore(prod): add production orchestrator, operator run script, PR commands and checklist"
+git push --set-upstream origin feat/prod-orchestrator
+```
+
+2) Create the PR (use gh)
+
+```bash
+gh pr create --title "chore(prod): add production orchestrator & operator run scripts" --body-file - <<'PRBODY'
+This PR adds:
+- orchestrator/production_orchestrator.py and GH workflow to run it (Run Production Orchestrator)
+- scripts/run_full_gate_and_deploy.sh — operator single-script to run gate + deploy device cohort
+- ml/anomaly (anomaly detector prototype) and remediation assistant scaffolds (assistant_agent, webhook, executor)
+- docs/pr_and_git_commands.md (this file) and runbooks/one_page_checklist.md (operator checklist)
+
+Purpose:
+Sequence the production gate: Agentic chaos (3 runs) → Edge rotation drill → Quantum reconcile → RLHF pilot.
+Operator-run device cohort deploys and enrollment are included. All artifact upload locations are s3://<COMPLIANCE_BUCKET>/...
+
+Notes for reviewers:
+- Ensure GitHub secrets set: COMPLIANCE_BUCKET, PROM_URL, KUBECONFIG_STAGING, AWS creds, GITHUB_TOKEN
+- This PR is intended to be reviewed by ops, security and ML teams.
+PRBODY
+
+# Add reviewers and labels (adjust handles to real teams)
+gh pr edit --add-reviewer ops-team --add-reviewer security --add-label production,automation
+```
+
+3) After PR is created
+ - Assign reviewers from Ops, Security and ML.
+ - Run CI workflows in staging with the secrets configured.
+ - Merge only after at least one SRE and one security reviewer approve.
+
*** End Patch
*** Begin Patch
*** Add File: runbooks/one_page_checklist.md
+# Production Gate — One‑Page Checklist (printable)
+
+Project: Aegis  
+Gate: Full Production Gate — Agentic → Edge → Quantum → Generative  
+Operator: ______________________    Date/time start: _______________
+
+Prechecks
+- [ ] gh CLI authenticated (run `gh auth status`)
+- [ ] AWS creds configured and COMPLIANCE_BUCKET set: s3://________________
+- [ ] KUBECONFIG for staging available: __________________
+- [ ] Operators & SRE on call (names): __________________
+- [ ] Vault operator token available for provider secrets (if needed)
+
+1) Agentic chaos (3 runs)
+- Command:
+  gh workflow run agentic_full_chaos_sequence.yml --ref main -f runs=3 -f duration=600 -f namespace=aegis
+- Monitor:
+  gh run watch <run-id>
+- Artifacts:
+  - Local download: /tmp/agentic_chaos_run/
+  - S3: s3://<COMPLIANCE_BUCKET>/chaos/<artifact>.tgz
+  - Required file: chaos_summary.json
+- Acceptance:
+  - chaos_summary.json: stuck_tx_ids == [] AND fatal_errors == []
+
+2) Adapter tuning & rollout
+- Commands:
+  PROM_URL=<prom> python3 participant/adapter_timeout_tuner.py
+  KUBECONFIG=<kubeconfig> python3 agentic/auto_tuner_apply.py
+- Verify:
+  kubectl -n aegis rollout status deploy -l app=example-tool-adapter
+
+3) Edge device cohort deploy & enroll
+- Ansible deploy:
+  ansible-playbook -i <ANSIBLE_INVENTORY> edge/device_deploy/ansible/deploy_tpm2_tools.yml
+- Enroll devices:
+  ansible -i <ANSIBLE_INVENTORY> devices -m shell -a "sudo python3 /opt/device_agent/enroll_ondevice.py"
+- Artifacts:
+  - s3://<COMPLIANCE_BUCKET>/attestations/
+  - s3://<COMPLIANCE_BUCKET>/hsm/rotation_*.json
+  - Rekor entries (URL/ID)
+- Acceptance:
+  - Each device has attestation in S3 or Rekor entry
+
+4) Edge rotation drill
+- Command:
+  gh workflow run edge_rotation_drill_ci.yml --ref main -f total_devices=500
+- Artifacts:
+  - s3://<COMPLIANCE_BUCKET>/hsm/rotation_*.json
+- Acceptance:
+  - Canary enrolls succeed and evidence uploaded; critical outage <1%
+
+5) Quantum provider job submissions & reconcile
+- Operator submit examples:
+  python3 quantum/staging/submit_and_wait.py --backend ibm --qasm /path/sample.qasm --tenant staging
+- Trigger reconcile:
+  gh workflow run quantum_full_prod_reconcile.yml --ref main
+- Artifacts:
+  - s3://<COMPLIANCE_BUCKET>/provider_receipts/<provider>/
+  - s3://<COMPLIANCE_BUCKET>/quantum/reconcile/v4/quantum_reconcile_v4_*.json
+- Acceptance:
+  - reconcile report: anomalies == 0 OR remediation tickets created & assigned
+
+6) Generative RLHF pilot
+- Launch:
+  gh workflow run rlhf_prod_pilot.yml --ref main -f profile=pilot_medium
+- Artifacts:
+  - RLHF checkpoint tar (.tar.gz) in GH artifacts or MLflow
+  - s3://<COMPLIANCE_BUCKET>/rlhf/<run>/
+- Local checks:
+  - python3 rl/checkpoint_restore_test.py --ckpt <ckpt>
+  - python3 scripts/adversarial_harness_enhanced.py
+  - python3 scripts/ensure_cosign_signed.py --artifact <ckpt> --pubkey /path/pubkey.pem
+- Acceptance:
+  - checkpoint restore OK; adversarial harness OK; cosign verify OK; billing_reconcile no anomalies
+
+7) Final evidence upload
+- Command:
+  python3 scripts/upload_runbook_evidence.py --paths "/tmp/*_artifacts/*" --bucket <COMPLIANCE_BUCKET>
+- Verify S3 paths:
+  - s3://<COMPLIANCE_BUCKET>/chaos/
+  - s3://<COMPLIANCE_BUCKET>/orchestrator/<run-id>/
+  - s3://<COMPLIANCE_BUCKET>/hsm/
+  - s3://<COMPLIANCE_BUCKET>/quantum/reconcile/
+  - s3://<COMPLIANCE_BUCKET>/rlhf/
+  - s3://<COMPLIANCE_BUCKET>/pen_tests/
+  - s3://<COMPLIANCE_BUCKET>/backups/approvals_*.db
+
+Post-run
+- If any [FAIL], capture DB snapshot, pod logs, upload to S3, and open incident ticket in GitHub with artifact links.
+- Document run summary in runbooks/reports/ e.g., chaos_run_<ts>.json, rlhf_pilot_<ts>.json
+
+Operator signature: ______________________   Date/time end: _______________
+
*** End Patch
