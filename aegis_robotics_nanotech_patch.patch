*** Begin Patch
*** Add File:edge/edge_runtime/RTOS_REALTIME_NOTES.md
+# Real-time & Edge Runtime Notes (Aegis)
+
+This document summarizes recommendations for real-time controllers and on-device runtimes when using Aegis for robotics and nanotechnology.
+
+Key points:
+- Use Real-time Linux or an RTOS for the control loop host. Isolate CPU cores for deterministic scheduling.
+- Microcontrollers / NPUs / FPGAs should run low-latency kernels (TFLite, ONNX-RT, TVM generated kernels / FINN).
+- Ensure signed model and firmware delivery via OTA. Use HSM-backed signatures for all artifacts.
+- Keep a small local feature cache on NVMe for lookups needed by plannersâ€”persist manifests to object store and sign.
+
+Ops checklist:
+- Reserve CPU cores for controller threads and disable power-saving on those cores.
+- Configure NIC affinity and disable interrupt balancing for tight latencies.
+- Use lightweight telemetry protocol (protobuf over UDP or RTPS/ROS2) to move high-rate sensor data off device when possible.
+
*** End Patch
*** Begin Patch
*** Add File:edge/edge_agent/ota_verify.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# OTA verify helper for edge agent.
+# Downloads artifact, verifies signature (via model signing helper) and installs if valid.
+#
+ARTIFACT_URL=${1:-}
+SIG_URL=${2:-}
+WORKDIR=${WORKDIR:-/var/lib/aegis/ota}
+mkdir -p "$WORKDIR"
+
+if [ -z "$ARTIFACT_URL" ] || [ -z "$SIG_URL" ]; then
+  echo "Usage: ota_verify.sh <artifact_url> <signature_url>"
+  exit 2
+fi
+
+echo "Downloading artifact and signature..."
+curl -sSL "$ARTIFACT_URL" -o "$WORKDIR/artifact.bin"
+curl -sSL "$SIG_URL" -o "$WORKDIR/artifact.sig"
+
+echo "Verifying signature..."
+python3 - <<'PY'
+import sys, subprocess, json
+try:
+    from production.policy.signing.sign_with_retry import verify_signature
+except Exception as e:
+    print("sign_with_retry not available; attempt using vendor verify or exit", e)
+    sys.exit(3)
+ok, meta = verify_signature(open("/var/lib/aegis/ota/artifact.bin","rb").read(), open("/var/lib/aegis/ota/artifact.sig","rb").read())
+print("Signature verification:", ok, meta)
+if not ok:
+    sys.exit(4)
+PY
+
+echo "Signature valid. Installing artifact (operator should replace with real install steps)."
+# Placeholder installation
+mv "$WORKDIR/artifact.bin" /opt/aegis/installed/artifact-$(date -u +%Y%m%dT%H%M%SZ).bin
+echo "Installed artifact to /opt/aegis/installed/"
+
*** End Patch
*** Begin Patch
*** Add File:data/trace_schema.json
+{
+  "$schema": "http://json-schema.org/draft-07/schema#",
+  "title": "Aegis Sequence-First Trace Schema",
+  "type": "object",
+  "required": ["episode_id","device_id","steps","manifest"],
+  "properties": {
+    "episode_id": {"type":"string"},
+    "device_id": {"type":"string"},
+    "firmware_version": {"type":"string"},
+    "calibration_id": {"type":"string"},
+    "sim_flag": {"type":"boolean"},
+    "seed": {"type":"integer"},
+    "manifest": {
+      "type":"object",
+      "properties": {
+        "created_at": {"type":"string","format":"date-time"},
+        "checksum": {"type":"string"},
+        "format": {"type":"string"}
+      }
+    },
+    "steps": {
+      "type": "array",
+      "items": {
+        "type":"object",
+        "required":["step_idx","timestamp_ns"],
+        "properties": {
+          "step_idx": {"type":"integer"},
+          "timestamp_ns": {"type":"integer"},
+          "sensors": {"type":"object"},
+          "action": {"type":"object"},
+          "controller_state": {"type":"object"},
+          "notes": {"type":"string"}
+        }
+      }
+    }
+  },
+  "additionalProperties": false
+}
+
*** End Patch
*** Begin Patch
*** Add File:simulator/ISAAC/isaac_sim_integration.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: isaac-sim-export-
+  namespace: aegis
+spec:
+  entrypoint: isaac-export
+spec:
+  templates:
+    - name: isaac-export
+      container:
+        image: registry.example.com/aegis/isaac-sim-runner:latest
+        command: [sh, -c]
+        args:
+          - |
+            set -euo pipefail
+            # Run Isaac Sim exporter to produce sequence-first traces
+            python3 simulator/ISAAC/export_dataset.py --out /tmp/isaac_export --episodes 500 --seed 42
+            # Validate trace schema
+            python3 - <<PY
+import json,sys
+schema=json.load(open('data/trace_schema.json'))
+print('Schema loaded')
+PY
+            ls -l /tmp/isaac_export
+
*** End Patch
*** Begin Patch
*** Add File:hil/hil_replay_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: hil-replay-
+  namespace: aegis
+spec:
+  entrypoint: hil-replay
+spec:
+  templates:
+    - name: hil-replay
+      steps:
+        - - name: fetch-trace
+            template: fetch-trace
+        - - name: replay
+            template: replay
+            arguments:
+              parameters:
+                - name: trace
+                  value: "{{steps.fetch-trace.outputs.parameters.trace}}"
+        - - name: safety-check
+            template: safety-check
+
+    - name: fetch-trace
+      outputs:
+        parameters:
+          - name: trace
+            valueFrom:
+              path: /tmp/trace_path.txt
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install boto3 && python3 - <<PY
+import os,boto3
+bucket=os.environ.get('MODEL_ARTIFACT_BUCKET','')
+if bucket:
+  s3=boto3.client('s3')
+  # For demo pick latest under hil/
+  resp=s3.list_objects_v2(Bucket=bucket,Prefix='hil/',MaxKeys=10)
+  key=resp.get('Contents',[])[-1]['Key']
+  s3.download_file(bucket,key,'/tmp/trace.json')
+  print('/tmp/trace.json', file=open('/tmp/trace_path.txt','w'))
+else:
+  # fallback to local test trace
+  cp simulator/ISAAC/sample_trace.json /tmp/trace.json || true
+  print('/tmp/trace.json', file=open('/tmp/trace_path.txt','w'))
+PY
+
+    - name: replay
+      inputs:
+        parameters:
+          - name: trace
+      container:
+        image: registry.example.com/aegis/hil-replayer:latest
+        command: [sh,-c]
+        args:
+          - |
+            set -euo pipefail
+            TRACE="{{inputs.parameters.trace}}"
+            echo "Replaying trace $TRACE into HIL rig (operator should map device interfaces)"
+            python3 hil/replay/replay_to_hardware.py --trace "$TRACE" --interface /dev/ttyHIL0 || true
+
+    - name: safety-check
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install pandas && python3 hil/replay/safety_checks.py --report /tmp/hil_report.json && cat /tmp/hil_report.json
+
*** End Patch
*** Begin Patch
*** Add File:hil/replay/replay_to_hardware.py
+#!/usr/bin/env python3
+"""
+Replay trace into hardware interface (serial/CAN/EtherCAT). This is a safe stub: replace interface mapping as needed.
+"""
+import argparse, json, time, sys
+
+def replay(trace_path, interface):
+    data=json.load(open(trace_path))
+    steps=data.get('steps',[])
+    print(f"Replaying {len(steps)} steps to {interface}")
+    for s in steps:
+        # In production send via serial/CAN/EtherCAT
+        # This stub sleeps to emulate timing
+        time.sleep(0.001)
+    print("Replay complete")
+
+if __name__ == "__main__":
+    p=argparse.ArgumentParser()
+    p.add_argument("--trace", required=True)
+    p.add_argument("--interface", default="/dev/ttyHIL0")
+    args=p.parse_args()
+    replay(args.trace, args.interface)
+
*** End Patch
*** Begin Patch
*** Add File:calibration/calibrate_and_manifest.py
+#!/usr/bin/env python3
+"""
+Run device calibration, produce calibration manifest (JSON) and sign it using platform signing helper.
+"""
+import argparse, json, time, os
+
+def run_calibration(device_id, out_dir):
+    os.makedirs(out_dir, exist_ok=True)
+    # Placeholder calibration values
+    cal = {
+        "device_id": device_id,
+        "calibration_id": f"cal-{int(time.time())}",
+        "created_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
+        "parameters": {"offset": 0.001, "scale": 1.0001},
+        "uncertainty": {"offset_std": 1e-6}
+    }
+    path = os.path.join(out_dir, f"{cal['calibration_id']}.json")
+    with open(path,"w") as f:
+        json.dump(cal, f, indent=2)
+    # Sign manifest if signing helper available
+    try:
+        from production.policy.signing.sign_with_retry import sign_payload
+        sig, meta = sign_payload(open(path,"rb").read(), None)
+        cal['signature'] = sig
+        cal['signed_by'] = meta
+        with open(path,"w") as f:
+            json.dump(cal, f, indent=2)
+    except Exception as e:
+        cal['sign_error'] = str(e)
+        with open(path,"w") as f:
+            json.dump(cal, f, indent=2)
+    return path
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--device", required=True)
+    p.add_argument("--out", default="/tmp/calibration")
+    args = p.parse_args()
+    pth = run_calibration(args.device, args.out)
+    print("Wrote calibration manifest:", pth)
+
*** End Patch
*** Begin Patch
*** Add File:governance/gatekeeper_constraints.yaml
+apiVersion: templates.gatekeeper.sh/v1
+kind: ConstraintTemplate
+metadata:
+  name: k8srequiredhsm
+spec:
+  crd:
+    spec:
+      names:
+        kind: K8sRequiredHSM
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package k8srequiredhsm
+        violation[{"msg": msg}] {
+          input.review.kind.kind == "Deployment"
+          not input.review.object.metadata.annotations["aegis.hsm.signed"]
+          msg := "Deployment must include aegis.hsm.signed annotation pointing to signed manifest"
+        }
+
+---
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: K8sRequiredHSM
+metadata:
+  name: require-hsm-signed
+spec:
+  match:
+    kinds:
+      - apiGroups: [""]
+        kinds: ["Deployment"]
+
*** End Patch
*** Begin Patch
*** Add File:observability/prometheus/safety_rules.yaml
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: robotics-safety-rules
+  namespace: aegis
+spec:
+  groups:
+    - name: safety
+      rules:
+        - alert: SafetyInvariantViolation
+          expr: sum(aegis_safety_invariant_violations_total{job=~"hil.*|controller.*"}) > 0
+          for: 1m
+          labels:
+            severity: critical
+          annotations:
+            summary: "Safety invariant triggered in HIL/controller"
+            description: "One or more safety invariants have triggered."
+        - alert: ControlLoopLatencyHigh
+          expr: histogram_quantile(0.95, sum(rate(control_loop_duration_seconds_bucket[2m])) by (le)) > 0.01
+          for: 2m
+          labels:
+            severity: critical
+          annotations:
+            summary: "Control loop 95th percentile latency exceeded"
+            description: "Control loop 95th percentile latency exceeded threshold (example 10ms)."
+
*** End Patch
*** Begin Patch
*** Add File:federated/crypten_multi_robot_orchestrator.py
+#!/usr/bin/env python3
+"""
+Multi-host CrypTen orchestrator stub for federated multi-robot learning.
+This script demonstrates launching per-robot training jobs (K8s Jobs) and a central aggregator orchestration flow.
+In production replace SSH/exec calls with a proper job scheduler (Kubernetes Jobs or MPI).
+"""
+import subprocess, os, json, time
+
+ROBOTS = os.environ.get("ROBOTS","robot1,robot2,robot3").split(",")
+JOB_TEMPLATE = "federated/k8s/robot_fed_job.yaml"
+
+def launch_robot_jobs():
+    for r in ROBOTS:
+        print("Launching job for", r)
+        # In production we would template robot name into Job YAML and kubectl apply -f
+        subprocess.run(["kubectl","apply","-f", JOB_TEMPLATE, "-n", "aegis"], check=False)
+        time.sleep(0.5)
+    print("Launched per-robot jobs (template) - monitor via kubectl")
+
+def aggregate():
+    print("Waiting for jobs to complete... (operator must implement proper wait)")
+    time.sleep(10)
+    print("Running secure aggregation (demo). In production use CrypTen multi-host config.")
+
+if __name__ == "__main__":
+    launch_robot_jobs()
+    aggregate()
+
*** End Patch
*** Begin Patch
*** Add File:tvm/tvm_build_pipeline.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# TVM build pipeline stub: ONNX -> TVM module -> save artifacts for FPGA/ASIC.
+# Requires TVM infra; this is a minimal example.
+ONNX=${1:-/tmp/model.onnx}
+OUTDIR=${2:-/tmp/tvm_build}
+BATCH=${3:-1}
+mkdir -p "$OUTDIR"
+python3 - <<PY
+import tvm, onnx, os
+from tvm import relay
+model = onnx.load("${ONNX}")
+shape_dict = {"input": (int(${BATCH}),3,224,224)}
+mod, params = relay.frontend.from_onnx(model, shape_dict)
+target = "llvm"  # replace with 'metal' or custom FPGA target when available
+with tvm.transform.PassContext(opt_level=3):
+    lib = relay.build(mod, target=target, params=params)
+lib.export_library(os.path.join("${OUTDIR}","lib.so"))
+open(os.path.join("${OUTDIR}","params.json"),"w").write(str(params.keys()))
+print("TVM build artifacts written to ${OUTDIR}")
+PY
+
*** End Patch
*** Begin Patch
*** Add File:triton/onrack_triton_edge.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: triton-onrack
+  namespace: aegis
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: triton-onrack
+  template:
+    metadata:
+      labels:
+        app: triton-onrack
+    spec:
+      containers:
+        - name: triton
+          image: nvcr.io/nvidia/tritonserver:23.06-py3
+          args:
+            - tritonserver
+            - --model-repository=/models
+            - --model-control-mode=explicit
+          resources:
+            limits:
+              nvidia.com/gpu: 1
+              cpu: "4"
+              memory: "12Gi"
+            requests:
+              nvidia.com/gpu: 1
+              cpu: "2"
+              memory: "8Gi"
+          volumeMounts:
+            - name: model-repo
+              mountPath: /models
+      volumes:
+        - name: model-repo
+          persistentVolumeClaim:
+            claimName: triton-model-repo-pvc
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: triton-onrack
+  namespace: aegis
+spec:
+  selector:
+    app: triton-onrack
+  ports:
+    - name: http
+      port: 8000
+      targetPort: 8000
+    - name: metrics
+      port: 8002
+      targetPort: 8002
+
*** End Patch
*** Begin Patch
*** Add File:evidence/enhanced_assemble_audit_bundle.py
+#!/usr/bin/env python3
+"""
+Enhanced evidence bundle assembler: includes calibration manifests, HIL reports, and signed artifacts.
+Results are packaged into a tar.gz and optionally uploaded to EVIDENCE_BUCKET.
+"""
+import os, tarfile, time, glob, json, boto3
+
+OUTDIR="/tmp/aegis_evidence"
+os.makedirs(OUTDIR, exist_ok=True)
+paths=[]
+# collect calibration manifests
+for p in glob.glob("/tmp/calibration/*.json"):
+    paths.append(p)
+# collect HIL reports
+for p in glob.glob("/tmp/hil_report*.json"):
+    paths.append(p)
+# collect model MCP artifacts if any
+for p in glob.glob("/tmp/mcp_*.json"):
+    paths.append(p)
+bundle_path=os.path.join(OUTDIR, f"aegis_evidence_{int(time.time())}.tar.gz")
+with tarfile.open(bundle_path,"w:gz") as tar:
+    for p in paths:
+        tar.add(p, arcname=os.path.basename(p))
+print("Wrote evidence bundle:", bundle_path)
+bucket=os.environ.get("EVIDENCE_BUCKET","")
+if bucket:
+    s3=boto3.client("s3")
+    key=f"evidence/bundles/{os.path.basename(bundle_path)}"
+    s3.upload_file(bundle_path,bucket,key)
+    print("Uploaded to s3://%s/%s" % (bucket,key))
+
*** End Patch
*** Begin Patch
*** Add File:README_ROBOTICS_NANOTECH.md
+# Aegis Robotics & Nanotechnology Integration - Quickstart
+
+This folder contains scaffolding to operate robotics and nanotechnology experiments with Aegis:
+
+- Edge: OTA verify helper (edge/edge_agent/ota_verify.sh) and RTOS notes.
+- Data: sequence-first trace schema (data/trace_schema.json).
+- Simulation: Isaac sim integration Argo job (simulator/ISAAC/isaac_sim_integration.yaml).
+- HIL: HIL replay Argo workflow and replayer script (hil/).
+- Calibration: calibrate_and_manifest.py to run calibrations and produce signed manifests.
+- Governance: Gatekeeper constraint example requiring HSM-signed deployments.
+- Observability: Prometheus safety rules and alerts.
+- Federated learning: multi-robot orchestrator stub (federated/crypten_multi_robot_orchestrator.py).
+- Edge inference: TVM build pipeline stub and on-rack Triton deployment.
+- Evidence: enhanced assemble script to package calibration & HIL artifacts into evidence bundle.
+
+Next steps (recommended)
+1. Review and adapt HIL replayer to match your hardware interfaces (serial, CAN, EtherCAT).
+2. Integrate vendor HSM rotation/signing commands and verify OTA pipeline in a staging rig.
+3. Wire Prometheus metrics from controller/HIL harness to enable safety rules and HPA on latency.
+4. Run the Isaac Sim exporter at scale to generate traces for sim-to-real training.
+5. Replace TVM and FPGA/ASIC stubs with target-specific build pipelines.
+
+If you'd like, I can:
+- (A) produce a complete HIL replayer for specific hardware (serial/CAN/EtherCAT) if you provide device interfaces,
+- (B) generate a concrete TVM/FPGA pipeline for a target board, or
+- (C) produce a safety test suite for your HIL harness (Argo workflows + Prometheus rules).
+
*** End Patch
*** End Patch
