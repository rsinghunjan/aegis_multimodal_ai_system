diff --git a/services/executor_service/requirements.txt b/services/executor_service/requirements.txt
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/services/executor_service/requirements.txt
@@ -0,0 +1,6 @@
+Flask==2.2.5
+gunicorn==20.1.0
+requests==2.31.0
+kubernetes==26.1.0
+python-json-logger==2.0.4
+PyYAML==6.0
diff --git a/services/executor_service/main.py b/services/executor_service/main.py
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/services/executor_service/main.py
@@ -0,0 +1,360 @@
+#!/usr/bin/env python3
+"""
+Hardened executor service for automated approvals.
+
+Goals:
+ - Authenticate requests using a short-lived bearer token (or mTLS in future).
+ - Enforce a whitelist of allowed actions (no arbitrary shell).
+ - Use Kubernetes API for actions (scale, rollout, restart jobs) with least privilege service account.
+ - Record decisions to decision_log via tools.decisionlog_client.insert_decision when available.
+ - Expose Prometheus-friendly metrics endpoints.
+
+Usage:
+ - Configure AUTH_TOKEN env var (shared secret for CI/orchestrator) or rely on in-cluster ServiceAccount + mTLS (future).
+ - Run with gunicorn in k8s deployment.
+"""
+import os
+import json
+import time
+from functools import wraps
+from flask import Flask, request, jsonify, abort
+from python_json_logger import jsonlogger
+import logging
+
+AUTH_TOKEN = os.environ.get("EXECUTOR_AUTH_TOKEN", "")
+OPA_URL = os.environ.get("OPA_URL", "http://opa:8181")
+
+app = Flask(__name__)
+handler = logging.StreamHandler()
+handler.setFormatter(jsonlogger.JsonFormatter())
+app.logger.addHandler(handler)
+app.logger.setLevel(logging.INFO)
+
+try:
+    from tools.decisionlog_client import insert_decision
+except Exception:
+    def insert_decision(agent, action, payload, evidence):
+        app.logger.info("decision_log stub", extra={"agent": agent, "action": action, "payload": payload, "evidence": evidence})
+        return None
+
+try:
+    from kubernetes import client, config
+    # attempt in-cluster, else from KUBECONFIG
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    k8s_apps = client.AppsV1Api()
+    k8s_core = client.CoreV1Api()
+except Exception as e:
+    app.logger.warning("kubernetes client not available: %s", e)
+    k8s_apps = None
+    k8s_core = None
+
+# Simple metrics
+METRICS = {"approvals_total": 0, "denials_total": 0, "deferred_total": 0, "executions_total": 0}
+
+def check_auth(f):
+    @wraps(f)
+    def wrapped(*args, **kwargs):
+        if AUTH_TOKEN:
+            auth = request.headers.get("Authorization", "")
+            if not auth.startswith("Bearer ") or auth.split(" ", 1)[1] != AUTH_TOKEN:
+                abort(401)
+        # else: if no token configured, assume in-cluster restricted network access; still log remote addr
+        return f(*args, **kwargs)
+    return wrapped
+
+def opa_evaluate(input_obj):
+    try:
+        import requests
+        resp = requests.post(f"{OPA_URL}/v1/data/aegis/policies/auto_approval/result", json={"input": input_obj}, timeout=10)
+        resp.raise_for_status()
+        return resp.json().get("result", {})
+    except Exception as e:
+        app.logger.error("OPA eval failed: %s", e)
+        return None
+
+def safe_scale(namespace, name, replicas):
+    if not k8s_apps:
+        raise RuntimeError("kubernetes client not configured")
+    body = {"spec": {"replicas": int(replicas)}}
+    res = k8s_apps.patch_namespaced_deployment_scale(name, namespace, body)
+    return res.to_dict()
+
+def safe_restart_deployment(namespace, name):
+    if not k8s_apps:
+        raise RuntimeError("kubernetes client not configured")
+    # trigger rollout restart
+    body = {"spec": {"template": {"metadata": {"annotations": {"aegis-restart-ts": str(int(time.time()))}}}}}
+    res = k8s_apps.patch_namespaced_deployment(name, namespace, body)
+    return res.to_dict()
+
+ALLOWED_ACTIONS = {
+    # action_name: handler info (requires params)
+    "scale_deployment": {"handler": safe_scale, "required": ["namespace", "name", "replicas"], "description": "Scale a deployment"},
+    "restart_deployment": {"handler": safe_restart_deployment, "required": ["namespace", "name"], "description": "Restart (rollout) a deployment"},
+}
+
+@app.route("/healthz")
+def healthz():
+    return "ok", 200
+
+@app.route("/metrics")
+def metrics():
+    text = []
+    for k, v in METRICS.items():
+        text.append(f"aegis_executor_{k} {v}")
+    return "\n".join(text), 200, {"Content-Type": "text/plain; version=0.0.4"}
+
+@app.route("/execute", methods=["POST"])
+@check_auth
+def execute():
+    """
+    Expected JSON:
+    {
+      "action": "scale_deployment" | "restart_deployment",
+      "params": {"namespace":"aegis-ml","name":"aegis-vllm","replicas":3},
+      "model": "model-name",
+      "metadata": {...}  # optional
+    }
+    """
+    payload = request.get_json(force=True)
+    app.logger.info("execute request received", extra={"payload": payload})
+
+    # Evaluate auto-approval policy first (delegated to OPA)
+    opa_result = opa_evaluate(payload)
+    if opa_result is None:
+        insert_decision("executor", "evaluate_failed", payload, {"error": "opa_unreachable"})
+        METRICS["denials_total"] += 1
+        return jsonify({"ok": False, "reason": "policy_evaluation_failed"}), 503
+
+    if opa_result.get("allow"):
+        # permitted to execute
+        action = payload.get("action")
+        if action not in ALLOWED_ACTIONS:
+            METRICS["denials_total"] += 1
+            insert_decision("executor", "deny", payload, {"reason": "action_not_allowed"})
+            return jsonify({"ok": False, "reason": "action_not_allowed"}), 403
+
+        # validate params
+        params = payload.get("params", {}) or {}
+        for r in ALLOWED_ACTIONS[action]["required"]:
+            if r not in params:
+                METRICS["denials_total"] += 1
+                insert_decision("executor", "deny", payload, {"reason": f"missing_param:{r}"})
+                return jsonify({"ok": False, "reason": f"missing_param:{r}"}), 400
+
+        # Execute handler
+        try:
+            handler = ALLOWED_ACTIONS[action]["handler"]
+            # map required args
+            if action == "scale_deployment":
+                res = handler(params["namespace"], params["name"], params["replicas"])
+            else:
+                res = handler(params["namespace"], params["name"])
+            METRICS["executions_total"] += 1
+            insert_decision("executor", "executed", payload, {"result": "success", "details": str(res)})
+            return jsonify({"ok": True, "result": "executed", "details": res}), 200
+        except Exception as e:
+            METRICS["denials_total"] += 1
+            insert_decision("executor", "execution_failed", payload, {"error": str(e)})
+            app.logger.exception("execution failed")
+            return jsonify({"ok": False, "reason": "execution_failed", "error": str(e)}), 500
+
+    elif opa_result.get("defer"):
+        # Deferred: create signoff issue / notify and return defer status
+        METRICS["deferred_total"] += 1
+        insert_decision("executor", "deferred", payload, {"reason": opa_result.get("reason"), "timeout_seconds": opa_result.get("timeout_seconds")})
+        return jsonify({"ok": False, "deferred": True, "reason": opa_result.get("reason"), "timeout_seconds": opa_result.get("timeout_seconds")}), 202
+    else:
+        METRICS["denials_total"] += 1
+        insert_decision("executor", "deny", payload, {"reason": opa_result.get("reason")})
+        return jsonify({"ok": False, "denied": True, "reason": opa_result.get("reason")}), 403
+
+if __name__ == "__main__":
+    bind = os.environ.get("LISTEN_ADDR", "0.0.0.0:8080")
+    app.logger.info("Starting executor service on %s", bind)
+    # Use gunicorn recommended invocation for production; here we allow direct run for dev
+    from werkzeug.middleware.proxy_fix import ProxyFix
+    app.wsgi_app = ProxyFix(app.wsgi_app)
+    app.run(host="0.0.0.0", port=int(bind.split(":")[-1]), debug=False)
+
diff --git a/k8s/manifests/executor_deployment.yaml b/k8s/manifests/executor_deployment.yaml
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/k8s/manifests/executor_deployment.yaml
@@ -0,0 +1,240 @@
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: aegis-executor-sa
+  namespace: aegis-ml
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: aegis-executor-role
+  namespace: aegis-ml
+rules:
+  - apiGroups: ["apps"]
+    resources: ["deployments/scale","deployments"]
+    verbs: ["get","list","patch","update"]
+  - apiGroups: [""]
+    resources: ["pods"]
+    verbs: ["get","list"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: aegis-executor-rolebinding
+  namespace: aegis-ml
+subjects:
+  - kind: ServiceAccount
+    name: aegis-executor-sa
+    namespace: aegis-ml
+roleRef:
+  kind: Role
+  name: aegis-executor-role
+  apiGroup: rbac.authorization.k8s.io
+
+---
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-executor
+  namespace: aegis-ml
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: aegis-executor
+  template:
+    metadata:
+      labels:
+        app: aegis-executor
+    spec:
+      serviceAccountName: aegis-executor-sa
+      containers:
+        - name: executor
+          image: <REGISTRY>/aegis-executor:latest
+          env:
+            - name: EXECUTOR_AUTH_TOKEN
+              valueFrom:
+                secretKeyRef:
+                  name: aegis-executor-secret
+                  key: token
+            - name: OPA_URL
+              value: "http://opa.aegis-ml.svc.cluster.local:8181"
+          ports:
+            - containerPort: 8080
+          readinessProbe:
+            httpGet:
+              path: /healthz
+              port: 8080
+            initialDelaySeconds: 10
+            periodSeconds: 10
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-executor
+  namespace: aegis-ml
+spec:
+  selector:
+    app: aegis-executor
+  ports:
+    - name: http
+      port: 8080
+      targetPort: 8080
+
diff --git a/tools/compensation_controller.py b/tools/compensation_controller.py
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/tools/compensation_controller.py
@@ -0,0 +1,320 @@
+#!/usr/bin/env python3
+"""
+Compensation controller:
+ - Polls Prometheus for configured SLO breach queries
+ - When a configured SLO is breached, it calls the executor service to perform a rollback or compensation action
+ - Records actions in decision_log
+
+Usage:
+  PROM_URL=http://prometheus-operated.monitoring.svc.cluster.local:9090 EXECUTOR_URL=http://aegis-executor.aegis-ml.svc.cluster.local:8080 python3 tools/compensation_controller.py
+"""
+import os
+import time
+import requests
+import json
+
+PROM_URL = os.environ.get("PROM_URL", "http://prometheus-operated.monitoring.svc.cluster.local:9090")
+EXECUTOR_URL = os.environ.get("EXECUTOR_URL", "http://aegis-executor.aegis-ml.svc.cluster.local:8080")
+CHECK_INTERVAL = int(os.environ.get("CHECK_INTERVAL", "30"))
+
+SLO_QUERIES = {
+    # name: (promql, threshold boolean when to act)
+    "p95_latency_breach": "histogram_quantile(0.95, sum(rate(aegis_inference_request_latency_seconds_bucket[5m])) by (le)) > 1.0",
+}
+
+try:
+    from tools.decisionlog_client import insert_decision
+except Exception:
+    def insert_decision(agent, action, payload, evidence):
+        print("[decision_log stub]", agent, action, payload, evidence)
+        return None
+
+def prom_query(expr):
+    try:
+        r = requests.get(f"{PROM_URL}/api/v1/query", params={"query": expr}, timeout=10)
+        r.raise_for_status()
+        data = r.json()
+        if data.get("status") == "success":
+            return data.get("data", {}).get("result", [])
+    except Exception as e:
+        print("Prometheus query failed:", e)
+    return []
+
+def call_executor(action_payload):
+    try:
+        r = requests.post(f"{EXECUTOR_URL}/execute", json=action_payload, timeout=15)
+        r.raise_for_status()
+        return r.json()
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+def main():
+    while True:
+        for name, q in SLO_QUERIES.items():
+            res = prom_query(q)
+            if res:
+                # Non-empty result means threshold exceeded
+                print(f"SLO breach detected: {name} -> taking compensation action")
+                payload = {
+                    "action": "restart_deployment",
+                    "params": {"namespace": "aegis-ml", "name": "aegis-vllm"},
+                    "metadata": {"reason": f"auto_compensation_{name}"},
+                }
+                insert_decision("compensation_controller", "invoke_executor", {"slo": name}, {"executor_payload": payload})
+                exec_res = call_executor(payload)
+                insert_decision("compensation_controller", "executor_result", {"slo": name}, exec_res)
+        time.sleep(CHECK_INTERVAL)
+
+if __name__ == "__main__":
+    main()
+
diff --git a/policy/opa/auto_approval_extended.rego b/policy/opa/auto_approval_extended.rego
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/policy/opa/auto_approval_extended.rego
@@ -0,0 +1,220 @@
+package aegis.policies.auto_approval
+
+import data.models
+import future.keywords.ifelse
+
+default result = {"allow": false, "defer": false, "reason": "no match", "timeout_seconds": 0}
+
+eligible_actions = {"scale_deployment","restart_deployment"}
+
+budget_for_model[m] = b {
+  bm := data.models.models[m]
+  b := bm.budget_usd_per_month
+}
+budget_for_model[m] = 1000 {
+  not data.models.models[m]
+}
+
+# runtime metrics considered:
+# input.metrics.p95_latency, input.metrics.error_rate, input.metrics.safety_checks_ok
+
+is_eligible {
+  input.action == a
+  a := eligible_actions[_]
+  input.model
+}
+
+low_cost_ok {
+  est := input.params.estimated_cost_usd
+  est != null
+  b := budget_for_model[input.model]
+  est <= (b * 0.10)
+}
+
+slo_ok {
+  # allow for restart/scale only if p95 latency below a safe threshold and error rate low
+  p95 := input.metrics.p95_latency
+  err := input.metrics.error_rate
+  p95 != null
+  err != null
+  p95 <= 1.0
+  err <= 0.01
+}
+
+safety_ok {
+  input.metrics.safety_checks_ok == true
+}
+
+auto_approve {
+  is_eligible
+  safety_ok
+  low_cost_ok
+  slo_ok
+}
+
+defer_conditions {
+  is_eligible
+  not auto_approve
+}
+
+result = {"allow": true, "defer": false, "reason": "auto-approved (extended)", "timeout_seconds": 0} {
+  auto_approve
+}
+
+result = {"allow": false, "defer": true, "reason": "deferred: requires human signoff or metrics", "timeout_seconds": 3600} {
+  defer_conditions
+}
+
+result = {"allow": false, "defer": false, "reason": "denied by policy", "timeout_seconds": 0} {
+  not is_eligible
+}
+
diff --git a/policy/opa/tests/auto_approval_extended_tests.rego b/policy/opa/tests/auto_approval_extended_tests.rego
new file mode 100644
index 0000000..6666666
--- /dev/null
+++ b/policy/opa/tests/auto_approval_extended_tests.rego
@@ -0,0 +1,220 @@
+package aegis.policies.tests
+
+import data.aegis.policies.auto_approval
+
+test_auto_approve_when_all_metrics_ok {
+  input := {"action":"scale_deployment","model":"low-demo-model","env":"production","params":{"estimated_cost_usd":10},"metrics":{"safety_checks_ok":true,"p95_latency":0.5,"error_rate":0.001}}
+  result := data.aegis.policies.auto_approval.result with input as input
+  result.allow == true
+}
+
+test_defer_when_p95_high {
+  input := {"action":"scale_deployment","model":"low-demo-model","env":"production","params":{"estimated_cost_usd":10},"metrics":{"safety_checks_ok":true,"p95_latency":2.0,"error_rate":0.001}}
+  result := data.aegis.policies.auto_approval.result with input as input
+  result.defer == true
+}
+
+test_deny_non_eligible_action {
+  input := {"action":"promote","model":"low-demo-model","env":"production","params":{"estimated_cost_usd":1},"metrics":{"safety_checks_ok":true,"p95_latency":0.5,"error_rate":0.001}}
+  result := data.aegis.policies.auto_approval.result with input as input
+  result.allow == false
+  result.defer == false
+}
+
diff --git a/ui/auditor_dashboard.py b/ui/auditor_dashboard.py
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/ui/auditor_dashboard.py
@@ -0,0 +1,300 @@
+#!/usr/bin/env python3
+"""
+Minimal auditor dashboard:
+ - Reads pending approval/deferred entries from decision_log database (Postgres)
+ - Displays them as JSON via a simple Flask UI for auditors
+
+Environment:
+ - DECISIONLOG_DB_DSN (e.g., postgres://user:pass@host:5432/db)
+ - PORT (optional)
+"""
+import os
+from flask import Flask, jsonify, request
+import psycopg2
+import psycopg2.extras
+
+DSN = os.environ.get("DECISIONLOG_DB_DSN")
+PORT = int(os.environ.get("PORT", "8081"))
+
+app = Flask(__name__)
+
+def get_conn():
+    if not DSN:
+        raise RuntimeError("DECISIONLOG_DB_DSN not set")
+    return psycopg2.connect(DSN, cursor_factory=psycopg2.extras.RealDictCursor)
+
+@app.route("/healthz")
+def healthz():
+    return "ok", 200
+
+@app.route("/pending")
+def pending():
+    """
+    Returns JSON list of pending approval requests with relevant fields.
+    """
+    conn = get_conn()
+    with conn.cursor() as cur:
+        cur.execute("""
+            SELECT id, created_at, agent, payload, evidence
+            FROM decision_log
+            WHERE payload->>'action' IS NOT NULL
+              AND (evidence->>'status' IS NULL OR evidence->>'status' = 'deferred' OR evidence->>'status' = 'pending')
+            ORDER BY created_at DESC
+            LIMIT 200
+        """)
+        rows = cur.fetchall()
+    conn.close()
+    return jsonify(rows)
+
+@app.route("/approve", methods=["POST"])
+def approve():
+    """
+    Accepts JSON: { "id": <decision_id>, "approver": "auditor@org" }
+    Marks as approved by inserting decision_log entry referencing the original request.
+    In a production system, this should be an authenticated action and tie to userid.
+    """
+    data = request.get_json(force=True)
+    dec_id = data.get("id")
+    approver = data.get("approver", "auditor")
+    if not dec_id:
+        return jsonify({"ok": False, "error": "id required"}), 400
+    # append an approval record to decision_log via DB
+    conn = get_conn()
+    with conn.cursor() as cur:
+        cur.execute("INSERT INTO decision_log (agent, payload, evidence) VALUES (%s, %s, %s) RETURNING id", ("auditor-ui", json.dumps({"approved_id": dec_id, "approver": approver}), json.dumps({"status": "approved"})))
+        new_id = cur.fetchone()[0]
+        conn.commit()
+    conn.close()
+    return jsonify({"ok": True, "id": new_id})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=PORT)
+
diff --git a/k8s/manifests/auditor_ui_deployment.yaml b/k8s/manifests/auditor_ui_deployment.yaml
new file mode 100644
index 0000000..8888888
--- /dev/null
+++ b/k8s/manifests/auditor_ui_deployment.yaml
@@ -0,0 +1,220 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-auditor-ui
+  namespace: aegis-ml
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-auditor-ui
+  template:
+    metadata:
+      labels:
+        app: aegis-auditor-ui
+    spec:
+      containers:
+        - name: auditor-ui
+          image: <REGISTRY>/aegis-auditor-ui:latest
+          env:
+            - name: DECISIONLOG_DB_DSN
+              valueFrom:
+                secretKeyRef:
+                  name: aegis-decisionlog-secret
+                  key: dsn
+          ports:
+            - containerPort: 8081
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-auditor-ui
+  namespace: aegis-ml
+spec:
+  selector:
+    app: aegis-auditor-ui
+  ports:
+    - port: 8081
+      targetPort: 8081
+
diff --git a/scripts/auto_rollback_test.sh b/scripts/auto_rollback_test.sh
new file mode 100644
index 0000000..9999999
--- /dev/null
+++ b/scripts/auto_rollback_test.sh
@@ -0,0 +1,220 @@
+#!/usr/bin/env bash
+#
+# Simulate failure to test automated rollback & compensation controller
+#
+# Steps:
+#  - Deploy a failing load generator or artificially increase latency
+#  - Wait for compensation_controller to detect SLO breach and call executor
+#  - Validate that executor restarted the deployment (or performed configured compensation)
+
+PROM_URL="${PROM_URL:-http://prometheus-operated.monitoring.svc.cluster.local:9090}"
+SLEEP_SEC="${SLEEP_SEC:-60}"
+EXECUTOR_URL="${EXECUTOR_URL:-http://aegis-executor.aegis-ml.svc.cluster.local:8080}"
+
+echo "Simulating artificial SLO breach by injecting high latency into service (operator must implement an injeciton mechanism)."
+echo "Sleeping ${SLEEP_SEC}s to allow controller to detect and act..."
+sleep "${SLEEP_SEC}"
+
+echo "Checking executor logs / decision_log for compensation action."
+echo "Querying executor metrics:"
+curl -s "${EXECUTOR_URL}/metrics" || true
+
+echo "Test complete - inspect decision_log entries for compensation_controller/executor_result"
+exit 0
+
diff --git a/monitoring/prometheus/auto_approval_alerts.yaml b/monitoring/prometheus/auto_approval_alerts.yaml
new file mode 100644
index 0000000..aaaaaaaa
--- /dev/null
+++ b/monitoring/prometheus/auto_approval_alerts.yaml
@@ -0,0 +1,220 @@
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: aegis-auto-approval-alerts
+  namespace: aegis-ml
+spec:
+  groups:
+    - name: aegis.auto_approval
+      rules:
+        - alert: AutoApprovalsFailing
+          expr: increase(aegis_executor_executions_total[5m]) == 0 and increase(aegis_executor_denials_total[5m]) > 0
+          for: 10m
+          labels:
+            severity: warning
+          annotations:
+            summary: "Executor experiencing denials without successful executions"
+        - alert: CompensationTriggered
+          expr: increase(aegis_compensation_invocations_total[1h]) > 0
+          for: 5m
+          labels:
+            severity: warning
+          annotations:
+            summary: "Compensation actions triggered in the last hour"
+
diff --git a/docs/SECURE_EXECUTOR_RUNBOOK.md b/docs/SECURE_EXECUTOR_RUNBOOK.md
new file mode 100644
index 0000000..bbbbbbbb
--- /dev/null
+++ b/docs/SECURE_EXECUTOR_RUNBOOK.md
@@ -0,0 +1,240 @@
+# Secure Executor & Auto-Approval â€” Runbook
+
+Overview
+- The executor service replaces ad-hoc shell-based execution with an authenticated, least-privilege Kubernetes-backed executor.
+- It queries OPA (auto_approval policy) and records decision events to decision_log.
+- Compensation controller monitors SLOs and invokes the executor to perform safe rollback actions (restart deployments).
+- Auditor UI reads decision_log and allows auditors to approve pending requests (creates approval decision entries).
+
+Deployment checklist
+1. Build and push executor image (<REGISTRY>/aegis-executor:latest).
+2. Create secret aegis-executor-secret with key "token" containing a strong bearer token.
+3. Deploy k8s/manifests/executor_deployment.yaml in aegis-ml namespace.
+4. Deploy compensation_controller as a Deployment or CronJob (wrap tools/compensation_controller.py).
+5. Deploy auditor UI (ui/auditor_dashboard.py) as a Deployment using k8s/manifests/auditor_ui_deployment.yaml.
+6. Ensure OPA URL reachable by executor and that auto_approval policy is loaded.
+
+Operational notes
+- The executor exposes /metrics that report internal counters; scrape via Prometheus.
+- The executor only allows actions in ALLOWED_ACTIONS; extend conservatively and update RBAC accordingly.
+- The compensation controller should run with a ServiceAccount that can call executor (network-only) and decision_log write access.
+- All execution attempts are recorded in decision_log; auditors should review deferred actions via the auditor UI and either label the GitHub issue or use the UI to insert approval records.
+
+Testing & rollback hardening
+ - Run scripts/auto_rollback_test.sh to simulate an SLO breach and validate compensation actions.
+ - Perform canary tests where the executor is allowed to scale up a non-critical deployment; verify rollback triggers when latency rises.
+ - Ensure the executor's Role only grants necessary verbs on specific resource names (narrow scope).
+
+Security considerations
+ - Use short-lived tokens or a KMS-backed secret for EXECUTOR_AUTH_TOKEN.
+ - Prefer mTLS in front of the executor (service mesh) or in-cluster network policy to restrict access.
+ - Harden the auditor UI with authentication (OIDC) before exposing to auditors; current UI is a minimal prototype.
+
+Extensions
+ - Replace GitHub issue-based signoff with an internal approval GUI connected to auditor UI.
+ - Add more compensation actions (scale-to-zero, redirect traffic, clear caches) and test thoroughly.
+
+End.
