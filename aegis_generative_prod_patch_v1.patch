*** Begin Patch
*** Add File: k8s/rlhf/mpi_rlhf_job.yaml
+apiVersion: kubeflow.org/v1
+kind: MPIJob
+metadata:
+  name: rlhf-mpi-train
+  namespace: aegis-ml
+spec:
+  slotsPerWorker: 1
+  cleanPodPolicy: Running
+  mpiReplicaSpecs:
+    Launcher:
+      replicas: 1
+      template:
+        spec:
+          containers:
+            - name: mpi-launcher
+              image: aegis/rlhf:latest
+              command:
+                - /bin/sh
+                - -c
+                - |
+                  # Example: run accelerate launch for distributed RLHF training
+                  /opt/rl/accelerate_multi_node.sh --config /configs/accelerate_config.yaml --mlflow $MLFLOW_TRACKING_URI
+              env:
+                - name: MLFLOW_TRACKING_URI
+                  valueFrom:
+                    secretKeyRef:
+                      name: mlflow-secrets
+                      key: tracking-uri
+              resources:
+                limits:
+                  nvidia.com/gpu: 1
+                  memory: "32Gi"
+                  cpu: "8"
+                requests:
+                  nvidia.com/gpu: 1
+                  memory: "16Gi"
+                  cpu: "4"
+    Worker:
+      replicas: 4
+      template:
+        spec:
+          containers:
+            - name: mpi-worker
+              image: aegis/rlhf:latest
+              command: ["/bin/sh","-c","sleep infinity"]
+              resources:
+                limits:
+                  nvidia.com/gpu: 1
+                  memory: "64Gi"
+                  cpu: "16"
+                requests:
+                  nvidia.com/gpu: 1
+                  memory: "32Gi"
+                  cpu: "8"
+
+---
+# Note: This is an example MPIJob that expects a kubeflow MPI operator to be installed. 
+# The launcher script should orchestrate the accelerate/trl training across worker replicas.
+
*** End Patch
*** Begin Patch
*** Add File: rl/accelerate_multi_node.sh
+#!/usr/bin/env bash
+set -euo pipefail
+
+# Wrapper to prepare accelerate config for multi-node runs and start the RLHF training.
+# Expects:
+#  - --config <accelerate_config.yaml>
+#  - --mlflow <mlflow_tracking_uri>
+ARGS=()
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --config) ACCEL_CONF="$2"; shift 2;;
+    --mlflow) MLFLOW_URI="$2"; shift 2;;
+    *) ARGS+=("$1"); shift;;
+  esac
+done
+
+: "${ACCEL_CONF:=/configs/accelerate_config.yaml}"
+: "${MLFLOW_URI:=http://mlflow.aegis.svc:5000}"
+
+export MLFLOW_TRACKING_URI="${MLFLOW_URI}"
+
+echo "Using accelerate config: ${ACCEL_CONF}"
+cat "${ACCEL_CONF}"
+
+# Example: start supervised pretrain then PPO via trl.
+echo "Starting supervised fine-tune (launcher) ..."
+python rl/train_supervised.py --config /configs/supervised.yaml
+
+echo "Starting TRL PPO via ppo_trainer_trl.py"
+python rl/ppo_trainer_trl.py
+
+echo "Training completed in launcher"
+
*** End Patch
*** Begin Patch
*** Add File: billing/enhanced_reconcile.py
+#!/usr/bin/env python3
+"""
+Enhanced billing reconciliation:
+ - Fetches invoices from COMPLIANCE_BUCKET
+ - Queries Prometheus for token metrics to compare with Redis counters
+ - Detects discrepancies and sends alerts to operator webhook
+"""
+import os, json, time
+import redis, boto3, requests
+from urllib.parse import urljoin
+
+REDIS_URL = os.environ.get("REDIS_URL", "redis://redis:6379/3")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+PROM_URL = os.environ.get("PROM_URL", "http://prometheus.monitoring.svc:9090")
+OPERATOR_WEBHOOK = os.environ.get("OPERATOR_NOTIFY_WEBHOOK")
+
+redis_client = redis.from_url(REDIS_URL)
+s3 = boto3.client("s3") if COMPLIANCE_BUCKET else None
+
+def fetch_invoices(prefix="billing/invoices/"):
+    invoices = []
+    if not s3:
+        return invoices
+    objs = s3.list_objects_v2(Bucket=COMPLIANCE_BUCKET, Prefix=prefix)
+    for o in objs.get("Contents", []):
+        key = o["Key"]
+        tmp = "/tmp/" + key.replace("/","_")
+        s3.download_file(COMPLIANCE_BUCKET, key, tmp)
+        with open(tmp) as fh:
+            data = json.load(fh)
+            invoices.extend(data)
+    return invoices
+
+def prometheus_query(query):
+    url = urljoin(PROM_URL, "/api/v1/query")
+    r = requests.get(url, params={"query": query}, timeout=10)
+    r.raise_for_status()
+    data = r.json().get("data", {}).get("result", [])
+    return data
+
+def aggregate_redis_tokens():
+    data = redis_client.hgetall("llm:tokens") or {}
+    return {k.decode(): int(v.decode()) for k,v in data.items()}
+
+def detect_discrepancies():
+    invoices = fetch_invoices()
+    redis_vals = aggregate_redis_tokens()
+    anomalies = []
+    # simple check: invoice tokens vs recent prometheus counter for tokens
+    for inv in invoices:
+        tenant = inv.get("tenant")
+        inv_tokens = inv.get("tokens", 0)
+        redis_tokens = redis_vals.get(tenant, 0)
+        # query prometheus for tenant token counters if metric exported as aegis_llm_tokens_total{tenant="<tenant>"}
+        q = f'aegis_llm_tokens_total{{tenant="{tenant}"}}'
+        try:
+            prom = prometheus_query(q)
+            prom_val = int(prom[0]["value"][1]) if prom else 0
+        except Exception:
+            prom_val = 0
+        # compare invoice vs prom and redis
+        if abs(inv_tokens - prom_val) > max(1000, 0.1 * max(inv_tokens, 1)):
+            anomalies.append({"tenant":tenant, "invoice_tokens":inv_tokens, "prom_tokens":prom_val, "redis_tokens": redis_tokens})
+    if anomalies and OPERATOR_WEBHOOK:
+        try:
+            requests.post(OPERATOR_WEBHOOK, json={"alert":"billing_discrepancies","items":anomalies}, timeout=5)
+        except Exception:
+            pass
+    return anomalies
+
+if __name__=="__main__":
+    a = detect_discrepancies()
+    print("Anomalies:", json.dumps(a, indent=2))
+
*** End Patch
*** Begin Patch
*** Add File: ci/canary_promote_manager.py
+#!/usr/bin/env python3
+"""
+Canary Promote Manager:
+ - Queries OpenSearch/ES and Prometheus to compute live metrics (hallucination rate, latency, cost)
+ - Decides to promote or rollback a canary model via model_registry API
+ - Retries decisions with exponential backoff and records actions to compliance bucket
+"""
+import os, time, json, requests
+from elasticsearch import Elasticsearch
+
+ES_HOST = os.environ.get("ES_HOST")
+PROM_URL = os.environ.get("PROM_URL", "http://prometheus.monitoring.svc:9090")
+MODEL_REGISTRY_API = os.environ.get("MODEL_REGISTRY_API")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+OPERATOR_WEBHOOK = os.environ.get("OPERATOR_NOTIFY_WEBHOOK")
+
+es = Elasticsearch([ES_HOST]) if ES_HOST else None
+
+def query_hallucination_rate(model_id, window_mins=30):
+    # Query ES for hallu_check records for this model; this assumes index "aegis-audit"
+    if not es:
+        return 0.0
+    now = int(time.time()*1000)
+    start = now - window_mins*60*1000
+    body = {
+      "query": {
+        "bool": {
+          "must": [
+            {"range": {"ts": {"gte": start}}},
+            {"term": {"kind": "hallu_check"}},
+            {"term": {"record.model_id": model_id}}
+          ]
+        }
+      },
+      "size": 1000
+    }
+    res = es.search(index="aegis-audit*", body=body)
+    hits = res.get("hits", {}).get("hits", [])
+    if not hits:
+        return 0.0
+    hallu = sum(1 for h in hits if h["_source"].get("record", {}).get("is_hallucination"))
+    return hallu / len(hits)
+
+def query_prometheus(query):
+    r = requests.get(f"{PROM_URL}/api/v1/query", params={"query": query}, timeout=10)
+    r.raise_for_status()
+    res = r.json()
+    vals = res.get("data", {}).get("result", [])
+    if not vals:
+        return 0.0
+    return float(vals[0]["value"][1])
+
+def decide_and_act(model_id):
+    hallu = query_hallucination_rate(model_id, window_mins=30)
+    latency = query_prometheus(f'histogram_quantile(0.95, sum(rate(llm_request_duration_seconds_bucket{{model="{model_id}"}}[5m])) by (le))')
+    cost = query_prometheus(f'rate(aegis_llm_cost_total{{model="{model_id}"}}[5m])')
+    action = None
+    if hallu <= float(os.environ.get("CANARY_HALLU_THRESH", "0.02")) and cost <= float(os.environ.get("CANARY_COST_THRESH", "10.0")):
+        requests.post(f"{MODEL_REGISTRY_API}/models/promote", json={"model": model_id}, timeout=10)
+        action = "promote"
+    else:
+        requests.post(f"{MODEL_REGISTRY_API}/models/rollback", json={"model": model_id}, timeout=10)
+        action = "rollback"
+    out = {"model": model_id, "hallu": hallu, "latency": latency, "cost": cost, "action": action, "ts": int(time.time())}
+    if OPERATOR_WEBHOOK:
+        try:
+            requests.post(OPERATOR_WEBHOOK, json=out, timeout=5)
+        except Exception:
+            pass
+    # persist action to compliance bucket if configured
+    if COMPLIANCE_BUCKET:
+        try:
+            import boto3, tempfile
+            s3 = boto3.client("s3")
+            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".json")
+            tmp.write(json.dumps(out).encode()); tmp.flush(); tmp.close()
+            key = f"canary/actions/{model_id}_{int(time.time())}.json"
+            s3.upload_file(tmp.name, COMPLIANCE_BUCKET, key)
+        except Exception:
+            pass
+    return out
+
+if __name__=="__main__":
+    import sys
+    if len(sys.argv)<2:
+        print("usage: canary_promote_manager.py <model_id>")
+        raise SystemExit(2)
+    print(decide_and_act(sys.argv[1]))
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/generative_canary_gate.yml
+name: Generative Canary Gate
+on:
+  workflow_dispatch:
+    inputs:
+      model_id:
+        required: true
+
+jobs:
+  adversarial-and-canary:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run adversarial gate
+        env:
+          LLM_ENDPOINT: ${{ secrets.LLM_ENDPOINT }}
+          ADV_MANIFEST: tests/adversarial_prompts.jsonl
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+        run: |
+          python safety/adversarial_harness.py
+      - name: Run canary promote manager
+        if: success()
+        env:
+          ES_HOST: ${{ secrets.ES_HOST }}
+          PROM_URL: ${{ secrets.PROM_URL }}
+          MODEL_REGISTRY_API: ${{ secrets.MODEL_REGISTRY_API }}
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+          OPERATOR_NOTIFY_WEBHOOK: ${{ secrets.OPERATOR_NOTIFY_WEBHOOK }}
+        run: |
+          python ci/canary_promote_manager.py "${{ github.event.inputs.model_id }}"
+      - name: Fail workflow on adversarial failure
+        if: failure()
+        run: |
+          echo "Adversarial tests failed; blocking promotion"
+          exit 2
+
*** End Patch
*** Begin Patch
*** Add File: compliance/signoff_api.py
+#!/usr/bin/env python3
+"""
+Compliance Signoff API:
+ - Record auditor/manager signoffs for model promotions or major changes.
+ - Simple FastAPI service storing signoffs in SQLite and writing evidence to COMPLIANCE_BUCKET.
+"""
+import os, sqlite3, json, time
+from fastapi import FastAPI, HTTPException
+from pydantic import BaseModel
+import boto3
+
+DB = os.environ.get("SIGNOFF_DB", "/data/signoffs.sqlite")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+os.makedirs(os.path.dirname(DB), exist_ok=True)
+
+def conn():
+    c = sqlite3.connect(DB, check_same_thread=False)
+    c.execute("""CREATE TABLE IF NOT EXISTS signoffs (
+        id INTEGER PRIMARY KEY AUTOINCREMENT,
+        model_id TEXT,
+        actor TEXT,
+        role TEXT,
+        notes TEXT,
+        evidence_s3 TEXT,
+        ts INTEGER
+    )""")
+    c.commit()
+    return c
+
+app = FastAPI(title="Aegis Signoff API")
+
+class SignoffIn(BaseModel):
+    model_id: str
+    actor: str
+    role: str
+    notes: str = ""
+    evidence_blob: str = None  # base64 or S3 path preferrably
+
+@app.post("/signoff")
+def signoff(s: SignoffIn):
+    c = conn()
+    ts = int(time.time())
+    evidence_s3 = None
+    if s.evidence_blob and COMPLIANCE_BUCKET:
+        # store evidence to S3
+        s3 = boto3.client("s3")
+        key = f"signoff/{s.model_id}/{ts}.json"
+        s3.put_object(Bucket=COMPLIANCE_BUCKET, Key=key, Body=s.evidence_blob.encode() if isinstance(s.evidence_blob, str) else s.evidence_blob)
+        evidence_s3 = f"s3://{COMPLIANCE_BUCKET}/{key}"
+    c.execute("INSERT INTO signoffs (model_id,actor,role,notes,evidence_s3,ts) VALUES (?,?,?,?,?,?)",
+              (s.model_id, s.actor, s.role, s.notes, evidence_s3, ts))
+    c.commit()
+    return {"ok": True, "evidence_s3": evidence_s3}
+
+@app.get("/signoffs/{model_id}")
+def get_signoffs(model_id: str):
+    c = conn()
+    cur = c.cursor()
+    cur.execute("SELECT actor,role,notes,evidence_s3,ts FROM signoffs WHERE model_id=? ORDER BY ts DESC", (model_id,))
+    rows = cur.fetchall()
+    return [{"actor":r[0],"role":r[1],"notes":r[2],"evidence":r[3],"ts":r[4]} for r in rows]
+
+if __name__=="__main__":
+    import uvicorn
+    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT","8315")))
+
*** End Patch
*** Begin Patch
*** Add File: docs/generative_prod_checklist.md
+# Generative Productionization Checklist
+
+This checklist helps drive the last mile from prototype -> production for generative LLM workloads.
+
+Secrets & Signing
+- Ensure Vault policies are applied and tested: vault/enable_audit_and_roles.sh
+- Confirm operator-signing service network policy blocks CI namespace.
+- Run .github/workflows/verify_no_signing_access.yml from CI and validate failure (CI must not reach signing endpoint).
+- Ensure every sign operation appears in Vault audit log and in COMPLIANCE_BUCKET.
+
+RLHF & Training
+- Use kubeflow MPIJob (k8s/rlhf/mpi_rlhf_job.yaml) for multi-node training pilot.
+- Use rl/accelerate_multi_node.sh and rl/ppo_trainer_trl.py for a staged run; validate checkpoints with rl/checkpoint_validate.py.
+- Run ci/rlhf_smoke_test.yml in staging before large runs.
+- Ensure MLflow captures runs, parameters and artifacts for reproducibility.
+
+Cost & Billing
+- Wire gateway to lua quota and ensure billing/enhanced_reconcile.py runs hourly to detect anomalies.
+- Configure Prometheus metric exports for token usage, cost per model and link to auto_canary_manager.
+
+Canary & Automation
+- Deploy canary pipeline using .github/workflows/generative_canary_gate.yml and ci/canary_promote_manager.py.
+- Tune CANARY_HALLU_THRESH and CANARY_COST_THRESH per model and environment.
+
+Governance & Compliance
+- Require compliance signoff using compliance/signoff_api.py for promotions of sensitive models.
+- Ensure signoffs and remediation evidence are stored in COMPLIANCE_BUCKET and searchable.
+
+Monitoring & SLOs
+- Install Prometheus alert rules (prometheus/alerts-agent.rules.yaml) and set SLOs for latency/hallucination/cost.
+- Run load test and ingest results to ES using load_test/ingest_load_results.py.
+
*** End Patch
*** End Patch
