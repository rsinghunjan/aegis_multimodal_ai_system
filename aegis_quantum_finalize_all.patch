*** Begin Patch
*** Add File:quantum/hsm/vendor_onboard/README_ONBOARD.md
+Vendor HSM Onboarding Guide (operator)
+=====================================
+
+Purpose
+- Steps for onboarding a vendor HSM (Thales/Entrust/Luna/CloudHSM) into Aegis staging and production.
+
+Prereqs
+- Vendor HSM appliance or cloud HSM account & admin console access
+- PKCS#11 module (.so) and documentation from vendor
+- Network connectivity between signing service and HSM (VPN or VPC peering)
+- Vault operator access
+
+High-level steps
+1. Procurement & Contract
+   - Ensure vendor contract includes audit log access, PKCS#11 support, key management SLA, export-control clauses.
+2. Staging prep
+   - Deploy vendor HSM in staging network or use vendor-managed HSM.
+   - Obtain PKCS#11 module path, slot id and admin credentials.
+3. Soft validation (optional)
+   - Use SoftHSM to validate PKCS#11 flow locally first (see quantum/hsm).
+4. Vendor integration
+   - Install PKCS#11 module on signing host(s).
+   - Test PKCS#11 listing and key import using vendor CLI or pkcs11-tool.
+5. Publish verification public key to Vault
+   - Upload exported public key PEM to Vault path: secret/pq-keys/<customer>
+   - Set access policy: only signing service + compliance may read
+6. Configure hybrid_signer to call HSM
+   - Provide pkcs11 module path, slot, pin, and key label to hybrid_signer_hsm or HSMService.
+7. Audit logs
+   - Configure vendor audit log forwarding (syslog or S3 export).
+   - Verify logs appear in S3 bucket and are accessible to compliance pipeline.
+8. Rotation test
+   - Run hsm_rotation.sh: create new key, publish new public key to Vault, update services, record rotation metadata.
+9. Production cutover
+   - Migrate signing from SoftHSM/test key to vendor HSM in controlled maintenance window.
+
+Acceptance
+- HSM responds to PKCS#11 sign requests from signing service.
+- Public verification key stored in Vault and retrievable by verification service.
+- HSM audit logs are flowing to the configured S3/SIEM and are included in compliance evidence bundle.
+
*** End Patch
*** Begin Patch
*** Add File:quantum/hsm/vendor_provision.tf
+/*
+Placeholder Terraform for vendor HSM onboarding:
+This is intentionally vendor-agnostic and contains operator steps (null_resource) to run vendor-specific provisioning scripts.
+Replace null_resource steps with vendor Terraform provider resources when available.
+*/
+variable "operator_email" { type = string }
+variable "staging_admin_contact" { type = string }
+
+resource "null_resource" "vendor_hsm_onboard" {
+  provisioner "local-exec" {
+    command = <<EOT
+echo "Run vendor provisioning from operator workstation:"
+echo " - Use vendor console to create cluster"
+echo " - Obtain PKCS11 module path and slot"
+echo " - Upload public verification key to a safe location and give to Aegis operator"
+EOT
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:providers/pilot/run_all_pilots.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run Braket and IBM pilots in staging. Assumes Vault is configured and VAULT_TOKEN set.
+# Usage: ./run_all_pilots.sh --program demo.qasm --s3-bucket my-staging-bucket --ibm-backend ibmq_quito --vault-path secret/data/quantum/providers
+
+PROG=""
+S3_BUCKET=""
+IBM_BACKEND=""
+VAULT_PATH=""
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --program) PROG="$2"; shift 2;;
+    --s3-bucket) S3_BUCKET="$2"; shift 2;;
+    --ibm-backend) IBM_BACKEND="$2"; shift 2;;
+    --vault-path) VAULT_PATH="$2"; shift 2;;
+    *) echo "Unknown $1"; exit 1;;
+  esac
+done
+
+if [ -z "$PROG" ] || [ -z "$S3_BUCKET" ] || [ -z "$VAULT_PATH" ]; then
+  echo "Usage: $0 --program <qasm> --s3-bucket <bucket> --vault-path <vault> [--ibm-backend <name>]"
+  exit 2
+fi
+
+echo "Running Braket pilot..."
+python3 providers/pilot/orchestrator.py --provider braket --vault-path "$VAULT_PATH" --program "$PROG" --s3-bucket "$S3_BUCKET"
+
+if [ -n "$IBM_BACKEND" ]; then
+  echo "Running IBM pilot..."
+  python3 providers/pilot/orchestrator.py --provider ibm --vault-path "$VAULT_PATH" --program "$PROG" --s3-bucket "$S3_BUCKET" --backend "$IBM_BACKEND"
+fi
+
+echo "Pilots submitted. Check MLflow experiment 'quantum-pilots' and Rekor entries."
+
*** End Patch
*** Begin Patch
*** Add File:quantum/rekor/check_mlflow_rekor.py
+#!/usr/bin/env python3
+"""
+CI utility: verify that the latest MLflow runs in an experiment have Rekor entries attached.
+Usage:
+  python3 check_mlflow_rekor.py --mlflow-url http://mlflow:5000 --experiment quantum-pilots --threshold 5
+
+This script exits non-zero if any of the most recent runs lack the 'rekor.entry' tag.
+"""
+import argparse, mlflow, sys
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--mlflow-url", required=True)
+    p.add_argument("--experiment", default="quantum-pilots")
+    p.add_argument("--threshold", type=int, default=5)
+    args = p.parse_args()
+    mlflow.set_tracking_uri(args.mlflow_url)
+    client = mlflow.tracking.MlflowClient()
+    try:
+        exp = client.get_experiment_by_name(args.experiment)
+        if not exp:
+            print("Experiment not found:", args.experiment); sys.exit(1)
+        runs = client.search_runs([exp.experiment_id], order_by=["attributes.start_time DESC"], max_results=args.threshold)
+        ok = True
+        for r in runs:
+            tags = r.data.tags
+            if "rekor.entry" not in tags:
+                print("Run missing Rekor entry:", r.info.run_id)
+                ok = False
+        if not ok:
+            sys.exit(2)
+        print("All recent runs have Rekor entries.")
+    except Exception as e:
+        print("Error:", e)
+        sys.exit(3)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/rekor_enforce_mlflow.yml
+name: Enforce Rekor for Recent MLflow Runs
+on:
+  workflow_dispatch:
+jobs:
+  check-mlflow:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.10'
+      - name: Install deps
+        run: |
+          pip install mlflow
+      - name: Run Rekor check
+        env:
+          MLFLOW_URL: ${{ secrets.MLFLOW_URL }}
+        run: |
+          python3 quantum/rekor/check_mlflow_rekor.py --mlflow-url "${MLFLOW_URL}" --experiment quantum-pilots --threshold 10
+
*** End Patch
*** Begin Patch
*** Add File: broker/helm/cert-manager/README.md
+Cert-manager integration (operator)
+---------------------------------
+This folder contains manifests and guidance to enable cert-manager and create TLS certs for the broker.
+
+Steps:
+1. Install cert-manager in cluster (CRDs + controller).
+   kubectl apply -f https://github.com/cert-manager/cert-manager/releases/latest/download/cert-manager.yaml
+2. Create ClusterIssuer (example in broker/k8s/cert-manager-issuer.yaml)
+3. Apply certificate manifest; cert-manager will create TLS secret aegis-broker-tls-secret
+4. Update broker Helm chart values to mount TLS secret and configure mTLS for clients (istio/nginx ingress)
+
*** End Patch
*** Begin Patch
*** Add File: broker/terraform/rds_management.md
+Managed RDS Deployment (operator checklist)
+-----------------------------------------
+1. Prepare VPC, subnets and security groups per cloud networking policies.
+2. Run broker/terraform/rds_multi_az.tf with operator-provided variables.
+3. Create Kubernetes secret aegis-db-secret containing JOB_DATABASE_URL (pointing to RDS endpoint)
+4. Validate connectivity from broker namespace to RDS and enable automated backups & maintenance windows.
+
*** End Patch
*** Begin Patch
*** Add File: broker/helm/production_hardening.md
+Production Broker hardening notes
+--------------------------------
+1. Use managed Postgres (RDS/CloudSQL) with multi-AZ and automated backups.
+2. Deploy cert-manager and enable mTLS between internal services (signing services, workers).
+3. Enable pod security policies and network policies to restrict egress to provider endpoints only.
+4. Use external secrets operator (or Vault CSI) to mount secrets in pods rather than env vars.
+5. Configure HPA and test autoscaling under synthetic load.
+
*** End Patch
*** Begin Patch
*** Add File: observability/billing/ingest_daily_costs.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# Example scheduled job to ingest cloud provider CSV to billing DB
+# Operator should run daily in a cronjob or Airflow
+CSV_PATH=${1:-/data/cloud_costs/today.csv}
+TENANT=${2:-default}
+if [ ! -f "$CSV_PATH" ]; then
+  echo "No cost CSV at $CSV_PATH"; exit 1
+fi
+python3 broker/quotas/chargeback_connector.py "$CSV_PATH" "$TENANT"
+echo "Ingested cost CSV for tenant $TENANT"
+
*** End Patch
*** Begin Patch
*** Add File: observability/test_fallback.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Test that Alertmanager -> webhook -> broker fallback works.
+#
+WEBHOOK_URL=${1:-http://localhost:8085/webhook}
+cat > /tmp/test_alert.json <<JSON
+{
+  "alerts": [
+    {
+      "labels": {"alertname":"QuantumBrokerHighQueue"}
+    }
+  ]
+}
+JSON
+curl -s -X POST $WEBHOOK_URL -H "Content-Type: application/json" -d @/tmp/test_alert.json
+echo "Webhook sent to $WEBHOOK_URL"
+
*** End Patch
*** Begin Patch
*** Add File: compliance/auditor_handoff/packager.py
+#!/usr/bin/env python3
+"""
+Create auditor handoff bundle for PQ/HSM & quantum pilots.
+Collects:
+ - HSM audit logs from S3 (list & fetch recent)
+ - Rekor entries exported from rekor-cli (for provided artifacts)
+ - MLflow run artifacts for pilot runs
+ - Broker logs & deployment manifests
+Produces a tar.gz suitable to send to auditors.
+"""
+import os, subprocess, json, tempfile
+
+OUTDIR = os.environ.get("AUDIT_OUT", "/tmp/aegis_audit_bundle")
+S3_BUCKET = os.environ.get("HSM_AUDIT_BUCKET")
+
+def fetch_hsm_audit(s3bucket, outdir):
+    if not s3bucket:
+        return
+    subprocess.check_call(["aws","s3","ls", f"s3://{s3bucket}/hsm-audit/"], stdout=subprocess.PIPE)
+    subprocess.check_call(["aws","s3","cp", f"s3://{s3bucket}/hsm-audit/", outdir, "--recursive"])
+
+def fetch_rekor_entries(artifacts, outdir):
+    for a in artifacts:
+        subprocess.check_call(["rekor-cli","search","--hash", a, "--output", os.path.join(outdir, f"rekor_{a}.json")])
+
+def package_all(outdir):
+    os.makedirs(outdir, exist_ok=True)
+    subprocess.check_call(["kubectl","logs","-n","aegis","deployment/aegis-quantum-broker"], stdout=open(os.path.join(outdir,"broker.log"),"w"))
+    if S3_BUCKET:
+        fetch_hsm_audit(S3_BUCKET, outdir)
+    # tar
+    subprocess.check_call(["tar","czf", f"{outdir}.tar.gz", "-C", outdir, "."])
+    print("Created audit bundle:", f"{outdir}.tar.gz")
+
+if __name__ == "__main__":
+    package_all(OUTDIR)
+
*** End Patch
*** Begin Patch
*** Add File: runbooks/acceptance_checklist_quantum_ready.md
+# Acceptance checklist — Quantum production readiness
+
+Crypto / HSM
+- Vendor HSM provisioned in staging and production
+- Signing service uses HSM PKCS#11 for PQ signatures
+- Public verification keys stored in Vault and access-limited
+- Automated rotation tested and rotation metadata in Vault
+- HSM audit logs forwarded to S3 and collected by compliance
+
+Provenance & Rekor
+- All pilot and promoted artifacts have Rekor entries
+- CI gates fail if Rekor entries missing (check_mlflow_rekor.py)
+- MLflow runs have 'rekor.entry' tag linking to Rekor result
+
+Providers / Pilots
+- Braket + IBM pilots executed successfully in staging
+- Raw shots & calibration/noise snapshots stored in lakeFS/S3
+- Reproducibility: playback tool reproduces counts within expected variance
+
+Broker & Ops
+- Broker deployed to staging with managed Postgres and cert-manager
+- HPA tested and autoscaling triggers under load
+- JWT rotation tested via broker/jwt_rotate.sh
+- Fallback to simulator triggered by alertmanager webhook and cost enforcer
+
+Observability & Billing
+- Prometheus & Grafana dashboards imported and alert rules active
+- Chargeback ingestion schedules producing billing rows
+- Alert → webhook → fallback tested
+
+Compliance & Legal
+- Vendor contracts signed and stored in compliance/evidence
+- Export control review completed and documented
+- SOC2 evidence bundle includes PQ/HSM artifacts and Rekor entries
+
*** End Patch
*** End Patch
