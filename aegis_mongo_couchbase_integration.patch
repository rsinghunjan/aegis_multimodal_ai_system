*** Begin Patch
*** Add File:terraform/mongo_atlas/main.tf
+terraform {
+  required_providers {
+    mongodbatlas = {
+      source  = "mongodb/mongodbatlas"
+      version = "~> 1.4"
+    }
+  }
+}
+
+provider "mongodbatlas" {
+  public_key  = var.atlas_public_key    # set via env or terraform variables
+  private_key = var.atlas_private_key
+  org_id      = var.atlas_org_id
+}
+
+resource "mongodbatlas_project" "aegis" {
+  name = var.project_name
+}
+
+resource "mongodbatlas_cluster" "aegis_cluster" {
+  project_id   = mongodbatlas_project.aegis.id
+  name         = var.cluster_name
+  provider_name = "AWS"
+  provider_region_name = var.aws_region
+  provider_instance_size_name = "M10" # adjust for scale
+  provider_backup_enabled = true
+  replication_specs {
+    num_shards = 1
+    regions_config {
+      (var.aws_region) = {
+        electable_nodes = 3
+        priority = 7
+      }
+    }
+  }
+}
+
+resource "mongodbatlas_database_user" "aegis_user" {
+  username = var.db_user
+  password = var.db_password
+  project_id = mongodbatlas_project.aegis.id
+  roles {
+    role_name = "readWrite"
+    database_name = "aegis"
+  }
+  labels = {
+    "created-by" = "aegis-terraform"
+  }
+}
+
+output "mongo_connection_string" {
+  value = "mongodb+srv://${mongodbatlas_database_user.aegis_user.username}:${mongodbatlas_database_user.aegis_user.password}@${mongodbatlas_cluster.aegis_cluster.name}.mongodb.net/aegis?retryWrites=true&w=majority"
+}
+
*** End Patch
*** Begin Patch
*** Add File:terraform/mongo_atlas/variables.tf
+variable "atlas_public_key" {
+  type = string
+}
+variable "atlas_private_key" {
+  type = string
+  sensitive = true
+}
+variable "atlas_org_id" {
+  type = string
+}
+variable "project_name" {
+  type = string
+  default = "aegis-mongo-project"
+}
+variable "cluster_name" {
+  type = string
+  default = "aegis-cluster"
+}
+variable "db_user" {
+  type = string
+  default = "aegis_user"
+}
+variable "db_password" {
+  type = string
+  default = "REPLACE_WITH_STRONG_PASSWORD"
+  sensitive = true
+}
+variable "aws_region" {
+  type = string
+  default = "us-west-2"
+}
+
*** End Patch
*** Begin Patch
*** Add File:terraform/mongo_atlas/outputs.tf
+output "mongo_connection_string" {
+  value = "mongodb+srv://${mongodbatlas_database_user.aegis_user.username}:${mongodbatlas_database_user.aegis_user.password}@${mongodbatlas_cluster.aegis_cluster.name}.mongodb.net/aegis?retryWrites=true&w=majority"
+  sensitive = true
+}
+
*** End Patch
*** Begin Patch
*** Add File:k8s/mongodb/secret-mongodb.yaml
+apiVersion: v1
+kind: Secret
+metadata:
+  name: mongodb-connection
+  namespace: aegis
+type: Opaque
+stringData:
+  # Fill with the Atlas connection string output from terraform
+  MONGO_URI: "mongodb+srv://<user>:<pass>@cluster.example.mongodb.net/aegis?retryWrites=true&w=majority"
+
*** End Patch
*** Begin Patch
*** Add File:couchbase/operator/INSTALL.md
+# Couchbase Autonomous Operator - Install notes
+
+This patch uses Couchbase Autonomous Operator (self-managed) for Couchbase as the specialized, low‑latency KV/cache + mobile sync option.
+
+Install operator (official docs): https://docs.couchbase.com/operator/current/installation.html
+
+Quick install (example using kubectl / helm):
+- Ensure the Operator CRDs are installed:
+  kubectl apply -f https://packages.couchbase.com/helm/couchbase-operator/crds.yaml
+- Install operator in namespace 'couchbase':
+  kubectl create ns couchbase
+  helm repo add couchbase https://couchbase-partners.github.io/helm-charts
+  helm repo update
+  helm install couchbase-operator couchbase/couchbase-operator --namespace couchbase
+
+After operator is installed, apply the CouchbaseCluster manifest included in this patch.
+
*** End Patch
*** Begin Patch
*** Add File:couchbase/cluster/couchbasecluster.yaml
+apiVersion: couchbase.com/v2
+kind: CouchbaseCluster
+metadata:
+  name: aegis-cb-cluster
+  namespace: couchbase
+spec:
+  version: "7.2.0"
+  insecureSkipTLS: true
+  servers:
+    - size: 3
+      services:
+        - data
+        - query
+        - index
+  buckets:
+    - name: artifacts
+      memoryQuota: 256
+      replicas: 1
+      evictionPolicy: fullEviction
+    - name: sessions
+      memoryQuota: 128
+      replicas: 1
+  users:
+    - username: "cb_admin"
+      displayName: "aegis cb admin"
+      password: "REPLACE_COUCHBASE_PASSWORD"
+      roles:
+        - admin
+
+---
+# Sync Gateway and mobile sync (optional) requires additional deployment via Sync Gateway manifests; see Couchbase docs.
+
*** End Patch
*** Begin Patch
*** Add File:couchbase/secret-couchbase.yaml
+apiVersion: v1
+kind: Secret
+metadata:
+  name: couchbase-credentials
+  namespace: couchbase
+type: Opaque
+stringData:
+  COUCHBASE_USER: "cb_admin"
+  COUCHBASE_PASSWORD: "REPLACE_COUCHBASE_PASSWORD"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/ingest/mongo_to_couchbase.py
+#!/usr/bin/env python3
+"""
+MongoDB -> Couchbase change stream consumer
+
+Watches the artifacts collection in MongoDB and upserts documents into Couchbase bucket 'artifacts'.
+Idempotent by document _id.
+"""
+import os
+import time
+import json
+from pymongo import MongoClient
+from pymongo.errors import PyMongoError
+from couchbase.cluster import Cluster, ClusterOptions
+from couchbase_core.cluster import PasswordAuthenticator
+from couchbase.exceptions import CouchbaseException
+
+MONGO_URI = os.environ.get("MONGO_URI", "mongodb://localhost:27017")
+MONGO_DB = os.environ.get("MONGO_DB", "aegis")
+MONGO_COLLECTION = os.environ.get("MONGO_COLLECTION", "artifacts")
+
+CB_HOST = os.environ.get("COUCHBASE_HOST", "couchbase.cluster.local")
+CB_USER = os.environ.get("COUCHBASE_USER", "cb_admin")
+CB_PASS = os.environ.get("COUCHBASE_PASSWORD", "REPLACE_COUCHBASE_PASSWORD")
+CB_BUCKET = os.environ.get("COUCHBASE_BUCKET", "artifacts")
+
+def connect_mongo():
+    client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
+    # test
+    client.admin.command('ping')
+    return client
+
+def connect_couchbase():
+    cluster = Cluster(f"couchbase://{CB_HOST}", ClusterOptions(PasswordAuthenticator(CB_USER, CB_PASS)))
+    bucket = cluster.bucket(CB_BUCKET)
+    coll = bucket.default_collection()
+    return coll
+
+def process_change(coll_cb, change):
+    try:
+        doc = change.get("fullDocument")
+        if not doc:
+            return
+        docid = str(doc.get("_id"))
+        # Convert ObjectId if present
+        payload = json.loads(json.dumps(doc, default=str))
+        coll_cb.upsert(docid, payload)
+        print("Upserted to Couchbase id=", docid)
+    except CouchbaseException as e:
+        print("Couchbase upsert error:", e)
+
+def main():
+    while True:
+        try:
+            mg = connect_mongo()
+            db = mg[MONGO_DB]
+            coll = db[MONGO_COLLECTION]
+            cb_coll = connect_couchbase()
+            print("Connected to MongoDB and Couchbase; starting change stream.")
+            with coll.watch(full_document='updateLookup') as stream:
+                for change in stream:
+                    process_change(cb_coll, change)
+        except PyMongoError as e:
+            print("Mongo error:", e)
+            time.sleep(5)
+        except Exception as e:
+            print("Unexpected error:", e)
+            time.sleep(5)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:scripts/db/create_collections_indexes.py
+#!/usr/bin/env python3
+"""
+Create MongoDB collections and indexes for Aegis
+"""
+import os
+from pymongo import MongoClient, IndexModel, ASCENDING
+
+MONGO_URI = os.environ.get("MONGO_URI", "mongodb://localhost:27017")
+DB_NAME = os.environ.get("MONGO_DB", "aegis")
+
+def main():
+    client = MongoClient(MONGO_URI)
+    db = client[DB_NAME]
+    # ensure collections
+    artifacts = db["artifacts"]
+    evidence = db["evidence"]
+    devices = db["devices"]
+    # indexes
+    artifacts.create_indexes([
+        IndexModel([("artifact_id", ASCENDING)], name="artifact_id_idx", unique=True),
+        IndexModel([("git_sha", ASCENDING)], name="git_sha_idx"),
+    ])
+    evidence.create_indexes([
+        IndexModel([("artifact_id", ASCENDING)], name="e_artifact_idx"),
+        IndexModel([("created_at", ASCENDING)], name="e_created_idx"),
+    ])
+    devices.create_indexes([
+        IndexModel([("device_id", ASCENDING)], name="device_id_idx", unique=True),
+        IndexModel([("last_seen", ASCENDING)], name="device_last_seen_idx"),
+    ])
+    print("Collections and indexes created.")
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/ci_write_metadata.yml
+name: CI — write artifact metadata to MongoDB (post-sign)
+on:
+  workflow_run:
+    workflows: ["Build → SBOM → SCA → Sign → Upload"]
+    types: [completed]
+
+jobs:
+  write_metadata:
+    runs-on: ubuntu-latest
+    if: ${{ github.event.workflow_run.conclusion == 'success' }}
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Install Python deps
+        run: |
+          python -m pip install --upgrade pip
+          pip install pymongo boto3
+      - name: Write metadata to MongoDB
+        env:
+          MONGO_URI: ${{ secrets.MONGO_URI }}
+          ARTIFACT_S3: ${{ secrets.MODEL_ARTIFACT_BUCKET }}
+          GITHUB_SHA: ${{ github.sha }}
+        run: |
+          python - <<PY
+import os, json
+from pymongo import MongoClient
+uri = os.environ['MONGO_URI']
+client = MongoClient(uri)
+db = client['aegis']
+art = {
+  "artifact_id": "artifact-${{ github.sha }}",
+  "git_sha": os.environ['GITHUB_SHA'],
+  "manifest_s3": "s3://${{ secrets.MODEL_ARTIFACT_BUCKET }}/artifacts/manifest.json",
+  "created_at": __import__('time').time()
+}
+db.artifacts.insert_one(art)
+print("Inserted artifact metadata")
+PY
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/mongo_exporter/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: mongodb-exporter
+  namespace: monitoring
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: mongodb-exporter
+  template:
+    metadata:
+      labels:
+        app: mongodb-exporter
+    spec:
+      containers:
+        - name: mongodb-exporter
+          image: bitnami/mongodb-exporter:0.12.0
+          env:
+            - name: MONGODB_URI
+              valueFrom:
+                secretKeyRef:
+                  name: mongodb-connection
+                  key: MONGO_URI
+          ports:
+            - containerPort: 9216
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/couchbase_exporter/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: couchbase-exporter
+  namespace: monitoring
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: couchbase-exporter
+  template:
+    metadata:
+      labels:
+        app: couchbase-exporter
+    spec:
+      containers:
+        - name: couchbase-exporter
+          image: couchbase/couchbase-exporter:1.3.0
+          env:
+            - name: CB_HOST
+              value: "couchbase.cluster.local"
+            - name: CB_USER
+              valueFrom:
+                secretKeyRef:
+                  name: couchbase-credentials
+                  key: COUCHBASE_USER
+            - name: CB_PASSWORD
+              valueFrom:
+                secretKeyRef:
+                  name: couchbase-credentials
+                  key: COUCHBASE_PASSWORD
+          ports:
+            - containerPort: 9300
+
*** End Patch
*** Begin Patch
*** Add File:scripts/db/backup_mongo_to_s3.sh
+#!/usr/bin/env bash
+set -euo pipefail
+OUT_DIR=${1:-/tmp/mongo-backup}
+S3_BUCKET=${2:-${EVIDENCE_BUCKET:-}}
+mkdir -p "${OUT_DIR}"
+echo "Running mongodump to ${OUT_DIR} (requires mongo tools and network access to Atlas via private endpoint or public IP allowlist)"
+mongodump --uri="${MONGO_URI:-mongodb://localhost:27017}" --archive="${OUT_DIR}/dump-$(date +%s).gz" --gzip
+if [ -n "${S3_BUCKET}" ]; then
+  aws s3 cp "${OUT_DIR}" "s3://${S3_BUCKET}/db-backups/" --recursive || true
+  echo "Uploaded dumps to s3://${S3_BUCKET}/db-backups/"
+else
+  echo "EVIDENCE_BUCKET not set; backup stored locally at ${OUT_DIR}"
+fi
+
*** End Patch
*** Begin Patch
*** Add File:docs/MONGO_COUCHBASE_RUNBOOK.md
+# Aegis MongoDB (primary) + Couchbase (secondary) Runbook
+
+Overview
+- MongoDB (Atlas) is the primary metadata store: artifacts, evidence index, devices, queries, and change streams.
+- Couchbase (Autonomous Operator) is the specialized low‑latency KV/cache and mobile sync layer; content is materialized from MongoDB change streams.
+
+High-level flow
+1. CI builds and signs artifacts; CI writes artifact metadata into MongoDB (see .github/workflows/ci_write_metadata.yml).
+2. MongoDB change streams (scripts/ingest/mongo_to_couchbase.py) consume inserts/updates on collections (artifacts) and upsert the materialized data to Couchbase 'artifacts' bucket for low-latency reads.
+3. Argo promotion workflows read from MongoDB (primary) for authoritative metadata; Couchbase is used by serving layer for fast lookups.
+4. Backup: MongoDB backups through Atlas (preferred) or mongodump -> S3 (scripts/db/backup_mongo_to_s3.sh). Couchbase backups per operator docs; persist to EVIDENCE_BUCKET.
+
+Installation order (recommended)
+1. Provision MongoDB Atlas via Terraform (terraform/mongo_atlas)
+   - Set atlas_public_key, atlas_private_key, atlas_org_id, db_password as variables securely.
+   - terraform init && terraform apply
+   - Copy the output mongo_connection_string into Kubernetes Secret k8s/mongodb/secret-mongodb.yaml
+
+2. Install Couchbase Operator & apply CouchbaseCluster (couchbase/cluster/couchbasecluster.yaml)
+   - Update passwords in couchbase/secret-couchbase.yaml
+   - kubectl apply -f couchbase/secret-couchbase.yaml
+   - kubectl apply -f couchbase/cluster/couchbasecluster.yaml
+
+3. Create MongoDB collections & indexes
+   - kubectl create secret generic mongodb-connection --from-literal=MONGO_URI='<connection-string>' -n aegis
+   - Run scripts/db/create_collections_indexes.py with MONGO_URI env set (or run locally)
+
+4. Deploy the change stream consumer
+   - Package scripts/ingest/mongo_to_couchbase.py into a small container image (or run as a Deployment)
+   - Deployment should mount env vars: MONGO_URI, COUCHBASE_HOST, COUCHBASE_USER, COUCHBASE_PASSWORD, COUCHBASE_BUCKET
+
+5. CI integration
+   - Add secrets: MONGO_URI (from Atlas), COUCHBASE creds, EVIDENCE_BUCKET
+   - Ensure .github/workflows/ci_build_sign.yml and .github/workflows/ci_write_metadata.yml are enabled
+
+6. Monitoring & backups
+   - Deploy monitoring exporters (monitoring/mongo_exporter and monitoring/couchbase_exporter)
+   - Configure backup strategy: Atlas snapshots (preferred) or scheduled mongodump to S3. Couchbase backups via Operator (see vendor docs).
+
+Security & networking
+- Use Atlas Private Endpoint or VPC peering to avoid public IP. Use IP allowlist if private endpoint not available.
+- Use TLS for all DB connections and enforce user-based auth. Rotate DB creds regularly.
+- Limit network access via K8s NetworkPolicy to only Aegis services that need DB access.
+- Store DB connection strings in Kubernetes Secrets and in CI secret store (GitHub Secrets) with appropriate access controls.
+
+Operational notes
+- Keep MongoDB as the canonical source of truth. Use change streams to materialize selected fields into Couchbase; do not write authoritative updates directly into Couchbase unless it's explicitly allowed.
+- Maintain idempotency in the change stream consumer (use document _id as Couchbase key).
+- Monitor change stream lag and consumer health; restart consumer on transient errors with exponential backoff.
+- Regularly test backup restore procedures for both stores and upload signed proof-of-restore to EVIDENCE_BUCKET.
+
*** End Patch
*** End Patch
