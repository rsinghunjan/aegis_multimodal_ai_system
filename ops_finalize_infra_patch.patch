*** Begin Patch
*** Add File:terraform/irsa/README.md
+# IRSA Terraform - Apply and annotate ServiceAccounts
+
+This document explains how to run the IRSA Terraform module and annotate Kubernetes ServiceAccounts with the created IAM role ARNs.
+
+Important:
+- Do NOT commit secrets or your my.tfvars.
+- Run terraform locally or from a CI job that has appropriate permissions.
+
+Quick steps (local operator)
+1. Copy & edit the tfvars locally:
+   cp terraform/irsa/my.tfvars.example terraform/irsa/my.tfvars
+   # Edit terraform/irsa/my.tfvars and replace REPLACE_* tokens with real non-secret values
+
+2. Initialize and apply:
+   cd terraform/irsa
+   terraform init
+   terraform plan -var-file=my.tfvars
+   terraform apply -var-file=my.tfvars
+
+3. Save outputs:
+   terraform output -json > /tmp/irsa_outputs.json
+
+4. Annotate ServiceAccounts (IRSA):
+   ./irsa_annotate_sa.sh /tmp/irsa_outputs.json
+
+CI / Infra pipeline notes
+- You can run terraform in a pipeline (GitHub Actions/GitLab/Circle). See .github/workflows/terraform_apply_oidc.yml for a GitHub Actions example using OIDC/assume-role.
+- When running in CI, prefer using OIDC-based role assumption instead of long-lived credentials.
+
+Post-apply validation (smoke)
+- Ensure annotated SA can assume role:
+  kubectl -n aegis run --rm -it irsa-test --restart=Never --serviceaccount=braket-sa --image=amazon/aws-cli -- bash -c "aws sts get-caller-identity"
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/terraform_apply_oidc.yml
+name: Terraform IRSA Apply (OIDC)
+
+on:
+  workflow_dispatch:
+    inputs:
+      auto-approve:
+        description: 'Auto approve apply (dangerous). Use only with care.'
+        required: false
+        default: 'false'
+
+jobs:
+  terraform:
+    runs-on: ubuntu-latest
+    permissions:
+      id-token: write
+      contents: read
+    env:
+      TF_WORKING_DIR: terraform/irsa
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Setup Terraform
+        uses: hashicorp/setup-terraform@v2
+        with:
+          terraform_version: 1.5.0
+
+      - name: Configure AWS credentials via OIDC (assume infra role)
+        uses: aws-actions/configure-aws-credentials@v2
+        with:
+          role-to-assume: ${{ secrets.TERRAFORM_OIDC_ROLE }} # role allowing Terraform runs
+          aws-region: REPLACE_AWS_REGION
+
+      - name: Terraform Init
+        working-directory: ${{ env.TF_WORKING_DIR }}
+        run: terraform init -input=false
+
+      - name: Terraform Plan
+        working-directory: ${{ env.TF_WORKING_DIR }}
+        run: terraform plan -input=false -var-file=my.tfvars -out=tfplan
+
+      - name: Upload plan (artifact)
+        uses: actions/upload-artifact@v4
+        with:
+          name: terraform-plan
+          path: terraform/irsa/tfplan
+
+      - name: Terraform Apply (manual approval optional)
+        if: ${{ github.event.inputs.auto-approve == 'true' }}
+        working-directory: ${{ env.TF_WORKING_DIR }}
+        run: terraform apply -input=false -auto-approve tfplan
+
+      - name: Create apply comment (requires manual approval)
+        if: ${{ github.event.inputs.auto-approve != 'true' }}
+        uses: actions/github-script@v6
+        with:
+          github-token: ${{ secrets.GITHUB_TOKEN }}
+          script: |
+            const body = "Terraform plan is ready. To apply run this workflow again with auto-approve=true or apply locally.";
+            github.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: context.issue.number || 1, body });
+
*** End Patch
*** Begin Patch
*** Add File:ops/provision_github_and_k8s_secrets.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Operator helper: set GitHub secrets (via gh) and create ExternalSecrets manifests.
+#
+# Usage (example):
+#   export REPO="owner/repo"
+#   export COSIGN_KMS_ARN="arn:aws:kms:..."
+#   export REKOR_URL="https://rekor.example.com"
+#   export EVIDENCE_BUCKET="aegis-evidence-123"
+#   export MLFLOW_TRACKING_URI="https://mlflow.example.com"
+#   export AWS_ROLE_TO_ASSUME="arn:aws:iam::123:role/ci-oidc-role"
+#   ./ops/provision_github_and_k8s_secrets.sh
+
+REPO=${REPO:-REPLACE_GITHUB_REPOSITORY}
+NAMESPACE=${NAMESPACE:-aegis}
+
+required=(COSIGN_KMS_ARN REKOR_URL EVIDENCE_BUCKET MLFLOW_TRACKING_URI)
+for v in "${required[@]}"; do
+  if [ -z "${!v:-}" ]; then
+    echo "Environment variable ${v} not set. Please export it before running."
+    exit 2
+  fi
+done
+
+echo "Creating GitHub secrets in ${REPO}..."
+gh secret set COSIGN_KMS_ARN --repo "${REPO}" --body "${COSIGN_KMS_ARN}"
+gh secret set REKOR_URL --repo "${REPO}" --body "${REKOR_URL}"
+gh secret set EVIDENCE_BUCKET --repo "${REPO}" --body "${EVIDENCE_BUCKET}"
+gh secret set MLFLOW_TRACKING_URI --repo "${REPO}" --body "${MLFLOW_TRACKING_URI}"
+if [ -n "${AWS_ROLE_TO_ASSUME:-}" ]; then
+  gh secret set AWS_ROLE_TO_ASSUME --repo "${REPO}" --body "${AWS_ROLE_TO_ASSUME}"
+fi
+
+echo "Applying ExternalSecrets manifests (ensure ExternalSecrets operator installed)"
+kubectl apply -n "${NAMESPACE}" -f k8s/external-secrets/secretstore.aws.yaml || true
+kubectl apply -n "${NAMESPACE}" -f k8s/external-secrets/externalsecret_runtime_values.yaml || true
+
+echo "GitHub secrets and ExternalSecrets created (or applied). Verify in GitHub UI and kubectl get externalsecret -n ${NAMESPACE}"
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/registry_push_oidc_example.yml
+name: Registry Push (OIDC) â€” Example for ECR
+
+on:
+  workflow_dispatch:
+
+jobs:
+  push:
+    runs-on: ubuntu-latest
+    permissions:
+      id-token: write
+      contents: read
+      packages: write
+    steps:
+      - uses: actions/checkout@v4
+
+      - name: Configure AWS credentials via OIDC
+        uses: aws-actions/configure-aws-credentials@v2
+        with:
+          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
+          aws-region: REPLACE_AWS_REGION
+
+      - name: Build & push to ECR
+        run: |
+          REPO="${{ secrets.ECR_REGISTRY }}"
+          IMAGE="${REPO}/aegis-quantum:${GITHUB_SHA}"
+          aws ecr get-login-password --region REPLACE_AWS_REGION | docker login --username AWS --password-stdin ${REPO}
+          docker build -t "${IMAGE}" -f docker/quantum/Dockerfile .
+          docker push "${IMAGE}"
+
+      - name: Sign with cosign (awskms)
+        env:
+          COSIGN_KMS_ARN: ${{ secrets.COSIGN_KMS_ARN }}
+          REKOR_URL: ${{ secrets.REKOR_URL }}
+        run: |
+          IMAGE="${{ secrets.ECR_REGISTRY }}/aegis-quantum:${GITHUB_SHA}"
+          cosign sign --key "awskms://${COSIGN_KMS_ARN}" --rekor-server "${REKOR_URL}" "${IMAGE}"
+
*** End Patch
*** Begin Patch
*** Add File:argocd/application-auto-sync-staging.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Application
+metadata:
+  name: aegis-staging-autosync
+  namespace: argocd
+spec:
+  project: default
+  source:
+    repoURL: 'https://github.com/REPLACE_GITOPS_OWNER/REPLACE_GITOPS_REPO.git'
+    targetRevision: HEAD
+    path: 'overlays/staging'
+  destination:
+    server: 'https://kubernetes.default.svc'
+    namespace: aegis
+  syncPolicy:
+    automated:
+      prune: true
+      selfHeal: true
+    syncOptions:
+      - CreateNamespace=true
+      - ApplyOutOfSyncOnly=true
+
*** End Patch
*** Begin Patch
*** Add File:ops/install_service_mesh_and_metric_proxy.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Install Istio service mesh (demo profile) and deploy metric-proxy for Argo to query Prometheus.
+#
+# Usage:
+#   ./ops/install_service_mesh_and_metric_proxy.sh REPLACE_PROMETHEUS_INTERNAL_URL
+
+PROM_URL=${1:-"REPLACE_PROMETHEUS_INTERNAL_URL"}
+
+echo "Installing Istio (demo profile). This uses istioctl; adjust version in the script if needed."
+./istio/install_istio.sh || true
+
+echo "Deploying metric-proxy (make sure metric-proxy-configmap and deployment manifests are present)"
+kubectl apply -f ops/metric-proxy-configmap.yaml
+kubectl apply -f ops/metric-proxy-deployment.yaml
+kubectl -n aegis patch deployment metric-proxy --patch "{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"proxy\",\"env\":[{\"name\":\"PROMETHEUS_URL\",\"value\":\"${PROM_URL}\"}]}]}}}}"
+
+echo "Service mesh installed and metric-proxy deployed. Ensure Prometheus internal URL is reachable from the aegis namespace."
+
*** End Patch
*** Begin Patch
*** Add File:ops/setup_gatekeeper_and_branch_protection.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Install Gatekeeper, apply constraints, and set GitHub branch protection requiring CI checks and PR reviews.
+#
+REPO=${REPO:-REPLACE_GITHUB_REPOSITORY}
+TARGET_BRANCH=${TARGET_BRANCH:-main}
+
+echo "Installing Gatekeeper and applying constraints"
+./ops/install_gatekeeper.sh
+
+echo "Applying GitHub branch protection for ${REPO} ${TARGET_BRANCH}"
+required_contexts=("ci_train_validate_register" "image_build_cosign" "secret-and-deploy-preflight")
+
+# Use gh api to set branch protection with required status checks and required reviews
+gh api --method PUT /repos/${REPO}/branches/${TARGET_BRANCH}/protection -f required_status_checks.strict=true -f required_status_checks.contexts='["ci_train_validate_register","image_build_cosign","secret-and-deploy-preflight"]' -f enforce_admins=true -f required_pull_request_reviews.required_approving_review_count=1
+
+echo "Gatekeeper installed and branch protection configured (adjust contexts as needed)."
+
*** End Patch
*** Begin Patch
*** Add File:ops/upload_signed_legal_and_enable_checks.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Upload legal signoff and ensure CI checks block merges until sanitizer and CI pass.
+#
+FILE=${1:-"ops/legal_signoff.md"}
+EVIDENCE_BUCKET=${EVIDENCE_BUCKET:-"REPLACE_EVIDENCE_BUCKET"}
+REPO=${REPO:-REPLACE_GITHUB_REPOSITORY}
+BRANCH=${BRANCH:-main}
+
+if [ ! -f "${FILE}" ]; then
+  echo "Legal signoff file not found: ${FILE}"
+  exit 2
+fi
+
+echo "Uploading legal signoff to s3://${EVIDENCE_BUCKET}/legal_signoff/"
+aws s3 cp "${FILE}" "s3://${EVIDENCE_BUCKET}/legal_signoff/$(basename "${FILE}")"
+
+echo "Enforcing required CI checks on branch ${BRANCH} in ${REPO}"
+gh api --method PUT /repos/${REPO}/branches/${BRANCH}/protection -f required_status_checks.strict=true -f required_status_checks.contexts='["sanitizer","ci_train_validate_register","secret-and-deploy-preflight"]' -f enforce_admins=true
+
+echo "Legal signoff uploaded and CI branch protection configured."
+
*** End Patch
*** Begin Patch
*** Add File:ops/tune_and_validate_slos.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Tune SLOs and run simple validation queries against Prometheus via metric-proxy.
+#
+METRIC_PROXY_URL=${1:-"http://metric-proxy.aegis.svc.cluster.local:8080"}
+P95_THRESHOLD=${2:-0.5}
+ERROR_RATE_THRESHOLD=${3:-0.02}
+
+echo "Patching SLO configmap in namespace aegis"
+kubectl -n aegis create configmap aegis-slo-config --from-literal=p95_latency_threshold_seconds="${P95_THRESHOLD}" --from-literal=canary_error_rate_threshold="${ERROR_RATE_THRESHOLD}" -o yaml --dry-run=client | kubectl apply -f -
+
+echo "Querying metric-proxy for P95 latency (sample query)"
+QUERY='histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="kserve",env="prod"}[5m])) by (le))'
+URL="${METRIC_PROXY_URL}/api/v1/query?query=$(python3 -c "import urllib.parse; print(urllib.parse.quote('''${QUERY}'''))")"
+echo "Query URL: ${URL}"
+curl -s "${URL}" | jq .
+
+echo "If metrics exceed thresholds, tune node pools, HPA or rollback canary. Use rollout_promote_workflow_metricproxy for automated decisions."
+
*** End Patch
*** End Patch
