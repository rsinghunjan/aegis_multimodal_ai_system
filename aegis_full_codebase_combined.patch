*** Begin Patch
*** Add File: governance/opa/policies/multi_sig.rego
+package aegis.policies
+
+# Multi-sig and approval policies for critical automation actions.
+# Input expected:
+# {
+#   "action": "hsm_rotate" | "promote_model" | "deploy_fleet" | ...,
+#   "approvers": ["alice","bob"],
+#   "required": 2
+# }
+
+default allow = false
+
+allow {
+  input.action != "hsm_rotate"  # non-critical actions allowed by other controls (example)
+}
+
+allow {
+  input.action == "hsm_rotate"
+  count_approvers(input.approvers) >= input.required
+}
+
+# Example: require at least one approver for model promotions (tune as needed)
+allow {
+  input.action == "promote_model"
+  count_approvers(input.approvers) >= 1
+}
+
+count_approvers(arr) = n {
+  n := count({v | arr[_] == v})
+}
+
*** End File
*** Add File: governance/opa/opa_deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: opa-server
+  namespace: ops
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: opa
+  template:
+    metadata:
+      labels:
+        app: opa
+    spec:
+      containers:
+      - name: opa
+        image: openpolicyagent/opa:0.57.0
+        args:
+          - "run"
+          - "--server"
+          - "--set=decision_logs.console=true"
+          - "/policies"
+        ports:
+          - containerPort: 8181
+        volumeMounts:
+          - name: policy-volume
+            mountPath: /policies
+      volumes:
+        - name: policy-volume
+          configMap:
+            name: opa-policies
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: opa
+  namespace: ops
+spec:
+  selector:
+    app: opa
+  ports:
+    - port: 8181
+      targetPort: 8181
+
+---
+apiVersion: v1
+kind: ConfigMap
+metadata:
+  name: opa-policies
+  namespace: ops
+data:
+  multi_sig.rego: |
+    package aegis.policies
+
+    default allow = false
+
+    allow {
+      input.action != "hsm_rotate"
+    }
+
+    allow {
+      input.action == "hsm_rotate"
+      count_approvers(input.approvers) >= input.required
+    }
+
+    count_approvers(arr) = n {
+      n := count({v | arr[_] == v})
+    }
+
*** End File
*** Add File: k8s/rollouts/transaction-manager-rollout.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: AnalysisTemplate
+metadata:
+  name: canary-slo-check
+spec:
+  metrics:
+  - name: error-rate
+    interval: 1m
+    provider:
+      prometheus:
+        address: http://prometheus-operated.monitoring.svc:9090
+        query: |
+          sum(rate(transaction_errors_total[5m])) / sum(rate(transaction_requests_total[5m]))
+    failureLimit: 1
+    successCondition: result < 0.01
+
+---
+apiVersion: argoproj.io/v1alpha1
+kind: Rollout
+metadata:
+  name: transaction-manager
+  namespace: staging
+spec:
+  replicas: 3
+  strategy:
+    canary:
+      steps:
+      - setWeight: 10
+      - pause: {duration: 10m}
+      - analysis:
+          templates:
+          - templateName: canary-slo-check
+      - setWeight: 50
+      - pause: {duration: 30m}
+      - setWeight: 100
+  selector:
+    matchLabels:
+      app: transaction-manager
+  template:
+    metadata:
+      labels:
+        app: transaction-manager
+    spec:
+      containers:
+      - name: tm
+        image: ghcr.io/yourorg/transaction-manager:stable
+        ports:
+        - containerPort: 8080
+
*** End File
*** Add File: .github/workflows/promote_with_rollout.yml
+name: Promote with Argo Rollout (with OPA check)
+on:
+  workflow_dispatch:
+    inputs:
+      image:
+        description: "Image to promote (registry/image:tag)"
+        required: true
+      action:
+        description: "Logical action name for policy (e.g., promote_model)"
+        required: true
+      approvers:
+        description: "Comma-separated list of approvers who have approved"
+        required: true
+      required_approvals:
+        description: "Number of required approvals"
+        required: false
+        default: "1"
+
+jobs:
+  preflight:
+    runs-on: ubuntu-latest
+    steps:
+      - name: OPA policy check
+        env:
+          OPA_URL: ${{ secrets.OPA_URL }} # http://opa.ops.svc.cluster.local:8181/v1/data/aegis/policies/allow
+        run: |
+          APPROVERS="${{ github.event.inputs.approvers }}"
+          REQ="${{ github.event.inputs.required_approvals }}"
+          ACTION="${{ github.event.inputs.action }}"
+          PAYLOAD=$(jq -n --arg action "$ACTION" --argjson approvers "$(jq -R -s -c 'split(",")' <<< "$APPROVERS") --argjson req $REQ '{action: $action, approvers: $approvers, required: ($req|tonumber)}')
+          echo "Payload: $PAYLOAD"
+          RES=$(curl -s -X POST -H "Content-Type: application/json" --data "$PAYLOAD" "${{ secrets.OPA_URL }}")
+          echo "OPA response: $RES"
+          ALLOW=$(echo "$RES" | jq -r '.result.allow // "false"')
+          if [ "$ALLOW" != "true" ]; then
+            echo "OPA denied action. Aborting."
+            exit 1
+          fi
+      - name: Patch Rollout image
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG_STAGING }}
+        run: |
+          IMAGE="${{ github.event.inputs.image }}"
+          kubectl -n staging set image rollout/transaction-manager transaction-manager=$IMAGE
+          echo "Patched rollout image to $IMAGE"
+
*** End File
*** Add File: .github/workflows/multisig_approval_with_opa.yml
+name: Multi-sig Approval with OPA Validation
+on:
+  workflow_dispatch:
+    inputs:
+      issue_number:
+        description: "GitHub issue number requesting approval"
+        required: true
+      action:
+        description: "Action being approved (e.g., hsm_rotate, promote_model)"
+        required: true
+      required_approvals:
+        description: "Number of distinct approvers required"
+        required: false
+        default: "2"
+
+jobs:
+  wait:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Wait for approvals (poll comments)
+        id: wait
+        env:
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          ISSUE=${{ github.event.inputs.issue_number }}
+          REQUIRED=${{ github.event.inputs.required_approvals }}
+          REPO=${{ github.repository }}
+          echo "Waiting for $REQUIRED distinct approvers on issue #$ISSUE"
+          for i in $(seq 1 120); do
+            APPROVERS=$(curl -s -H "Authorization: token $GITHUB_TOKEN" "https://api.github.com/repos/$REPO/issues/$ISSUE/comments" \
+              | jq -r '.[] | select(.body|test("^/approve$")) | .user.login' | sort -u)
+            COUNT=$(echo "$APPROVERS" | wc -l)
+            echo "Approvals: $COUNT"
+            if [ "$COUNT" -ge "$REQUIRED" ]; then
+              echo "Approvals met: $APPROVERS"
+              echo "::set-output name=approvers::$APPROVERS"
+              exit 0
+            fi
+            sleep 20
+          done
+          echo "Timed out waiting for approvals"
+          exit 1
+      - name: OPA validation
+        if: steps.wait.outputs.approvers != ''
+        env:
+          OPA_URL: ${{ secrets.OPA_URL }}
+        run: |
+          ACTION="${{ github.event.inputs.action }}"
+          APPR=$(echo "${{ steps.wait.outputs.approvers }}" | jq -R -s -c 'split("\n")[:-1]')
+          REQ=${{ github.event.inputs.required_approvals }}
+          PAYLOAD=$(jq -n --arg action "$ACTION" --argjson approvers "$APPR" --argjson required $REQ '{action: $action, approvers: $approvers, required: ($required|tonumber)}')
+          echo "OPA payload: $PAYLOAD"
+          RES=$(curl -s -X POST -H "Content-Type: application/json" --data "$PAYLOAD" "${{ secrets.OPA_URL }}")
+          echo "OPA => $RES"
+          ALLOW=$(echo "$RES" | jq -r '.result.allow // "false"')
+          if [ "$ALLOW" != "true" ]; then
+            echo "OPA denied action."
+            exit 1
+          fi
+
*** End File
*** Add File: monitoring/prometheus/automation_kpis.yaml
+groups:
+- name: automation.kpis
+  rules:
+  - alert: HighAutomationRollbackRate
+    expr: (increase(automation_rollbacks_total[1h]) / increase(automation_deploys_total[1h])) > 0.05
+    for: 30m
+    labels:
+      severity: critical
+    annotations:
+      summary: "Automation rollback rate > 5% (1h)"
+      description: "Rollback rate for automated deploys is above 5% in the last hour."
+
+  - alert: HighAnomalyDetectorFPRate
+    expr: increase(anomaly_false_positives_total[1h]) / increase(anomaly_checks_total[1h]) > 0.15
+    for: 30m
+    labels:
+      severity: warning
+    annotations:
+      summary: "Anomaly detector false positive rate high"
+      description: "False positive rate >15% over last hour."
+
+  - alert: AutomationFailureSpike
+    expr: increase(automation_failures_total[15m]) > 5
+    for: 10m
+    labels:
+      severity: critical
+    annotations:
+      summary: "Automation failures increased"
+      description: "More than 5 automation failures in 15m."
+
*** End File
*** Add File: monitoring/grafana/automation_kpis_dashboard.json
+{
+  "dashboard": {
+    "annotations": { "list": [] },
+    "editable": true,
+    "gnetId": null,
+    "panels": [
+      {
+        "type": "graph",
+        "title": "Automation Success Rate",
+        "targets": [
+          { "expr": "1 - (rate(automation_failures_total[5m]) / rate(automation_runs_total[5m]))", "legendFormat": "success_rate" }
+        ],
+        "id": 1
+      },
+      {
+        "type": "graph",
+        "title": "Rollback Rate (1h)",
+        "targets": [
+          { "expr": "rate(automation_rollbacks_total[1h]) / rate(automation_deploys_total[1h])", "legendFormat": "rollback_rate" }
+        ],
+        "id": 2
+      },
+      {
+        "type": "graph",
+        "title": "Anomaly Detector FP Rate",
+        "targets": [
+          { "expr": "rate(anomaly_false_positives_total[1h]) / rate(anomaly_checks_total[1h])", "legendFormat": "fp_rate" }
+        ],
+        "id": 3
+      }
+    ],
+    "schemaVersion": 16,
+    "title": "Automation KPIs",
+    "uid": "automation-kpis"
+  }
+}
+
*** End File
*** Add File: .github/workflows/anomaly_replay_validation.yml
+name: Anomaly Replay Validation
+on:
+  workflow_dispatch:
+    inputs:
+      metrics_s3_prefix:
+        required: true
+      incidents_s3_key:
+        required: true
+
+jobs:
+  replay:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install deps
+        run: python -m pip install --upgrade pip && pip install boto3 scikit-learn joblib pandas
+      - name: Download historic metrics & incidents
+        env:
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+        run: |
+          aws s3 cp "s3://${COMPLIANCE_BUCKET}/${{ github.event.inputs.metrics_s3_prefix }}" ./metrics.csv
+          aws s3 cp "s3://${COMPLIANCE_BUCKET}/${{ github.event.inputs.incidents_s3_key }}" ./incidents.csv
+      - name: Run replay evaluation
+        run: |
+          python3 ml/anomaly/eval_replay.py --metrics-csv ./metrics.csv --incidents-csv ./incidents.csv --model ml/anomaly/model.joblib
+
*** End File
*** Add File: ml/anomaly/synthetic_dataset_generator.py
+#!/usr/bin/env python3
+"""
+Generate a small synthetic metrics CSV + incidents file for replay validation.
+"""
+import csv
+import random
+import datetime
+
+def gen_metrics(path, n=1000, start_ts=None):
+    start = start_ts or datetime.datetime.utcnow()
+    with open(path, "w", newline='') as f:
+        w = csv.writer(f)
+        w.writerow(["ts","stuck_increase_5m","prepare_fail_rate","commit_fail_rate","tm_restarts","tx_queue"])
+        for i in range(n):
+            t = start + datetime.timedelta(seconds=i*60)
+            row = [
+                t.isoformat(),
+                max(0, random.gauss(0.1, 0.5)),
+                abs(random.gauss(0.01, 0.02)),
+                abs(random.gauss(0.01, 0.02)),
+                abs(int(random.gauss(0,1))),
+                max(0, random.gauss(5,3))
+            ]
+            w.writerow(row)
+
+def gen_incidents(path, metrics_csv, rate=0.01):
+    # naive: mark some timestamps as incidents
+    ts = []
+    with open(metrics_csv) as f:
+        reader = csv.DictReader(f)
+        for r in reader:
+            if random.random() < rate:
+                ts.append(r["ts"])
+    with open(path, "w", newline='') as f:
+        w = csv.writer(f)
+        w.writerow(["ts_iso","label"])
+        for t in ts:
+            w.writerow([t,1])
+
+if __name__ == "__main__":
+    gen_metrics("synthetic_metrics.csv", n=1440)
+    gen_incidents("synthetic_incidents.csv", "synthetic_metrics.csv", rate=0.005)
+    print("Wrote synthetic_metrics.csv and synthetic_incidents.csv")
+
*** End File
*** Add File: services/audit_collector/app.py
+from flask import Flask, request, jsonify
+import os
+import sqlite3
+import time
+import json
+import boto3
+
+DB_PATH = os.environ.get("AUDIT_DB", "/data/audit.db")
+S3_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+
+def ensure_db():
+    os.makedirs(os.path.dirname(DB_PATH) or ".", exist_ok=True)
+    conn = sqlite3.connect(DB_PATH)
+    c = conn.cursor()
+    c.execute("""CREATE TABLE IF NOT EXISTS events (id INTEGER PRIMARY KEY AUTOINCREMENT, ts INTEGER, actor TEXT, action TEXT, payload TEXT)""")
+    conn.commit(); conn.close()
+
+ensure_db()
+app = Flask("audit-collector")
+
+@app.route("/event", methods=["POST"])
+def event():
+    data = request.get_json() or {}
+    actor = data.get("actor")
+    action = data.get("action")
+    payload = data.get("payload", {})
+    ts = int(time.time())
+    conn = sqlite3.connect(DB_PATH)
+    c = conn.cursor()
+    c.execute("INSERT INTO events (ts, actor, action, payload) VALUES (?, ?, ?, ?)", (ts, actor, action, json.dumps(payload)))
+    conn.commit()
+    ev_id = c.lastrowid
+    conn.close()
+    # upload to S3 for immutable evidence
+    if S3_BUCKET:
+        s3 = boto3.client("s3")
+        key = f"audit/events/event_{ev_id}_{ts}.json"
+        s3.put_object(Bucket=S3_BUCKET, Key=key, Body=json.dumps({"id": ev_id, "ts": ts, "actor": actor, "action": action, "payload": payload}))
+    return jsonify({"ok": True, "id": ev_id})
+
+@app.route("/health", methods=["GET"])
+def health():
+    return jsonify({"ok": True})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", "8088")))
+
*** End File
*** Add File: services/audit_collector/requirements.txt
+Flask==2.2.5
+boto3==1.26.XXX
+
*** End File
*** Add File: k8s/manifests/audit-collector-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: audit-collector
+  namespace: ops
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: audit-collector
+  template:
+    metadata:
+      labels:
+        app: audit-collector
+    spec:
+      containers:
+      - name: audit-collector
+        image: ghcr.io/yourorg/audit-collector:latest
+        env:
+          - name: COMPLIANCE_BUCKET
+            valueFrom:
+              secretKeyRef:
+                name: aegis-secrets
+                key: compliance_bucket
+        ports:
+          - containerPort: 8088
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: audit-collector
+  namespace: ops
+spec:
+  selector:
+    app: audit-collector
+  ports:
+    - port: 8088
+      targetPort: 8088
+
*** End File
*** Add File: scripts/opa_query_before_action.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Query OPA for permission to perform an action.
+# Usage: ./opa_query_before_action.sh <action> "<approver1,approver2,...>" <required>
+
+ACTION=${1:-}
+APPR_LIST=${2:-""}
+REQUIRED=${3:-1}
+OPA_URL=${OPA_URL:-http://opa.ops.svc.cluster.local:8181/v1/data/aegis/policies/allow}
+
+if [ -z "$ACTION" ]; then
+  echo "Usage: $0 <action> <approvers_csv> <required>"
+  exit 2
+fi
+
+PAYLOAD=$(jq -n --arg action "$ACTION" --argjson approvers "$(jq -R -s -c 'split(",")' <<< "$APPR_LIST") --argjson req $REQUIRED '{action: $action, approvers: $approvers, required: ($req|tonumber)}')
+echo "Querying OPA with payload: $PAYLOAD"
+RES=$(curl -s -X POST -H "Content-Type: application/json" --data "$PAYLOAD" "$OPA_URL")
+echo "OPA response: $RES"
+ALLOW=$(echo "$RES" | jq -r '.result.allow // "false"')
+if [ "$ALLOW" != "true" ]; then
+  echo "OPA: action denied"
+  exit 1
+fi
+echo "OPA: action allowed"
+
*** End File
*** Add File: cloud_tpu/.github/workflows/cloud_tpu_smoke.yml
+name: Cloud TPU Smoke Test
+on:
+  workflow_dispatch:
+    inputs:
+      tpu_name:
+        required: false
+        default: tpuvm-smoke
+      zone:
+        required: false
+        default: us-central1-b
+      accelerator_type:
+        required: false
+        default: v4-8
+      tpu_version:
+        required: false
+        default: v4
+
+jobs:
+  smoke:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Authenticate to GCP
+        env:
+          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
+        run: |
+          echo "$GCP_SA_KEY" > /tmp/gcp-key.json
+          gcloud auth activate-service-account --key-file=/tmp/gcp-key.json
+          gcloud config set project "${{ secrets.GCP_PROJECT }}"
+
+      - name: Create TPU VM
+        env:
+          TPU_NAME: ${{ github.event.inputs.tpu_name }}
+          TPU_ZONE: ${{ github.event.inputs.zone }}
+          TPU_TYPE: ${{ github.event.inputs.accelerator_type }}
+          TPU_VERSION: ${{ github.event.inputs.tpu_version }}
+        run: |
+          echo "Creating TPU VM ${TPU_NAME}..."
+          gcloud compute tpus tpu-vm create "${TPU_NAME}" \
+            --zone="${TPU_ZONE}" \
+            --accelerator-type="${TPU_TYPE}" \
+            --version="${TPU_VERSION}" \
+            --quiet
+
+      - name: Copy smoke test to TPU VM and run
+        env:
+          TPU_NAME: ${{ github.event.inputs.tpu_name }}
+          TPU_ZONE: ${{ github.event.inputs.zone }}
+        run: |
+          gcloud compute tpus tpu-vm scp ./cloud_tpu/tpu_smoke_test.py "${TPU_NAME}":~/ --zone="${TPU_ZONE}"
+          gcloud compute tpus tpu-vm ssh "${TPU_NAME}" --zone="${TPU_ZONE}" --command "python3 ~/tpu_smoke_test.py"
+
+      - name: Delete TPU VM (teardown)
+        env:
+          TPU_NAME: ${{ github.event.inputs.tpu_name }}
+          TPU_ZONE: ${{ github.event.inputs.zone }}
+        run: |
+          echo "Deleting TPU VM ${TPU_NAME}..."
+          gcloud compute tpus tpu-vm delete "${TPU_NAME}" --zone="${TPU_ZONE}" --quiet
+
*** End File
*** Add File: cloud_tpu/Dockerfile.tpu
+FROM python:3.10-slim
+
+# Minimal image with JAX and TPU tooling. In practice, pick the official TPU/JAX images.
+RUN apt-get update && apt-get install -y --no-install-recommends \
+    build-essential git curl ca-certificates ssh \
+  && rm -rf /var/lib/apt/lists/*
+
+RUN pip install --no-cache-dir jax jaxlib==0.4.14+cuda11_cudnn86 -f https://storage.googleapis.com/jax-releases/jax_releases.html || true
+
+WORKDIR /workspace
+COPY tpu_smoke_test.py /workspace/tpu_smoke_test.py
+CMD ["python3","/workspace/tpu_smoke_test.py"]
+
*** End File
*** Add File: cloud_tpu/tpu_smoke_test.py
+"""
+Simple TPU smoke test.
+- Prints available devices via jax.
+- Exits non-zero if no TPU devices are available.
+"""
+import sys
+import time
+
+try:
+    import jax
+except Exception as e:
+    print("Failed to import jax:", e)
+    sys.exit(2)
+
+devs = jax.devices()
+print("JAX devices:", devs)
+if not devs:
+    print("No TPU devices found")
+    sys.exit(1)
+else:
+    print("TPU smoke test OK")
+    sys.exit(0)
+
*** End File
*** Add File: cloud_tpu/README.md
+# Cloud TPU integration (smoke test)
+
+What this provides
+- A GitHub Actions workflow that provisions a TPU VM, copies a small TPU smoke test script, runs it, and tears down the TPU VM.
+
+Prerequisites
+- GCP project with TPU quota enabled.
+- Service account key with appropriate roles stored as `GCP_SA_KEY` in GitHub Secrets.
+- `GCP_PROJECT` secret set to target project.
+
+Notes
+- This workflow is a minimal example for validation. For production training adapt images and launch training processes that use XLA/JAX/TF TPU runtimes and checkpoint to your COMPLIANCE_BUCKET.
+
*** End File
*** Add File: edge_tpu/ansible/roles/edge_tpu/tasks/main.yml
+---
+- name: Ensure apt cache updated
+  apt:
+    update_cache: yes
+
+- name: Add Coral APT repository (Debian/Ubuntu)
+  apt_repository:
+    repo: 'deb https://packages.cloud.google.com/apt coral-edgetpu-stable main'
+    state: present
+  when: ansible_os_family == "Debian"
+
+- name: Install libedgetpu runtime (Debian/Ubuntu)
+  apt:
+    name:
+      - libedgetpu1-std
+      - python3-pip
+    state: present
+  when: ansible_os_family == "Debian"
+
+- name: Install Python dependencies for smoke test
+  pip:
+    name:
+      - pycoral
+    executable: pip3
+
+- name: Create directory for edge-tpu test
+  file:
+    path: /opt/edge_tpu
+    state: directory
+    owner: root
+    mode: "0755"
+
+- name: Copy smoke test
+  copy:
+    src: ../../smoke_test.py
+    dest: /opt/edge_tpu/smoke_test.py
+    mode: "0755"
+
+- name: Run smoke test
+  command: python3 /opt/edge_tpu/smoke_test.py
+  register: smoke
+  failed_when: smoke.rc != 0
+
*** End File
*** Add File: edge_tpu/ansible/roles/edge_tpu/files/README.txt
+Place any vendor packages or local driver files here if you need offline installation.
+By default this role installs packages from the Coral package repository.
+
*** End File
*** Add File: edge_tpu/docker/edge_tpu_test.Dockerfile
+FROM debian:bookworm-slim
+RUN apt-get update && apt-get install -y --no-install-recommends python3 python3-pip ca-certificates \
+  && rm -rf /var/lib/apt/lists/*
+RUN pip3 install pycoral
+WORKDIR /opt/edge_tpu
+COPY smoke_test.py /opt/edge_tpu/smoke_test.py
+CMD ["python3", "/opt/edge_tpu/smoke_test.py"]
+
*** End File
*** Add File: edge_tpu/smoke_test.py
+"""
+Edge TPU (Coral) smoke test placeholder using pycoral.
+This script tries to import pycoral and reports success.
+On a real device, you'd run an inference with an edgetpu-compiled model.
+"""
+import sys
+try:
+    from pycoral.utils.edgetpu import list_edge_tpus
+    tpus = list_edge_tpus()
+    print("Edge TPUs found:", tpus)
+    if not tpus:
+        print("No Edge TPU devices found")
+        sys.exit(1)
+    print("Edge TPU smoke test OK")
+    sys.exit(0)
+except Exception as e:
+    print("Edge TPU smoke test failure:", e)
+    sys.exit(2)
+
*** End File
*** Add File: docs/tpu_support.md
+# TPU Support in Aegis
+
+This document describes the TPU support we are adding: Cloud TPUs (GCP TPU VMs) and Edge TPUs (Coral).
+
+Cloud TPU (GCP)
+- Workflow: .github/workflows/cloud_tpu_smoke.yml
+- Smoke test: cloud_tpu/tpu_smoke_test.py
+- Image example: cloud_tpu/Dockerfile.tpu
+- Secrets required:
+  - GCP_SA_KEY (service account JSON)
+  - GCP_PROJECT
+  - Optionally GCP_ZONE / TPU type can be passed as workflow inputs
+
+Edge TPU (Coral)
+- Ansible role: edge_tpu/ansible/roles/edge_tpu/
+- Smoke test: edge_tpu/smoke_test.py
+- Container example: edge_tpu/docker/edge_tpu_test.Dockerfile
+- Notes: role installs libedgetpu via Coral APT repository; devices must have network access or you must supply packages in role files.
+
+Validation
+- Cloud TPU: run the workflow (dispatch) to create a TPU VM, run the smoke test, and teardown.
+- Edge TPU: run the Ansible role against a test device in inventory and verify the smoke test passes and artifacts are created.
+
+Costs & cautions
+- Cloud TPUs incur charges while provisioned; workflows tear down resources but be mindful of quotas and accidental long-lived resources.
+- Edge TPU installs require root access and driver installs on devices.
+
*** End File
*** Add File: k8s/examples/edge-tpu-job.yaml
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: edge-tpu-smoke
+  namespace: staging
+spec:
+  template:
+    spec:
+      restartPolicy: Never
+      containers:
+      - name: edge-tpu-test
+        image: ghcr.io/yourorg/edge-tpu-test:latest
+        # If running on a node with hostPath to device, mount as needed:
+        # volumeMounts:
+        # - name: usb
+        #   mountPath: /dev/bus/usb
+        resources:
+          limits:
+            cpu: "500m"
+            memory: "256Mi"
+      # volumes:
+      # - name: usb
+      #   hostPath:
+      #     path: /dev/bus/usb
+
*** End File
*** Add File: runbooks/tpu_runbook.md
+# TPU Runbook — smoke tests and validation
+
+## Cloud TPU smoke test (GCP)
+Preconditions:
+- GCP project with TPU quota, service account key in GitHub secret `GCP_SA_KEY`.
+
+Dispatch workflow:
+ - Go to Actions → "Cloud TPU Smoke Test" → Run workflow
+ - Provide inputs if needed (tpu_name, zone, accelerator_type)
+
+What it does:
+ - Creates a TPU VM, copies tpu_smoke_test.py, runs it, then deletes the TPU VM.
+ - Check logs in the GitHub Action for success/failure and jax device listing.
+
+Troubleshooting:
+ - If creation fails, verify TPU quota and network/VPC configuration.
+ - If jax import fails on TPU VM, ensure TPU runtime and pip packages are present or use an official TPU image.
+
+## Edge TPU smoke test (Coral)
+Preconditions:
+- Device accessible via SSH/Ansible, running Debian/Ubuntu (the role targets Debian family).
+
+Run:
+ - ansible-playbook -i inventory/edge_devices.ini edge_tpu/ansible/roles/edge_tpu/tasks/main.yml
+
+What it does:
+ - Installs libedgetpu and pycoral, copies smoke_test.py and runs it.
+ - On success the playbook completes; on failure Ansible will report failed task and output.
+
+Troubleshooting:
+ - If apt repo is not reachable, place packages in edge_tpu/ansible/roles/edge_tpu/files and adjust the role to install locally.
+ - For Coral Dev Board, check vendor docs for any board-specific steps.
+
*** End File
*** Add File: argo/workflows/tpu_provision_and_train.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  name: tpu-provision-train
+  namespace: staging
+spec:
+  entrypoint: tpu-train
+  templates:
+  - name: tpu-train
+    steps:
+    - - name: create-tpu
+        template: gcloud-step
+        arguments:
+          parameters:
+            - name: cmd
+              value: |
+                gcloud compute tpus tpu-vm create {{workflow.parameters.tpuName}} \
+                  --zone={{workflow.parameters.zone}} \
+                  --accelerator-type={{workflow.parameters.acceleratorType}} \
+                  --version={{workflow.parameters.tpuVersion}} --quiet
+    - - name: scp-and-run
+        template: gcloud-step
+        arguments:
+          parameters:
+            - name: cmd
+              value: |
+                gcloud compute tpus tpu-vm scp training/tpu_training.py {{workflow.parameters.tpuName}}:~/ --zone={{workflow.parameters.zone}}
+                gcloud compute tpus tpu-vm ssh {{workflow.parameters.tpuName}} --zone={{workflow.parameters.zone}} --command "python3 ~/tpu_training.py"
+    - - name: delete-tpu
+        template: gcloud-step
+        arguments:
+          parameters:
+            - name: cmd
+              value: |
+                gcloud compute tpus tpu-vm delete {{workflow.parameters.tpuName}} --zone={{workflow.parameters.zone}} --quiet
+  - name: gcloud-step
+    inputs:
+      parameters:
+      - name: cmd
+    container:
+      image: google/cloud-sdk:slim
+      command: [sh, -c]
+      args:
+        - |
+          set -xe
+          echo "Running: {{inputs.parameters.cmd}}"
+          gcloud auth activate-service-account --key-file=/secrets/gcp-key.json
+          gcloud config set project $GCP_PROJECT
+          {{inputs.parameters.cmd}}
+    volumeMounts:
+      - name: gcp-key
+        mountPath: /secrets
+        readOnly: true
+  volumes:
+    - name: gcp-key
+      secret:
+        secretName: gcp-service-account
+  arguments:
+    parameters:
+      - name: tpuName
+        value: tpuvm-train
+      - name: zone
+        value: us-central1-b
+      - name: acceleratorType
+        value: v4-8
+      - name: tpuVersion
+        value: v4
+
+# Notes:
+# - Requires a Kubernetes secret named `gcp-service-account` with the service account JSON at key 'gcp-key.json'.
+# - The training script `training/tpu_training.py` is copied from this repo to the TPU VM and executed. It should save checkpoints locally and push to your agreed storage (S3/GCS).
+
*** End File
*** Add File: training/tpu_training.py
+"""
+Minimal TPU-capable training script (example).
+- Uses JAX if available; creates a tiny "checkpoint" and uploads to S3 if AWS creds are present.
+"""
+import os
+import time
+import json
+
+def dummy_train_and_checkpoint():
+    # Simulate training and write a minimal checkpoint file
+    ckpt = {"trained_steps": 10, "timestamp": int(time.time())}
+    path = "/tmp/tpu_ckpt.json"
+    with open(path, "w") as f:
+        json.dump(ckpt, f)
+    return path
+
+def upload_to_s3(local_path, s3_uri):
+    try:
+        import boto3
+        from urllib.parse import urlparse
+        p = urlparse(s3_uri)
+        bucket = p.netloc
+        key = p.path.lstrip("/")
+        s3 = boto3.client("s3")
+        s3.upload_file(local_path, bucket, key)
+        print(f"Uploaded {local_path} -> s3://{bucket}/{key}")
+    except Exception as e:
+        print("S3 upload failed (ensure AWS creds configured):", e)
+
+def main():
+    out = dummy_train_and_checkpoint()
+    print("Wrote checkpoint:", out)
+    s3_dest = os.environ.get("TRAINING_CHECKPOINT_S3")
+    if s3_dest:
+        upload_to_s3(out, s3_dest)
+    else:
+        print("TRAINING_CHECKPOINT_S3 not set; skipping upload")
+
+if __name__ == "__main__":
+    main()
+
*** End File
*** Add File: k8s/device-plugin/edge-tpu-hostpath-job.yaml
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: edge-tpu-hostpath-smoke
+  namespace: staging
+spec:
+  template:
+    spec:
+      restartPolicy: Never
+      nodeSelector:
+        edge_tpu: "true"   # label nodes that have Edge TPU attached
+      containers:
+      - name: edge-tpu-test
+        image: ghcr.io/yourorg/edge-tpu-test:latest
+        volumeMounts:
+          - name: usb-dev
+            mountPath: /dev/bus/usb
+            readOnly: true
+        resources:
+          limits:
+            cpu: "500m"
+            memory: "256Mi"
+      volumes:
+        - name: usb-dev
+          hostPath:
+            path: /dev/bus/usb
+            type: Directory
+
+# To run this in-cluster, ensure at least one node is labeled:
+# kubectl label node <node-name> edge_tpu=true
+
*** End File
*** Add File: .github/workflows/edge_tpu_incluster_smoke.yml
+name: Edge TPU In-Cluster Smoke Test
+on:
+  workflow_dispatch:
+    inputs:
+      job_manifest:
+        description: "Manifest path for job"
+        default: k8s/device-plugin/edge-tpu-hostpath-job.yaml
+
+jobs:
+  smoke:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Setup kubectl
+        uses: azure/setup-kubectl@v3
+        with:
+          version: 'v1.27.0'
+
+      - name: Configure KUBECONFIG
+        run: |
+          echo "${{ secrets.KUBECONFIG }}" > /tmp/kubeconfig
+          export KUBECONFIG=/tmp/kubeconfig
+        shell: bash
+
+      - name: Apply Job manifest
+        run: |
+          kubectl --kubeconfig=/tmp/kubeconfig apply -f ${{ github.event.inputs.job_manifest }}
+          JOB_NAME=$(yq e '.metadata.name' ${{ github.event.inputs.job_manifest }})
+          echo "Waiting for job $JOB_NAME to complete..."
+          kubectl --kubeconfig=/tmp/kubeconfig wait --for=condition=complete job/$JOB_NAME --timeout=10m
+
+      - name: Fetch pod logs (if failed)
+        if: failure()
+        run: |
+          POD=$(kubectl --kubeconfig=/tmp/kubeconfig get pods -l job-name=$(yq e '.metadata.name' ${{ github.event.inputs.job_manifest }}) -o jsonpath='{.items[0].metadata.name}')
+          kubectl --kubeconfig=/tmp/kubeconfig logs $POD --tail=200 || true
+
*** End File
*** Add File: .github/workflows/build_push_tpu_images.yml
+name: Build & Push TPU Images
+on:
+  workflow_dispatch:
+    inputs:
+      tag:
+        required: false
+        default: ${{ github.sha }}
+
+jobs:
+  build:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Set up QEMU and Docker Buildx
+        uses: docker/setup-buildx-action@v2
+
+      - name: Login to registry
+        uses: docker/login-action@v2
+        with:
+          registry: ${{ secrets.REGISTRY_HOST }}
+          username: ${{ secrets.REGISTRY_USER }}
+          password: ${{ secrets.REGISTRY_TOKEN }}
+
+      - name: Build and push cloud TPU image
+        id: cloud_build
+        uses: docker/build-push-action@v4
+        with:
+          context: ./cloud_tpu
+          file: ./cloud_tpu/Dockerfile.tpu
+          push: true
+          tags: ${{ secrets.REGISTRY_HOST }}/aegis-cloud-tpu:${{ github.event.inputs.tag }}
+
+      - name: Get cloud image digest
+        run: |
+          IMAGE=${{ secrets.REGISTRY_HOST }}/aegis-cloud-tpu:${{ github.event.inputs.tag }}
+          docker pull $IMAGE
+          DIGEST=$(docker image inspect --format='{{index .RepoDigests 0}}' $IMAGE | awk -F@ '{print $2}')
+          echo "cloud_digest=$DIGEST" >> $GITHUB_OUTPUT
+
+      - name: Build and push edge TPU image
+        id: edge_build
+        uses: docker/build-push-action@v4
+        with:
+          context: ./edge_tpu/docker
+          file: ./edge_tpu/docker/edge_tpu_test.Dockerfile
+          push: true
+          tags: ${{ secrets.REGISTRY_HOST }}/aegis-edge-tpu:${{ github.event.inputs.tag }}
+
+      - name: Get edge image digest
+        run: |
+          IMAGE=${{ secrets.REGISTRY_HOST }}/aegis-edge-tpu:${{ github.event.inputs.tag }}
+          docker pull $IMAGE
+          DIGEST=$(docker image inspect --format='{{index .RepoDigests 0}}' $IMAGE | awk -F@ '{print $2}')
+          echo "edge_digest=$DIGEST" >> $GITHUB_OUTPUT
+
+      - name: Summary
+        run: |
+          echo "Cloud image: ${{ secrets.REGISTRY_HOST }}/aegis-cloud-tpu:${{ github.event.inputs.tag }}@${{ steps.cloud_build.outputs.cloud_digest || github.outputs.cloud_digest || '' }}"
+          echo "Edge image: ${{ secrets.REGISTRY_HOST }}/aegis-edge-tpu:${{ github.event.inputs.tag }}@${{ steps.edge_build.outputs.edge_digest || github.outputs.edge_digest || '' }}"
+
+# Required secrets:
+# - REGISTRY_HOST (e.g., ghcr.io/yourorg)
+# - REGISTRY_USER
+# - REGISTRY_TOKEN
+
*** End File
*** Add File: docs/tpu_full_support_next_steps.md
+# TPU Full Support — next steps to finalize production readiness
+
+What this patch adds
+- Argo workflow to provision TPU VMs, run training, and tear down (argo/workflows/tpu_provision_and_train.yaml)
+- Example training script that writes a checkpoint and uploads to S3 if configured (

