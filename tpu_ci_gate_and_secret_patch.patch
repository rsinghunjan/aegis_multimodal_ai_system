*** Begin Patch
*** Add File: .github/workflows/create_k8s_gcp_secret.yml
+name: Create k8s GCP Service Account Secret (from GH Secret)
+on:
+  workflow_dispatch:
+    inputs:
+      kubeconfig_secret:
+        description: "Name of the GH secret that contains KUBECONFIG content (default: KUBECONFIG)"
+        required: false
+        default: KUBECONFIG
+
+jobs:
+  create-secret:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Install kubectl
+        uses: azure/setup-kubectl@v3
+        with:
+          version: 'v1.27.0'
+
+      - name: Write kubeconfig file
+        env:
+          KUBECONFIG_SECRET: ${{ github.event.inputs.kubeconfig_secret }}
+        run: |
+          if [ -z "${{ secrets[env.KUBECONFIG_SECRET] || '' }}" ]; then
+            echo "KUBECONFIG secret '${{ env.KUBECONFIG_SECRET }}' not found in repository secrets. Aborting."
+            exit 1
+          fi
+          echo "${{ secrets[env.KUBECONFIG_SECRET] }}" > /tmp/kubeconfig
+          export KUBECONFIG=/tmp/kubeconfig
+          kubectl version --client
+
+      - name: Create gcp-service-account secret from GCP_SA_KEY
+        env:
+          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
+        run: |
+          if [ -z "$GCP_SA_KEY" ]; then
+            echo "GCP_SA_KEY secret not provided. Set the GitHub secret GCP_SA_KEY (base64 or raw JSON)."
+            exit 1
+          fi
+          # Support both raw JSON and base64-encoded secrets:
+          echo "$GCP_SA_KEY" | jq -e . >/dev/null 2>&1 && echo "$GCP_SA_KEY" > /tmp/gcp-key.json || ( echo "$GCP_SA_KEY" | base64 -d > /tmp/gcp-key.json )
+          kubectl -n staging create secret generic gcp-service-account --from-file=gcp-key.json=/tmp/gcp-key.json --dry-run=client -o yaml | kubectl apply -f -
+          echo "K8s secret 'gcp-service-account' created/updated in namespace 'staging'."
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/tpu_promotion_gate.yml
+name: TPU Artifact Promotion Gate (replay + adversarial + OPA preflight)
+on:
+  workflow_dispatch:
+    inputs:
+      image:
+        description: "Image to promote (registry/image:tag or digest)"
+        required: true
+      metrics_s3_prefix:
+        description: "S3 path prefix to historic metrics (e.g., historical/metrics.csv)"
+        required: true
+      incidents_s3_key:
+        description: "S3 key for incidents/labels CSV (e.g., historical/incidents.csv)"
+        required: true
+      action:
+        description: "Logical action name for OPA (e.g., promote_model)"
+        required: true
+      approvers:
+        description: "Comma-separated approver usernames (for record)"
+        required: true
+      required_approvals:
+        description: "Number of required approvals"
+        required: false
+        default: "1"
+
+jobs:
+  validate:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Install tooling
+        run: |
+          python -m pip install --upgrade pip
+          pip install boto3 pandas scikit-learn joblib jq
+          sudo apt-get update && sudo apt-get install -y jq
+
+      - name: Download historic metrics & incidents from S3
+        env:
+          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
+          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+        run: |
+          set -xe
+          mkdir -p /tmp/tpu_replay
+          aws s3 cp "s3://${COMPLIANCE_BUCKET}/${{ github.event.inputs.metrics_s3_prefix }}" /tmp/tpu_replay/metrics.csv
+          aws s3 cp "s3://${COMPLIANCE_BUCKET}/${{ github.event.inputs.incidents_s3_key }}" /tmp/tpu_replay/incidents.csv
+
+      - name: Run replay evaluation (anomaly)
+        run: |
+          set -xe
+          # Use existing eval_replay script in ml/anomaly if present
+          if [ -f ml/anomaly/eval_replay.py ]; then
+            python3 ml/anomaly/eval_replay.py --metrics-csv /tmp/tpu_replay/metrics.csv --incidents-csv /tmp/tpu_replay/incidents.csv --model ml/anomaly/model.joblib || (echo "Replay validation failed" && exit 1)
+          else
+            echo "No eval_replay.py found; skipping replay check (consider adding replay script to repo)"
+          fi
+
+      - name: Run adversarial harness (if present)
+        run: |
+          if [ -f scripts/adversarial_harness_enhanced.py ]; then
+            python3 scripts/adversarial_harness_enhanced.py || (echo "Adversarial harness failed" && exit 1)
+          else
+            echo "No adversarial_harness_enhanced.py present; skipping adversarial step"
+          fi
+
+      - name: OPA preflight check
+        env:
+          OPA_URL: ${{ secrets.OPA_URL }}
+        run: |
+          ACTION="${{ github.event.inputs.action }}"
+          APPR="${{ github.event.inputs.approvers }}"
+          REQ="${{ github.event.inputs.required_approvals }}"
+          APPR_JSON=$(jq -Rn --arg s "$APPR" '[$s | split(",")[]]')
+          PAYLOAD=$(jq -n --arg action "$ACTION" --argjson approvers "$APPR_JSON" --argjson required "$REQ" '{action: $action, approvers: $approvers, required: ($required|tonumber)}')
+          echo "OPA payload: $PAYLOAD"
+          RES=$(curl -s -X POST -H "Content-Type: application/json" --data "$PAYLOAD" "${{ secrets.OPA_URL }}")
+          echo "OPA response: $RES"
+          ALLOW=$(echo "$RES" | jq -r '.result.allow // "false"')
+          if [ "$ALLOW" != "true" ]; then
+            echo "OPA denied the action. Aborting promotion."
+            exit 1
+          fi
+
+      - name: Promote image (patch Argo Rollout / kubectl set image)
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG }}
+        run: |
+          IMAGE="${{ github.event.inputs.image }}"
+          echo "Promoting image: $IMAGE"
+          # Example: patch an Argo Rollout named 'transaction-manager' in namespace 'staging'
+          # This requires KUBECONFIG secret in the repo (raw kubeconfig content)
+          echo "${KUBECONFIG}" > /tmp/kubeconfig
+          export KUBECONFIG=/tmp/kubeconfig
+          kubectl -n staging set image rollout/transaction-manager transaction-manager="$IMAGE" --record
+          echo "Triggered rollout update to $IMAGE"
+
*** End Patch
*** Begin Patch
*** Add File: scripts/opa_preflight_check.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Small helper to call OPA preflight from local shell or CI steps.
+# Usage: scripts/opa_preflight_check.sh <action> "<approver1,approver2,...>" <required>
+
+ACTION=${1:-}
+APPR_LIST=${2:-""}
+REQUIRED=${3:-1}
+OPA_URL=${OPA_URL:-${OPA_URL:-http://opa.ops.svc.cluster.local:8181/v1/data/aegis/policies/allow}}
+
+if [ -z "$ACTION" ]; then
+  echo "Usage: $0 <action> <approvers_csv> <required>"
+  exit 2
+fi
+
+APPR_JSON=$(jq -Rn --arg s "$APPR_LIST" '[$s | split(",")[]]')
+PAYLOAD=$(jq -n --arg action "$ACTION" --argjson approvers "$APPR_JSON" --argjson required "$REQUIRED" '{action: $action, approvers: $approvers, required: ($required|tonumber)}')
+echo "Querying OPA with payload: $PAYLOAD"
+RES=$(curl -s -X POST -H "Content-Type: application/json" --data "$PAYLOAD" "$OPA_URL")
+echo "OPA response: $RES"
+ALLOW=$(echo "$RES" | jq -r '.result.allow // "false"')
+if [ "$ALLOW" != "true" ]; then
+  echo "OPA: action denied"
+  exit 1
+fi
+echo "OPA: action allowed"
+
*** End Patch
*** Begin Patch
*** Add File: docs/tpu_promotion_gate.md
+# TPU Promotion Gate — replay, adversarial, OPA preflight
+
+Overview
+- This workflow implements a promotion gate for TPU artifacts. It runs:
+  1. Anomaly replay validation using historic metrics & incident labels (from S3).
+  2. An adversarial harness (if present in scripts/).
+  3. An OPA preflight policy check (using secrets.OPA_URL).
+  4. If all checks pass, it updates the target Argo Rollout (example is transaction-manager) by setting the image.
+
+Pre-requisites (defaults already chosen)
+- GCP_SA_KEY: GitHub secret containing GCP service account JSON (raw or base64).
+- GCP_PROJECT: GitHub secret with project id (if using cloud workflows).
+- COMPLIANCE_BUCKET: S3 bucket for metrics & artifacts (GitHub secret).
+- AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY: GitHub secrets if reading replay data from S3.
+- KUBECONFIG: GitHub secret with raw kubeconfig content for the cluster (used to run kubectl).
+- OP A_URL: GitHub secret with OPA decision API endpoint (e.g., http://opa.ops.svc.cluster.local:8181/v1/data/aegis/policies/allow)
+- REGISTRY_HOST/REGISTRY_*: used elsewhere for image build/push workflows (defaults: ghcr.io/yourorg).
+
+How to use
+1. Ensure your secrets are configured in the repository (Settings → Secrets).
+2. Prepare historic metrics and incidents and upload to s3://<COMPLIANCE_BUCKET>/<prefix> paths.
+3. From the Actions UI, run "TPU Artifact Promotion Gate":
+   - image: registry/image:tag (the image you want to promote)
+   - metrics_s3_prefix: historical/metrics.csv
+   - incidents_s3_key: historical/incidents.csv
+   - action: promote_model
+   - approvers: comma-separated usernames (for OPA record)
+   - required_approvals: number
+
+Notes
+- The replay step uses ml/anomaly/eval_replay.py if present in the repo.
+- The adversarial harness step will run scripts/adversarial_harness_enhanced.py if present.
+- The OPA preflight endpoint must be reachable from GitHub Actions (or you can use a public endpoint or proxy).
+- The example promotion operation patches an Argo Rollout named `transaction-manager` in namespace `staging`; edit the workflow if your rollout is named differently.
+
*** End Patch
*** End Patch
