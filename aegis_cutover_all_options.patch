*** Begin Patch
*** Add File:production/cutover/run_staging_playbook.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# One-click staging playbook to validate the Aegis platform end-to-end in staging.
+# It runs (in order):
+#  1) preflight checks
+#  2) optional CloudHSM provisioning + HSM validation
+#  3) install PKCS#11 on signing hosts (operator may need to run per-host)
+#  4) run credentialed QPU pilots (if creds provided in Vault)
+#  5) deploy Feast staging/production helpers and kick ingestion CronJob
+#  6) submit Argo model lifecycle workflow (train->validate->sign->canary->monitor->approve->promote)
+#  7) collect evidence bundle for auditor
+#  8) run smoke & load tests (broker, HPA, serving canary SLI)
+
+# NOTE: This script orchestrates existing scripts in the repo; it requires operator intervention for vendor-specific steps.
+
+PROVISION_HSM="${PROVISION_HSM:-true}"     # set to false to skip TF provisioning
+VAULT_ADDR="${VAULT_ADDR:-}"
+VAULT_TOKEN="${VAULT_TOKEN:-}"
+HSM_TFVARS="${HSM_TFVARS:-cloud/hsm/terraform.tfvars}"
+PKCS11_MODULE="${PKCS11_MODULE:-/opt/vendor/lib/pkcs11.so}"
+PKCS11_SLOT="${PKCS11_SLOT:-0}"
+PKCS11_PIN="${PKCS11_PIN:-}"
+KEY_LABEL="${KEY_LABEL:-pqkey}"
+VAULT_HSM_PATH="${VAULT_HSM_PATH:-secret/data/hsm/config}"
+S3_AUDIT_BUCKET="${S3_AUDIT_BUCKET:-}"
+SIEM_ENDPOINT="${SIEM_ENDPOINT:-}"
+VAULT_PILOT_PATH="${VAULT_PILOT_PATH:-secret/data/quantum/providers}"
+BRAKET_DEVICE="${BRAKET_DEVICE:-}"
+IBM_TOKEN="${IBM_TOKEN:-}"
+S3_PILOT_BUCKET="${S3_PILOT_BUCKET:-aegis-staging-bucket}"
+MLFLOW_URL="${MLFLOW_URL:-http://mlflow:5000}"
+ARGO_WORKFLOW_YAML="production/pipeline/argo_model_lifecycle.yaml"
+MODEL_ARTIFACT_BUCKET="${MODEL_ARTIFACT_BUCKET:-aegis-models}"
+REKOR_URL="${REKOR_URL:-}"
+REGISTRY="${REGISTRY:-}"
+IMAGE_TAG="${IMAGE_TAG:-staging}"
+PROM_URL="${PROM_URL:-http://prometheus.aegis:9090}"
+
+function preflight() {
+  echo "Running preflight checks..."
+  for cmd in kubectl argo aws vault jq python3; do
+    if ! command -v "${cmd}" >/dev/null 2>&1; then
+      echo "Missing required command: ${cmd}. Please install and retry."
+      exit 2
+    fi
+  done
+  if [ -z "${VAULT_TOKEN}" ] || [ -z "${VAULT_ADDR}" ]; then
+    echo "WARNING: VAULT_TOKEN or VAULT_ADDR unset; Vault operations will fail if required."
+  fi
+  echo "Preflight checks complete."
+}
+
+function provision_and_validate_hsm() {
+  if [ "${PROVISION_HSM}" = "true" ]; then
+    echo "Provisioning CloudHSM via Terraform (may take many minutes)..."
+    bash ops/provision_validate_hsm_end_to_end.sh --hsm-tfvars "${HSM_TFVARS}" --pkcs11-module "${PKCS11_MODULE}" --pkcs11-slot "${PKCS11_SLOT}" --pkcs11-pin "${PKCS11_PIN}" --key-label "${KEY_LABEL}" --vault-path "${VAULT_HSM_PATH}" --s3-audit-bucket "${S3_AUDIT_BUCKET}" --siem-endpoint "${SIEM_ENDPOINT}"
+  else
+    echo "Skipping HSM TF provisioning; running install/validate steps only."
+    bash quantum/hsm/vendor_integration/install_vendor_pkcs11.sh --module "${PKCS11_MODULE}" --s3-audit-bucket "${S3_AUDIT_BUCKET}" --siem-endpoint "${SIEM_ENDPOINT}"
+    bash quantum/hsm/validate_hsm_end_to_end.sh --artifact /tmp/aegis_hsm_test.bin --pkcs11-lib "${PKCS11_MODULE}" --pkcs11-slot "${PKCS11_SLOT}" --pkcs11-pin "${PKCS11_PIN}" --pkcs11-keylabel "${KEY_LABEL}" --s3-bucket "${S3_AUDIT_BUCKET}"
+  fi
+}
+
+function run_credentialed_pilots() {
+  if [ -n "${BRAKET_DEVICE}" ] || [ -n "${IBM_TOKEN}" ]; then
+    echo "Running credentialed QPU pilots..."
+    bash quantum/pilot/run_credentialed_pilots.sh --vault-path "${VAULT_PILOT_PATH}" --braket-device "${BRAKET_DEVICE}" --ibm-token "${IBM_TOKEN}" --program /tmp/demo.qasm --s3-bucket "${S3_PILOT_BUCKET}" --mlflow-url "${MLFLOW_URL}"
+  else
+    echo "No QPU credentials provided. Skipping credentialed pilots."
+  fi
+}
+
+function deploy_feast_and_ingest() {
+  echo "Deploying Feast (Helm helpers) and enabling ingestion CronJob..."
+  bash feature_store/feast_prod_helper.sh
+}
+
+function submit_pipeline_workflow() {
+  echo "Submitting Argo model lifecycle workflow..."
+  argo submit "${ARGO_WORKFLOW_YAML}" --watch --parameter MLFLOW_URL="${MLFLOW_URL}" --parameter MODEL_ARTIFACT_BUCKET="${MODEL_ARTIFACT_BUCKET}" --parameter VAULT_PATH="${VAULT_HSM_PATH}" --parameter REKOR_URL="${REKOR_URL}" --parameter REGISTRY="${REGISTRY}" --parameter IMAGE_TAG="${IMAGE_TAG}" --parameter PROM_URL="${PROM_URL}"
+}
+
+function collect_evidence() {
+  echo "Collecting evidence bundle for auditor..."
+  python3 compliance/generate_evidence_bundle_enhanced.py
+  echo "Evidence bundle produced at /tmp/aegis_evidence.tar.gz (or ${EVIDENCE_OUT:-})"
+}
+
+function run_smoke_load() {
+  echo "Running smoke & load tests..."
+  bash ops/smoke_and_load_runbook.sh aegis
+}
+
+### Main
+preflight
+provision_and_validate_hsm
+run_credentialed_pilots
+deploy_feast_and_ingest
+submit_pipeline_workflow
+collect_evidence
+run_smoke_load
+
+echo "Staging playbook complete. Review logs and evidence bundle for issues."
+
*** End Patch
*** Begin Patch
*** Add File:production/cutover/preflight.md
+Preflight checklist — one-click staging playbook
+
+Environment variables (export before running run_staging_playbook.sh)
+- VAULT_ADDR — Vault HTTP(S) address
+- VAULT_TOKEN — Vault admin token (or token with kv put permissions)
+- PROVISION_HSM — "true" or "false" (TF provisioning)
+- HSM_TFVARS — path to Terraform tfvars file for CloudHSM provisioning
+- PKCS11_MODULE — path to vendor PKCS#11 .so (for install script)
+- PKCS11_SLOT, PKCS11_PIN, KEY_LABEL — HSM parameters
+- S3_AUDIT_BUCKET — S3 bucket to collect HSM audit logs
+- SIEM_ENDPOINT — optional SIEM HTTP ingest endpoint
+- VAULT_PILOT_PATH — Vault KV path to write QPU provider credentials
+- BRAKET_DEVICE, IBM_TOKEN — optional QPU credentials
+- MLFLOW_URL — MLflow tracking URL
+- MODEL_ARTIFACT_BUCKET — S3 bucket for signed model artifacts
+- REKOR_URL — Rekor server (optional)
+- REGISTRY, IMAGE_TAG — image registry and tag for CI canary
+- PROM_URL — Prometheus server URL
+
+Prerequisites
+- kubectl configured for target cluster
+- argo CLI configured (if using Argo CLI for submission)
+- aws CLI configured (if provisioning CloudHSM in AWS)
+- cosign installed (for local signing fallback)
+- jq, python3 available on operator workstation
+
+Operator responsibilities (manual steps)
+- Ensure vendor HSM account/vendor onboarding is handled before TF apply
+- Export vendor public keys to /tmp/<key_label>.pub as needed
+- For rotation tests: create new vendor key and export /tmp/<key_label>-v2.pub
+- Confirm Vault policies and k8s ExternalSecrets role are provisioned
+
*** End Patch
*** Begin Patch
*** Add File:production/cutover/argo_closed_loop_demo.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-closed-loop-demo-
+spec:
+  entrypoint: closed-loop
+  templates:
+  - name: closed-loop
+    steps:
+      - - name: detect-drift
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "python3 aiops/drift/data_quality_checks.py --baseline /workspace/data/baseline.csv --candidate /workspace/data/candidate.csv --out /tmp/drift.json --alert-url http://alertmanager.aegis:9093/api/v1/alerts"
+      - - name: incident-bundle
+          template: run-script
+          when: "{{steps.detect-drift.status}} == Succeeded"
+          arguments:
+            parameters:
+              - name: script
+                value: "python3 aiops/incident/incident_bundler.py --deployment aegis-model --out /tmp/incident_{{workflow.name}}.tar.gz --s3-bucket ${EVIDENCE_BUCKET}"
+      - - name: wait-approval
+          template: approval
+      - - name: retrain
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "python3 aiops/retrain/retrain_trigger.py --model aegis-model --dataset latest"
+      - - name: train-validate-deploy
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "argo submit production/pipeline/argo_model_lifecycle.yaml --watch --parameter IMAGE_TAG=${NEW_IMAGE_TAG} --parameter MLFLOW_URL=${MLFLOW_URL} --parameter REGISTRY=${REGISTRY} || true"
+
+  - name: run-script
+    inputs:
+      parameters:
+        - name: script
+    container:
+      image: python:3.10-slim
+      command: [sh, -c]
+      args: ["{{inputs.parameters.script}}"]
+
+  - name: approval
+    suspend: {}
+
+  arguments:
+    parameters:
+      - name: EVIDENCE_BUCKET
+        value: ""
+      - name: NEW_IMAGE_TAG
+        value: ""
+      - name: MLFLOW_URL
+        value: ""
+      - name: REGISTRY
+        value: ""
+
*** End Patch
*** Begin Patch
*** Add File:production/cutover/secret_templates.yaml
+#
+# ExternalSecret and Vault sample templates for production cutover wiring.
+# Operator must adapt to their Vault mount paths, roles and k8s namespaces.
+
+--- # ExternalSecret for broker DB
+apiVersion: kubernetes-client.io/v1
+kind: ExternalSecret
+metadata:
+  name: aegis-broker-db
+  namespace: aegis
+spec:
+  backendType: vault
+  vaultMountPoint: "secret"
+  vaultRole: "aegis-k8s-role"
+  data:
+    - key: "secret/data/job_database"
+      name: JOB_DATABASE_URL
+
+--- # ExternalSecret for HSM config
+apiVersion: kubernetes-client.io/v1
+kind: ExternalSecret
+metadata:
+  name: aegis-hsm-config
+  namespace: aegis
+spec:
+  backendType: vault
+  vaultMountPoint: "secret"
+  vaultRole: "aegis-k8s-role"
+  data:
+    - key: "secret/data/hsm/config"
+      name: HSM_CONFIG
+
+--- # Vault policy sample (run via vault CLI)
+#
+# vault policy write aegis-production-policy - <<EOF
+# path "secret/data/*" { capabilities = ["read","list"] }
+# path "secret/data/job_database" { capabilities = ["read"] }
+# EOF
+
*** End Patch
*** Begin Patch
*** Add File:sprint_plan/PRIORITIZED_SPRINT_PLAN.md
+# Aegis — Prioritized Sprint Plan to Complete Production Cutover
+
+Overview
+- This plan breaks the remaining work into prioritized tickets with owners, acceptance criteria and estimated effort. Use these items to create sprint tickets in your tracker.
+
+Sprint 1 (2 weeks) — Critical operational validation
+1. HSM Provisioning & Validation (Owner: Security/Infra) — 5d
+   - Tasks: Run cloud/hsm TF with HSM_TFVARS; install PKCS#11 on signing host(s); run ops/provision_validate_hsm_end_to_end.sh; verify S3 audit and SIEM sample.
+   - Commands:
+     - export VAULT_ADDR=... VAULT_TOKEN=...
+     - bash production/cutover/run_staging_playbook.sh
+   - Acceptance: hybrid-signature.json present; S3 hsm-audit objects visible; verify_hsm_audit logs pass.
+
+2. Credentialed QPU Pilots (Owner: Quantum) — 4d
+   - Tasks: Add provider creds to Vault, run run_credentialed_pilots.sh, validate MLflow+Rekor entries and simulator_playback.
+   - Acceptance: At least one successful hardware pilot per vendor logged to MLflow with rekor entry.
+
+Sprint 2 (2 weeks) — Serving & Feast prodization
+3. Feast Production Deploy + Ingestion (Owner: Data Platform) — 5d
+   - Tasks: Apply feature_store/externalsecret_feast_db.yaml, run feature_store/feast_prod_helper.sh, validate ingest CronJob.
+   - Acceptance: Feature values available in online store for a sample training job; lineage recorded in MLflow.
+
+4. Serving Promotion & SLI (Owner: ML Platform) — 4d
+   - Tasks: Wire ci/serving/promote_and_verify.sh into CI; test canary deploy, SLI checks and automated rollback.
+   - Acceptance: Image promotion flow passes SLI checks in staging and rolls back on failure.
+
+Sprint 3 (2 weeks) — Closed-loop & Security hardening
+5. Closed-loop remediation validation (Owner: Platform/Automation) — 6d
+   - Tasks: Deploy aiops detectors, submit production/cutover/argo_closed_loop_demo.yaml, verify approval gate and retrain trigger.
+   - Acceptance: Drift detection triggers incident bundler; Argo suspend waits for approval; retrain job created on approval.
+
+6. RBAC/OIDC & Secrets (Owner: Security) — 4d
+   - Tasks: Configure Keycloak clients for agents/UI, apply ops/vault_k8s_setup.sh, deploy ExternalSecrets.
+   - Acceptance: Agents authenticate via k8s service accounts and read secrets via ExternalSecrets; audit logs show Vault access.
+
+Sprint 4 (2 weeks) — Scale & UX
+7. CUR stress tests & chargeback tuning (Owner: FinOps) — 5d
+   - Tasks: Run billing/scale/cur_scale_test_runner.sh, tune thresholds, validate fallback triggers.
+   - Acceptance: Chargeback mapping stable under load; fallback triggered as configured.
+
+8. UX & Model governance polish (Owner: Product) — 5d
+   - Tasks: Wire ui/.github/workflows/model_card_publish.yml, integrate explainability CI step (ci/serving/explainability_step.sh), finalize model card UI/approval flows.
+   - Acceptance: Model card upload works; explainability artifacts linked to model card and MLflow runs.
+
+Cross-cutting tasks (parallel)
+- Legal & SOC2 (Owner: Legal/Compliance) — 4–12 weeks
+  - Deliver evidence bundle per compliance/production_audit_playbook.md, finalize vendor contracts and run audit.
+
+How to use this plan
+- Create tickets for each task with acceptance criteria and estimated days.
+- Assign owners and run a weekly review to track blockers (HSM vendor times, QPU access).
+
*** End Patch
*** Begin Patch
*** Add File:production/cutover/PR_TEMPLATE.md
+Title: Production Cutover — Aegis End-to-End Staging Run & Cutover Scripts
+
+Description:
+- This PR bundles the production cutover scripts and Argo workflows for running the canonical staging validation and closed-loop demo. It includes:
+  - production/cutover/run_staging_playbook.sh
+  - production/cutover/argo_closed_loop_demo.yaml
+  - production/cutover/secret_templates.yaml
+  - sprint_plan/PRIORITIZED_SPRINT_PLAN.md
+
+Notes for reviewers:
+- Confirm Vault/ExternalSecrets templates fit your org policies.
+- Validate TF var files for CloudHSM in a separate secure repo (do not include secrets here).
+- Recommend running run_staging_playbook.sh in a test cluster before staging.
+
+Checklist:
+- [ ] Preflight checklist completed (production/cutover/preflight.md)
+- [ ] Vault roles/policies applied (ops/vault_k8s_setup.sh)
+- [ ] ExternalSecrets tested in a non-prod namespace
+- [ ] Argo workflows validated (dry-run)
+
*** End Patch
*** Begin Patch
*** Add File:production/cutover/README.md
+# Production cutover & one-click staging validation
+
+This folder contains artifacts for operators to perform a canonical staging validation and closed-loop demo for Aegis.
+
+Included
+- run_staging_playbook.sh — orchestrates HSM provisioning/validation, credentialed pilots, Feast deploy, Argo model lifecycle run, evidence collection and smoke tests.
+- preflight.md — preflight checklist and required environment variables.
+- argo_closed_loop_demo.yaml — Argo workflow to exercise detection→incident→approval→retrain→re-deploy loop.
+- secret_templates.yaml — ExternalSecret and Vault policy examples to wire secrets.
+- PR_TEMPLATE.md — reviewer checklist and PR template for ops team.
+
+How to run (staging)
+1. Populate environment variables as listed in preflight.md.
+2. Ensure Vault admin token is available as VAULT_TOKEN and VAULT_ADDR set.
+3. Run: bash production/cutover/run_staging_playbook.sh
+4. Review logs in /tmp and evidence bundle generated by compliance/generate_evidence_bundle_enhanced.py.
+
+Operator notes
+- This playbook is an orchestration tool — some vendor steps require manual intervention (vendor HSM key creation/rotation).
+- Do not store vendor secrets or TF var files in this repo. Use your secrets manager.
+
*** End Patch
