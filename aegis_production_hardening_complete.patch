*** Begin Patch
*** Add File:prod/hardening/rbac/namespace-restricted-rbac.yaml
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: read-only-resources
+  namespace: default
+rules:
+  - apiGroups: [""]
+    resources: ["pods","services","endpoints","configmaps","secrets"]
+    verbs: ["get","list","watch"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: read-only-binding
+  namespace: default
+subjects:
+  - kind: Group
+    name: "viewers@example.com"   # replace with your group
+    apiGroup: rbac.authorization.k8s.io
+roleRef:
+  kind: Role
+  name: read-only-resources
+  apiGroup: rbac.authorization.k8s.io
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: aegis-ops-admin
+rules:
+  - apiGroups: ["*"]
+    resources: ["*"]
+    verbs: ["get","list","watch","create","update","patch","delete","impersonate"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRoleBinding
+metadata:
+  name: aegis-ops-admin-binding
+subjects:
+  - kind: Group
+    name: "aegis-ops-admins@example.com"
+    apiGroup: rbac.authorization.k8s.io
+roleRef:
+  kind: ClusterRole
+  name: aegis-ops-admin
+  apiGroup: rbac.authorization.k8s.io
+
+# Operator: Replace group emails with your identity provider groups. Do NOT grant cluster-admin broadly.
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/networkpolicies/global-default-deny.yaml
+apiVersion: networking.k8s.io/v1
+kind: NetworkPolicy
+metadata:
+  name: default-deny-all-namespaces
+  namespace: default
+spec:
+  podSelector: {}
+  policyTypes:
+    - Ingress
+    - Egress
+
+---
+# Allow monitoring namespace to access control plane endpoints (adjust namespace names as required)
+apiVersion: networking.k8s.io/v1
+kind: NetworkPolicy
+metadata:
+  name: allow-monitoring-to-ops
+  namespace: ops
+spec:
+  podSelector:
+    matchLabels:
+      app: aegis-ops
+  ingress:
+    - from:
+        - namespaceSelector:
+            matchLabels:
+              monitoring: "true"
+      ports:
+        - protocol: TCP
+          port: 9090
+
+# Notes:
+# - Apply default-deny to each namespace (replace 'default' for other namespaces)
+# - Create explicit policies to allow required egress to cloud endpoints (KMS, S3, Rekor, Vault, etc.)
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/opa/policies.rego
+package aegis.safety
+
+# Disallow images from running unless they are signed and come from approved registries.
+default allow = false
+
+approved_registries = {"ghcr.io/yourorg", "docker.io/yourorg", "gcr.io/your-project"}
+
+image_allowed {
+  endswith(input.spec.image, ":latest") == false  # discourage :latest
+}
+
+signed_image {
+  input.metadata.annotations["aegis.cosign.rekor"] != ""  # controller must annotate signed artifacts
+}
+
+allow {
+  image_allowed
+  signed_image
+}
+
+# Tool safety: disallow containers that include shell interpreters in tool definitions unless explicitly allowed.
+deny_tool_with_shell[msg] {
+  some i
+  tool := input.spec.tools[i]
+  tool.kind == "container"
+  contains(tool.image, "bash")  # naive heuristic; tune based on your registry
+  msg = sprintf("tool %v contains shell in image %v", [tool.name, tool.image])
+}
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/conftest/policy/rego/forbidden_fields.rego
+package main
+
+# Example conftest rule: disallow containers with hostNetwork enabled
+deny[msg] {
+  input.kind == "Pod"
+  spec := input.spec
+  spec.hostNetwork == true
+  msg = "hostNetwork must not be used in production pods"
+}
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/conftest/check_manifests.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Run conftest checks on YAML manifests
+MANIFEST_DIR=${1:-.}
+echo "Running conftest against manifests in $MANIFEST_DIR"
+if ! command -v conftest >/dev/null 2>&1; then
+  echo "Install conftest (https://www.conftest.dev/) to run policy checks"
+  exit 2
+fi
+conftest test -p prod/hardening/conftest/policy $MANIFEST_DIR || { echo "Conftest checks failed"; exit 1; }
+echo "Conftest checks passed"
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/vault/auto_unseal_setup.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Configure Vault auto-unseal with AWS KMS (assumes terraform created key and IAM role)
+#
+KMS_KEY_ARN=${KMS_KEY_ARN:-}
+ROLE_ARN=${ROLE_ARN:-}
+
+if [ -z "$KMS_KEY_ARN" ] || [ -z "$ROLE_ARN" ]; then
+  echo "Please set KMS_KEY_ARN and ROLE_ARN env vars (from terraform outputs)"
+  exit 1
+fi
+
+echo "Creating Vault Helm values file for auto-unseal"
+cat > vault-auto-unseal-values.yaml <<EOF
+server:
+  extraEnvironmentVars:
+    VAULT_AWSKMS_KEY_ID: "$KMS_KEY_ARN"
+    VAULT_AWSKMS_REGION: "us-east-1"
+  ha:
+    enabled: true
+autoUnseal:
+  enabled: true
+  aws:
+    kmsKeyId: "$KMS_KEY_ARN"
+    roleArn: "$ROLE_ARN"
+EOF
+
+echo "Apply to Vault helm chart (operator):"
+echo "helm upgrade --install vault hashicorp/vault -n vault -f vault-auto-unseal-values.yaml"
+echo "Vault will auto-unseal using AWS KMS after Helm deployment"
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/kms/key_rotation_policy.tf
+resource "aws_kms_key" "aegis_signing" {
+  description = "Aegis signing key (auto-rotation enabled)"
+  enable_key_rotation = true
+  deletion_window_in_days = 30
+}
+
+output "aegis_kms_key_arn" {
+  value = aws_kms_key.aegis_signing.arn
+}
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/s3/bucket_policy_restrictive.json
+{
+  "Version": "2012-10-17",
+  "Statement": [
+    {
+      "Sid": "AllowAegisServices",
+      "Effect": "Allow",
+      "Principal": {
+        "AWS": [
+          "arn:aws:iam::123456789012:role/aegis-service-role"  /* replace with your role */
+        ]
+      },
+      "Action": [
+        "s3:GetObject",
+        "s3:PutObject",
+        "s3:ListBucket"
+      ],
+      "Resource": [
+        "arn:aws:s3:::aegis-lakefs-staging",
+        "arn:aws:s3:::aegis-lakefs-staging/*"
+      ]
+    },
+    {
+      "Sid": "DenyPublic",
+      "Effect": "Deny",
+      "Principal": "*",
+      "Action": "s3:*",
+      "Resource": [
+        "arn:aws:s3:::aegis-lakefs-staging",
+        "arn:aws:s3:::aegis-lakefs-staging/*"
+      ],
+      "Condition": {
+        "Bool": { "aws:SecureTransport": "false" }
+      }
+    }
+  ]
+}
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/monitoring/slo_rules.yaml
+groups:
+  - name: aegis-slos
+    rules:
+      - record: job:slo_latency_p90:avg
+        expr: histogram_quantile(0.90, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
+      - alert: ModelLatencyHigh
+        expr: job:slo_latency_p90:avg > 0.5  # 500ms threshold, tune per model
+        for: 5m
+        labels:
+          severity: page
+        annotations:
+          summary: "Model latency high (p90 > 500ms)"
+          description: "Model {{ $labels.model }} p90 latency is above 500ms for more than 5m"
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/alertmanager/alertmanager-example.yaml
+global:
+  resolve_timeout: 5m
+route:
+  group_by: ['alertname', 'model']
+  group_wait: 30s
+  group_interval: 5m
+  repeat_interval: 3h
+  receiver: ops
+receivers:
+  - name: 'ops'
+    pagers:
+      - pagerduty_configs: []
+    email_configs:
+      - to: ops@example.com
+  - name: 'security'
+    email_configs:
+      - to: security@example.com
+inhibit_rules: []
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/dr/verify_restore.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# verify_restore.sh
+# Non-destructive checks after restore: verifies object count, sample objects and Vault read
+BACKUP_BUCKET=${1:-aegis-lakefs-backups}
+PREFIX=${2:-latest-restore}
+SAMPLE_KEY=${3:-"README.md"}
+
+echo "Verifying lakeFS backup at s3://$BACKUP_BUCKET/$PREFIX..."
+COUNT=$(aws s3 ls "s3://$BACKUP_BUCKET/$PREFIX" --recursive | wc -l || true)
+echo "Object count: $COUNT"
+
+echo "Checking sample object: $SAMPLE_KEY"
+if aws s3 cp "s3://$BACKUP_BUCKET/$PREFIX/$SAMPLE_KEY" /tmp/sample.out >/dev/null 2>&1; then
+  echo "Sample object retrieved"
+else
+  echo "Sample object missing — investigate"
+  exit 2
+fi
+
+echo "Checking Vault status"
+if command -v vault >/dev/null 2>&1; then
+  vault status || true
+else
+  echo "vault CLI missing; manual check required"
+fi
+
+echo "Verify restore checks completed. Record RTO/RPO metrics manually and update runbook."
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/chaos/chaos_failover.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# chaos_failover.sh -- simulate Redis primary failure for ElastiCache/replication group
+REDIS_ENDPOINT=${1:-redis-cluster.example:6379}
+NAMESPACE=${2:-feast}
+TEST_KEY="aegis-chaos-test-$(date -u +%s)"
+
+echo "Writing test key to Feast online store (via Redis endpoint)"
+redis-cli -h ${REDIS_ENDPOINT%%:*} -p ${REDIS_ENDPOINT##*:} set $TEST_KEY "ok" || true
+
+echo "Simulate failover: operator action required (console or AWS CLI). Pause for manual failover step."
+read -p "Perform failover now (press Enter when done or Ctrl-C to abort)"
+
+echo "Validating Feast can still read key"
+val=$(redis-cli -h ${REDIS_ENDPOINT%%:*} -p ${REDIS_ENDPOINT##*:} get $TEST_KEY || true)
+echo "Value: $val"
+if [ "$val" = "ok" ]; then
+  echo "Failover validation succeeded"
+else
+  echo "Failover validation failed - investigate"
+  exit 2
+fi
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/autoscale/keda_gpu_scaledobject_demo.yaml
+apiVersion: keda.sh/v1alpha1
+kind: ScaledObject
+metadata:
+  name: triton-gpu-scaledobject
+  namespace: ml
+spec:
+  scaleTargetRef:
+    apiVersion: apps/v1
+    kind: Deployment
+    name: triton-deployment
+  pollingInterval: 30
+  cooldownPeriod: 300
+  minReplicaCount: 1
+  maxReplicaCount: 10
+  triggers:
+  - type: prometheus
+    metadata:
+      serverAddress: http://prometheus.monitoring.svc.cluster.local
+      metricName: dcgm_gpu_utilization
+      threshold: "60"  # suggested by perf tuner
+      query: avg(dcgm_gpu_utilization{job="triton"}) by (instance)
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/volcano/preempt_resubmit_cron.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: volcano-preempt-resubmitter
+  namespace: ml
+spec:
+  schedule: "*/5 * * * *"
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          containers:
+            - name: resubmitter
+              image: aegis/volcano-tools:latest
+              command: ["/bin/sh","-c","/opt/resubmit_on_preempt.sh"]
+              env:
+                - name: NAMESPACE
+                  value: "ml"
+          restartPolicy: OnFailure
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/edge/tpm_production_notes.md
+# TPM/TEE productionization notes (Edge)
+
+Key steps to move from demo to production:
+1. Device platform: ensure devices have TPM 2.0 or supported TEE with vendor attestation APIs.
+2. Root of trust: maintain a CA in HSM or KMS; never store CA private key on ordinary VMs.
+3. Quote verification: implement full TPM quote verification server that validates PCRs and nonce, using tpm2-tools or vendor SDK.
+4. Enrollment flow: use short-lived device certificates minted by CA after attestation, store metadata in hardened DB.
+5. OTA security: sign firmware with cosign (use vault:// or KMS-backed key) and publish to manifest; devices verify signatures and fetch updates over TLS.
+6. Offline Rekor: produce signed bundle on device and allow upload when connectivity resumes; Rekor ingestion scripts accept bundles.
+
+References:
+- tpm2-tools, Intel SGX SDK docs, vendor TEE documentation.
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/ota/ota_sign_and_rekor_submit.sh
+#!/usr/bin/env bash
+set -euo pipefail
+ARTIFACT=${1:-}
+if [ -z "$ARTIFACT" ]; then
+  echo "Usage: $0 /path/to/firmware.bin"
+  exit 1
+fi
+
+REKOR=${REKOR_SERVER:-https://rekor.sigstore.dev}
+COSIGN_KEY=${COSIGN_KEY:-"vault://transit/keys/aegis-signing-key"}
+
+echo "Signing artifact with cosign key: $COSIGN_KEY"
+cosign sign-blob --key "$COSIGN_KEY" --output-signature "${ARTIFACT}.sig" "$ARTIFACT"
+
+echo "Submitting artifact signature & payload to Rekor (via cosign Rekor integration)"
+cosign upload-blob --rekor-server "$REKOR" --signature "${ARTIFACT}.sig" "$ARTIFACT" || true
+
+echo "Created offline bundle: ${ARTIFACT}.bundle.tar.gz"
+tar -czf "${ARTIFACT}.bundle.tar.gz" "$ARTIFACT" "${ARTIFACT}.sig"
+echo "Bundle ready for offline devices to consume / verify"
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/devtools/aegisctl_auth_ci_tests.py
+import os, json, tempfile
+from prod.devtools.aegis_sdk.auth_complete import save, load, refresh_if_needed
+
+def test_save_and_load(tmp_path):
+    data = {"access_token":"abc","refresh_token":"r","expires_at": 9999999999, "token_url":"https://example/token","client_id":"cid"}
+    save(data)
+    got = load()
+    assert got["access_token"] == "abc"
+
+def test_refresh_noop(monkeypatch):
+    # Simulate no refresh needed
+    data = {"access_token":"abc","refresh_token":"r","expires_at": 9999999999}
+    save(data)
+    assert not refresh_if_needed()
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/ui/dashboard_improvements.md
+# Dashboard improvements for non-technical users
+
+Suggestions:
+- Add a "Model Health" summary with green/yellow/red badges per model (SLO status).
+- Add an "Audit Trail" view that lists recent model promotions with links to Rekor entries and approver names.
+- Add "Recent Incidents" with links to postmortems and the affected model.
+- Provide CSV export for auditors and an "Executive Summary" tile per week.
+
+Implementation:
+- Use Grafana for SLO panels + plugin for simple dashboard.
+- Small Flask/React UI (prod/ui/dashboard_stub) to aggregate Rekor + Prometheus metadata.
+
*** End Patch
*** Begin Patch
*** Add File:runbooks/hardening_acceptance_criteria.md
+# Hardening acceptance criteria (must pass to call environment "production hardened")
+
+1. Tenant & IAM
+ - OIDC provider configured per cloud; least-privilege roles in place and reviewed.
+ - KMS keys created with rotation enabled and IAM policies narrow to required principals.
+
+2. Secrets & Keys
+ - Vault HA deployed with KMS auto-unseal configured.
+ - Vault audit devices enabled and forwarder sending logs to SIEM (verify logs).
+
+3. Managed backends
+ - ElastiCache/MemoryStore/Bigtable provisioned and Feast/lakeFS point to managed backends.
+ - Failover tested and validated (run chaos_failover.sh).
+
+4. Security scans & pentest
+ - Automated scans (trivy/kube-bench/conftest) run and critical/high findings remediated.
+ - External pentest commissioned and all critical findings remediated or accepted with documented mitigations.
+
+5. Network & workload isolation
+ - Default-deny network policies applied in all namespaces.
+ - Pod security admission enforced (no privileged containers).
+
+6. Backup & DR
+ - Vault raft snapshots scheduled and tested.
+ - lakeFS backups scheduled and verified (verify_restore.sh).
+ - DR drill run and RTO/RPO documented.
+
+7. Monitoring & SLOs
+ - Prometheus recording rules and Alertmanager receivers configured; at least one SLO tested and alert flow verified.
+
+8. Autoscale & performance
+ - Triton perf sweep performed; KEDA thresholds set and validated under load; checkpoint/resume validated for spot jobs.
+
+9. Edge production
+ - TPM/TEE attestation flow enabled; OTA signing & offline Rekor bundle process validated on device or simulator.
+
+10. UX & CI
+ - aegisctl auth refresh tests pass; SDK CI green.
+ - Dashboard skeleton deployed and accessible to stakeholders.
+
+11. Governance & audit
+ - All promotion & deployment paths produce Rekor entries and cosign signatures; admission webhook rejects unsigned artifacts.
+
+Sign-off: security lead, SRE lead, and product owner must sign the checklist after verification.
+
*** End Patch
*** Begin Patch
*** Add File:security/pentest/remediation_tracker_template.csv
+id,component,severity,description,status,owner,created_at,resolved_at,notes
+001,container/image,critical,"Critical CVE in base image","open","devops","2025-12-23T00:00:00Z",,"Upgrade base image and rebuild"
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/backup/verify_lakefs_backup.sh
+#!/usr/bin/env bash
+set -euo pipefail
+BUCKET=${1:-aegis-lakefs-backups}
+PREFIX=${2:-}
+
+echo "Listing objects in s3://$BUCKET/$PREFIX"
+aws s3 ls "s3://$BUCKET/$PREFIX" --recursive | head -n 50
+echo "Checking object integrity via head-object sample"
+SAMPLE=$(aws s3 ls "s3://$BUCKET/$PREFIX" --recursive | awk '{print $4}' | head -n 1)
+if [ -z "$SAMPLE" ]; then
+  echo "No objects found - backup might be empty"
+  exit 2
+fi
+aws s3api head-object --bucket "$BUCKET" --key "$SAMPLE" >/dev/null
+echo "Sample object verified: $SAMPLE"
+
*** End Patch
*** Begin Patch
*** Add File:prod/hardening/sre/oncall_playbook.md
+# On-call playbook (SRE)
+
+Primary responsibilities:
+- Monitor SLO dashboards and Alertmanager.
+- Respond to page (severity=page) within the first 5 minutes.
+- Execute runbook steps for model degradation, serving failure, or security incident.
+
+Key runbook links:
+- Model latency high: prod/hardening/monitoring/slo_rules.yaml -> remediation: scale replicas, rollback model, trigger retrain.
+- Vault degraded: follow Vault HA recovery steps and restore from snapshot (prod/reliability/drill/drill_runner.sh)
+- Data store failover: run prod/hardening/chaos/chaos_failover.sh to validate and follow cloud provider failover runbooks.
+
+Post-incident:
+- Create postmortem with timeline, root cause, mitigations, follow-up actions and owners. Use remediation_tracker_template.csv to add tasks.
+
*** End Patch
*** Begin Patch
*** Add File:docs/security_policy.md
+# Aegis Security Policy (summary)
+
+1) Principle of Least Privilege
+ - All roles bound with least privilege; no wildcard "*" resources in production policies.
+
+2) Key & Secret Management
+ - All signing keys managed by KMS or Vault Transit; keys rotated regularly; auto‑unseal for Vault via KMS.
+
+3) Artifact Signing & Provenance
+ - All production artifacts must be signed (cosign + Vault) and recorded in Rekor prior to admission.
+
+4) Network & Isolation
+ - Default-deny network policies; explicit egress rules to cloud endpoints only.
+
+5) Monitoring & Incident Response
+ - Prometheus alerts and on-call playbooks; regular DR drills and SLO reviews.
+
+6) Edge & Device Trust
+ - TPM/TEE attestation mandatory for fleet devices in production; OTA signed via KMS-backed keys; offline bundles accepted only if signed and later ingested into Rekor.
+
+7) External Validation
+ - Annual external penetration test; remediation tracked and verified.
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/hardening_ci.yml
+name: Hardening CI
+on:
+  workflow_dispatch:
+jobs:
+  conftest:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install Conftest
+        run: |
+          curl -sSL https://github.com/open-policy-agent/conftest/releases/download/v0.36.0/conftest_0.36.0_Linux_x86_64.tar.gz | tar -xz -C /tmp
+          sudo mv /tmp/conftest /usr/local/bin
+      - name: Run conftest
+        run: |
+          ./prod/hardening/conftest/check_manifests.sh prod
+  scans:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run Trivy (if available)
+        run: |
+          if command -v trivy >/dev/null 2>&1; then
+             echo "Trivy present - running quick scan"
+             ./prod/security/pentest/prepare_pentest_bundle.sh
+          else
+             echo "trivy not available in runner"
+          fi
+  terraform-lint:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Terraform
+        uses: hashicorp/setup-terraform@v2
+      - name: Terraform fmt & validate (non-blocking)
+        run: |
+          find terraform -name '*.tf' -print0 | xargs -0 -n1 dirname | sort -u | while read d; do
+            (cd $d && terraform fmt -check) || true
+            (cd $d && terraform validate) || true
+          done
+
*** End Patch
*** End Patch
