*** Begin Patch
*** Add File:argo/workflows/hsm_qpu_full_run.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-hsm-qpu-run-
+spec:
+  entrypoint: hsm-qpu-flow
+  templates:
+  - name: hsm-qpu-flow
+    steps:
+      - - name: provision-hsm
+          template: terraform-apply
+          when: "{{workflow.parameters.run_hsm_provision}} == true"
+      - - name: wait-for-vendor-init
+          template: suspend-for-manual
+      - - name: install-pkcs11
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "quantum/hsm/vendor_integration/install_vendor_pkcs11.sh --module {{workflow.parameters.pkcs11_module}} --s3-audit-bucket {{workflow.parameters.hsm_audit_bucket}} --siem-endpoint {{workflow.parameters.siem_endpoint}}"
+      - - name: validate-hsm
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "quantum/hsm/validate_hsm_end_to_end.sh --artifact /tmp/aegis_hsm_test.bin --pkcs11-lib {{workflow.parameters.pkcs11_module}} --pkcs11-slot {{workflow.parameters.pkcs11_slot}} --pkcs11-pin {{workflow.parameters.pkcs11_pin}} --pkcs11-keylabel {{workflow.parameters.pkcs11_keylabel}} --s3-bucket {{workflow.parameters.hsm_audit_bucket}}"
+      - - name: rotation-manual
+          template: suspend-for-manual
+      - - name: rotation-test
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "quantum/hsm/vendor_rotation_test.sh --vault-path {{workflow.parameters.vault_path}} --new-label {{workflow.parameters.key_label_v2}} --pubkey /tmp/{{workflow.parameters.key_label_v2}}.pub --pkcs11-lib {{workflow.parameters.pkcs11_module}} --slot {{workflow.parameters.pkcs11_slot}} --pin {{workflow.parameters.pkcs11_pin}} --artifact /tmp/aegis_hsm_test.bin --s3-bucket {{workflow.parameters.hsm_audit_bucket}}"
+      - - name: run-pilot-braket
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "python3 quantum/pilot/credentialed_pilot_runner.py --vault-path {{workflow.parameters.vault_path}} --braket-device {{workflow.parameters.braket_device}} --program {{workflow.parameters.program}} --s3-bucket {{workflow.parameters.s3_bucket}} --mlflow-url {{workflow.parameters.mlflow_url}}"
+      - - name: run-pilot-ibm
+          template: run-script
+          arguments:
+            parameters:
+              - name: script
+                value: "python3 quantum/pilot/credentialed_pilot_runner.py --vault-path {{workflow.parameters.vault_path}} --ibm-token {{workflow.parameters.ibm_token}} --program {{workflow.parameters.program}} --s3-bucket {{workflow.parameters.s3_bucket}} --mlflow-url {{workflow.parameters.mlflow_url}}"
+
+  - name: terraform-apply
+    container:
+      image: hashicorp/terraform:light
+      command: [sh, -c]
+      args: ["cd cloud/hsm && terraform init && terraform apply -auto-approve -var-file={{workflow.parameters.hsm_tfvars}} || true"]
+
+  - name: run-script
+    inputs:
+      parameters:
+        - name: script
+    container:
+      image: alpine:3.17
+      command: [sh, -c]
+      args: ["{{inputs.parameters.script}}"]
+
+  - name: suspend-for-manual
+    suspend: {}
+
+  arguments:
+    parameters:
+      - name: run_hsm_provision
+        value: "true"
+      - name: hsm_tfvars
+        value: ""
+      - name: pkcs11_module
+        value: "/opt/vendor/lib/pkcs11.so"
+      - name: pkcs11_slot
+        value: "0"
+      - name: pkcs11_pin
+        value: "1234"
+      - name: pkcs11_keylabel
+        value: "pqkey"
+      - name: key_label_v2
+        value: "pqkey-v2"
+      - name: vault_path
+        value: "secret/data/hsm/config"
+      - name: hsm_audit_bucket
+        value: ""
+      - name: siem_endpoint
+        value: ""
+      - name: braket_device
+        value: ""
+      - name: ibm_token
+        value: ""
+      - name: program
+        value: "/tmp/demo.qasm"
+      - name: s3_bucket
+        value: "aegis-staging-bucket"
+      - name: mlflow_url
+        value: "http://mlflow:5000"
+
*** End Patch
*** Add File:quantum/hsm/vendor_rotation_cli_stub.sh
+#!/usr/bin/env bash
+#
+# Vendor CLI rotation stub
+# Replace the placeholder commands with the vendor's CLI commands to create/rotate keys.
+set -euo pipefail
+KEY_LABEL=${1:-pqkey-v2}
+echo "Running vendor CLI to create a new key labeled ${KEY_LABEL} (placeholder)."
+echo "Operator: replace the following lines with vendor-specific key creation commands."
+echo "Example (pseudo): vendor-hsm-cli create-key --label ${KEY_LABEL} --output-pub /tmp/${KEY_LABEL}.pub"
+# Placeholder fail-safe to avoid accidental no-op
+echo "This script is a template — do not assume it creates keys. Implement vendor commands."
+
*** End Patch
*** Add File:feature_store/k8s/feast-ingest-cronjob.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: feast-ingest
+  namespace: feast
+spec:
+  schedule: "0 * * * *"
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          containers:
+          - name: feast-ingest
+            image: python:3.10-slim
+            command: ["bash","-lc"]
+            args:
+              - |
+                pip install feast pandas mlflow
+                python3 /opt/ingest/ingest_pipeline.py --csv /opt/ingest/data/latest_batch.csv
+            volumeMounts:
+            - name: ingest-scripts
+              mountPath: /opt/ingest
+          restartPolicy: OnFailure
+          volumes:
+          - name: ingest-scripts
+            configMap:
+              name: feast-ingest-scripts
+
*** End Patch
*** Add File:feature_store/k8s/feast-ingest-configmap.yaml
+apiVersion: v1
+kind: ConfigMap
+metadata:
+  name: feast-ingest-scripts
+  namespace: feast
+data:
+  ingest_pipeline.py: |
+    # mounted script (implemented in feature_store/ingest/ingest_pipeline.py in repo)
+    pass
+  latest_batch.csv: |
+    user_id,event_timestamp,email_domain
+
*** End Patch
*** Add File:serving/argorollout/seldon_rollout.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Rollout
+metadata:
+  name: aegis-model-rollout
+  namespace: aegis
+spec:
+  replicas: 3
+  selector:
+    matchLabels:
+      app: aegis-model
+  template:
+    metadata:
+      labels:
+        app: aegis-model
+    spec:
+      containers:
+      - name: aegis-model
+        image: <REGISTRY>/aegis-model:latest
+        ports:
+        - containerPort: 8080
+  strategy:
+    canary:
+      steps:
+      - setWeight: 10
+      - pause: {duration: 60}
+      - setWeight: 50
+      - pause: {duration: 120}
+      - setWeight: 100
+
*** End Patch
*** Add File:ci/serving/push_and_canary.yml
+name: Push Model Image & Canary Deploy
+on:
+  workflow_dispatch:
+jobs:
+  build_and_deploy:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Build and push
+        uses: docker/build-push-action@v4
+        with:
+          push: true
+          tags: ${{ secrets.REGISTRY }}/aegis-model:${{ github.sha }}
+      - name: Notify cluster and create rollout
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG }}
+        run: |
+          kubectl -n aegis set image deployment/aegis-model aegis-model=${{ secrets.REGISTRY }}/aegis-model:${{ github.sha }}
+          kubectl argo rollouts promote aegis-model-rollout --namespace aegis || true
+
*** End Patch
*** Add File:agent/auth/keycloak_integration.md
+Keycloak / OIDC integration notes (operator)
+- Deploy Keycloak and create a client for Aegis UI and a client for agent service accounts.
+- Configure OIDC provider in Kubernetes API server or use Dex + External OIDC.
+- Map OIDC groups to Kubernetes RBAC roles for agent service accounts.
+- This document is guidance — actual integration requires your org's IDP config and secrets.
+
*** End Patch
*** Add File:agent/k8s/agent-serviceaccount-rbac.yaml
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: aegis-agent
+  namespace: aegis
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: aegis-agent-role
+  namespace: aegis
+rules:
+  - apiGroups: [""]
+    resources: ["pods","pods/log","configmaps"]
+    verbs: ["get","list","watch"]
+  - apiGroups: ["batch"]
+    resources: ["jobs","cronjobs"]
+    verbs: ["create","get","list","delete"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: aegis-agent-rb
+  namespace: aegis
+subjects:
+  - kind: ServiceAccount
+    name: aegis-agent
+    namespace: aegis
+roleRef:
+  kind: Role
+  name: aegis-agent-role
+  apiGroup: rbac.authorization.k8s.io
+
*** End Patch
*** Add File:agent/observability/flower_deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-celery-flower
+  namespace: aegis
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-celery-flower
+  template:
+    metadata:
+      labels:
+        app: aegis-celery-flower
+    spec:
+      containers:
+      - name: flower
+        image: mher/flower:0.9.7
+        args: ["--broker=${CELERY_BROKER_URL}", "--port=5555"]
+        env:
+        - name: CELERY_BROKER_URL
+          value: redis://redis:6379/0
+        ports:
+        - containerPort: 5555
+
*** End Patch
*** Add File:compliance/generate_evidence_bundle_enhanced.py
+#!/usr/bin/env python3
+"""
+Enhanced evidence bundle:
+ - Collect Rekor entries for artifacts (rekor-cli)
+ - Collect MLflow runs & artifacts
+ - Collect HSM audit logs from S3 and forward a sample to SIEM (if configured)
+ - Create signed tarball using cosign (if COSIGN_KEY env supplied)
+"""
+import os, subprocess, json, shutil, tempfile, boto3
+
+OUTDIR = os.environ.get("EVIDENCE_OUT","/tmp/aegis_evidence")
+MLFLOW_URL = os.environ.get("MLFLOW_URL")
+HSM_AUDIT_BUCKET = os.environ.get("HSM_AUDIT_BUCKET")
+SIEM_ENDPOINT = os.environ.get("SIEM_ENDPOINT")
+COSIGN_KEY = os.environ.get("COSIGN_KEY")
+
+def collect_rekor_for_hash(sha256):
+    try:
+        out = subprocess.check_output(["rekor-cli","search","--hash","sha256:"+sha256,"--output","json"])
+        return json.loads(out)
+    except Exception:
+        return None
+
+def collect_mlflow(out=OUTDIR, experiment="quantum-pilots"):
+    if not MLFLOW_URL:
+        return
+    try:
+        import mlflow
+        mlflow.set_tracking_uri(MLFLOW_URL)
+        client = mlflow.tracking.MlflowClient()
+        exp = client.get_experiment_by_name(experiment)
+        if not exp:
+            return
+        os.makedirs(os.path.join(out,"mlflow"), exist_ok=True)
+        runs = client.search_runs([exp.experiment_id], max_results=100)
+        for r in runs:
+            rid = r.info.run_id
+            client.download_artifacts(rid, "", os.path.join(out, "mlflow", rid))
+    except Exception as e:
+        print("mlflow collect:", e)
+
+def collect_hsm_audit(out=OUTDIR):
+    if not HSM_AUDIT_BUCKET:
+        return
+    s3 = boto3.client("s3")
+    tmp = os.path.join(out, "hsm_audit")
+    os.makedirs(tmp, exist_ok=True)
+    resp = s3.list_objects_v2(Bucket=HSM_AUDIT_BUCKET, Prefix="hsm-audit/", MaxKeys=200)
+    for o in resp.get("Contents", []):
+        key = o["Key"]
+        local = os.path.join(tmp, os.path.basename(key))
+        s3.download_file(HSM_AUDIT_BUCKET, key, local)
+        # optionally forward one sample to SIEM
+        if SIEM_ENDPOINT:
+            try:
+                subprocess.check_call(["curl","-sS","-X","POST",SIEM_ENDPOINT,"--data-binary",f"@{local}"])
+            except Exception:
+                pass
+
+def collect_broker_logs(out=OUTDIR):
+    os.makedirs(out, exist_ok=True)
+    try:
+        subprocess.check_call(["kubectl","logs","-n","aegis","deployment/aegis-quantum-broker"], stdout=open(os.path.join(out,"broker.log"),"w"))
+    except Exception:
+        pass
+
+def package(out=OUTDIR):
+    tb = out + ".tar.gz"
+    shutil.make_archive(out, 'gztar', root_dir=out)
+    if COSIGN_KEY:
+        try:
+            subprocess.check_call(["cosign","sign-blob","--key",COSIGN_KEY,"--output-signature", out+"/evidence.sig", out+".tar.gz"])
+        except Exception as e:
+            print("cosign signing failed:", e)
+    print("Packaged evidence at", tb)
+
+def main():
+    out = OUTDIR
+    os.makedirs(out, exist_ok=True)
+    collect_broker_logs(out)
+    collect_mlflow(out)
+    collect_hsm_audit(out)
+    package(out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Add File:billing/cur/stress_test_cur_generator.py
+#!/usr/bin/env python3
+"""
+Generate a synthetic simplified CUR CSV for load-testing the billing ingestion.
+Usage: python3 stress_test_cur_generator.py --out /tmp/cur.csv --rows 100000 --jobs 1000
+"""
+import csv, random, argparse, uuid
+
+def generate(out, rows=10000, jobs=100):
+    jobs_list = [f"job-{i}" for i in range(jobs)]
+    with open(out, "w", newline='') as f:
+        w = csv.DictWriter(f, fieldnames=["job","cost"])
+        w.writeheader()
+        for _ in range(rows):
+            job = random.choice(jobs_list)
+            cost = round(random.random() * 50, 2)
+            w.writerow({"job": job, "cost": str(cost)})
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--out", required=True)
+    p.add_argument("--rows", type=int, default=10000)
+    p.add_argument("--jobs", type=int, default=100)
+    args = p.parse_args()
+    generate(args.out, args.rows, args.jobs)
+    print("Generated", args.out)
+
*** End Patch
*** Add File:ui/backend/model_cards_api.py
+from flask import Blueprint, request, jsonify
+import os, json
+
+bp = Blueprint("model_cards", __name__, url_prefix="/api/model-cards")
+STORAGE_DIR = os.environ.get("MODEL_CARD_DIR", "/var/aegis/model-cards")
+os.makedirs(STORAGE_DIR, exist_ok=True)
+
+@bp.route("/", methods=["POST"])
+def create_model_card():
+    payload = request.json or {}
+    model_id = payload.get("model_id")
+    if not model_id:
+        return jsonify({"error":"model_id required"}), 400
+    path = os.path.join(STORAGE_DIR, f"{model_id}.json")
+    with open(path, "w") as f:
+        json.dump(payload, f, indent=2)
+    return jsonify({"status":"created","path":path})
+
+@bp.route("/<model_id>", methods=["GET"])
+def get_model_card(model_id):
+    path = os.path.join(STORAGE_DIR, f"{model_id}.json")
+    if not os.path.exists(path):
+        return jsonify({"error":"not found"}), 404
+    with open(path) as f:
+        return jsonify(json.load(f))
+
*** End Patch
*** Add File:sdk/cli/aegis_cli/model_card_commands.py
+import click, requests, os, json
+API_URL = os.environ.get("AEGIS_API","http://localhost:8081/api")
+
+@click.command()
+@click.option("--model-id", required=True)
+@click.option("--file", required=True)
+def upload_model_card(model_id, file):
+    data = json.load(open(file))
+    data["model_id"] = model_id
+    r = requests.post(f"{API_URL}/model-cards/", json=data)
+    print(r.status_code, r.text)
+
+@click.command()
+@click.option("--model-id", required=True)
+def get_model_card(model_id):
+    r = requests.get(f"{API_URL}/model-cards/{model_id}")
+    print(r.status_code, r.text)
+
*** End Patch
*** Add File:infra/scripts/full_smoke_and_load.sh
+#!/usr/bin/env bash
+set -euo pipefail
+NAMESPACE=${1:-aegis}
+echo "Running broker smoke tests..."
+bash broker/scripts/smoke_tests.sh "${NAMESPACE}"
+
+echo "Running HPA autoscale test (requires BROKER_JWT in env)..."
+if [ -z "${BROKER_JWT:-}" ]; then
+  echo "BROKER_JWT not set; skipping HPA load test"
+else
+  ./broker/runbooks/load_test_hpa.sh "http://aegis-quantum-broker.${NAMESPACE}.svc.cluster.local/submit" "${BROKER_JWT}" 200
+  echo "Wait 2 minutes for HPA"
+  sleep 120
+  kubectl get hpa -n "${NAMESPACE}"
+  echo "Restore baseline replicas"
+  ./broker/scripts/test_hpa_autoscale_and_restore.sh "${NAMESPACE}"
+fi
+
+echo "Verify model serving SLI: query Prometheus for error rate (requires PROM_URL)"
+if [ -n "${PROM_URL:-}" ]; then
+  curl -s "${PROM_URL}/api/v1/query?query=rate(http_requests_total[5m])" | jq .
+fi
+
+echo "Full smoke & load completed."
+
*** End Patch
*** Add File:compliance/auto_email_attach_and_notify.sh
+#!/usr/bin/env bash
+#
+# Prepare evidence bundle and produce a draft email for legal with instruction to attach evidence.
+OUTDIR=${1:-/tmp/aegis_evidence}
+python3 compliance/generate_evidence_bundle_enhanced.py
+EVIDENCE="${OUTDIR}.tar.gz"
+cat > /tmp/aegis_legal_draft.txt <<EOF
+To: legal@example.com
+Subject: Aegis Evidence & Contract Review — draft
+
+Attached: ${EVIDENCE}
+
+Please review vendor contracts and export-control items. Evidence bundle location: ${EVIDENCE}
+EOF
+echo "Draft email saved to /tmp/aegis_legal_draft.txt; operator should attach evidence and send via corporate email."
+
*** End Patch
*** End Patch
