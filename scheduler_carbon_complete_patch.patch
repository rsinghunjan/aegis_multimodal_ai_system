*** Begin Patch
*** Add File:scheduler/carbon/power_profiles.yaml
+# Default power models (W) per node type. Operators should calibrate with calibrate.py.
+# Keys: node_type (label or flavor) -> dict of base_power_w and gpu_power_w_per_card (if applicable)
+default:
+  base_power_w: 150        # typical idle power for a compute node (CPU, memory, fans)
+  gpu_power_w_per_card: 300
+
+gpu.large:
+  base_power_w: 200
+  gpu_power_w_per_card: 400
+
+cpu.large:
+  base_power_w: 250
+  gpu_power_w_per_card: 0
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/feed_aggregator.py
+#!/usr/bin/env python3
+"""
+FeedAggregator: query multiple carbon intensity providers with fallback and caching.
+Supported sources: CO2Signal, AWS (power usage estimator placeholder), GCP (placeholder).
+Caches last value in memory (or you can plug Redis).
+"""
+import time
+import requests
+import os
+from typing import Optional
+
+class FeedAggregator:
+    def __init__(self, co2signal_key: Optional[str]=None, aws_region: Optional[str]=None, cache_ttl=300):
+        self.co2signal_key = co2signal_key or os.environ.get("CO2SIGNAL_API_KEY")
+        self.aws_region = aws_region or os.environ.get("AWS_REGION")
+        self.cache_ttl = cache_ttl
+        self._cache = {"ts": 0, "value": None, "source": None}
+
+    def _fetch_co2signal(self, country="US") -> Optional[int]:
+        if not self.co2signal_key:
+            return None
+        try:
+            r = requests.get(f"https://api.co2signal.com/v1/latest?countryCode={country}", headers={"auth-token": self.co2signal_key}, timeout=5)
+            r.raise_for_status()
+            data = r.json().get("data", {})
+            return int(data.get("carbonIntensity"))
+        except Exception:
+            return None
+
+    def _fetch_aws_estimate(self) -> Optional[int]:
+        # Placeholder: integrate cloud provider-specific carbon APIs or per-region emission factors
+        # Return None if not available
+        return None
+
+    def get_intensity(self, region_hint: str="US") -> (int, str):
+        now = time.time()
+        if self._cache["ts"] + self.cache_ttl > now and self._cache["value"] is not None:
+            return self._cache["value"], self._cache["source"]
+
+        # Try multiple sources in order
+        value = self._fetch_co2signal(region_hint)
+        source = "co2signal"
+        if value is None:
+            value = self._fetch_aws_estimate()
+            source = "aws"
+        if value is None:
+            # fallback: use a conservative default high intensity
+            value = 999
+            source = "fallback"
+
+        self._cache = {"ts": now, "value": value, "source": source}
+        return value, source
+
+if __name__ == "__main__":
+    fa = FeedAggregator()
+    v, s = fa.get_intensity("US")
+    print("Intensity:", v, "source:", s)
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/estimator.py
+#!/usr/bin/env python3
+"""
+Per-job carbon estimator:
+ - Uses node power model, requested resources and expected runtime to estimate energy and emissions.
+ - Emits estimated energy (kWh) and kgCO2e.
+"""
+import yaml
+import os
+from typing import Dict
+
+DEFAULT_POWER_FILE = os.environ.get("POWER_PROFILES", "/app/power_profiles.yaml")
+
+def load_power_profiles(path: str = DEFAULT_POWER_FILE) -> Dict:
+    try:
+        with open(path) as f:
+            return yaml.safe_load(f)
+    except Exception:
+        return {"default": {"base_power_w": 150, "gpu_power_w_per_card": 300}}
+
+def estimate_emissions(requested: Dict, expected_seconds: float, node_type: str = "default", intensity_gco2_per_kwh: float = 500.0):
+    """
+    requested: dict with keys cpu (cores), gpu (count), mem_mb (MB)
+    expected_seconds: estimated runtime
+    node_type: flavor label used to lookup power profile
+    intensity_gco2_per_kwh: gCO2 per kWh (from feed aggregator)
+    Returns dict: {energy_kwh, emissions_kg}
+    """
+    profiles = load_power_profiles()
+    profile = profiles.get(node_type, profiles.get("default"))
+    base_w = profile.get("base_power_w", 150)
+    gpu_w = profile.get("gpu_power_w_per_card", 300)
+
+    # Simple model: base + gpu * per_gpu + cpu contribution (approx proportional)
+    cpu_cores = float(requested.get("cpu", 1))
+    gpu_count = int(requested.get("gpu", 0))
+    # scale cpu power roughly (this is approximate; calibrate with telemetry)
+    cpu_power_w = min(100 * cpu_cores, 300)
+
+    total_w = base_w + cpu_power_w + gpu_count * gpu_w
+    runtime_h = float(expected_seconds) / 3600.0
+    energy_kwh = (total_w / 1000.0) * runtime_h
+    emissions_kg = energy_kwh * (float(intensity_gco2_per_kwh) / 1000.0)
+
+    return {"node_type": node_type, "total_power_w": total_w, "runtime_h": runtime_h, "energy_kwh": energy_kwh, "emissions_kg": emissions_kg}
+
+if __name__ == "__main__":
+    print(estimate_emissions({"cpu":4,"gpu":1}, 3600, "gpu.large", 200.0))
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/spot_optimizer.py
+#!/usr/bin/env python3
+"""
+Spot/preemptible optimizer:
+ - Decides whether to prefer spot/preemptible instance pools based on carbon intensity and cost policies.
+ - Integrates with token-budget service to ensure cost/carbon tradeoffs align with team budgets.
+"""
+import os
+import requests
+
+TOKEN_BUDGET_URL = os.environ.get("TOKEN_BUDGET_URL", "http://token-budget.aegis.svc:9200")
+
+def prefer_spot(team: str, estimated_emissions_kg: float, intensity: int, cost_sensitivity: float = 1.0):
+    """
+    Return True if job should prefer spot nodes.
+    Simple heuristic: if intensity low and token_budget allows additional cost saving.
+    """
+    # If carbon intensity low, spot is fine
+    spot_ok = intensity < 150
+
+    # Query token-budget for allowance (example API)
+    try:
+        r = requests.post(f"{TOKEN_BUDGET_URL}/check_quota", json={"team": team, "kind": "spot", "amount":1}, timeout=5)
+        allowed = r.json().get("allowed", False)
+    except Exception:
+        allowed = False
+
+    return spot_ok and allowed
+
+if __name__ == "__main__":
+    print(prefer_spot("team-a", 1.2, 120))
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/manifest_updater.py
+#!/usr/bin/env python3
+"""
+Update a job/training manifest with carbon estimation fields and upload to S3 evidence bucket.
+"""
+import json
+import os
+import boto3
+from datetime import datetime
+
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+
+def attach_carbon_manifest(manifest_path: str, carbon_info: dict, upload_key_prefix: str):
+    # Append carbon_info to manifest JSON
+    m = json.load(open(manifest_path))
+    m["carbon"] = carbon_info
+    out = manifest_path + ".carbon.json"
+    json.dump(m, open(out, "w"), indent=2)
+    if EVIDENCE_BUCKET:
+        s3 = boto3.client("s3")
+        key = os.path.join(upload_key_prefix.rstrip("/"), f"manifest-{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json")
+        s3.upload_file(out, EVIDENCE_BUCKET, key)
+        return {"s3_key": key}
+    return {"local": out}
+
+if __name__ == "__main__":
+    print(attach_carbon_manifest("/tmp/manifest.json", {"estimated_kg":1.2}, "carbon-manifests"))
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/prom_exporter.py
+#!/usr/bin/env python3
+"""
+Prometheus exporter for carbon metrics (per-job estimates and intensity feed).
+Run as a small process and push metrics via HTTP /metrics.
+"""
+from prometheus_client import start_http_server, Gauge
+import time
+import argparse
+
+g_job_estimate = Gauge("aegis_job_estimated_emissions_kg", "Estimated job emissions in kg", ["job_id","team"])
+g_intensity = Gauge("aegis_region_carbon_intensity_gco2_per_kwh", "Region carbon intensity (gCO2/kWh)", ["region","source"])
+
+def set_job_estimate(job_id, team, kg):
+    g_job_estimate.labels(job_id=job_id, team=team).set(float(kg))
+
+def set_intensity(region, source, value):
+    g_intensity.labels(region=region, source=source).set(int(value))
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--port", type=int, default=9610)
+    args = p.parse_args()
+    start_http_server(args.port)
+    print("Carbon metrics exporter listening on", args.port)
+    while True:
+        time.sleep(10)
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/webhook.py
+#!/usr/bin/env python3
+"""
+Mutating admission webhook for Argo Workflows / Pods to:
+ - estimate per-job carbon emissions
+ - annotate the submitted object with estimate + scheduling hint (nodeSelector or defer timestamp)
+ - optionally reject the admission if policy prohibits the submission now
+
+This is a best-effort scaffold. In production the webhook must be served over TLS with Kubernetes CA-signed certs.
+"""
+import json
+import base64
+from flask import Flask, request, jsonify
+from scheduler.carbon.feed_aggregator import FeedAggregator
+from scheduler.carbon.estimator import estimate_emissions
+from scheduler.carbon.spot_optimizer import prefer_spot
+from datetime import datetime, timedelta
+
+app = Flask("carbon-webhook")
+fa = FeedAggregator()
+
+def build_patch_add_annotation(path, value):
+    return [{"op": "add", "path": path, "value": value}]
+
+@app.route("/mutate", methods=["POST"])
+def mutate():
+    req = request.get_json()
+    # AdmissionReview v1: get object
+    obj = req["request"]["object"]
+    kind = req["request"]["kind"]["kind"]
+    name = obj.get("metadata", {}).get("name", "unknown")
+    namespace = obj.get("metadata", {}).get("namespace", "default")
+    annotations = obj.get("metadata", {}).get("annotations", {}) or {}
+    team = annotations.get("aegis.team", "unknown")
+    # Try to extract resource requests from spec for Pods or Jobs or Argo Workflows (best-effort)
+    # For Argo Workflow, container templates are nested; here we look for top-level pod template
+    # We'll attempt to read an expected runtime annotation; else default to 3600s
+    expected_seconds = float(annotations.get("aegis.expected_seconds", "3600"))
+    # choose node_type from annotation or default
+    node_type = annotations.get("aegis.node_type", "default")
+
+    # simple requested resources: try to read first container resources.requests
+    reqs = {"cpu": 1, "gpu": 0}
+    try:
+        if "spec" in obj:
+            # attempt to find container spec
+            template = obj["spec"].get("template", obj["spec"])
+            containers = template.get("containers") or template.get("workflowTemplate", {}).get("templates", [{}])[0].get("container", [{}])
+            if containers:
+                c = containers[0]
+                resources = c.get("resources", {}).get("limits") or c.get("resources", {}).get("requests") or {}
+                cpu = resources.get("cpu") or resources.get("nvidia.com/gpu") or resources.get("limits.cpu")
+                if cpu:
+                    # normalize CPU: could be "1000m"
+                    if isinstance(cpu, str) and cpu.endswith("m"):
+                        reqs["cpu"] = float(cpu[:-1]) / 1000.0
+                    else:
+                        reqs["cpu"] = float(cpu)
+                gpu = resources.get("nvidia.com/gpu") or resources.get("gpu")
+                if gpu:
+                    reqs["gpu"] = int(gpu)
+    except Exception:
+        pass
+
+    intensity, source = fa.get_intensity("US")
+    est = estimate_emissions(reqs, expected_seconds, node_type, intensity)
+
+    # decide scheduling hint
+    hint = {}
+    if intensity > 300:
+        # high-carbon; suggest deferral for up to 2 hours
+        defer_until = (datetime.utcnow() + timedelta(hours=2)).isoformat() + "Z"
+        hint["action"] = "defer"
+        hint["defer_until"] = defer_until
+    else:
+        hint["action"] = "run"
+        # optionally prefer spot
+        if prefer_spot(team, est["emissions_kg"], intensity):
+            hint["prefer_spot"] = True
+        else:
+            hint["prefer_spot"] = False
+
+    # Build JSON patch to add annotations
+    patch = []
+    ann_path = "/metadata/annotations"
+    add_ann = {
+        "aegis.carbon.intensity": str(intensity),
+        "aegis.carbon.intensity_source": source,
+        "aegis.carbon.estimated_kg": f"{est['emissions_kg']:.6f}",
+        "aegis.carbon.energy_kwh": f"{est['energy_kwh']:.6f}",
+        "aegis.carbon.hint": json.dumps(hint)
+    }
+
+    # If annotations missing, add entire map; else add each key
+    if not obj.get("metadata", {}).get("annotations"):
+        patch.append({"op":"add","path":ann_path,"value":add_ann})
+    else:
+        for k,v in add_ann.items():
+            path = f"{ann_path}/{k.replace('/','~1')}"
+            patch.append({"op":"add","path":path,"value":v})
+
+    admission_response = {
+        "uid": req["request"]["uid"],
+        "allowed": True,
+        "patch": base64.b64encode(json.dumps(patch).encode()).decode(),
+        "patchType": "JSONPatch"
+    }
+
+    return jsonify({"response": admission_response})
+
+@app.route("/healthz")
+def healthz():
+    return "ok"
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=9443)
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/mutating_webhook_k8s.yaml
+apiVersion: admissionregistration.k8s.io/v1
+kind: MutatingWebhookConfiguration
+metadata:
+  name: aegis-carbon-webhook
+webhooks:
+  - name: carbon.aegis.example.com
+    admissionReviewVersions: ["v1"]
+    clientConfig:
+      service:
+        name: aegis-carbon-webhook
+        namespace: aegis
+        path: "/mutate"
+      # caBundle must be filled with the webhook server CA cert (operator step)
+      caBundle: "REPLACE_WITH_CA_BUNDLE"
+    rules:
+      - apiGroups: ["", "argoproj.io"]
+        apiVersions: ["v1", "v1alpha1"]
+        operations: ["CREATE"]
+        resources: ["pods", "workflows"]
+    sideEffects: None
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/webhook_deploy.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-carbon-webhook
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: aegis-carbon-webhook
+  template:
+    metadata:
+      labels:
+        app: aegis-carbon-webhook
+    spec:
+      containers:
+        - name: webhook
+          image: ghcr.io/yourorg/aegis-carbon-webhook:latest
+          ports:
+            - containerPort: 9443
+          env:
+            - name: CO2SIGNAL_API_KEY
+              valueFrom:
+                secretKeyRef:
+                  name: aegis-secrets
+                  key: CO2SIGNAL_API_KEY
+            - name: AWS_REGION
+              value: us-west-2
+          readinessProbe:
+            httpGet:
+              path: /healthz
+              port: 9443
+            initialDelaySeconds: 5
+            periodSeconds: 10
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-carbon-webhook
+  namespace: aegis
+spec:
+  selector:
+    app: aegis-carbon-webhook
+  ports:
+    - protocol: TCP
+      port: 443
+      targetPort: 9443
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/prometheus_rules_carbon.yaml
+groups:
+- name: aegis-carbon.rules
+  rules:
+  - alert: JobCarbonEstimateExceeded
+    expr: aegis_job_estimated_emissions_kg > 50
+    for: 30m
+    labels:
+      severity: warning
+    annotations:
+      summary: "Job estimated carbon > 50kg"
+      description: "A job has an estimated emissions exceeding threshold."
+
+  - alert: RegionCarbonHigh
+    expr: aegis_region_carbon_intensity_gco2_per_kwh > 400
+    for: 15m
+    labels:
+      severity: warning
+    annotations:
+      summary: "Regional carbon intensity high"
+      description: "Consider deferring non-urgent jobs."
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/grafana/carbon_dashboard.json
+{
+  "annotations": {"list": []},
+  "title": "Aegis Carbon Dashboard",
+  "panels": [
+    {
+      "type": "graph",
+      "title": "Region Carbon Intensity",
+      "targets": [{"expr": "aegis_region_carbon_intensity_gco2_per_kwh", "legendFormat": "{{region}} - {{source}}"}],
+      "id": 1
+    },
+    {
+      "type": "graph",
+      "title": "Job Estimated Emissions (kg)",
+      "targets": [{"expr": "aegis_job_estimated_emissions_kg", "legendFormat": "{{job_id}} ({{team}})"}],
+      "id": 2
+    }
+  ],
+  "schemaVersion": 16,
+  "version": 0
+}
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/calibrate.py
+#!/usr/bin/env python3
+"""
+Calibrate power profile values from telemetry.
+Input: CSV with columns node_type, measured_power_w (average), timestamp
+Output: updates power_profiles.yaml with averaged observed values.
+"""
+import csv
+import yaml
+import sys
+from collections import defaultdict
+
+PROFILES_PATH = "/app/power_profiles.yaml"
+
+def calibrate(csv_path, out_path=PROFILES_PATH):
+    sums = defaultdict(float)
+    counts = defaultdict(int)
+    with open(csv_path) as f:
+        r = csv.DictReader(f)
+        for row in r:
+            n = row.get("node_type","default")
+            w = float(row.get("measured_power_w",0))
+            sums[n] += w
+            counts[n] += 1
+    profiles = {}
+    for n in sums:
+        avg = sums[n] / counts[n]
+        # simplistic: set base_power_w = avg - 1*gpu_power if node likely has gpu; keep gpu_power as prior
+        profiles[n] = {"base_power_w": avg, "gpu_power_w_per_card": 300}
+    with open(out_path,"w") as f:
+        yaml.safe_dump(profiles, f)
+    print("Wrote calibrated profiles to", out_path)
+
+if __name__ == "__main__":
+    if len(sys.argv) < 2:
+        print("usage: calibrate.py telemetry.csv")
+        sys.exit(2)
+    calibrate(sys.argv[1])
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/policy_store_example.yaml
+#
+# Example policy store mapping teams/projects to carbon policy.
+# Operators should store these in a central config (e.g., ConfigMap or DB).
+#
+policies:
+  team-a:
+    mode: "low-carbon-only"   # options: low-carbon-only | best-effort
+    carbon_threshold: 200
+  team-b:
+    mode: "best-effort"
+    carbon_threshold: 400
+
*** End Patch
*** Begin Patch
*** Add File:scheduler/carbon/README.md
+# Aegis Carbon Scheduling Components
+
+This directory implements:
+- feed_aggregator.py: queries multiple carbon feeds with fallback.
+- estimator.py: per-job emissions estimator using power profiles.
+- webhook.py: mutating admission webhook that annotates Pods/Workflows with carbon estimates and scheduling hints.
+- prom_exporter.py: Prometheus exporter skeleton for carbon metrics.
+- spot_optimizer.py: simple heuristic for preferring spot/preemptible nodes.
+- manifest_updater.py: append carbon info to job manifest and upload to evidence bucket.
+- calibrate.py: calibrate power profiles from telemetry.
+
+How to deploy (high level):
+1. Build and push container image for webhook and exporter (image references are placeholders).
+2. Deploy webhook_deploy.yaml and mutating_webhook_k8s.yaml (operator must populate CA cert in caBundle).
+3. Deploy prom_exporter and wire Prometheus scrape.
+4. Ensure power_profiles.yaml is tuned via calibrate.py with real telemetry.
+5. Hook manifest_updater into CI or Argo post-submit step to attach carbon manifest and upload evidence.
+
+Note: This is a scaffold; operators must secure TLS for the webhook, integrate with team policy DB, and adjust estimators to measured telemetry.
+
*** End Patch
*** End Patch
