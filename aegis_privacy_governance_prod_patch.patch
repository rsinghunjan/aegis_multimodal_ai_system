*** Begin Patch
*** Add File:requirements-compliance.txt
+psycopg2-binary
+boto3
+requests
+python-jose[cryptography]
+cachetools
+
*** End Patch
*** Begin Patch
*** Add File:compliance/dsr/delete_user_data_prod.py
+#!/usr/bin/env python3
+"""
+Production-grade DSR erasure/export helper.
+
+Behavior:
+ - Export: collects DB rows for configured tables, downloads S3 objects under a per-user prefix,
+   packages into a tar.gz export and uploads evidence to EVIDENCE_BUCKET (optional).
+ - Erase: deletes DB rows for configured tables and deletes S3 objects under the per-user prefix.
+   Writes a deletion_manifest.json and uploads it to EVIDENCE_BUCKET (optional).
+
+Configuration (via environment variables):
+ - DB_DSN: Postgres DSN (e.g., postgresql://user:pass@host:5432/db)
+ - S3_BUCKET: primary artifacts bucket (where user artifacts are stored)
+ - S3_USER_PREFIX: prefix template for user objects; use `{subject}` placeholder. Default "users/{subject}/"
+ - TABLES_TO_PURGE: comma-separated list of DB tables with a `subject_id` column to delete from (default: predictions,user_profiles,events)
+ - EVIDENCE_BUCKET: optional S3 bucket to upload evidence manifests/exports
+ - ERASE_BACKUPS: "true" to attempt to also delete backup objects (operator must ensure correct backup paths)
+
+Usage:
+  python3 delete_user_data_prod.py --action export --subject alice --out /tmp/alice_export.tar.gz
+  python3 delete_user_data_prod.py --action erase --subject alice
+
+WARNING: erase is destructive. Test in staging first.
+"""
+import argparse, os, json, tempfile, tarfile, shutil, sys, datetime
+import psycopg2, boto3
+
+DB_DSN = os.environ.get("DB_DSN", os.environ.get("DATABASE_URL"))
+S3_BUCKET = os.environ.get("S3_BUCKET", os.environ.get("MODEL_ARTIFACT_BUCKET"))
+S3_USER_PREFIX = os.environ.get("S3_USER_PREFIX", "users/{subject}/")
+TABLES_TO_PURGE = os.environ.get("TABLES_TO_PURGE", "predictions,user_profiles,events").split(",")
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET","")
+ERASE_BACKUPS = os.environ.get("ERASE_BACKUPS","false").lower() == "true"
+
+def connect_db():
+    if not DB_DSN:
+        raise RuntimeError("DB_DSN / DATABASE_URL not set")
+    return psycopg2.connect(DB_DSN, sslmode="require")
+
+def export_db_rows(subject, outdir):
+    conn = connect_db()
+    cur = conn.cursor()
+    for table in TABLES_TO_PURGE:
+        try:
+            cur.execute(f"SELECT * FROM {table} WHERE subject_id = %s", (subject,))
+            cols = [d.name for d in cur.description] if cur.description else []
+            rows = cur.fetchall() if cols else []
+            out = {"table": table, "columns": cols, "rows": rows}
+            with open(os.path.join(outdir, f"{table}.json"), "w") as f:
+                json.dump(out, f, default=str)
+        except Exception as e:
+            print("DB export error for", table, e)
+    cur.close()
+    conn.close()
+
+def download_s3_user_objects(subject, outdir, max_objects=1000):
+    if not S3_BUCKET:
+        return
+    s3 = boto3.client("s3")
+    prefix = S3_USER_PREFIX.format(subject=subject)
+    resp = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=prefix, MaxKeys=max_objects)
+    for o in resp.get("Contents", []):
+        key = o["Key"]
+        local = os.path.join(outdir, os.path.basename(key))
+        try:
+            s3.download_file(S3_BUCKET, key, local)
+        except Exception as e:
+            print("Failed to download", key, e)
+
+def package_export(tmpdir, outpath):
+    with tarfile.open(outpath, "w:gz") as tar:
+        tar.add(tmpdir, arcname=os.path.basename(tmpdir))
+
+def upload_evidence(localpath, bucket, key_prefix="dsr"):
+    if not bucket:
+        print("No EVIDENCE_BUCKET configured; skipping upload")
+        return ""
+    s3 = boto3.client("s3")
+    key = f"{key_prefix}/{os.path.basename(localpath)}"
+    s3.upload_file(localpath, bucket, key)
+    return f"s3://{bucket}/{key}"
+
+def export_subject(subject, out="/tmp/dsr_export.tar.gz"):
+    tmp = tempfile.mkdtemp(prefix=f"dsr_export_{subject}_")
+    try:
+        export_db_rows(subject, tmp)
+        download_s3_user_objects(subject, tmp)
+        package_export(tmp, out)
+        evidence_uri = upload_evidence(out, EVIDENCE_BUCKET, key_prefix=f"dsr_exports/{subject}")
+        print("Export ready:", out, "evidence_uri:", evidence_uri)
+    finally:
+        shutil.rmtree(tmp, ignore_errors=True)
+
+def erase_db_rows(subject):
+    conn = connect_db()
+    cur = conn.cursor()
+    deleted = {}
+    for table in TABLES_TO_PURGE:
+        try:
+            cur.execute(f"DELETE FROM {table} WHERE subject_id = %s RETURNING id", (subject,))
+            rows = cur.fetchall()
+            deleted[table] = len(rows)
+            conn.commit()
+        except Exception as e:
+            print("DB delete error for", table, e)
+            conn.rollback()
+    cur.close()
+    conn.close()
+    return deleted
+
+def delete_s3_user_objects(subject):
+    if not S3_BUCKET:
+        return []
+    s3 = boto3.client("s3")
+    prefix = S3_USER_PREFIX.format(subject=subject)
+    resp = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=prefix)
+    deleted = []
+    for o in resp.get("Contents", []):
+        key = o["Key"]
+        try:
+            s3.delete_object(Bucket=S3_BUCKET, Key=key)
+            deleted.append(key)
+        except Exception as e:
+            print("Failed to delete", key, e)
+    # optionally delete backups (operator must ensure accurate backup paths)
+    if ERASE_BACKUPS:
+        # Placeholder: implement backup deletion paths relevant to your infra
+        print("ERASE_BACKUPS enabled: operator must implement backup path deletion")
+    return deleted
+
+def erase_subject(subject):
+    manifest = {"subject": subject, "deleted_at": datetime.datetime.utcnow().isoformat(), "db": {}, "s3": []}
+    db_deleted = erase_db_rows(subject)
+    manifest["db"] = db_deleted
+    s3_deleted = delete_s3_user_objects(subject)
+    manifest["s3"] = s3_deleted
+    # write manifest locally and upload to evidence bucket
+    out = f"/tmp/dsr_erase_{subject}_{int(datetime.datetime.utcnow().timestamp())}.json"
+    with open(out, "w") as f:
+        json.dump(manifest, f, indent=2)
+    evidence_uri = upload_evidence(out, EVIDENCE_BUCKET, key_prefix=f"dsr_erasure/{subject}")
+    print("Erasure complete. Manifest:", out, "evidence_uri:", evidence_uri)
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--action", choices=["export","erase"], required=True)
+    p.add_argument("--subject", required=True)
+    p.add_argument("--out", default="/tmp/dsr_export.tar.gz")
+    args = p.parse_args()
+    if args.action == "export":
+        export_subject(args.subject, out=args.out)
+    else:
+        confirm = os.environ.get("FORCE_ERASE","false").lower()=="true"
+        if not confirm:
+            print("FORCE_ERASE environment variable must be set to 'true' to allow destructive erase in this script.")
+            sys.exit(2)
+        erase_subject(args.subject)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Update File:ui/backend/dsr_api.py
@@
-from flask import Blueprint, request, jsonify
-import os, json, subprocess, uuid, time
-
-bp = Blueprint("dsr", __name__, url_prefix="/api/dsr")
-DSR_STORE = os.environ.get("DSR_STORE", "/var/aegis/dsr")
-os.makedirs(DSR_STORE, exist_ok=True)
-
-def require_auth():
-    # placeholder: integrate with Keycloak / OIDC
-    token = request.headers.get("Authorization")
-    if not token:
-        return False
-    return True
+from flask import Blueprint, request, jsonify, current_app
+import os, json, subprocess, uuid, time
+from auth.keycloak_jwt import validate_and_extract_user
+
+bp = Blueprint("dsr", __name__, url_prefix="/api/dsr")
+DSR_STORE = os.environ.get("DSR_STORE", "/var/aegis/dsr")
+os.makedirs(DSR_STORE, exist_ok=True)
+
+def require_auth():
+    # Validate Keycloak JWT and return user info
+    auth = request.headers.get("Authorization")
+    if not auth:
+        return None
+    token = auth.split("Bearer ")[-1] if "Bearer " in auth else auth
+    try:
+        user = validate_and_extract_user(token)
+        return user
+    except Exception:
+        return None
@@
-    if not require_auth():
-        return jsonify({"error":"unauthenticated"}), 401
+    user = require_auth()
+    if not user:
+        return jsonify({"error":"unauthenticated"}), 401
     payload = request.json or {}
     subject = payload.get("subject_id")
     if not subject:
         return jsonify({"error":"subject_id required"}), 400
     req_id = str(uuid.uuid4())
-    rec = {"id": req_id, "subject_id": subject, "type": payload.get("type","access"), "status": "created", "created_at": time.time(), "notes": payload.get("notes","")}
+    rec = {"id": req_id, "subject_id": subject, "type": payload.get("type","access"), "status": "created", "created_at": time.time(), "notes": payload.get("notes",""), "requested_by": user}
     with open(os.path.join(DSR_STORE, req_id + ".json"), "w") as f:
         json.dump(rec, f)
     # enqueue worker: for demo, call the export tool in background
-    subprocess.Popen(["python3","compliance/dsr/delete_user_data.py","--action","export","--subject",subject,"--out","/tmp/dsr_"+req_id+".tar.gz"])
+    subprocess.Popen(["python3","compliance/dsr/delete_user_data_prod.py","--action","export","--subject",subject,"--out",f"/tmp/dsr_{req_id}.tar.gz"])
     return jsonify({"request_id": req_id, "status":"created"})
@@
-    if not require_auth():
-        return jsonify({"error":"unauthenticated"}), 401
+    user = require_auth()
+    if not user:
+        return jsonify({"error":"unauthenticated"}), 401
     payload = request.json or {}
     subject = payload.get("subject_id")
     if not subject:
         return jsonify({"error":"subject_id required"}), 400
     # enqueue erase
     req_id = str(uuid.uuid4())
-    subprocess.Popen(["python3","compliance/dsr/delete_user_data.py","--action","erase","--subject",subject])
+    # erase script requires FORCE_ERASE=true in environment to run destructive ops
+    env = os.environ.copy()
+    env["FORCE_ERASE"] = env.get("FORCE_ERASE","false")
+    subprocess.Popen(["python3","compliance/dsr/delete_user_data_prod.py","--action","erase","--subject",subject], env=env)
     return jsonify({"request_id": req_id, "status":"enqueued"})
*** End Patch
*** Begin Patch
*** Add File:auth/keycloak_jwt.py
+"""
+Keycloak JWT validation helper using JWKS.
+ - Fetches JWKS from Keycloak realm and caches keys for validation.
+ - Uses python-jose to verify signature and returns a small user dict.
+
+Environment:
+ - KEYCLOAK_URL (e.g., https://auth.example.com)
+ - KEYCLOAK_REALM (e.g., aegis)
+ - KEYCLOAK_AUDIENCE (optional, client_id)
+"""
+import os, requests, time
+from jose import jwt
+from cachetools import TTLCache
+
+JWKS_CACHE = TTLCache(maxsize=2, ttl=300)
+
+def fetch_jwks():
+    url = os.environ.get("KEYCLOAK_URL")
+    realm = os.environ.get("KEYCLOAK_REALM")
+    if not url or not realm:
+        raise RuntimeError("KEYCLOAK_URL / KEYCLOAK_REALM env vars must be set")
+    jwks_url = f"{url.rstrip('/')}/realms/{realm}/protocol/openid-connect/certs"
+    r = requests.get(jwks_url, timeout=5)
+    r.raise_for_status()
+    return r.json()
+
+def get_jwks():
+    if "jwks" in JWKS_CACHE:
+        return JWKS_CACHE["jwks"]
+    jwks = fetch_jwks()
+    JWKS_CACHE["jwks"] = jwks
+    return jwks
+
+def validate_and_extract_user(token):
+    jwks = get_jwks()
+    # python-jose accepts jwks data directly
+    audience = os.environ.get("KEYCLOAK_AUDIENCE")
+    options = {"verify_aud": bool(audience)}
+    try:
+        claims = jwt.decode(token, jwks, algorithms=['RS256'], audience=audience, options=options)
+    except Exception as e:
+        raise
+    # extract preferred fields; this may vary by Keycloak setup
+    user = {"sub": claims.get("sub"), "username": claims.get("preferred_username") or claims.get("username"), "email": claims.get("email")}
+    return user
+
*** End Patch
*** Begin Patch
*** Update File:ui/backend/audit_middleware.py
@@
-import time, json, os
-from flask import request
-AUDIT_LOG = os.environ.get("AUDIT_LOG", "/var/log/aegis/audit.log")
-SIEM_WEBHOOK = os.environ.get("SIEM_WEBHOOK")
-
-def audit_record(app):
-    @app.before_request
-    def _audit_before():
-        # minimal audit event
-        ev = {
-            "ts": time.time(),
-            "method": request.method,
-            "path": request.path,
-            "remote_addr": request.remote_addr,
-            "user": request.headers.get("X-User","unknown"),
-            "auth": "bearer" in (request.headers.get("Authorization") or "").lower()
-        }
-        try:
-            os.makedirs(os.path.dirname(AUDIT_LOG), exist_ok=True)
-            with open(AUDIT_LOG, "a") as f:
-                f.write(json.dumps(ev) + "\n")
-        except Exception:
-            pass
-        # optional SIEM forward
-        if SIEM_WEBHOOK:
-            try:
-                import requests
-                requests.post(SIEM_WEBHOOK, json=ev, timeout=2)
-            except Exception:
-                pass
+import time, json, os
+from flask import request
+from auth.keycloak_jwt import validate_and_extract_user
+
+AUDIT_LOG = os.environ.get("AUDIT_LOG", "/var/log/aegis/audit.log")
+SIEM_WEBHOOK = os.environ.get("SIEM_WEBHOOK")
+
+def audit_record(app):
+    @app.before_request
+    def _audit_before():
+        user = None
+        try:
+            auth = request.headers.get("Authorization")
+            if auth:
+                token = auth.split("Bearer ")[-1] if "Bearer " in auth else auth
+                user = validate_and_extract_user(token)
+        except Exception:
+            user = None
+        ev = {
+            "ts": time.time(),
+            "method": request.method,
+            "path": request.path,
+            "remote_addr": request.remote_addr,
+            "user": user or {"sub": None, "username": None, "email": None},
+        }
+        try:
+            os.makedirs(os.path.dirname(AUDIT_LOG), exist_ok=True)
+            with open(AUDIT_LOG, "a") as f:
+                f.write(json.dumps(ev) + "\n")
+        except Exception:
+            pass
+        # optional SIEM forward
+        if SIEM_WEBHOOK:
+            try:
+                import requests
+                requests.post(SIEM_WEBHOOK, json=ev, timeout=2)
+            except Exception:
+                pass
*** End Patch
*** Begin Patch
*** Add File:security/terraform/module/kms_s3/README.md
+# Terraform module: KMS + S3 (production hardened)
+
+This module creates:
+- KMS key with automatic rotation enabled
+- S3 bucket configured with server-side encryption using the KMS key
+- S3 bucket versioning and public access block
+- Optional server access logging to a logging bucket
+- IAM policy snippets for restricting PutObject to require SSE-KMS
+
+Usage (example):
+  module "aegis_models" {
+    source = "./module/kms_s3"
+    bucket_name = "aegis-model-artifacts-prod"
+    region = "us-west-2"
+    enable_logging = true
+    log_bucket_name = "aegis-s3-access-logs"
+  }
+
+Customize lifecycle rules and MFA-delete/backup approaches in your org's infra repo.
+
*** End Patch
*** Begin Patch
*** Add File:security/terraform/module/kms_s3/variables.tf
+variable "bucket_name" {
+  type = string
+}
+variable "region" {
+  type = string
+  default = "us-west-2"
+}
+variable "enable_logging" {
+  type = bool
+  default = false
+}
+variable "log_bucket_name" {
+  type = string
+  default = ""
+}
+
*** End Patch
*** Begin Patch
*** Add File:security/terraform/module/kms_s3/main.tf
+provider "aws" {
+  region = var.region
+}
+
+resource "aws_kms_key" "aegis_s3_key" {
+  description             = "KMS key for Aegis S3 encryption"
+  deletion_window_in_days = 30
+  enable_key_rotation     = true
+}
+
+resource "aws_s3_bucket" "aegis_models" {
+  bucket = var.bucket_name
+  force_destroy = false
+
+  server_side_encryption_configuration {
+    rule {
+      apply_server_side_encryption_by_default {
+        kms_master_key_id = aws_kms_key.aegis_s3_key.arn
+        sse_algorithm     = "aws:kms"
+      }
+    }
+  }
+
+  versioning {
+    enabled = true
+  }
+
+  lifecycle_rule {
+    id      = "expire-versions"
+    enabled = true
+    noncurrent_version_expiration {
+      days = 365
+    }
+  }
+
+  depends_on = [aws_kms_key.aegis_s3_key]
+}
+
+resource "aws_s3_bucket_public_access_block" "aegis_models_block" {
+  bucket = aws_s3_bucket.aegis_models.id
+  block_public_acls       = true
+  block_public_policy     = true
+  ignore_public_acls      = true
+  restrict_public_buckets = true
+}
+
+resource "aws_s3_bucket_policy" "aegis_models_policy" {
+  bucket = aws_s3_bucket.aegis_models.id
+  policy = data.aws_iam_policy_document.aegis_models_policy.json
+}
+
+data "aws_iam_policy_document" "aegis_models_policy" {
+  statement {
+    sid    = "AllowSSES3KMS"
+    effect = "Allow"
+    principals {
+      type        = "AWS"
+      identifiers = ["*"]
+    }
+    actions = ["s3:PutObject", "s3:AbortMultipartUpload"]
+    resources = [
+      "${aws_s3_bucket.aegis_models.arn}/*"
+    ]
+    condition {
+      test     = "StringEquals"
+      variable = "s3:x-amz-server-side-encryption"
+      values   = ["aws:kms"]
+    }
+  }
+  statement {
+    sid    = "DenyInsecureTransport"
+    effect = "Deny"
+    principals {
+      type        = "AWS"
+      identifiers = ["*"]
+    }
+    actions = ["s3:*"]
+    resources = [
+      aws_s3_bucket.aegis_models.arn,
+      "${aws_s3_bucket.aegis_models.arn}/*"
+    ]
+    condition {
+      test     = "Bool"
+      variable = "aws:SecureTransport"
+      values   = ["false"]
+    }
+  }
+}
+
+resource "aws_s3_bucket" "log_bucket" {
+  count = var.enable_logging && var.log_bucket_name != "" ? 1 : 0
+  bucket = var.log_bucket_name
+  force_destroy = false
+  acl = "log-delivery-write"
+}
+
+resource "aws_s3_bucket_logging" "aegis_models_logging" {
+  count = var.enable_logging && var.log_bucket_name != "" ? 1 : 0
+  bucket = aws_s3_bucket.aegis_models.id
+  target_bucket = aws_s3_bucket.log_bucket[0].id
+  target_prefix = "access-logs/"
+}
+
*** End Patch
*** Begin Patch
*** Add File:security/terraform/module/kms_s3/outputs.tf
+output "s3_bucket_id" {
+  value = aws_s3_bucket.aegis_models.id
+}
+output "kms_key_arn" {
+  value = aws_kms_key.aegis_s3_key.arn
+}
+
*** End Patch
*** Begin Patch
*** Add File:compliance/soc2/SOC2_CHECKLIST.md
+# SOC 2 Readiness Checklist — mapping to Aegis repo artifacts & runbook
+
+This checklist maps Trust Services Criteria and common SOC2 evidence to files, scripts and runbooks in this repository. Use this to collect artifacts for an auditor.
+
+- Control: Logical Access Controls (CC6)
+  - Evidence:
+    - Access review generator: ops/access_review/generate_access_review.py
+      - Command: python3 ops/access_review/generate_access_review.py -> /tmp/access_review.json
+    - RBAC manifests and role bindings:
+      - k8s/modelcontext_rbac.yaml
+      - k8s/testrun_rbac.yaml
+  - Acceptance:
+    - Evidence file /tmp/access_review.json produced and included in evidence bundle.
+
+- Control: System and Communications Protection (CC7)
+  - Evidence:
+    - mTLS ingress examples: security/mtls/nginx_ingress_mtls.yaml
+    - Terraform KMS + S3 module: security/terraform/module/kms_s3/*
+    - KMS usage: outputs from Terraform apply (kms_key_arn)
+  - Acceptance:
+    - KMS key exists and S3 bucket has SSE-KMS enforced; evidence via terraform output and AWS console screenshots or CLI.
+
+- Control: Change Management & Deployment (CC8)
+  - Evidence:
+    - Argo workflow for model lifecycle: production/pipeline/argo_model_lifecycle.yaml
+    - CI promote script with SLI & MCP checks: ci/serving/promote_and_verify.sh and tools/mcp_validate_cli.py
+    - TestRun CRD and controller: k8s/crd/testrun_crd.yaml, controllers/testrun_controller.py
+  - Acceptance:
+    - Demonstrate a sample run (Argo workflow) and include the argo workflow logs and MCP artifact in evidence bundle.
+
+- Control: Data Subject Rights & Privacy (CC9)
+  - Evidence:
+    - DSR API: ui/backend/dsr_api.py
+    - Production erasure/export script: compliance/dsr/delete_user_data_prod.py
+    - Portability exporter: compliance/portability/export_portability.py
+  - Acceptance:
+    - Run an export and erasure in staging and include export tar.gz and erasure manifest in evidence bundle.
+
+- Control: Logging, Monitoring & Incident Response (CC10)
+  - Evidence:
+    - Audit middleware & audit logs: ui/backend/audit_middleware.py -> /var/log/aegis/audit.log
+    - Evidence collector & periodic evidence job: compliance/evidence_collector_enhanced.py and .github/workflows/compliance_evidence.yml
+    - Incident bundler: aiops/incident/incident_bundler.py
+  - Acceptance:
+    - Provide recent audit_tail.log (last 10k lines), incident bundles from remediation runs, and evidence bundle artifact.
+
+- Control: Vendor & Subprocessor Management (CC11)
+  - Evidence:
+    - Legal templates and contracts: legal/data_processing_agreement.md, legal/BAA_template.md
+    - HSM provisioning & vendor scripts: ops/provision_validate_hsm_end_to_end.sh
+  - Acceptance:
+    - Signed DPAs/BAAs and proof of HSM vendor provisioning runs or receipts.
+
+- Control: Backup & Retention (CC12)
+  - Evidence:
+    - Retention purger & manifests: compliance/retention/evidence_purger.py and compliance/k8s/data_retention_cronjob.yaml
+    - Retention deletion manifest sample: /tmp/retention_deletions.json
+  - Acceptance:
+    - Evidence that retention policies executed and deletion manifests uploaded to EVIDENCE_BUCKET.
+
+- Control: Data Classification & DLP (CC13)
+  - Evidence:
+    - PII scanner & classification report: compliance/pii_scanner.py and compliance/classification/classification_report.py
+  - Acceptance:
+    - Classification report showing findings and remediation notes.
+
+- Control: PCI & Payment Handling (where applicable)
+  - Evidence:
+    - Tokenization proxy example: payments/tokenize_proxy.py
+    - PAN attest script: payments/attest_no_pan.sh
+  - Acceptance:
+    - Demonstrate that tokenization service is used and PAN scan returns no results.
+
+How to produce the auditor evidence bundle
+1. Ensure required env vars set (VAULT, AWS creds, DB_DSN, MODEL_ARTIFACT_BUCKET, EVIDENCE_BUCKET).
+2. Run evidence collector:
+   - python3 compliance/evidence_collector_enhanced.py
+3. Upload the produced tar.gz to a secure place or provide auditor access to EVIDENCE_BUCKET.
+
+Notes & next steps
+- Legal must sign DPAs/BAAs and document roles/ownership.
+- Pen tests and third-party audits must be scheduled and their reports included in evidence.
+- This checklist is starter guidance — auditors will request additional artifacts and process descriptions.
+
*** End Patch
*** End Patch
