*** Begin Patch
*** Add File: providers/braket_adapter.py
+"""
+AWS Braket provider adapter (PoC).
+Requires boto3 and amazon-braket-sdk when submitting to real Braket tasks.
+This adapter attempts to retrieve provider credentials from Vault (via VaultClient)
+or environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION).
+"""
+from __future__ import annotations
+import logging
+import os
+from typing import Dict, Any, Optional
+
+LOG = logging.getLogger("braket-adapter")
+logging.basicConfig(level=logging.INFO)
+
+try:
+    import boto3  # type: ignore
+    from braket.aws import AwsDevice, AwsDeviceCapabilities  # optional types
+except Exception:
+    boto3 = None
+
+from utils.vault_client import VaultClient, VaultClientError
+
+
+class BraketAdapterError(RuntimeError):
+    pass
+
+
+class BraketAdapter:
+    def __init__(self, provider_name: str = "braket"):
+        # Try to obtain AWS creds from Vault if available
+        aws_access_key = os.environ.get("AWS_ACCESS_KEY_ID")
+        aws_secret = os.environ.get("AWS_SECRET_ACCESS_KEY")
+        aws_region = os.environ.get("AWS_REGION", "us-west-1")
+        if os.environ.get("VAULT_ADDR") and os.environ.get("VAULT_TOKEN"):
+            try:
+                vc = VaultClient()
+                creds = vc.get_provider_creds("braket")
+                aws_access_key = creds.get("aws_access_key_id") or aws_access_key
+                aws_secret = creds.get("aws_secret_access_key") or aws_secret
+                aws_region = creds.get("region") or aws_region
+            except VaultClientError:
+                LOG.warning("Vault provider secret not available for Braket; falling back to env")
+        if not aws_access_key or not aws_secret:
+            raise BraketAdapterError("AWS credentials not available for Braket adapter")
+        if boto3 is None:
+            raise BraketAdapterError("boto3 / braket SDK not installed")
+        # create boto3 session
+        self.session = boto3.Session(aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret, region_name=aws_region)
+        self.s3 = self.session.client("s3")
+        LOG.info("BraketAdapter initialized for region %s", aws_region)
+
+    def preflight_check(self, device_arn: Optional[str] = None) -> bool:
+        """
+        Check device availability (PoC). If device_arn is None, use a simulator check.
+        """
+        try:
+            if device_arn:
+                # example: list devices via braket (not importing heavy SDK)
+                LOG.info("Preflight: checking device arn %s", device_arn)
+            else:
+                LOG.info("Preflight: simulator path ok")
+            return True
+        except Exception:
+            LOG.exception("Preflight failed")
+            return False
+
+    def submit(self, program_payload: Dict[str, Any], s3_bucket: str, s3_prefix: str, device_arn: Optional[str] = None, shots: int = 1000):
+        """
+        Submit a job to Braket (PoC). Uploads program payload to S3 and returns a job descriptor.
+        In a real implementation, use braket.AwsDevice and AwsQuantumTask API.
+        """
+        # upload to s3
+        key = f"{s3_prefix.rstrip('/')}/program.json"
+        import json
+        self.s3.put_object(Bucket=s3_bucket, Key=key, Body=json.dumps(program_payload).encode("utf-8"))
+        LOG.info("Uploaded program to s3://%s/%s", s3_bucket, key)
+        # PoC: return a simulated task id
+        task_id = f"braket-task-{int(__import__('time').time()*1000)}"
+        return {"task_id": task_id, "s3": f"s3://{s3_bucket}/{key}", "device": device_arn or "simulator", "shots": shots}
+
*** End Patch
*** Begin Patch
*** Add File: scripts/provider_test_ibm.py
+#!/usr/bin/env python3
+"""
+Test harness to submit a small job to IBM Quantum (using qiskit-ibm-runtime)
+Requires IBM_TOKEN and optionally VAULT_* to be configured.
+"""
+from __future__ import annotations
+import os
+import json
+import time
+import sys
+from providers.qiskit_runtime_adapter_real import QiskitRuntimeAdapter
+
+def main():
+    try:
+        adapter = QiskitRuntimeAdapter(provider_name="ibm")
+    except Exception as e:
+        print("Adapter not configured:", e)
+        sys.exit(2)
+    # create a tiny circuit via qiskit
+    try:
+        from qiskit import QuantumCircuit
+    except Exception as e:
+        print("qiskit not installed:", e)
+        sys.exit(2)
+    qc = QuantumCircuit(1, 1)
+    qc.h(0)
+    qc.measure(0, 0)
+    try:
+        transpiled = adapter.preflight_transpile(qc, backend_name="aer_simulator")
+        print("Preflight transpile OK")
+    except Exception as e:
+        print("Preflight transpile failed:", e)
+        sys.exit(3)
+    # Submit to provider (PoC will return descriptor)
+    desc = adapter.submit(program=qc, options={"backend": "aer_simulator", "shots": 256})
+    print("Submission descriptor:", desc)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: scripts/provider_test_braket.py
+#!/usr/bin/env python3
+"""
+Test harness to submit to AWS Braket (PoC). Requires AWS creds in env or Vault.
+"""
+from __future__ import annotations
+import os
+import sys
+from providers.braket_adapter import BraketAdapter
+
+def main():
+    try:
+        adapter = BraketAdapter()
+    except Exception as e:
+        print("Braket not configured:", e)
+        sys.exit(2)
+    payload = {"qasm": "X 0\nMEASURE 0\n"}
+    res = adapter.submit(payload, s3_bucket=os.environ.get("BRK_S3_BUCKET", "my-bucket"), s3_prefix="aegis/test", device_arn=None, shots=100)
+    print("Braket submission (PoC):", res)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: scripts/vault/write_provider_secret.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Write a provider secret to Vault at secret/data/quantum/providers/<name>
+# Usage: VAULT_ADDR=... VAULT_TOKEN=... ./write_provider_secret.sh <provider> <json-file>
+
+PROVIDER="${1:-}"
+JSON="${2:-}"
+if [ -z "$PROVIDER" ] || [ -z "$JSON" ]; then
+  echo "Usage: $0 <provider> <json-file>"
+  exit 2
+fi
+if [ -z "${VAULT_ADDR:-}" ] || [ -z "${VAULT_TOKEN:-}" ]; then
+  echo "Set VAULT_ADDR and VAULT_TOKEN env vars"
+  exit 3
+fi
+
+curl -sS --header "X-Vault-Token: $VAULT_TOKEN" --request POST --data "{\"data\": $(cat "$JSON")}" "${VAULT_ADDR%/}/v1/secret/data/quantum/providers/${PROVIDER}" | jq .
+echo "Wrote provider secret for ${PROVIDER}"
+
*** End Patch
*** Begin Patch
*** Add File: k8s/redis/redis-statefulset.yaml
+apiVersion: apps/v1
+kind: StatefulSet
+metadata:
+  name: redis
+  namespace: aegis
+spec:
+  serviceName: "redis"
+  replicas: 3
+  selector:
+    matchLabels:
+      app: redis
+  template:
+    metadata:
+      labels:
+        app: redis
+    spec:
+      containers:
+      - name: redis
+        image: redis:6.2
+        args: ["redis-server", "--appendonly", "yes"]
+        ports:
+        - containerPort: 6379
+        readinessProbe:
+          exec:
+            command:
+            - redis-cli
+            - ping
+          initialDelaySeconds: 5
+          periodSeconds: 10
+        livenessProbe:
+          exec:
+            command:
+            - redis-cli
+            - ping
+          initialDelaySeconds: 15
+          periodSeconds: 20
+        resources:
+          requests:
+            cpu: "100m"
+            memory: "128Mi"
+          limits:
+            cpu: "500m"
+            memory: "512Mi"
+  volumeClaimTemplates:
+  - metadata:
+      name: redis-data
+    spec:
+      accessModes: ["ReadWriteOnce"]
+      resources:
+        requests:
+          storage: 1Gi
+
*** End Patch
*** Begin Patch
*** Add File: k8s/deployments/quantum-controller-deploy.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: quantum-controller
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: quantum-controller
+  template:
+    metadata:
+      labels:
+        app: quantum-controller
+    spec:
+      containers:
+        - name: controller
+          image: ghcr.io/yourorg/aegis-quantum-controller:latest
+          env:
+            - name: REDIS_URL
+              value: "redis://redis-0.redis.aegis.svc.cluster.local:6379/0"
+            - name: VAULT_ADDR
+              valueFrom:
+                secretKeyRef:
+                  name: vault-credentials
+                  key: addr
+          readinessProbe:
+            httpGet:
+              path: /healthz
+              port: 8080
+            initialDelaySeconds: 5
+            periodSeconds: 10
+          livenessProbe:
+            httpGet:
+              path: /livez
+              port: 8080
+            initialDelaySeconds: 15
+            periodSeconds: 20
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+            limits:
+              cpu: "1"
+              memory: "1Gi"
+      restartPolicy: Always
+---
+apiVersion: autoscaling/v2
+kind: HorizontalPodAutoscaler
+metadata:
+  name: quantum-controller-hpa
+  namespace: aegis
+spec:
+  scaleTargetRef:
+    apiVersion: apps/v1
+    kind: Deployment
+    name: quantum-controller
+  minReplicas: 2
+  maxReplicas: 5
+  metrics:
+  - type: Resource
+    resource:
+      name: cpu
+      target:
+        type: Utilization
+        averageUtilization: 50
+
*** End Patch
*** Begin Patch
*** Add File: k8s/deployments/quantum-worker-deploy.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: quantum-worker
+  namespace: aegis
+spec:
+  replicas: 3
+  selector:
+    matchLabels:
+      app: quantum-worker
+  template:
+    metadata:
+      labels:
+        app: quantum-worker
+    spec:
+      containers:
+        - name: worker
+          image: ghcr.io/yourorg/aegis-quantum-worker:latest
+          env:
+            - name: REDIS_URL
+              value: "redis://redis-0.redis.aegis.svc.cluster.local:6379/0"
+            - name: VAULT_ADDR
+              valueFrom:
+                secretKeyRef:
+                  name: vault-credentials
+                  key: addr
+          readinessProbe:
+            exec:
+              command: ["redis-cli", "-h", "redis-0.redis.aegis.svc.cluster.local", "ping"]
+            initialDelaySeconds: 5
+            periodSeconds: 10
+          livenessProbe:
+            exec:
+              command: ["redis-cli", "-h", "redis-0.redis.aegis.svc.cluster.local", "ping"]
+            initialDelaySeconds: 15
+            periodSeconds: 20
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+            limits:
+              cpu: "1"
+              memory: "1Gi"
+      restartPolicy: Always
+---
+apiVersion: autoscaling/v2
+kind: HorizontalPodAutoscaler
+metadata:
+  name: quantum-worker-hpa
+  namespace: aegis
+spec:
+  scaleTargetRef:
+    apiVersion: apps/v1
+    kind: Deployment
+    name: quantum-worker
+  minReplicas: 2
+  maxReplicas: 10
+  metrics:
+  - type: Resource
+    resource:
+      name: cpu
+      target:
+        type: Utilization
+        averageUtilization: 60
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/hardware-runners.yml
+name: Hardware Tests (self-hosted)
+on:
+  workflow_dispatch:
+
+jobs:
+  rpi_tests:
+    runs-on: [self-hosted, rpi]
+    steps:
+      - uses: actions/checkout@v4
+      - name: Pull image and run benchmark
+        run: |
+          docker pull ghcr.io/${{ github.repository_owner }}/aegis-edge-tflite:latest || true
+          docker run --rm ghcr.io/${{ github.repository_owner }}/aegis-edge-tflite:latest python benchmarks/benchmark_tflite.py --model /models/example_int8.tflite --iters 20
+
+  qpu_adjacent:
+    runs-on: [self-hosted, qpu-adjacent]
+    steps:
+      - uses: actions/checkout@v4
+      - name: Provider smoke tests
+        run: |
+          python scripts/provider_test_ibm.py || true
+          python scripts/provider_test_braket.py || true
+
*** End Patch
*** Begin Patch
*** Add File: prometheus/quantum_scrape_config.yaml
+scrape_configs:
+  - job_name: "aegis-quantum-controller"
+    metrics_path: /metrics
+    static_configs:
+      - targets: ["quantum-controller.aegis.svc.cluster.local:8001"]
+  - job_name: "aegis-quantum-worker"
+    metrics_path: /metrics
+    static_configs:
+      - targets: ["quantum-worker.aegis.svc.cluster.local:8001"]
+
*** End Patch
*** Begin Patch
*** Add File: grafana/dashboards/quantum_dashboard.json
+{
+  "id": null,
+  "title": "Aegis Quantum Overview",
+  "panels": [
+    {
+      "type": "graph",
+      "title": "Quantum Queue Length",
+      "targets": [{ "expr": "aegis_quantum_queue_length", "legendFormat": "queue_len" }]
+    },
+    {
+      "type": "graph",
+      "title": "Jobs Completed / Failed",
+      "targets": [
+        { "expr": "aegis_quantum_jobs_completed_total", "legendFormat": "completed" },
+        { "expr": "aegis_quantum_jobs_failed_total", "legendFormat": "failed" }
+      ]
+    },
+    {
+      "type": "stat",
+      "title": "Estimated Cost (last 24h)",
+      "targets": [{ "expr": "sum(aegis_quantum_job_cost_estimate) by (team)", "legendFormat": "{{team}}" }]
+    }
+  ],
+  "schemaVersion": 16,
+  "version": 0
+}
+
*** End Patch
*** Begin Patch
*** Add File: admin_ui/oidc_auth.py
+"""
+OIDC authentication helper for admin UI (PoC).
+Validates JWT in Authorization header using JWKS endpoint.
+Requires OIDC_ISSUER env var.
+"""
+from __future__ import annotations
+import os
+import requests
+import time
+import logging
+from functools import wraps
+from flask import request, Response
+import jwt  # PyJWT
+
+LOG = logging.getLogger("oidc-auth")
+logging.basicConfig(level=logging.INFO)
+
+OIDC_ISSUER = os.environ.get("OIDC_ISSUER", "")
+OIDC_AUDIENCE = os.environ.get("OIDC_AUDIENCE", "")
+_JWKS_CACHE = {"keys": None, "expires": 0}
+
+def _fetch_jwks():
+    if not OIDC_ISSUER:
+        raise RuntimeError("OIDC_ISSUER not configured")
+    now = time.time()
+    if _JWKS_CACHE["keys"] and _JWKS_CACHE["expires"] > now:
+        return _JWKS_CACHE["keys"]
+    jwks_uri = OIDC_ISSUER.rstrip("/") + "/.well-known/jwks.json"
+    r = requests.get(jwks_uri, timeout=5)
+    r.raise_for_status()
+    keys = r.json()
+    _JWKS_CACHE["keys"] = keys
+    _JWKS_CACHE["expires"] = now + 3600
+    return keys
+
+def requires_oidc(f):
+    @wraps(f)
+    def decorated(*args, **kwargs):
+        auth = request.headers.get("Authorization", "")
+        if not auth.startswith("Bearer "):
+            return Response("Missing Bearer token", status=401)
+        token = auth.split(" ", 1)[1]
+        try:
+            jwks = _fetch_jwks()
+            unverified = jwt.decode(token, options={"verify_signature": False})
+            kid = unverified.get("kid")
+            # find key by kid
+            from jwt.algorithms import RSAAlgorithm
+            key = None
+            for k in jwks.get("keys", []):
+                if k.get("kid") == kid:
+                    key = RSAAlgorithm.from_jwk(k)
+                    break
+            if key is None:
+                return Response("Invalid token key", status=401)
+            payload = jwt.decode(token, key=key, audience=OIDC_AUDIENCE, algorithms=["RS256"])
+            request.oidc_user = payload
+            return f(*args, **kwargs)
+        except Exception as e:
+            LOG.exception("OIDC validation failed: %s", e)
+            return Response("Unauthorized", status=401)
+    return decorated
+
*** End Patch
*** Begin Patch
*** Update File: admin_ui/app.py
@@
-from admin_ui.auth_wrapper import requires_auth
+from admin_ui.oidc_auth import requires_oidc
@@
-@requires_auth
+@requires_oidc
 def pending_jobs():
@@
-@requires_auth
 def approve():
     data = request.json or {}
     name = data.get("name")
     if not name:
         return jsonify({"error": "name required"}), 400
@@
-    # append audit log
-    audit_line = f"{name} approved by {request.authorization.username} at {time.strftime('%Y-%m-%dT%H:%M:%SZ')}\n"
-    with open("/var/log/aegis/quantum_admin_audit.log", "a") as f:
-        f.write(audit_line)
+    # append audit log (OIDC subject if available)
+    user = getattr(request, "oidc_user", {}).get("sub", "unknown")
+    audit_line = f"{name} approved by {user} at {time.strftime('%Y-%m-%dT%H:%M:%SZ')}\n"
+    os.makedirs("/var/log/aegis", exist_ok=True)
+    with open("/var/log/aegis/quantum_admin_audit.log", "a") as f:
+        f.write(audit_line)
     return jsonify({"ok": True})
*** End Patch
*** Begin Patch
*** Add File: utils/cost_meter.py
+"""
+Cost meter helper to estimate and accumulate job costs per team.
+Stores per-team aggregates in a ConfigMap path or local JSON file for PoC.
+"""
+from __future__ import annotations
+import json
+import os
+from pathlib import Path
+from typing import Dict
+
+STORE_PATH = Path(os.environ.get("COST_STORE", "/var/lib/aegis/quantum_costs.json"))
+
+def estimate_cost(backend: str, shots: int) -> float:
+    price_map = {"simulator": 0.0, "qpu-default": 0.001}
+    price = price_map.get(backend, price_map["qpu-default"])
+    return shots * price
+
+def add_cost(team: str, amount: float):
+    STORE_PATH.parent.mkdir(parents=True, exist_ok=True)
+    if STORE_PATH.exists():
+        data = json.loads(STORE_PATH.read_text())
+    else:
+        data = {}
+    data[team] = data.get(team, 0.0) + amount
+    STORE_PATH.write_text(json.dumps(data))
+
+def get_costs() -> Dict[str, float]:
+    if STORE_PATH.exists():
+        return json.loads(STORE_PATH.read_text())
+    return {}
+
*** End Patch
*** Begin Patch
*** Add File: scripts/ci_sign_and_rekor_step.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# CI step: sign artifact and submit to Rekor if REKOR_URL configured
+ART="$1"
+SIG_OUT="${ART}.sig.json"
+python scripts/quantum_sign_artifact.py --artifact "$ART" --out "$SIG_OUT" --local-key "${LOCAL_KEY:-}" || true
+if [ -n "${REKOR_URL:-}" ]; then
+  python - <<'PY'
+import json, os, subprocess
+from utils.rekor_client import submit_to_rekor
+sig = json.load(open("'%s'" % os.environ.get("CI_ART_SIG", "'" + SIG_OUT + "'")))
+res = submit_to_rekor("%s", sig.get("signature"))
+print(res)
+PY
+fi
+echo "Signed and (optionally) submitted to Rekor: $SIG_OUT"
+
*** End Patch
*** Begin Patch
*** Add File: tests/test_provider_adapters.py
+import pytest
+import os
+
+from providers.qiskit_runtime_adapter_real import QiskitRuntimeAdapter
+
+def test_qiskit_adapter_smoke():
+    # This test will skip if no IBM_TOKEN or Vault not configured
+    if not (os.environ.get("IBM_TOKEN") or (os.environ.get("VAULT_ADDR") and os.environ.get("VAULT_TOKEN"))):
+        pytest.skip("No IBM credentials configured")
+    adapter = QiskitRuntimeAdapter()
+    # basic preflight using local simulator
+    import qiskit
+    qc = qiskit.QuantumCircuit(1,1)
+    qc.h(0)
+    qc.measure(0,0)
+    t = adapter.preflight_transpile(qc, backend_name="aer_simulator")
+    assert t is not None
+
+def test_braket_adapter_smoke():
+    # Skip if no AWS creds
+    if not (os.environ.get("AWS_ACCESS_KEY_ID") and os.environ.get("AWS_SECRET_ACCESS_KEY")) and not (os.environ.get("VAULT_ADDR") and os.environ.get("VAULT_TOKEN")):
+        pytest.skip("No AWS credentials configured")
+    from providers.braket_adapter import BraketAdapter
+    adapter = BraketAdapter()
+    ok = adapter.preflight_check()
+    assert ok
+
*** End Patch
*** Begin Patch
*** Add File: docs/runbooks/provider_onboarding.md
+# Provider Onboarding Runbook (PoC)
+
+1) Vault secret for provider
+ - Create a JSON file with provider credentials (example for IBM):
+   { "ibm_token": "xxxxx", "url": "https://api.quantum.ibm.com" }
+ - Write to Vault:
+   VAULT_ADDR=https://vault.example.com VAULT_TOKEN=... ./scripts/vault/write_provider_secret.sh ibm provider_ibm.json
+
+2) Create Vault policy for provider read
+ - Use scripts/vault/roles_and_policies/provider-read.hcl as a starting point
+ - vault policy write quantum-provider-read provider-read.hcl
+
+3) Create controller scoped token
+ - VAULT_ADDR=... VAULT_TOKEN=... ./scripts/vault/rotate_controller_token.sh quantum-controller 1h
+ - Store token as Kubernetes secret `vault-credentials` in namespace `aegis`
+
+4) Deploy controller & worker with REDIS_URL set and secret ref to vault-credentials
+ - kubectl apply -f k8s/redis/redis-statefulset.yaml
+ - kubectl apply -f k8s/deployments/quantum-controller-deploy.yaml
+ - kubectl apply -f k8s/deployments/quantum-worker-deploy.yaml
+
+5) Run provider smoke test from self-hosted runner:
+ - python scripts/provider_test_ibm.py
+
+6) Verify job lifecycle via kubectl and Grafana dashboards
+
*** End Patch
*** Begin Patch
*** Update File: README.edge.md
@@
 Notes & next steps:
 - You need Vault admin to create policies/roles and write provider secrets. See scripts/vault/roles_and_policies for examples.
 - Deploy Redis in HA and provide REDIS_URL to controller/worker.
 - Configure Prometheus to scrape controller/worker metrics and create Grafana dashboards.
 - Replace PoC basic-auth with OIDC or OAuth2 for production admin UI.
 - Final provider integration testing requires QPU/sandbox credentials â€” follow runbook to provision and test.
+
+New in this patch (provider productionization & infra)
+- AWS Braket adapter PoC (providers/braket_adapter.py) and provider test harnesses (scripts/provider_test_braket.py, scripts/provider_test_ibm.py).
+- Vault helper to write provider secrets (scripts/vault/write_provider_secret.sh).
+- Redis HA StatefulSet (k8s/redis/redis-statefulset.yaml) with readiness/liveness probes.
+- K8s Deployments for controller & worker with liveness/readiness and HPA (k8s/deployments/*).
+- Self-hosted hardware runners workflow for provider-adjacent tests (.github/workflows/hardware-runners.yml).
+- Prometheus scrape config and Grafana dashboard skeleton (prometheus/..., grafana/...).
+- OIDC-based admin UI auth PoC (admin_ui/oidc_auth.py) and admin runbook for provider onboarding.
+- Cost meter helper and tests for provider adapters (utils/cost_meter.py, tests/test_provider_adapters.py).
+
*** End Patch
