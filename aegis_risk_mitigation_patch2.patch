*** Begin Patch
*** Add File:ops/hsm/hsm_rotation_and_validation.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# HSM key rotation and validation helper (operator-run or CI)
+# - Rotates an HSM key via vendor CLI or PKCS#11 (placeholder)
+# - Runs health checks and latency tests
+# - Records events to local audit log and uploads evidence to S3 if MODEL_ARTIFACT_BUCKET set
+#
+# WARNING: This script contains placeholders for vendor-specific rotation commands.
+#
+OUT_DIR=${OUT_DIR:-/tmp/hsm_rotation}
+mkdir -p "$OUT_DIR"
+LOG="$OUT_DIR/hsm_rotation_$(date -u +%Y%m%dT%H%M%SZ).json"
+
+echo '{"start": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'" }' > "$LOG"
+
+echo "Step 1: Run vendor healthcheck (placeholder)"
+# Replace the following with vendor-specific healthcheck command
+if command -v ops/hsm/hsm_healthcheck.py >/dev/null 2>&1; then
+  python3 ops/hsm/hsm_healthcheck.py --json >> "$LOG" 2>&1 || true
+else
+  echo '{"healthcheck":"skipped","reason":"no hsm_healthcheck script found"}' >> "$LOG"
+fi
+
+echo "Step 2: Attempt HSM rotation (vendor-specific placeholder)"
+# Example vendor CLI (pseudo):
+# vendor-hsm-cli rotate-key --keylabel aegis-signing-key --new-keylabel aegis-signing-key-rot-$(date +%s)
+echo '{"rotation":"skipped","reason":"vendor CLI not configured"}' >> "$LOG"
+
+echo "Step 3: Run HSM latency exporter once"
+if command -v python3 >/dev/null 2>&1 && [ -f ops/hsm/pkcs11_latency_exporter.py ]; then
+  python3 ops/hsm/pkcs11_latency_exporter.py >/dev/null 2>&1 || true
+  echo '{"latency_check":"ran"}' >> "$LOG"
+else
+  echo '{"latency_check":"skipped"}' >> "$LOG"
+fi
+
+echo "Step 4: Record fallback audit if fallback used"
+if [ -f /tmp/hsm_health.json ]; then
+  jq -s '.[0] + {"hsm_health":.[1]}' "$LOG" /tmp/hsm_health.json > "${LOG}.tmp" || true
+  mv "${LOG}.tmp" "$LOG" || true
+fi
+
+echo "Step 5: Upload evidence to S3 (if configured)"
+if [ -n "${MODEL_ARTIFACT_BUCKET:-}" ]; then
+  aws s3 cp "$LOG" "s3://${MODEL_ARTIFACT_BUCKET}/hsm-rotation/$(basename $LOG)" || true
+  echo '{"upload":"attempted"}' >> "$LOG"
+fi
+
+echo "Wrote rotation log: $LOG"
+
*** End Patch
*** Begin Patch
*** Add File:ops/hsm/hsm_healthcheck.py
+#!/usr/bin/env python3
+"""
+Simple HSM healthcheck script that performs basic PKCS#11 operations and reports JSON.
+ - Checks signing of a small payload with configured key (uses production.policy.signing.sign_with_retry if available)
+ - Measures latency and reports fallback usage if sign fails
+ Usage: python3 ops/hsm/hsm_healthcheck.py --json
+"""
+import time, json, sys
+from argparse import ArgumentParser
+
+def main():
+    p = ArgumentParser()
+    p.add_argument("--json", action="store_true")
+    args = p.parse_args()
+    out = {"timestamp": time.time(), "ok": False}
+    payload = b"healthcheck"
+    try:
+        from production.policy.signing.sign_with_retry import sign_payload
+        t0 = time.time()
+        sig, meta = sign_payload(payload, None)
+        latency = time.time() - t0
+        out.update({"ok": bool(sig), "latency_s": latency, "meta": meta})
+    except Exception as e:
+        out.update({"ok": False, "error": str(e)})
+        # fallback detection heuristic
+        try:
+            # If cosign path exists, attempt simple cosign sign (placeholder)
+            out["fallback"] = True
+        except Exception:
+            out["fallback"] = False
+    if args.json:
+        print(json.dumps(out))
+    else:
+        print(out)
+    # write to common health file used by other tools
+    with open("/tmp/hsm_health.json", "w") as f:
+        json.dump(out, f)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:policies/gatekeeper/ct_high_risk_model.yaml
+apiVersion: templates.gatekeeper.sh/v1
+kind: ConstraintTemplate
+metadata:
+  name: highriskmodel
+spec:
+  crd:
+    spec:
+      names:
+        kind: RequireHighRiskModelApproval
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package highriskmodel
+
+        violation[{"msg": msg}] {
+          input.review.object.kind == "Deployment"
+          labels := input.review.object.metadata.labels
+          labels["model.risk"] == "high"
+          not approved(input.review.object.metadata.annotations)
+          msg := "High-risk model deployment requires human approval: add annotation aegis/approved=true to proceed"
+        }
+
+        approved(ann) {
+          ann["aegis/approved"] == "true"
+        }
+
*** End Patch
*** Begin Patch
*** Add File:policies/gatekeeper/constraint_high_risk_model.yaml
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: RequireHighRiskModelApproval
+metadata:
+  name: require-high-risk-model-approval
+spec:
+  match:
+    kinds:
+      - apiGroups: [""]
+        kinds: ["Deployment"]
+    namespaces: ["aegis", "aegis-prod"]
+
*** End Patch
*** Begin Patch
*** Add File:argo/manual_approval_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-manual-approval-
+  namespace: aegis
+spec:
+  entrypoint: approval
+  templates:
+    - name: approval
+      steps:
+        - - name: request-approval
+            template: request-approval
+        - - name: wait-approval
+            template: wait-approval
+
+    - name: request-approval
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - |
+            echo "Triggering approval request via approvals API"
+            # Post to approvals service - operators must review and set annotation on deployment
+            python3 - <<'PY'
+import os,requests,json
+URL=os.environ.get('APPROVAL_API','http://approvals.aegis.svc/api/request')
+payload={"entity":"model","entity_id":os.environ.get('MODEL_ID','unknown')}
+try:
+    r=requests.post(URL,json=payload,timeout=10)
+    print("Requested approval:",r.status_code,r.text)
+except Exception as e:
+    print("Approval request failed",e)
+PY
+
+    - name: wait-approval
+      suspend:
+        duration: "72h"
+
+  # run this workflow as a gating step before deployment promotion
+
*** End Patch
*** Begin Patch
*** Add File:ops/erasure/discover_backups.py
+#!/usr/bin/env python3
+"""
+Discover backup/archival locations across S3 prefixes, MinIO, and a list of external backup endpoints.
+Produces a YAML/JSON inventory of locations and sample object lists to help ensure DSR completeness.
+"""
+import os, json, boto3, argparse, requests
+
+def list_s3(bucket, prefix, max_keys=100):
+    s3 = boto3.client("s3")
+    out=[]
+    try:
+        resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=max_keys)
+        for o in resp.get("Contents",[]):
+            out.append(o["Key"])
+    except Exception as e:
+        out.append({"error": str(e)})
+    return out
+
+def probe_http(url, timeout=5):
+    try:
+        r = requests.head(url, timeout=timeout)
+        return {"status": r.status_code, "length": r.headers.get("Content-Length","unknown")}
+    except Exception as e:
+        return {"error": str(e)}
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--bucket", default=os.environ.get("MODEL_ARTIFACT_BUCKET",""))
+    p.add_argument("--prefixes", default="feast/,mcp/,models/")
+    p.add_argument("--externals", default="")
+    p.add_argument("--out", default="/tmp/backup_inventory.json")
+    args = p.parse_args()
+    inv = {"bucket": args.bucket, "time": None, "entries": {}}
+    import time
+    inv["time"] = time.time()
+    for pref in args.prefixes.split(","):
+        inv["entries"][pref] = list_s3(args.bucket, pref)
+    if args.externals:
+        inv["externals"] = {}
+        for url in args.externals.split(","):
+            inv["externals"][url] = probe_http(url)
+    with open(args.out,"w") as f:
+        json.dump(inv, f, indent=2)
+    print("Wrote inventory to", args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/erasure/erase_and_manifest.py
+#!/usr/bin/env python3
+"""
+Erase objects by prefix and produce a signed manifest for evidence.
+ - Scans S3 prefix, deletes objects, and writes a manifest with deleted keys + counts
+ - Optionally uploads manifest to MODEL_ARTIFACT_BUCKET under evidence/erasure/
+WARNING: destructive â€” use with care and test in staging.
+"""
+import os, json, boto3, argparse, datetime
+
+def list_keys(bucket,prefix):
+    s3=boto3.client("s3")
+    out=[]
+    cont=None
+    kwargs={"Bucket":bucket,"Prefix":prefix}
+    while True:
+        resp = s3.list_objects_v2(**kwargs)
+        for o in resp.get("Contents",[]):
+            out.append(o["Key"])
+        if not resp.get("IsTruncated"):
+            break
+        kwargs["ContinuationToken"]=resp.get("NextContinuationToken")
+    return out
+
+def delete_keys(bucket, keys):
+    s3=boto3.client("s3")
+    deleted=0
+    # delete in batches of 1000
+    for i in range(0,len(keys),1000):
+        chunk = keys[i:i+1000]
+        objs=[{"Key":k} for k in chunk]
+        s3.delete_objects(Bucket=bucket, Delete={"Objects":objs})
+        deleted += len(chunk)
+    return deleted
+
+def main():
+    p=argparse.ArgumentParser()
+    p.add_argument("--prefix", required=True)
+    p.add_argument("--bucket", default=os.environ.get("MODEL_ARTIFACT_BUCKET",""))
+    p.add_argument("--manifest-out", default="/tmp/erasure_manifest.json")
+    args=p.parse_args()
+    keys = list_keys(args.bucket, args.prefix)
+    deleted = delete_keys(args.bucket, keys)
+    manifest = {"prefix": args.prefix, "bucket": args.bucket, "deleted_count": deleted, "deleted_keys_sample": keys[:1000], "time": datetime.datetime.utcnow().isoformat()}
+    with open(args.manifest_out,"w") as f:
+        json.dump(manifest,f, indent=2)
+    # sign manifest if signing available
+    try:
+        from production.policy.signing.sign_with_retry import sign_payload
+        sig, meta = sign_payload(json.dumps(manifest).encode(), None)
+        manifest["signature"] = sig
+        manifest["signed_by"] = meta.get("keylabel", meta.get("method"))
+    except Exception:
+        manifest["signature"] = ""
+    # upload
+    if args.bucket:
+        s3=boto3.client("s3")
+        key=f"evidence/erasure/manifest_{int(time.time())}.json"
+        s3.put_object(Bucket=args.bucket, Key=key, Body=json.dumps(manifest).encode())
+        print("Uploaded manifest to s3://%s/%s" % (args.bucket,key))
+    print("Erased", deleted, "objects. Manifest saved to", args.manifest_out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:observability/prometheus/relabelling_enforce_configmap.yaml
+apiVersion: v1
+kind: ConfigMap
+metadata:
+  name: prometheus-relabel-config
+  namespace: monitoring
+data:
+  relabels.yaml: |
+    # Drop extremely high-cardinality labels at scrape time
+    - job_name: 'kubernetes-pods'
+      relabel_configs:
+        - source_labels: [__meta_kubernetes_pod_label_request_id]
+          regex: '.*'
+          action: drop
+        - source_labels: [__meta_kubernetes_pod_label_user_id]
+          regex: '.*'
+          action: replace
+          replacement: 'user_aggregated'
+        - source_labels: [__meta_kubernetes_pod_label_model_version]
+          regex: '.*'
+          action: replace
+          replacement: 'model_v_agg'
+
*** End Patch
*** Begin Patch
*** Add File:observability/prometheus/recording_rules_strict.yaml
+groups:
+- name: aegis-strict-recording
+  rules:
+    - record: job:feast_lookup_latency:histogram_quantile_95
+      expr: histogram_quantile(0.95, sum(rate(feast_stream_process_seconds_bucket[5m])) by (le))
+    - record: job:model_inference_latency:histogram_quantile_95
+      expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
+    - record: aegis:high_cardinality_metrics_total
+      expr: count({__name__=~".+"})
+
*** End Patch
*** Begin Patch
*** Add File:observability/metric_cardinality_audit.py
+#!/usr/bin/env python3
+"""
+Query Prometheus to estimate metric cardinality growth and alert if above threshold.
+Configured via PROM_URL and CARDINALITY_THRESHOLD env vars.
+"""
+import os, requests, time, json
+
+PROM = os.environ.get("PROM_URL","http://prometheus-operated.monitoring.svc:9090")
+THRESH = int(os.environ.get("CARDINALITY_THRESHOLD","2000"))
+
+def count_series():
+    q = 'count({__name__=~".+"})'
+    r = requests.get(PROM + "/api/v1/query", params={"query": q}, timeout=20).json()
+    if r.get("status") != "success":
+        return None
+    return int(float(r["data"]["result"][0]["value"][1]))
+
+def main():
+    cnt = count_series()
+    now = time.time()
+    out = {"time": now, "series_count": cnt}
+    print(json.dumps(out))
+    if cnt and cnt > THRESH:
+        # create alert artifact
+        with open("/tmp/metric_cardinality_alert.json","w") as f:
+            json.dump(out,f)
+        print("Cardinality above threshold:", cnt)
+        # In production, send to alerting system / PagerDuty
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:compliance/DPA_Documentation_TEMPLATE.md
+# Data Processing Agreement (DPA) / BAA documentation template
+
+This is a template for legal teams to record DPA/BAA agreements for Aegis integrations.
+
+1. Parties
+   - Data Controller: <ORGANIZATION>
+   - Data Processor: <Aegis-platform-owner>
+
+2. Data types processed
+   - Enumerate PII types, sensitive categories.
+
+3. Subprocessors
+   - List services: MinIO, Redis, Kafka, IBMQ (if used), AWS Braket (if used), HSM vendor
+
+4. Security measures
+   - HSM key rotation schedule, Vault + SPIRE identity, signed MCP artifact retention
+
+5. Incident response & breach notification
+   - Timelines and contacts
+
+6. Audit & compliance
+   - Evidence bundle contents and retention
+
+Signatures
+
+-- END TEMPLATE --
+
*** End Patch
*** Begin Patch
*** Add File:compliance/assemble_audit_bundle.py
+#!/usr/bin/env python3
+"""
+Assemble compliance audit bundle:
+ - Collects MCPs, HSM logs, GE reports, DR manifests, and policy docs into a tar.gz
+ - Uploads to evidence bucket if configured
+"""
+import os, tarfile, glob, time, boto3
+
+OUT="/tmp/aegis_audit_bundle_{}.tar.gz".format(int(time.time()))
+SOURCES = [
+    "/tmp/mcp",
+    "/tmp/hsm_health.json",
+    "/tmp/hsm_rotation",
+    "/tmp/ge",
+    "/tmp/aegis_analysis",
+    "/tmp/backup_reconcile_report.json",
+    "compliance/DPA_Documentation_TEMPLATE.md"
+]
+
+def collect(out=OUT):
+    with tarfile.open(out,"w:gz") as tf:
+        for s in SOURCES:
+            if os.path.exists(s):
+                if os.path.isdir(s):
+                    for f in glob.glob(os.path.join(s,"**"), recursive=True):
+                        if os.path.isfile(f):
+                            tf.add(f, arcname=os.path.relpath(f, "/"))
+                elif os.path.isfile(s):
+                    tf.add(s, arcname=os.path.relpath(s, "/"))
+    print("Wrote bundle:", out)
+    bucket = os.environ.get("EVIDENCE_BUCKET","")
+    if bucket:
+        s3=boto3.client("s3")
+        key="evidence/audit_bundle_{}.tar.gz".format(int(time.time()))
+        s3.upload_file(out, bucket, key)
+        print("Uploaded to s3://{}/{}".format(bucket,key))
+
+if __name__ == "__main__":
+    collect()
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/risk_mitigation_checks.yml
+name: Risk mitigation checks
+on:
+  workflow_dispatch:
+
+jobs:
+  hsm-rotation-check:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run HSM healthcheck (dry)
+        run: |
+          python3 ops/hsm/hsm_healthcheck.py --json || true
+
+  metric-cardinality:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run metric cardinality audit
+        run: |
+          pip install requests
+          python3 observability/metric_cardinality_audit.py || true
+
+  backup-inventory:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Discover backups (needs AWS creds if bucket set)
+        run: |
+          pip install boto3 requests
+          python3 ops/erasure/discover_backups.py --out /tmp/backup_inventory.json || true
+      - name: Upload inventory artifact
+        uses: actions/upload-artifact@v4
+        with:
+          name: backup_inventory
+          path: /tmp/backup_inventory.json
+
+  assembly-audit:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Assemble audit bundle
+        run: |
+          pip install boto3
+          python3 compliance/assemble_audit_bundle.py || true
+      - name: Upload bundle
+        uses: actions/upload-artifact@v4
+        with:
+          name: audit-bundle
+          path: /tmp/aegis_audit_bundle_*.tar.gz
+
*** End Patch
*** Begin Patch
*** Add File:docs/RISK_MITIGATION_RUNBOOK.md
+# Risk Mitigation Runbook (Aegis)
+
+This runbook describes how to use the scripts and manifests added in this patch to mitigate the top risks.
+
+1) HSM signing & rotation failures
+ - Use ops/hsm/hsm_rotation_and_validation.sh to run a rotation and healthcheck. Replace vendor rotation placeholder with your HSM CLI.
+ - Run ops/hsm/hsm_healthcheck.py as a CronJob to populate /tmp/hsm_health.json.
+ - Periodically review /tmp/hsm_rotation/* logs and push evidence to EVIDENCE_BUCKET.
+ - Add a Prometheus alert to fire if hsm_sign_failure_total increases or if latency > threshold.
+
+2) Over-automation / unsafe rollouts
+ - Install Gatekeeper ConstraintTemplate policies/policies/gatekeeper/ct_high_risk_model.yaml and constraint_high_risk_model.yaml to require human approval annotation for any Deployment labeled model.risk=high.
+ - Use argo/manual_approval_workflow.yaml as a gating workflow: it posts requests to approvals service which humans can review. Ensure approvals API is protected and audited.
+ - For Rollouts, prefer pause steps with manual intervention before promotion.
+
+3) Incomplete erasure coverage
+ - Run ops/erasure/discover_backups.py to inventory backup locations and external archives. Use the output to identify prefixes to consider in erasure jobs.
+ - Use ops/erasure/erase_and_manifest.py to attempt deletion for a given prefix and produce a signed manifest uploading to MODEL_ARTIFACT_BUCKET evidence path.
+ - Maintain a persistent list of known backup endpoints and include them in the discovery job.
+
+4) Telemetry cost blowup
+ - Deploy observability/prometheus/relabelling_enforce_configmap.yaml into the Prometheus scrape configuration to drop high-cardinality labels at scrape time.
+ - Add recording rules observability/prometheus/recording_rules_strict.yaml to pre-aggregate metrics.
+ - Schedule observability/metric_cardinality_audit.py as a periodic job to monitor cardinality and create an alert artifact when thresholds are exceeded.
+ - Send remote_write to Thanos/Cortex with configured retention; ensure write_relabel_configs drop high-cardinality labels before sending long-term.
+
+5) Legal & compliance
+ - Use compliance/DPA_Documentation_TEMPLATE.md to capture negotiated DPAs/BAAs.
+ - Use compliance/assemble_audit_bundle.py regularly (e.g., nightly or on release) to build an evidence bundle with MCPs, HSM logs, GE reports, DR manifests and upload to EVIDENCE_BUCKET.
+ - Keep audit bundles for retention period required by legal.
+
+Operational tips
+ - Test all destructive scripts in staging (erase_and_manifest.py) before running in prod.
+ - Ensure Vault / SPIRE / Gatekeeper are deployed and integrated prior to enabling production constraints.
+ - Maintain runbooks for human approvers (who can set aegis/approved=true) and keep an audit trail of approvals.
+
*** End Patch
*** End Patch
