*** Begin Patch
*** Add File: terraform/aws/terraform.tfvars.template
+aws_region = "REPLACE_WITH_AWS_REGION"
+github_org = "REPLACE_WITH_GITHUB_ORG"
+github_repo = "REPLACE_WITH_GITHUB_REPO"
+oidc_provider_arn = "REPLACE_WITH_AWS_OIDC_PROVIDER_ARN"
+oidc_provider_url = "https://token.actions.githubusercontent.com"
+use_cloudhsm = false
+
+# Optional: set to true if you plan to use CloudHSM-backed KMS (requires extra provisioning)
+
*** End Patch
*** Begin Patch
*** Add File: terraform/gcp/terraform.tfvars.template
+gcp_project = "REPLACE_WITH_GCP_PROJECT_ID"
+gcp_region  = "REPLACE_WITH_GCP_REGION"
+github_repo = "REPLACE_WITH_GITHUB_OWNER/REPO"
+
+# Service account key path (created by gcloud) - do NOT commit secrets into repo
+# gcp_sa_key_file = "/path/to/service-account-key.json"
+
*** End Patch
*** Begin Patch
*** Add File: helm/vault/values-prod-aws-kms.tpl.yaml
+server:
+  ha:
+    enabled: true
+  dataStorage:
+    enabled: true
+  extraEnvironmentVars:
+    VAULT_LOCAL_CONFIG: |
+      ui = true
+      listener "tcp" {
+        address = "0.0.0.0:8200"
+        tls_disable = 0
+      }
+      storage "raft" {
+        path = "/vault/data"
+      }
+      seal "awskms" {
+        region = "${AWS_REGION}"
+        kms_key_id = "${AWS_KMS_KEY_ARN}"
+      }
+  service:
+    type: ClusterIP
+serverAffinity:
+  enabled: true
+injector:
+  enabled: true
+
+# Fill ${AWS_REGION} and ${AWS_KMS_KEY_ARN} via scripts/generate_pr_ready_files.sh
+
*** End Patch
*** Begin Patch
*** Add File: scripts/generate_pr_ready_files.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Populate template files to produce PR-ready tfvars and helm values.
+# Usage:
+#   ./scripts/generate_pr_ready_files.sh --aws-region us-west-2 --aws-kms-arn arn:aws:kms:...
+# The script writes terraform/aws/terraform.tfvars and helm/vault/values-prod-aws-kms.yaml
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --aws-region) AWS_REGION="$2"; shift 2;;
+    --aws-kms-arn) AWS_KMS_KEY_ARN="$2"; shift 2;;
+    --github-org) GITHUB_ORG="$2"; shift 2;;
+    --github-repo) GITHUB_REPO="$2"; shift 2;;
+    --gcp-project) GCP_PROJECT="$2"; shift 2;;
+    --gcp-region) GCP_REGION="$2"; shift 2;;
+    *) echo "Unknown arg: $1"; exit 2;;
+  esac
+done
+
+: "${AWS_REGION:=REPLACE_WITH_AWS_REGION}"
+: "${AWS_KMS_KEY_ARN:=REPLACE_WITH_AWS_KMS_KEY_ARN}"
+: "${GITHUB_ORG:=REPLACE_WITH_GITHUB_ORG}"
+: "${GITHUB_REPO:=REPLACE_WITH_GITHUB_REPO}"
+: "${GCP_PROJECT:=REPLACE_WITH_GCP_PROJECT}"
+: "${GCP_REGION:=REPLACE_WITH_GCP_REGION}"
+
+echo "Writing terraform/aws/terraform.tfvars"
+cat > terraform/aws/terraform.tfvars <<EOF
+aws_region = "${AWS_REGION}"
+github_org = "${GITHUB_ORG}"
+github_repo = "${GITHUB_REPO}"
+oidc_provider_arn = "REPLACE_WITH_AWS_OIDC_PROVIDER_ARN"
+oidc_provider_url = "https://token.actions.githubusercontent.com"
+use_cloudhsm = false
+EOF
+
+echo "Writing terraform/gcp/terraform.tfvars"
+cat > terraform/gcp/terraform.tfvars <<EOF
+gcp_project = "${GCP_PROJECT}"
+gcp_region  = "${GCP_REGION}"
+github_repo = "${GITHUB_ORG}/${GITHUB_REPO}"
+EOF
+
+echo "Rendering helm/vault/values-prod-aws-kms.yaml from template"
+envsubst '${AWS_REGION} ${AWS_KMS_KEY_ARN}' < helm/vault/values-prod-aws-kms.tpl.yaml > helm/vault/values-prod-aws-kms.yaml
+
+echo "Done. Review the files before committing and DO NOT commit secrets."
+echo "Next: run 'cd terraform/aws && terraform init && terraform apply -auto-approve' to create KMS resources (or create a PR)."
+
*** End Patch
*** Begin Patch
*** Add File: scripts/run_full_validation.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Orchestrator to run the full validation sequence in order and collect artifacts.
+# This script is interactive and will ask for confirmation before each major step.
+#
+ARTIFACT_DIR=${ARTIFACT_DIR:-artifacts/full_validation}
+mkdir -p "$ARTIFACT_DIR"
+
+confirm() {
+  read -p "$1 [y/N]: " yn
+  case "$yn" in [Yy]*) return 0 ;; *) return 1 ;; esac
+}
+
+echo "1) Terraform apply (AWS KMS). This will make changes in AWS (you can skip and provide outputs)."
+if confirm "Run terraform apply for terraform/aws now?"; then
+  (cd terraform/aws && terraform init && terraform apply -auto-approve)
+  echo "Terraform apply done." | tee "$ARTIFACT_DIR/terraform_apply.txt"
+fi
+
+echo "2) Set GitHub secrets from terraform outputs"
+if confirm "Set GitHub secrets using scripts/set_github_secrets_from_tf.sh?"; then
+  ./scripts/set_github_secrets_from_tf.sh "${GITHUB_REPO:-REPLACE_WITH_OWNER/REPO}" terraform/aws
+fi
+
+echo "3) Install Vault Helm (values file must be prepared)"
+if confirm "Install Vault Helm chart now?"; then
+  helm repo add hashicorp https://helm.releases.hashicorp.com || true
+  helm repo update
+  helm upgrade --install vault hashicorp/vault -n ops --create-namespace -f helm/vault/values-prod-aws-kms.yaml
+  echo "Vault chart deployed. Wait for pods to be ready, then run bootstrap script with root token." | tee "$ARTIFACT_DIR/vault_install.txt"
+fi
+
+echo "4) Run bootstrap Vault (you must supply root token)"
+if confirm "Run ./scripts/bootstrap_vault_prod_complete.sh now? (supply token when prompted)"; then
+  read -p "Enter VAULT_ROOT_TOKEN: " VAULT_ROOT_TOKEN
+  ./scripts/bootstrap_vault_prod_complete.sh "$VAULT_ROOT_TOKEN"
+fi
+
+echo "5) Build & push training images (user must have registry auth)"
+if confirm "Build & push training Docker images?"; then
+  docker build -f docker/deepspeed_fsdp.Dockerfile -t ${REGISTRY:-ghcr.io/yourorg}/deepspeed-fsdp:latest .
+  docker push ${REGISTRY:-ghcr.io/yourorg}/deepspeed-fsdp:latest
+  echo "Image pushed" | tee "$ARTIFACT_DIR/image_push.txt"
+fi
+
+echo "6) Submit DGX & TPU validation workflows (requires kubectl context and node labels)"
+if confirm "Submit DGX validation (kubectl apply -f dgx/argo/deepspeed_dgx_validation.yaml)?"; then
+  kubectl apply -f dgx/argo/deepspeed_dgx_validation.yaml
+fi
+if confirm "Submit TPU validation (kubectl apply -f gcp/argo/gcp_tpu_validation.yaml)?"; then
+  kubectl apply -f gcp/argo/gcp_tpu_validation.yaml
+fi
+
+echo "7) Start Quantum controller & workers (k8s or local). Deploy Redis+simulator if needed."
+if confirm "Deploy Redis and simulator (kubectl apply -f k8s/redis/redis-deployment.yaml && kubectl apply -f k8s/simulator/simulator-deployment.yaml)?"; then
+  kubectl apply -f k8s/redis/redis-deployment.yaml
+  kubectl apply -f k8s/simulator/simulator-deployment.yaml
+fi
+if confirm "Start quantum controller locally (uvicorn services/quantum_controller/main:app --host 0.0.0.0 --port 8080)?"; then
+  echo "Start in separate shell: cd services/quantum_controller && pip install -r requirements.txt && uvicorn main:app --host 0.0.0.0 --port 8080"
+fi
+
+echo "8) Run scale validation and collect artifacts"
+if confirm "Run scale validation script to collect artifacts now?"; then
+  python3 scripts/scale_validation/submit_and_validate.py --workflow argo/deepspeed_zeo_workflow_poc.yaml --workflow-name deepspeed-poc --s3-bucket ${COMPLIANCE_BUCKET:-REPLACE_BUCKET} --s3-prefix deepspeed/poc
+  cp -r artifacts/scale_validation "$ARTIFACT_DIR/"
+fi
+
+echo "9) Create signoff bundle"
+./scripts/create_signoff_report.sh
+cp aegis_signoff_* "$ARTIFACT_DIR/" || true
+
+echo "Full validation orchestration complete. Artifacts in $ARTIFACT_DIR"
+
*** End Patch
*** Begin Patch
*** Add File: services/quantum_controller/adapters/braket_adapter_impl.py
+"""
+BraketAdapter (implementation outline)
+This adapter:
+ - uploads circuit & input to S3
+ - calls braket.create_quantum_task with minimal required fields
+ - polls for task completion and downloads results from S3
+
+NOTE: This is a working scaffold but you must adapt S3 bucket names, IAM, and the task specification
+to your target Braket device and Braket SDK expectations.
+"""
+import os
+import time
+import json
+import boto3
+from botocore.exceptions import ClientError
+
+class BraketAdapter:
+    def __init__(self):
+        self.region = os.environ.get("AWS_REGION",
î€€
