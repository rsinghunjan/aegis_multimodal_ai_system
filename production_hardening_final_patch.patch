*** Begin Patch
*** Add File: provider/onboarding/procurement_package_generator.py
+#!/usr/bin/env python3
+"""
+Generate a provider procurement package:
+ - collects contract template, attestation example, onboarding instructions
+ - produces a tarball for procurement/legal and uploads to compliance S3 bucket
+"""
+import os, tarfile
+from datetime import datetime
+import boto3
+
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+OUT = f"/tmp/provider_procurement_package_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.tgz"
+FILES = [
+    "provider/onboarding/PROVIDER_CONTRACT_TEMPLATE.md",
+    "provider/onboarding/provider_attestation_example.json",
+    "provider/onboarding/ingestion_test.py",
+]
+
+def make_package():
+    with tarfile.open(OUT, "w:gz") as tg:
+        for p in FILES:
+            if os.path.exists(p):
+                tg.add(p, arcname=p)
+    print("Wrote", OUT)
+    if COMPLIANCE_BUCKET:
+        s3 = boto3.client("s3")
+        key = f"procurement/{os.path.basename(OUT)}"
+        s3.upload_file(OUT, COMPLIANCE_BUCKET, key)
+        print("Uploaded to s3://{}/{}".format(COMPLIANCE_BUCKET, key))
+
+if __name__ == "__main__":
+    make_package()
+
*** End Patch
*** Begin Patch
*** Add File: device/provisioning_api.py
+#!/usr/bin/env python3
+"""
+Device provisioning API for large-scale fleet onboarding.
+ - POST /provision to register a device, produce mapping entry and optionally print helm values fragment.
+ - Accepts device_id, node, ipmi_host, rack, and metadata.
+"""
+from flask import Flask, request, jsonify
+from device.device_registry import register_device
+import os, json
+
+app = Flask("device-provisioning")
+
+@app.route("/provision", methods=["POST"])
+def provision():
+    j = request.json or {}
+    device_id = j.get("device_id")
+    meta = {
+        "node": j.get("node"),
+        "ipmi_host": j.get("ipmi_host"),
+        "rack": j.get("rack"),
+        "meta": j.get("meta", {})
+    }
+    if not device_id:
+        return jsonify({"error":"device_id required"}), 400
+    register_device(device_id, meta)
+    # return helm config fragment to add mapping
+    fragment = {device_id: {"node": meta["node"], "rack": meta["rack"], "ipmi_host": meta["ipmi_host"]}}
+    return jsonify({"ok": True, "helm_mapping_fragment": fragment})
+
+if __name__=="__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT","8130")))
+
*** End Patch
*** Begin Patch
*** Add File: measurement/coverage_report.py
+#!/usr/bin/env python3
+"""
+Compute measurement coverage: % of recent jobs that have device mapping and a 'measured' event.
+Uploads report to compliance bucket for auditors and dashboards.
+"""
+import os, json, boto3
+from sqlalchemy import create_engine, text
+from datetime import datetime, timedelta
+
+DB_URL = os.environ.get("DATABASE_URL", "postgresql://aegis:aegis@localhost:5432/aegis")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+engine = create_engine(DB_URL)
+OUT = f"/tmp/measurement_coverage_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+
+def run(days=7):
+    with engine.connect() as conn:
+        since = datetime.utcnow() - timedelta(days=days)
+        total = conn.execute(text("SELECT count(*) FROM job_ledger WHERE created_at >= :since"), {"since": since}).scalar() or 0
+        mapped = conn.execute(text("SELECT count(distinct jl.job_id) FROM job_ledger jl JOIN job_device_map jdm ON jl.job_id=jdm.job_id WHERE jl.created_at >= :since"), {"since": since}).scalar() or 0
+        measured = conn.execute(text("SELECT count(distinct job_id) FROM job_events WHERE event='measured' AND ts >= :since"), {"since": since}).scalar() or 0
+    report = {"total_jobs": total, "mapped_jobs": mapped, "measured_jobs": measured, "coverage_pct_mapped": (mapped/total*100.0 if total else 0.0), "coverage_pct_measured": (measured/total*100.0 if total else 0.0), "ts": datetime.utcnow().isoformat()}
+    open(OUT,"w").write(json.dumps(report, indent=2))
+    if COMPLIANCE_BUCKET:
+        s3=boto3.client("s3"); key=f"measurement_reports/{os.path.basename(OUT)}"; s3.upload_file(OUT, COMPLIANCE_BUCKET, key)
+    print("Wrote coverage report", OUT)
+
+if __name__=="__main__":
+    run()
+
*** End Patch
*** Begin Patch
*** Add File: forecast/backtest_calibrate.py
+#!/usr/bin/env python3
+"""
+Systematic backtester and PI calibration for Prophet forecasts.
+ - Runs sliding-window cross-validation, computes MAE and PI coverage (how often true value within yhat_lower/upper)
+ - Emits calibration report to compliance bucket and exits non-zero if PI coverage is poor
+"""
+import os, json, pandas as pd
+from prophet import Prophet
+from datetime import datetime
+import boto3
+
+CACHE_PATH = os.environ.get("CARBON_HISTORY_PATH", "/data/carbon_history.json")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+REGION = os.environ.get("REGION", "US")
+
+def load_series(region):
+    j=json.load(open(CACHE_PATH))
+    rows=[]
+    for h in j.get("history",[]):
+        ts = h.get("ts"); val = h.get("regions",{}).get(region,{}).get("carbon_g_per_kwh")
+        if ts and val is not None:
+            rows.append({"ds": pd.to_datetime(ts), "y": float(val)})
+    return pd.DataFrame(rows)
+
+def sliding_backtest(df, initial_hours=24*7, horizon=24, step=24):
+    metrics=[]
+    n = len(df)
+    for start in range(0, max(1, n - initial_hours - horizon), step):
+        train = df.iloc[:initial_hours+start]
+        test = df.iloc[initial_hours+start:initial_hours+start+horizon]
+        if len(test) < horizon: break
+        m = Prophet(interval_width=0.9); m.fit(train)
+        fut = m.make_future_dataframe(periods=horizon, freq='H')
+        fc = m.predict(fut).tail(horizon)
+        pred = fc['yhat'].values; lower = fc['yhat_lower'].values; upper = fc['yhat_upper'].values
+        actual = test['y'].values
+        mae = float((abs(pred - actual)).mean())
+        # PI coverage
+        covered = sum((actual >= lower) & (actual <= upper))
+        coverage = covered / len(actual)
+        metrics.append({"mae": mae, "pi_coverage": coverage})
+    return metrics
+
+def main():
+    df = load_series(REGION)
+    if df.empty:
+        print("no history"); return
+    metrics = sliding_backtest(df)
+    avg_mae = sum(m['mae'] for m in metrics)/len(metrics) if metrics else None
+    avg_cov = sum(m['pi_coverage'] for m in metrics)/len(metrics) if metrics else None
+    report = {"region": REGION, "avg_mae": avg_mae, "avg_pi_coverage": avg_cov, "samples": len(metrics), "ts": datetime.utcnow().isoformat()}
+    out = f"/tmp/forecast_backtest_{REGION}_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    open(out,"w").write(json.dumps(report, indent=2))
+    if COMPLIANCE_BUCKET:
+        s3=boto3.client("s3"); s3.upload_file(out, COMPLIANCE_BUCKET, f"forecast_backtests/{os.path.basename(out)}")
+    print("Wrote backtest report", out)
+    # Fail if PI coverage too low (<80%)
+    if avg_cov is not None and avg_cov < 0.8:
+        print("PI coverage low:", avg_cov); raise SystemExit(2)
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: forecast/model_registry.py
+#!/usr/bin/env python3
+"""
+Simple model registry to record model versions, metadata and enable rollback.
+ - register_model(model_s3_path, region, mae)
+ - list_models(region)
+ - mark_active(model_id)
+ - rollback_to(model_id)
+"""
+import os, json
+from datetime import datetime
+from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, JSON, DateTime
+
+DB_URL = os.environ.get("DATABASE_URL", "sqlite:///./model_registry.db")
+engine = create_engine(DB_URL, future=True)
+meta = MetaData()
+models = Table("models", meta,
+               Column("id", Integer, primary_key=True),
+               Column("s3_path", String(1024)),
+               Column("region", String(32)),
+               Column("mae", String(32)),
+               Column("active", String(8)),
+               Column("created_at", DateTime))
+meta.create_all(engine)
+
+def register_model(s3_path, region, mae):
+    with engine.begin() as conn:
+        res = conn.execute(models.insert().values(s3_path=s3_path, region=region, mae=str(mae), active="false", created_at=datetime.utcnow()))
+        return res.inserted_primary_key[0]
+
+def list_models(region):
+    with engine.connect() as conn:
+        res = conn.execute(models.select().where(models.c.region==region).order_by(models.c.created_at.desc()))
+        return [dict(r._mapping) for r in res]
+
+def mark_active(model_id):
+    with engine.begin() as conn:
+        conn.execute(models.update().values(active="false").where(models.c.region==models.c.region))
+        conn.execute(models.update().where(models.c.id==model_id).values(active="true"))
+
+def rollback_to(model_id):
+    # operator must implement model deployment; here we mark active in registry
+    mark_active(model_id)
+    print("Marked model", model_id, "active")
+
+if __name__=="__main__":
+    print(list_models("US"))
+
*** End Patch
*** Begin Patch
*** Add File: hsm/rotate_coordinator.py
+#!/usr/bin/env python3
+"""
+Coordinate rotation/test signing across multiple HSM hosts and collect evidence.
+ - iterates HSM_ADMIN_HOSTS (comma separated), triggers remote sign, collects logs, uploads compiled rotation metadata to compliance bucket
+"""
+import os, subprocess, json, boto3
+from datetime import datetime
+
+HOSTS = [h for h in os.environ.get("HSM_ADMIN_HOSTS","").split(",") if h]
+SAMPLE_ARTIFACT = os.environ.get("HSM_SAMPLE_ART","/opt/aegis/sample_snapshot.json")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+
+def run_on_host(h):
+    out = f"/tmp/hsm_rotate_{h.replace('@','_')}.log"
+    try:
+        cmd = ["ssh", h, "bash -lc", f"'/opt/aegis/hsm_sign_snapshot_remote.sh \"{SAMPLE_ARTIFACT}\"; tail -n 200 /var/log/aegis/hsm_signing.log'"]
+        logs = subprocess.check_output(cmd, stderr=subprocess.STDOUT, timeout=120).decode()
+        open(out,"w").write(logs)
+        if COMPLIANCE_BUCKET:
+            s3=boto3.client("s3"); key=f"hsm_rotations/{os.path.basename(out)}"; s3.upload_file(out, COMPLIANCE_BUCKET, key)
+        return {"host": h, "ok": True, "log": out}
+    except Exception as e:
+        open(out,"w").write(str(e))
+        return {"host": h, "ok": False, "log": out, "error": str(e)}
+
+def main():
+    results=[]
+    for h in HOSTS:
+        if not h: continue
+        results.append(run_on_host(h))
+    meta = {"ts": datetime.utcnow().isoformat(), "results": results}
+    out="/tmp/hsm_rotation_meta.json"
+    open(out,"w").write(json.dumps(meta, indent=2))
+    if COMPLIANCE_BUCKET:
+        s3=boto3.client("s3"); s3.upload_file(out, COMPLIANCE_BUCKET, f"hsm_rotations/{os.path.basename(out)}")
+    print("Wrote rotation metadata", out)
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: scheduler/queue_backoff.py
+#!/usr/bin/env python3
+"""
+Simple Redis-backed queue + exponential backoff consumer for soft-throttled jobs.
+ - push job JSON to 'aegis:queue'
+ - consumer pops, attempts scheduling via scheduler adapter; on soft-throttle requeue with backoff
+Requires REDIS_URL env var.
+"""
+import os, json, time, redis, requests
+from datetime import datetime
+
+REDIS_URL = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
+r = redis.from_url(REDIS_URL)
+QUEUE = "aegis:queue"
+
+def push(job):
+    payload = {"job": job, "attempts": 0, "next_at": datetime.utcnow().isoformat()}
+    r.rpush(QUEUE, json.dumps(payload))
+
+def pop():
+    raw = r.lpop(QUEUE)
+    if not raw:
+        return None
+    return json.loads(raw)
+
+def requeue(payload, delay_sec):
+    payload["attempts"] += 1
+    payload["next_at"] = (datetime.utcnow() + timedelta(seconds=delay_sec)).isoformat()
+    # simplistic requeue as tail; in prod use sorted set by score
+    r.rpush(QUEUE, json.dumps(payload))
+
+def worker():
+    while True:
+        payload = pop()
+        if not payload:
+            time.sleep(2); continue
+        job = payload["job"]
+        # try schedule via scheduler adapter endpoint
+        try:
+            resp = requests.post(os.environ.get("SCHEDULER_ADAPTER_URL","http://localhost:8200/schedule"), json=job, timeout=10)
+            if resp.status_code == 200:
+                print("Scheduled job", job.get("job_id"))
+                continue
+            # if response indicates throttle, requeue with backoff
+            if resp.status_code == 429 or "throttle" in resp.text.lower():
+                attempts = payload.get("attempts",0)
+                delay = min(60*(2**attempts), 3600)
+                print("Throttle, requeueing with delay", delay)
+                time.sleep(delay)
+                r.rpush(QUEUE, json.dumps(payload))
+                continue
+            print("Schedule failed:", resp.status_code, resp.text)
+        except Exception as e:
+            print("Worker exception", e)
+            # exponential backoff and requeue
+            attempts = payload.get("attempts",0)
+            delay = min(60*(2**attempts), 3600)
+            time.sleep(delay)
+            r.rpush(QUEUE, json.dumps(payload))
+
+if __name__=="__main__":
+    worker()
+
*** End Patch
*** Begin Patch
*** Add File: scheduler/replay_test.py
+#!/usr/bin/env python3
+"""
+Replay recorded job submissions concurrently to stress-test admission/throttle.
+Reads /tmp/replay_jobs.json (list of job JSON) and replays with concurrency.
+"""
+import json, threading, requests, time
+
+JOBS_FILE = os.environ.get("REPLAY_JOBS_FILE", "/tmp/replay_jobs.json")
+ADMISSION = os.environ.get("ADMISSION_URL", "http://admission-prod.aegis.svc:9110/admit")
+
+def submit(job):
+    try:
+        r = requests.post(ADMISSION, json={"tenant": job["tenant"], "requested_kgco2e": job["kg"], "mode": "soft"}, timeout=5)
+        print("submitted", job["tenant"], job["kg"], "->", r.status_code)
+    except Exception as e:
+        print("submit error", e)
+
+def main(concurrency=10):
+    jobs = json.load(open(JOBS_FILE))
+    threads=[]
+    for i,job in enumerate(jobs):
+        t = threading.Thread(target=submit, args=(job,))
+        threads.append(t); t.start()
+        if len(threads) >= concurrency:
+            for th in threads:
+                th.join()
+            threads=[]
+    for th in threads: th.join()
+    print("replay complete")
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: experiments/ab_audit.py
+#!/usr/bin/env python3
+"""
+Audit A/B experiments: ensure sample-size, provenance (snapshot_id, attestation_ids) and randomization logs exist.
+Uploads audit report to compliance bucket.
+"""
+import os, json, boto3
+from datetime import datetime
+
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+INPUT_DIR = "experiments/ab_inputs"
+
+def audit():
+    report = {"results": [], "ts": datetime.utcnow().isoformat()}
+    if not os.path.isdir(INPUT_DIR):
+        print("no ab inputs"); return
+    a_path = os.path.join(INPUT_DIR, "ab_a.json"); b_path = os.path.join(INPUT_DIR, "ab_b.json")
+    meta_path = os.path.join(INPUT_DIR, "meta.json")
+    if not os.path.exists(a_path) or not os.path.exists(b_path):
+        print("missing inputs"); return
+    A = json.load(open(a_path)); B = json.load(open(b_path))
+    meta = json.load(open(meta_path)) if os.path.exists(meta_path) else {}
+    # basic checks
+    report["results"].append({"check":"sample_sizes","a":len(A),"b":len(B)})
+    report["results"].append({"check":"min_sample_size","required":meta.get("min_sample_size")})
+    report["meta"]=meta
+    out = f"/tmp/ab_audit_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.json"
+    open(out,"w").write(json.dumps(report, indent=2))
+    if COMPLIANCE_BUCKET:
+        s3=boto3.client("s3"); s3.upload_file(out, COMPLIANCE_BUCKET, f"ab_audits/{os.path.basename(out)}")
+    print("Wrote audit", out)
+
+if __name__=="__main__":
+    audit()
+
*** End Patch
*** Begin Patch
*** Add File: compliance/pen_test_tracker.py
+#!/usr/bin/env python3
+"""
+Simple pen-test findings tracker: create/findings.json and allow marking remediation.
+This is a lightweight local tracker for evidence of remediation and SLA.
+"""
+import json, os, uuid
+DB = "compliance/pen_test_findings.json"
+
+def ensure_db():
+    if not os.path.exists("compliance"):
+        os.makedirs("compliance")
+    if not os.path.exists(DB):
+        open(DB,"w").write(json.dumps({"findings": []}, indent=2))
+
+def add_finding(title, severity, description):
+    ensure_db()
+    d=json.load(open(DB))
+    fid=str(uuid.uuid4())
+    d["findings"].append({"id": fid, "title": title, "severity": severity, "description": description, "status": "open"})
+    open(DB,"w").write(json.dumps(d, indent=2))
+    print("Added", fid)
+
+def close_finding(fid, comment):
+    d=json.load(open(DB))
+    for f in d["findings"]:
+        if f["id"]==fid:
+            f["status"]="closed"; f.setdefault("notes",[]).append({"ts": __import__("datetime").datetime.utcnow().isoformat(), "comment": comment})
+    open(DB,"w").write(json.dumps(d, indent=2))
+    print("Closed", fid)
+
+if __name__=="__main__":
+    import sys
+    ensure_db()
+    if len(sys.argv) >= 2 and sys.argv[1]=="add":
+        add_finding(sys.argv[2], sys.argv[3] if len(sys.argv)>3 else "medium", sys.argv[4] if len(sys.argv)>4 else "")
+    elif len(sys.argv)>=3 and sys.argv[1]=="close":
+        close_finding(sys.argv[2], sys.argv[3] if len(sys.argv)>3 else "remediated")
+    else:
+        print("usage: pen_test_tracker.py add <title> [severity] [desc] | pen_test_tracker.py close <id> [note]")
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/restore_drill_and_ha.yml
+name: Restore Drill & HA Validation
+on:
+  workflow_dispatch:
+  schedule:
+    - cron: "0 5 1 * *" # monthly
+
+jobs:
+  run-drill:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Run restore drill
+        env:
+          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
+          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
+          COMPLIANCE_BUCKET: ${{ secrets.COMPLIANCE_BUCKET }}
+          PG_S3_PATH: ${{ secrets.PG_S3_PATH }}
+        run: |
+          pip install boto3 >/dev/null 2>&1 || true
+          python restore/automated_restore_drill.py || (echo "Restore drill failed" && exit 1)
+      - name: Upload drill artifacts
+        uses: actions/upload-artifact@v4
+        with:
+          name: restore-drill-artifacts
+          path: /tmp/restore_drill_report.json
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/src/WhatIf.js
+import React, {useState} from 'react';
+
+function WhatIf({tenant}) {
+  const [deferHours, setDeferHours] = useState(24);
+  const [estKg, setEstKg] = useState(1.0);
+  const [result, setResult] = useState(null);
+
+  const simulate = async () => {
+    // naive simulation: call prebook recommend endpoint to get recommended slot
+    const resp = await fetch(`/recommend/${tenant}`, {method: 'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({estimated_kgco2e: estKg, flexible: true})});
+    const j = await resp.json();
+    setResult(j);
+  };
+
+  return (
+    <div style={{marginTop:20}}>
+      <h3>What‑If: Defer Simulation</h3>
+      <div>
+        <label>Estimated kgCO2e: <input type="number" value={estKg} onChange={e=>setEstKg(parseFloat(e.target.value))} /></label>
+      </div>
+      <div>
+        <label>Defer hours: <input type="number" value={deferHours} onChange={e=>setDeferHours(parseInt(e.target.value))} /></label>
+      </div>
+      <button onClick={simulate}>Simulate</button>
+      {result && <pre>{JSON.stringify(result, null, 2)}</pre>}
+    </div>
+  );
+}
+
+export default WhatIf;
+
*** End Patch
*** Begin Patch
*** Add File: tenant-ui/src/App.js
+import React, {useState, useEffect} from 'react';
+import WhatIf from './WhatIf';
+
+function App(){
+  const [tenant, setTenant] = useState('alice');
+  const [summary, setSummary] = useState(null);
+  const [jobId, setJobId] = useState('');
+  const [decision, setDecision] = useState(null);
+
+  useEffect(()=>{
+    fetch(`/tenant/${tenant}/tradeoff`).then(r=>r.json()).then(setSummary).catch(()=>setSummary(null));
+  },[tenant]);
+
+  const fetchDecision = () => {
+    if(!jobId) return;
+    fetch(`/decision/${jobId}`).then(r=>r.json()).then(setDecision).catch(()=>setDecision(null));
+  };
+
+  return (
+    <div style={{padding:20,fontFamily:'Arial'}}>
+      <h2>Aegis Tenant Showback & What‑If</h2>
+      <label>Tenant: <input value={tenant} onChange={e=>setTenant(e.target.value)} /></label>
+      <div style={{marginTop:10}}>
+        <h3>Summary</h3>
+        {summary ? (
+          <div>
+            <div>Cost (30d): {summary.total_cost}</div>
+            <div>Carbon (30d): {summary.total_kg}</div>
+            <div>Most used snapshot: {summary.most_used_snapshot}</div>
+          </div>
+        ) : <div>Loading...</div>}
+      </div>
+      <div style={{marginTop:20}}>
+        <h3>Decision Explainability</h3>
+        <label>Job ID: <input value={jobId} onChange={e=>setJobId(e.target.value)} /></label>
+        <button onClick={fetchDecision}>Fetch Decision</button>
+        {decision && <pre>{JSON.stringify(decision, null, 2)}</pre>}
+      </div>
+      <WhatIf tenant={tenant} />
+    </div>
+  );
+}
+
+export default App;
+
*** End Patch
*** End Patch
    
