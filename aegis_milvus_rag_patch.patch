*** Begin Patch
*** Add File: scripts/rag_milvus_ingest.py
+#!/usr/bin/env python3
+"""
+Milvus-based RAG ingestion script.
+
+Walks selected repo directories, chunks text files, embeds using SentenceTransformer,
+and stores vectors + metadata in a Milvus collection.
+
+Environment variables:
+ - MILVUS_HOST (default: localhost)
+ - MILVUS_PORT (default: 19530)
+ - MILVUS_COLLECTION (default: "aegis_rag")
+ - EMBED_MODEL (default: "all-MiniLM-L6-v2")
+ - CHUNK_SIZE (default: 800)
+ - CHUNK_OVERLAP (default: 200)
+
+Notes:
+ - Requires `sentence-transformers`, `pymilvus`, `numpy`.
+ - This is a simple ingestion scaffold for Milvus; tune index params (metric_type, index) for your workload.
+"""
+import os
+import json
+import hashlib
+from pathlib import Path
+from typing import List
+
+try:
+    from sentence_transformers import SentenceTransformer
+except Exception as e:
+    raise SystemExit("Missing dependency: sentence-transformers. Install it before running this script.") from e
+
+import numpy as np
+
+try:
+    from pymilvus import (
+        connections,
+        FieldSchema,
+        CollectionSchema,
+        DataType,
+        Collection,
+        utility,
+    )
+except Exception as e:
+    raise SystemExit("Missing dependency: pymilvus. Install it before running this script.") from e
+
+# Config
+ROOT = Path(".")
+TARGET_DIRS = ["docs", "infra", "k8s", ".github/workflows", "scripts"]
+MILVUS_HOST = os.getenv("MILVUS_HOST", "localhost")
+MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")
+COLLECTION_NAME = os.getenv("MILVUS_COLLECTION", "aegis_rag")
+EMBED_MODEL = os.getenv("EMBED_MODEL", "all-MiniLM-L6-v2")
+CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "800"))
+CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", "200"))
+
+def text_chunks(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP):
+    start = 0
+    L = len(text)
+    while start < L:
+        end = start + chunk_size
+        yield text[start:end]
+        start = max(0, end - overlap)
+
+def collect_documents() -> List[dict]:
+    docs = []
+    for d in TARGET_DIRS:
+        p = ROOT / d
+        if not p.exists():
+            continue
+        for fp in p.rglob("*"):
+            if fp.is_file():
+                try:
+                    text = fp.read_text(encoding="utf-8")
+                except Exception:

î€€
