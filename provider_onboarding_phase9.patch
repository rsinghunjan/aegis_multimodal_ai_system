*** Begin Patch
*** Add File: scripts/verify_vault_provider_secret.py
+#!/usr/bin/env python3
+"""
+Check whether provider credentials exist in Vault at secret/data/quantum/providers/<provider>
+
+Usage:
+  VAULT_ADDR=https://vault.example.com VAULT_TOKEN=... python scripts/verify_vault_provider_secret.py ibm
+
+Exit codes:
+  0 - secret exists
+  1 - secret does not exist
+  2 - usage / environment error
+  3 - request error
+"""
+from __future__ import annotations
+import os
+import sys
+import requests
+
+
+def usage():
+    print("Usage: VAULT_ADDR=... VAULT_TOKEN=... python scripts/verify_vault_provider_secret.py <provider>")
+
+
+def main():
+    if len(sys.argv) != 2:
+        usage()
+        return 2
+    provider = sys.argv[1]
+    vault_addr = os.environ.get("VAULT_ADDR")
+    vault_token = os.environ.get("VAULT_TOKEN")
+    if not vault_addr or not vault_token:
+        print("Environment variables VAULT_ADDR and VAULT_TOKEN are required", file=sys.stderr)
+        return 2
+    path = f"{vault_addr.rstrip('/')}/v1/secret/data/quantum/providers/{provider}"
+    try:
+        r = requests.get(path, headers={"X-Vault-Token": vault_token}, timeout=10)
+    except Exception as e:
+        print("Error connecting to Vault:", e, file=sys.stderr)
+        return 3
+    if r.status_code == 200:
+        try:
+            data = r.json()
+            # Don't print secrets; show metadata summary only
+            meta = data.get("data", {}).get("metadata", {})
+            print(f"Found secret for provider '{provider}'. Metadata: {meta}")
+        except Exception:
+            print(f"Found secret for provider '{provider}' (could not parse JSON)")
+        return 0
+    elif r.status_code == 404:
+        print(f"No secret found at path secret/data/quantum/providers/{provider}")
+        return 1
+    else:
+        print(f"Unexpected response from Vault: {r.status_code} {r.text}", file=sys.stderr)
+        return 3
+
+
+if __name__ == "__main__":
+    sys.exit(main())
+
*** End Patch
*** Begin Patch
*** Add File: scripts/check_self_hosted_runner.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Check whether a GitHub self-hosted runner with the required labels exists for a repo or org.
+# Requires the GitHub CLI (gh) and authentication (gh auth login).
+#
+# Usage:
+#   REPO="owner/repo" ./scripts/check_self_hosted_runner.sh
+#   OR
+#   ORG="owner" ./scripts/check_self_hosted_runner.sh --org
+
+REPO="${REPO:-}"
+ORG="${ORG:-}"
+MODE="repo"
+
+if [ "${1:-}" = "--org" ]; then
+  MODE="org"
+fi
+
+if [ "$MODE" = "repo" ] && [ -z "$REPO" ]; then
+  echo "Set REPO=owner/repo or call with --org and set ORG=owner" >&2
+  exit 2
+fi
+if [ "$MODE" = "org" ] && [ -z "$ORG" ]; then
+  echo "Set ORG=owner when using --org" >&2
+  exit 2
+fi
+
+echo "Checking for self-hosted runners with labels 'self-hosted' and 'qpu-adjacent'..."
+if ! command -v gh >/dev/null 2>&1; then
+  echo "gh CLI not found; please install and authenticate (gh auth login)" >&2
+  exit 3
+fi
+
+if [ "$MODE" = "repo" ]; then
+  echo "Listing runners for repo $REPO..."
+  runners_json=$(gh api -X GET "/repos/${REPO}/actions/runners" 2>/dev/null) || { echo "Failed to query GH API"; exit 4; }
+else
+  echo "Listing runners for org $ORG..."
+  runners_json=$(gh api -X GET "/orgs/${ORG}/actions/runners" 2>/dev/null) || { echo "Failed to query GH API"; exit 4; }
+fi
+
+matches=$(echo "$runners_json" | jq -r '.runners[] | select(.labels[]?.name == "self-hosted") | select(.labels[]?.name == "qpu-adjacent") | .name' 2>/dev/null || true)
+
+if [ -n "$matches" ]; then
+  echo "Found self-hosted runners with required labels:"
+  echo "$matches"
+  exit 0
+else
+  echo "No self-hosted runner with both labels 'self-hosted' and 'qpu-adjacent' found."
+  echo "Please register a runner or provide credentials in Vault."
+  exit 1
+fi
+
*** End Patch
*** Begin Patch
*** Add File: scripts/operator_run_all.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Orchestrate: run Vault Terraform (or accept tf_out.json), create k8s secret, start rotator,
+# sync Argo apps to staging and run staging tests (redis failover & provider stress).
+#
+# Usage examples:
+# 1) If operator will run Terraform (requires VAULT_TOKEN admin):
+#    ./scripts/operator_run_all.sh --vault-addr https://vault.example.com --tf-dir terraform/vault --deploy-rotator
+
+# 2) If Vault admin already ran terraform and handed tf_out.json:
+#    ./scripts/operator_run_all.sh --tf-json tf_out.json --vault-addr https://vault.example.com --deploy-rotator
+
+TF_DIR=""
+TF_JSON=""
+VAULT_ADDR=""
+DEPLOY_ROTATOR="false"
+RESULTS_DIR="./staging_results"
+SKIP_ARGO="false"
+
+usage() {
+  cat <<EOF
+Usage: $0 [--tf-dir terraform/vault] [--tf-json tf_out.json] --vault-addr https://vault.example.com [--deploy-rotator] [--results-dir ./staging_results] [--skip-argo]
+
+Either --tf-dir (and VAULT_TOKEN env) OR --tf-json must be provided.
+EOF
+}
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --tf-dir) TF_DIR="$2"; shift 2;;
+    --tf-json) TF_JSON="$2"; shift 2;;
+    --vault-addr) VAULT_ADDR="$2"; shift 2;;
+    --deploy-rotator) DEPLOY_ROTATOR="true"; shift;;
+    --results-dir) RESULTS_DIR="$2"; shift 2;;
+    --skip-argo) SKIP_ARGO="true"; shift;;
+    -h|--help) usage; exit 0;;
+    *) echo "Unknown arg: $1"; usage; exit 2;;
+  esac
+done
+
+mkdir -p "$RESULTS_DIR"
+
+if [ -z "$TF_JSON" ]; then
+  if [ -n "$TF_DIR" ]; then
+    if [ -z "${VAULT_TOKEN:-}" ]; then
+      echo "VAULT_TOKEN must be set to run Terraform in $TF_DIR" >&2
+      exit 2
+    fi
+    echo "Running Terraform to provision AppRole & policy..."
+    ./scripts/run_vault_terraform_and_create_secret.sh --tf-dir "$TF_DIR" --vault-addr "$VAULT_ADDR" --out tf_out.json --deploy-rotator
+    TF_JSON="tf_out.json"
+  else
+    echo "Either --tf-json or --tf-dir must be provided" >&2
+    usage
+    exit 2
+  fi
+fi
+
+if [ -f "$TF_JSON" ]; then
+  echo "Bootstrapping k8s secret from Terraform outputs ($TF_JSON)..."
+  ./operator/bootstrap_from_tf_outputs.sh --tf-json "$TF_JSON" --vault-addr "$VAULT_ADDR" --deploy-rotator
+else
+  echo "TF outputs file not found: $TF_JSON" >&2
+  exit 3
+fi
+
+if [ "$SKIP_ARGO" = "false" ]; then
+  echo "Syncing Argo apps and running staging tests..."
+  ./scripts/sync_argo_and_run_staging_tests.sh --results-dir "$RESULTS_DIR"
+else
+  echo "Skipping Argo sync/tests as requested (--skip-argo)"
+fi
+
+echo "All orchestration steps completed. Results/outputs are in $RESULTS_DIR"
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/staging-full-deploy.yml
+name: Staging Full Deploy & Tests (self-hosted)
+on:
+  workflow_dispatch:
+
+jobs:
+  staging-full:
+    runs-on: [self-hosted, qpu-adjacent]
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Ensure prerequisites (kubectl, python)
+        run: |
+          if ! command -v kubectl >/dev/null 2>&1; then
+            curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
+            chmod +x kubectl
+            sudo mv kubectl /usr/local/bin/
+          fi
+          python3 -m pip install --upgrade pip || true
+          pip install requests || true
+
+      - name: Run full operator orchestration
+        env:
+          VAULT_ADDR: ${{ secrets.VAULT_ADDR }}
+          # Either provide VAULT_TOKEN (to run Terraform) or ensure tf_out.json is available in a secure artifact
+          VAULT_TOKEN: ${{ secrets.VAULT_TOKEN }}
+        run: |
+          chmod +x scripts/operator_run_all.sh
+          ./scripts/operator_run_all.sh --tf-dir terraform/vault --vault-addr "${VAULT_ADDR}" --deploy-rotator --results-dir provider_staging_results
+
+      - name: Upload results
+        uses: actions/upload-artifact@v4
+        with:
+          name: staging-full-results
+          path: provider_staging_results/**
+
*** End Patch
*** Begin Patch
*** Add File: docs/quick_steps_staging.md
+Quick steps to validate staging (short)
+=====================================
+
+This short doc lists the minimal steps to:
+- ensure provider credentials or a secure runner are available,
+- provision Vault AppRole (or use tf_out.json),
+- sync Argo apps to staging and run the tests.
+
+1) Provide provider sandbox credentials (preferred)
+ - Vault admin: write provider creds under secret/data/quantum/providers/<provider>
+   Example for IBM:
+     { "ibm_token": "xxxxx", "url": "https://api.quantum.ibm.com" }
+ - Or encrypt credentials and give to operator using:
+     ./credentials/encrypt_credentials.sh --in provider_ibm.json --pubkey operator_pub.pem --out-dir ./secure_creds
+
+2) Or register secure self-hosted runner (alternative)
+ - Register a GitHub self-hosted runner with labels: self-hosted, qpu-adjacent
+ - Use scripts/setup_self_hosted_runner.sh to install & configure the runner
+ - Verify with scripts/check_self_hosted_runner.sh
+
+3) Vault AppRole & secrets
+ - Vault admin runs terraform/vault/ (or operator runs scripts/run_vault_terraform_and_create_secret.sh)
+ - Admin hands tf_out.json to operator (out-of-band) if operator will not run terraform
+ - Operator runs:
+     ./operator/bootstrap_from_tf_outputs.sh --tf-json tf_out.json --vault-addr https://vault.example.com --deploy-rotator
+
+4) Sync Argo apps & run tests (operator)
+ - Run:
+     ./scripts/sync_argo_and_run_staging_tests.sh --results-dir ./provider_staging_results --wait 300
+ - Or trigger the GitHub workflow "Staging Full Deploy & Tests" (runs on self-hosted runner)
+
+5) Collect results and remediate
+ - Results are under provider_staging_results (logs, summaries, remediation hints)
+ - Use automation/argocd_sync_collect_and_remediate.sh to produce a remediation report
+
+Security notes
+ - Use provider sandboxes / limited accounts for testing.
+ - Never commit credentials to source control. Use Vault or the encryptor tool.
+ - Rotate tokens/keys after tests.
+
*** End Patch
*** End Patch
