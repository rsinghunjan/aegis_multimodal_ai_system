 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
 url=https://github.com/rsinghunjan/aegis_multimodal_ai_system/blob/main/argo/workflows/train_and_package.yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: aegis-train-package-
  namespace: aegis
spec:
  entrypoint: train-package
  templates:
    - name: train-package
      dag:
        tasks:
          - name: submit-pytorchjob
            template: submit-pytorchjob
          - name: wait-for-completion
            template: wait-for-completion
            dependencies: [submit-pytorchjob]
          - name: package-and-sign
            template: package-and-sign
            dependencies: [wait-for-completion]

    - name: submit-pytorchjob
      script:
        image: bitnami/kubectl:latest
        command: [sh]
        source: |
          set -euo pipefail
          cat <<'PYT' > /tmp/pytorchjob.yaml
          apiVersion: kubeflow.org/v1
          kind: PyTorchJob
          metadata:
            name: aegis-pytorch-train-{{workflow.name}}
            namespace: aegis
          spec:
            cleanPodPolicy: None
            pytorchReplicaSpecs:
              Master:
                replicas: 1
                restartPolicy: OnFailure
                template:
                  spec:
                    containers:
                      - name: pytorch
                        image: ghcr.io/rsinghunjan/aegis-train:latest
                        command: ["python","/workspace/training/pytorch_lightning_distributed.py","--out-dir","/workspace/model_registry/demo-models/cifar_demo/0.1","--max-epochs","1"]
                        resources:
                          limits:
                            nvidia.com/gpu: 1
                        env:
                          - name: MLFLOW_TRACKING_URI
                            value: "{{workflow.parameters.mlflow_uri}}"
              Worker:
                replicas: 1
                restartPolicy: OnFailure
                template:
                  spec:
                    containers:
                      - name: pytorch
                        image: ghcr.io/rsinghunjan/aegis-train:latest
                        command: ["sleep","3600"]
PYT
          kubectl apply -f /tmp/pytorchjob.yaml
    - name: wait-for-completion
      script:
        image: bitnami/kubectl:latest
        command: [sh]
        source: |
          set -euo pipefail
          # Wait for the pytorchjob to complete
          JOBNAME="aegis-pytorch-train-{{workflow.name}}"
          for i in $(seq 1 120); do
            status=$(kubectl -n aegis get pytorchjob "$JOBNAME" -o jsonpath='{.status.conditions[-1].type}' 2>/dev/null || true)
            echo "Status: $status"
            if [ "$status" = "Succeeded" ]; then
              echo "PyTorchJob Succeeded"
              exit 0
            fi
            if [ "$status" = "Failed" ]; then
              echo "PyTorchJob Failed" >&2
              exit 1
            fi
            sleep 10
          done
          echo "Timeout waiting for PyTorchJob" >&2
          exit 2
    - name: package-and-sign
      script:
        image: ghcr.io/rsinghunjan/aegis-tools:latest
        command: [sh]
        source: |
          set -euo pipefail
          # Assumes job produced model under /workspace/model_registry/demo-models/cifar_demo/0.1
          OUTDIR="/workspace/model_registry/demo-models/cifar_demo/0.1"
          ARTIFACT="/workspace/artifacts/cifar-demo-0.1.tar.gz"
          mkdir -p /workspace/artifacts
          echo "Packaging artifact..."
          python3 /workspace/scripts/make_deterministic_archive.py "$OUTDIR" "$ARTIFACT"
          echo "Computing sha256..."
          sha256sum "$ARTIFACT" | awk '{print $1}' > "${ARTIFACT}.sha256"
          # Use Vault transit to sign the digest (requires VAULT_ADDR + VAULT_TOKEN env via cluster auth)
          if [ -n "${VAULT_ADDR:-}" ] && [ -n "${VAULT_TOKEN:-}" ]; then
            DIGEST_B64=$(openssl dgst -sha256 -binary "$ARTIFACT" | base64 -w 0)
            SIGN_JSON=$(curl -sS --header "X-Vault-Token: $VAULT_TOKEN" --request POST --data "{\"input\":\"${DIGEST_B64}\"}" "${VAULT_ADDR%/}/v1/transit/sign/aegis-cosign")
            echo "$SIGN_JSON" > /workspace/artifacts/cosign_vault_sign.json
            # The actual signature extraction depends on transit config; store as .sig for consistency
            echo "$SIGN_JSON" > "${ARTIFACT}.sig"
            echo "Signed via Vault transit and stored ${ARTIFACT}.sig"
          else
            echo "VAULT_* not set; skipping Vault signing (development mode)"
          fi
          # Upload artifacts to S3 (cluster has role)
          if [ -n "${OBJECT_STORE_BUCKET:-}" ]; then
            aws s3 cp "$ARTIFACT" "s3://${OBJECT_STORE_BUCKET}/model-archives/demo/{{workflow.name}}/$(basename $ARTIFACT)"
            if [ -f "${ARTIFACT}.sig" ]; then
              aws s3 cp "${ARTIFACT}.sig" "s3://${OBJECT_STORE_BUCKET}/model-archives/demo/{{workflow.name}}/$(basename ${ARTIFACT}.sig)"
            fi
            echo "Uploaded artifacts to s3://${OBJECT_STORE_BUCKET}/model-archives/demo/{{workflow.name}}/"
          else
            echo "OBJECT_STORE_BUCKET not set; leaving artifact in workspace"
          fi
argo/workflows/train_and_package.yamlar
