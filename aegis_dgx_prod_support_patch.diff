diff --git a/scripts/dgx/full_prod_validation_and_archive.sh b/scripts/dgx/full_prod_validation_and_archive.sh
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/scripts/dgx/full_prod_validation_and_archive.sh
@@ -0,0 +1,330 @@
+#!/usr/bin/env bash
+#
+# Full production validation and archival for DGX support
+#
+# This orchestrator performs the end-to-end checks required to declare an image and DGX
+# environment "production-ready" for Aegis:
+#  - Verify image provenance (cosign + SBOM). Append digest-pinned entry to IMAGE_MATRIX.md.
+#  - Validate GPU Operator / driver strategy and node drivers (nvidia-smi).
+#  - Run NCCL tuning, apply suggested envs to dgx-nccl-config ConfigMap.
+#  - Run multi-node DeepSpeed scaling test and verify no NCCL/IB fatal errors.
+#  - Verify checkpoint PVC binding and trigger offload; check S3 for offloaded objects (optional).
+#  - Exercise SRE playbooks (cordon/drain/uncordon) in staging (operator confirmation required).
+#  - Archive all artifacts under artifacts/dgx_full_validation and produce provenance.json.
+#
+# Requirements:
+#  - kubectl configured to talk to DGX cluster (KUBECONFIG env or default)
+#  - cosign, syft, trivy, jq, yq, aws CLI (optional) installed on runner
+#  - scripts referenced below exist: scripts/dgx/* (helpers created earlier)
+#
+# Usage:
+#   REGISTRY=ghcr.io/org IMAGE_TAG=aegis-deepspeed:h100-cuda12.1-pytorch2.2 \
+#     KUBECONFIG=./kubeconfigs/kubeconfig-dgx ./scripts/dgx/full_prod_validation_and_archive.sh
+
+set -euo pipefail
+
+REGISTRY="${REGISTRY:-}"
+IMAGE_TAG="${IMAGE_TAG:-}"
+IMAGE_FULL="${REGISTRY}/${IMAGE_TAG}"
+OUT_DIR="${OUT_DIR:-./artifacts/dgx_full_validation}"
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+S3_BUCKET="${S3_BUCKET:-}"
+ALERTMANAGER_URL="${ALERTMANAGER_URL:-}"
+DECISION_LOG_URL="${DECISION_LOG_URL:-}"
+EXPECTED_CUDA="${EXPECTED_CUDA:-12.1}"
+EXPECTED_DRIVER="${EXPECTED_DRIVER:-535}"
+
+if [[ -z "$REGISTRY" || -z "$IMAGE_TAG" ]]; then
+  echo "REGISTRY and IMAGE_TAG must be set (e.g. REGISTRY=ghcr.io/org IMAGE_TAG=aegis-deepspeed:... )"
+  exit 2
+fi
+
+mkdir -p "$OUT_DIR"
+
+echo "=== 1) Ensure image provenance: cosign verify + SBOM generation ==="
+PROV_DIR="$OUT_DIR/provenance"
+mkdir -p "$PROV_DIR"
+
+if command -v cosign >/dev/null 2>&1; then
+  echo "Running cosign verify for $IMAGE_FULL"
+  if cosign verify --verbose "$IMAGE_FULL" > "$PROV_DIR/cosign_verify.txt" 2>&1; then
+    echo "cosign verification succeeded"
+    COSIGN_OK=true
+  else
+    echo "cosign verification FAILED; see $PROV_DIR/cosign_verify.txt"
+    COSIGN_OK=false
+  fi
+else
+  echo "cosign missing; cannot verify signature. Set COSIGN in runner env."
+  COSIGN_OK=false
+fi
+
+if command -v syft >/dev/null 2>&1; then
+  SBOM_FILE="$PROV_DIR/$(echo $IMAGE_TAG | tr '/:' '__')-sbom.json"
+  syft "$IMAGE_FULL" -o json > "$SBOM_FILE" 2> "$PROV_DIR/syft.log" || true
+  echo "SBOM generated to $SBOM_FILE"
+else
+  echo "syft missing; skipping SBOM generation"
+fi
+
+if command -v skopeo >/dev/null 2>&1; then
+  skopeo inspect "docker://${IMAGE_FULL}" > "$PROV_DIR/skopeo_inspect.json" 2>/dev/null || true
+  DIGEST=$(jq -r '.Digest // empty' "$PROV_DIR/skopeo_inspect.json" 2>/dev/null || echo "")
+fi
+if [[ -z "${DIGEST:-}" && command -v docker >/dev/null 2>&1 ]]; then
+  docker pull "$IMAGE_FULL" > "$PROV_DIR/docker_pull.txt" 2>&1 || true
+  DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' "$IMAGE_FULL" 2>/dev/null || echo "")
+fi
+if [[ -z "${DIGEST:-}" ]]; then
+  DIGEST="unknown"
+fi
+echo "$DIGEST" > "$PROV_DIR/image_digest.txt"
+
+# Append IMAGE_MATRIX entry if not present
+if [[ -f "docs/dgx/IMAGE_MATRIX.md" ]]; then
+  if ! grep -qF "$IMAGE_FULL" docs/dgx/IMAGE_MATRIX.md; then
+    timestamp=$(date -u +"%Y-%m-%d")
+    cat >> docs/dgx/IMAGE_MATRIX.md <<EOF
+- image: ${IMAGE_FULL}
+  digest: ${DIGEST}
+  validated_on: ${timestamp}
+  sbom: ${SBOM_FILE:-""}
+  cosign_verified: ${COSIGN_OK}
+EOF
+    echo "Appended image entry to docs/dgx/IMAGE_MATRIX.md"
+  else
+    echo "IMAGE_MATRIX already contains entry for $IMAGE_FULL"
+  fi
+else
+  echo "docs/dgx/IMAGE_MATRIX.md not found; create and commit entry manually"
+fi
+
+echo "=== 2) Validate GPU Operator and drivers on nodes ==="
+DRIVER_OUT="$OUT_DIR/driver_check"
+mkdir -p "$DRIVER_OUT"
+
+# Apply and collect driver-check daemonset logs if manifest exists
+if [[ -f k8s/manifests/dgx/driver-check-daemonset.yaml ]]; then
+  kubectl create ns "$NAMESPACE" --dry-run=client -o yaml | kubectl apply -f - || true
+  kubectl apply -f k8s/manifests/dgx/driver-check-daemonset.yaml -n "$NAMESPACE" || true
+  sleep 5
+  kubectl -n "$NAMESPACE" rollout status daemonset/dgx-driver-check --timeout=60s || true
+  pods=$(kubectl -n "$NAMESPACE" get pods -l app=dgx-driver-check -o jsonpath='{.items[*].metadata.name}')
+  for p in $pods; do
+    kubectl -n "$NAMESPACE" logs "$p" > "$DRIVER_OUT/${p}.log" 2>&1 || true
+  done
+  grep -E "Driver Version|CUDA Version" -n "$DR
î€€
