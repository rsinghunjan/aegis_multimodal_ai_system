{\rtf1\ansi\ansicpg1252\cocoartf2820
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs26 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 # docker-compose.yml\
version: '3.8'\
\
services:\
  # Our FastAPI App\
  aegis-api:\
    build: .\
    container_name: aegis_api\
    ports:\
      - "8000:8000"\
    env_file:\
      - .env.production\
    depends_on:\
      - redis\
      - vllm-server\
    restart: unless-stopped\
    networks:\
      - aegis-network\
\
  # Redis for caching and rate limiting\
  redis:\
    image: redis:7-alpine\
    container_name: aegis_redis\
    restart: unless-stopped\
    networks:\
      - aegis-network\
    volumes:\
      - redis_data:/data\
\
  # High-performance LLM server\
  vllm-server:\
    image: vllm/vllm-openai:latest\
    container_name: aegis_vllm\
    runtime: nvidia # Requires NVIDIA container runtime\
    environment:\
      - MODEL=meta-llama/Meta-Llama-3-8B-Instruct\
    ports:\
      - "8001:8000"\
    volumes:\
      - ./model_cache:/tmp\
    restart: unless-stopped\
    networks:\
      - aegis-network\
\
volumes:\
  redis_data:\
\
networks:\
  aegis-network:\
    driver: bridge\
}