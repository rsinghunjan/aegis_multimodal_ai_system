diff --git a/k8s/manifests/dgx/driver-check-daemonset.yaml b/k8s/manifests/dgx/driver-check-daemonset.yaml
new file mode 100644
index 0000000..1111111
--- /dev/null
+++ b/k8s/manifests/dgx/driver-check-daemonset.yaml
@@ -0,0 +1,86 @@
+apiVersion: apps/v1
+kind: DaemonSet
+metadata:
+  name: dgx-driver-check
+  namespace: aegis-ml
+  labels:
+    app: dgx-driver-check
+spec:
+  selector:
+    matchLabels:
+      app: dgx-driver-check
+  template:
+    metadata:
+      labels:
+        app: dgx-driver-check
+    spec:
+      tolerations:
+        - key: "nvidia.com/gpu"
+          operator: "Exists"
+          effect: "NoSchedule"
+      containers:
+        - name: driver-check
+          image: nvidia/cuda:12.1.1-runtime-ubuntu22.04
+          command:
+            - /bin/sh
+            - -c
+            - |
+              set -euo pipefail
+              if command -v nvidia-smi >/dev/null 2>&1; then
+                echo "=== nvidia-smi output ==="
+                nvidia-smi -q
+              else
+                echo "nvidia-smi not present in image; trying nvidia-container-cli (if available)"
+                which nvidia-container-cli || true
+              fi
+              # Keep the pod alive for a short time so logs can be collected
+              sleep 10
+          resources:
+            requests:
+              cpu: "100m"
+              memory: "128Mi"
+      hostNetwork: false
+      hostPID: false
+      restartPolicy: Always
+
+# Notes:
+# - This DaemonSet schedules a simple pod on each node (including DGX nodes labeled as such).
+# - The pod prints nvidia-smi output to its logs; the validation script collects logs and extracts driver/CUDA info.
+
diff --git a/scripts/dgx/run_driver_compat_check.sh b/scripts/dgx/run_driver_compat_check.sh
new file mode 100644
index 0000000..2222222
--- /dev/null
+++ b/scripts/dgx/run_driver_compat_check.sh
@@ -0,0 +1,220 @@
+#!/usr/bin/env bash
+#
+# Run the driver/ABI compatibility check by deploying the dgx-driver-check DaemonSet,
+# collecting logs from its pods, and comparing observed driver/CUDA versions to expected values.
+#
+# Usage:
+#   ./scripts/dgx/run_driver_compat_check.sh --expected-driver-version "535.86.05" --expected-cuda "12.1"
+
+set -euo pipefail
+
+EXPECTED_DRIVER=""
+EXPECTED_CUDA=""
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+ARTIFACT_DIR="${ARTIFACT_DIR:-./artifacts/dgx_driver_check}"
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --expected-driver-version) EXPECTED_DRIVER="$2"; shift 2;;
+    --expected-cuda) EXPECTED_CUDA="$2"; shift 2;;
+    --namespace) NAMESPACE="$2"; shift 2;;
+    --out) ARTIFACT_DIR="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 2;;
+  esac
+done
+
+mkdir -p "$ARTIFACT_DIR"
+
+echo "Applying driver-check DaemonSet into namespace $NAMESPACE"
+kubectl create ns "$NAMESPACE" --dry-run=client -o yaml | kubectl apply -f - || true
+kubectl apply -f k8s/manifests/dgx/driver-check-daemonset.yaml -n "$NAMESPACE"
+
+echo "Waiting for daemonset pods to be scheduled (20s)"
+sleep 5
+kubectl -n "$NAMESPACE" rollout status daemonset/dgx-driver-check --timeout=60s || true
+
+echo "Collecting logs from driver-check pods"
+pods=$(kubectl -n "$NAMESPACE" get pods -l app=dgx-driver-check -o jsonpath='{.items[*].metadata.name}')
+if [[ -z "$pods" ]]; then
+  echo "No pods found for dgx-driver-check; aborting"
+  exit 3
+fi
+
+results_file="$ARTIFACT_DIR/driver_check_results.txt"
+> "$results_file"
+
+for p in $pods; do
+  echo "==== Pod: $p ====" >> "$results_file"
+  kubectl -n "$NAMESPACE" logs "$p" >> "$results_file" 2>&1 || true
+done
+
+echo "Parsed results written to $results_file"
+
+echo "Extracting driver and CUDA versions from logs"
+grep -E "Driver Version|CUDA Version" -n "$results_file" || true
+
+if [[ -n "$EXPECTED_DRIVER" ]]; then
+  echo "Verifying expected driver version: $EXPECTED_DRIVER"
+  if grep -q "$EXPECTED_DRIVER" "$results_file"; then
+    echo "Driver version matches expected: $EXPECTED_DRIVER" | tee -a "$results_file"
+  else
+    echo "WARNING: Expected driver version $EXPECTED_DRIVER not found in logs" | tee -a "$results_file"
+  fi
+fi
+
+if [[ -n "$EXPECTED_CUDA" ]]; then
+  echo "Verifying expected CUDA version: $EXPECTED_CUDA"
+  if grep -q "$EXPECTED_CUDA" "$results_file"; then
+    echo "CUDA version matches expected: $EXPECTED_CUDA" | tee -a "$results_file"
+  else
+    echo "WARNING: Expected CUDA version $EXPECTED_CUDA not found in logs" | tee -a "$results_file"
+  fi
+fi
+
+echo "Driver compatibility check complete. Inspect $results_file for details."
+echo "Clean up: kubectl -n $NAMESPACE delete daemonset dgx-driver-check || true"
+exit 0
+
diff --git a/scripts/dgx/check_checkpoint_offload.sh b/scripts/dgx/check_checkpoint_offload.sh
new file mode 100644
index 0000000..3333333
--- /dev/null
+++ b/scripts/dgx/check_checkpoint_offload.sh
@@ -0,0 +1,200 @@
+#!/usr/bin/env bash
+#
+# Check that the checkpoint PVC is bound and that the offloader CronJob has recent successful runs.
+# Also optionally check that S3 objects exist (requires AWS CLI configured).
+#
+# Usage:
+#   ./scripts/dgx/check_checkpoint_offload.sh --namespace aegis-ml --s3-bucket my-bucket
+
+set -euo pipefail
+
+NAMESPACE="${NAMESPACE:-aegis-ml}"
+PVC_NAME="${PVC_NAME:-dgx-checkpoints-pvc}"
+CRONJOB_NAME="${CRONJOB_NAME:-dgx-checkpoint-offloader}"
+S3_BUCKET=""
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --namespace) NAMESPACE="$2"; shift 2;;
+    --pvc) PVC_NAME="$2"; shift 2;;
+    --cronjob) CRONJOB_NAME="$2"; shift 2;;
+    --s3-bucket) S3_BUCKET="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 2;;
+  esac
+done
+
+echo "Checking PVC $PVC_NAME in namespace $NAMESPACE"
+kubectl -n "$NAMESPACE" get pvc "$PVC_NAME" -o yaml || { echo "PVC not found or not bound"; exit 2; }
+
+echo "Checking CronJob $CRONJOB_NAME status"
+kubectl -n "$NAMESPACE" get cronjob "$CRONJOB_NAME" -o yaml || { echo "CronJob not found"; exit 3; }
+
+echo "Recent offloader job pods:"
+kubectl -n "$NAMESPACE" get jobs --selector=job-name -o wide || true
+kubectl -n "$NAMESPACE" get pods -l job-name -o wide || true
+
+if [[ -n "$S3_BUCKET" ]]; then
+  if command -v aws >/dev/null 2>&1; then
+    echo "Checking for objects in s3://$S3_BUCKET/dgx-checkpoints/"
+    aws s3 ls "s3://$S3_BUCKET/dgx-checkpoints/" || echo "No objects found or AWS creds not configured"
+  else
+    echo "AWS CLI not present; cannot check S3 contents"
+  fi
+else
+  echo "S3 bucket not provided; skipped check for S3 objects"
+fi
+
+echo "Checkpoint and offloader checks completed."
+exit 0
+
diff --git a/scripts/dgx/send_test_alert.sh b/scripts/dgx/send_test_alert.sh
new file mode 100644
index 0000000..4444444
--- /dev/null
+++ b/scripts/dgx/send_test_alert.sh
@@ -0,0 +1,160 @@
+#!/usr/bin/env bash
+#
+# Send a test alert to Alertmanager to verify routing to on-call receivers.
+#
+# Usage:
+#   ALERTMANAGER_URL=http://alertmanager.example.com:9093 ./scripts/dgx/send_test_alert.sh --summary "DGX test" --instance dgx-test-1
+
+set -euo pipefail
+
+AM_URL="${ALERTMANAGER_URL:-}"
+SUMMARY="DGX test alert"
+INSTANCE="dgx-test"
+SEVERITY="${SEVERITY:-warning}"
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --summary) SUMMARY="$2"; shift 2;;
+    --instance) INSTANCE="$2"; shift 2;;
+    --severity) SEVERITY="$2"; shift 2;;
+    --url) AM_URL="$2"; shift 2;;
+    *) echo "Unknown arg $1"; exit 2;;
+  esac
+done
+
+if [[ -z "$AM_URL" ]]; then
+  echo "Set ALERTMANAGER_URL env var or pass --url"; exit 2
+fi
+
+payload="[{
+  \"labels\": {\"alertname\": \"DGX_Test_Alert\", \"severity\": \"${SEVERITY}\", \"instance\": \"${INSTANCE}\"},
+  \"annotations\": {\"summary\": \"${SUMMARY}\", \"description\": \"Test alert generated to verify DGX routing\"},
+  \"startsAt\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"
+}]"
+
+echo "Posting test alert to $AM_URL/api/v1/alerts"
+curl -s -XPOST -H "Content-Type: application/json" -d "$payload" "$AM_URL/api/v1/alerts" || { echo "Failed to post alert"; exit 3; }
+echo "Posted test alert. Verify on-call channels (PagerDuty/Slack) received notification."
+exit 0
+
diff --git a/.github/workflows/promotion_gate.yml b/.github/workflows/promotion_gate.yml
new file mode 100644
index 0000000..5555555
--- /dev/null
+++ b/.github/workflows/promotion_gate.yml
@@ -0,0 +1,220 @@
+name: DGX Promotion Gate
+
+on:
+  workflow_dispatch:
+    inputs:
+      image:
+        description: 'Fully qualified image to promote (registry/image:tag or digest)'
+        required: true
+
+jobs:
+  promotion-checks:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Set up tools
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y jq curl
+          curl -sSfL https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64 -o /usr/local/bin/cosign || true
+          chmod +x /usr/local/bin/cosign || true
+
+      - name: Verify inputs
+        run: |
+          if [ -z "${{ github.event.inputs.image }}" ]; then echo "image input required"; exit 1; fi
+
+      - name: Run promotion policy check
+        env:
+          IMAGE: ${{ github.event.inputs.image }}
+          IMAGE_MATRIX_FILE: docs/dgx/IMAGE_MATRIX.md
+          ARTIFACT_PATH: artifacts/dgx_prod_validate
+        run: |
+          echo "Checking cosign signature for $IMAGE"
+          if ! command -v cosign >/dev/null 2>&1; then echo "cosign missing"; exit 2; fi
+          if ! cosign verify "$IMAGE" > /tmp/cosign_verify.txt 2>&1; then
+            echo "Cosign verification failed; aborting promotion"; cat /tmp/cosign_verify.txt; exit 3
+          fi
+          echo "Cosign verification passed"
+          echo "Checking IMAGE_MATRIX for entry"
+          if ! grep -q "$IMAGE" "$IMAGE_MATRIX_FILE"; then
+            echo "Image not recorded in $IMAGE_MATRIX_FILE; aborting"; exit 4
+          fi
+          echo "IMAGE_MATRIX contains entry for $IMAGE"
+          echo "Checking validation artifacts exist"
+          if [ ! -d "$ARTIFACT_PATH" ] || [ -z "$(ls -A $ARTIFACT_PATH 2>/dev/null)" ]; then
+            echo "Validation artifacts not found at $ARTIFACT_PATH; aborting"; exit 5
+          fi
+          echo "Artifacts present. Promotion gating checks passed."
+
+      - name: Done
+        run: echo "Promotion gate succeeded for image ${{ github.event.inputs.image }}"
+
diff --git a/.github/workflows/dgx_nightly_validation_enforced.yml b/.github/workflows/dgx_nightly_validation_enforced.yml
new file mode 100644
index 0000000..6666666
--- /dev/null
+++ b/.github/workflows/dgx_nightly_validation_enforced.yml
@@ -0,0 +1,260 @@
+name: DGX Nightly Validation (enforced)
+
+on:
+  schedule:
+    - cron: '0 3 * * *'
+  workflow_dispatch:
+    inputs:
+      image:
+        description: "Image to validate (tag or digest)"
+        required: true
+        default: "aegis-deepspeed:h100-cuda12.1-pytorch2.2"
+
+jobs:
+  dgx-validation:
+    runs-on: self-hosted
+    if: runner.labels contains 'dgx'
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Restore KUBECONFIG
+        env:
+          KUBECONFIG_DGX: ${{ secrets.KUBECONFIG_DGX }}
+        run: |
+          if [ -z "$KUBECONFIG_DGX" ]; then echo "KUBECONFIG_DGX missing"; exit 1; fi
+          echo "$KUBECONFIG_DGX" > "$HOME/.kube/config_dgx"
+          export KUBECONFIG="$HOME/.kube/config_dgx"
+          kubectl version --short
+
+      - name: Ensure image is registered in IMAGE_MATRIX
+        env:
+          IMAGE: ${{ github.event.inputs.image }}
+        run: |
+          if ! grep -q "$IMAGE" docs/dgx/IMAGE_MATRIX.md; then
+            echo "Image $IMAGE not recorded in docs/dgx/IMAGE_MATRIX.md; fail validation"; exit 2
+          fi
+
+      - name: Run driver compatibility check
+        run: |
+          chmod +x scripts/dgx/run_driver_compat_check.sh
+          ./scripts/dgx/run_driver_compat_check.sh --expected-cuda "12.1" --expected-driver-version "535" --out ./artifacts/driver_check || true
+
+      - name: Run NCCL tuning & apply
+        run: |
+          chmod +x scripts/dgx/run_nccl_tune_apply_and_update_job.sh
+          ./scripts/dgx/run_nccl_tune_apply_and_update_job.sh --out ./artifacts/nccl || true
+
+      - name: Run production validation job
+        env:
+          REGISTRY: ${{ secrets.DGX_IMAGE_REGISTRY }}
+          IMAGE_TAG: ${{ github.event.inputs.image }}
+          DECISION_LOG_URL: ${{ secrets.DECISION_LOG_URL }}
+        run: |
+          chmod +x scripts/dgx/prod_validate_and_run.sh
+          ./scripts/dgx/prod_validate_and_run.sh || { echo "Validation job failed; collecting artifacts"; exit 3; }
+
+      - name: Run chaos matrix (DGX profile)
+        run: |
+          if [ -x tools/chaos_matrix_runner.sh ]; then
+            ./tools/chaos_matrix_runner.sh --profile dgx --out ./artifacts/chaos || true
+          else
+            echo "No chaos_matrix_runner.sh; skipping"
+          fi
+
+      - name: Checkpoint offload sanity
+        run: |
+          chmod +x scripts/dgx/check_checkpoint_offload.sh
+          ./scripts/dgx/check_checkpoint_offload.sh --namespace aegis-ml || true
+
+      - name: Test Alert routing
+        env:
+          ALERTMANAGER_URL: ${{ secrets.ALERTMANAGER_URL }}
+        run: |
+          chmod +x scripts/dgx/send_test_alert.sh
+          ./scripts/dgx/send_test_alert.sh --url "$ALERTMANAGER_URL" --summary "DGX nightly validation test" --instance "nightly-dgx-$(date +%s)" || true
+
+      - name: Upload artifacts
+        if: always()
+        uses: actions/upload-artifact@v4
+        with:
+          name: dgx-nightly-artifacts
+          path: artifacts || .
+
+      - name: Fail on validation errors (enforce)
+        run: |
+          # Simple enforcement heuristic: require prod_validate created provenance.json and no critical logs.
+          if [ ! -f ./artifacts/dgx_prod_validate/provenance.json ]; then
+            echo "provenance.json missing; failing validation"; exit 4
+          fi
+          echo "provenance.json present. Nightly validation completed successfully."
+
diff --git a/scripts/dgx/verify_multi_node_scaling_results.sh b/scripts/dgx/verify_multi_node_scaling_results.sh
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/scripts/dgx/verify_multi_node_scaling_results.sh
@@ -0,0 +1,220 @@
+#!/usr/bin/env bash
+#
+# Basic verification script to scan DeepSpeed/multi-node job logs for NCCL errors and expected scaling outputs.
+#
+# Usage:
+#   ./scripts/dgx/verify_multi_node_scaling_results.sh --artifact-dir ./artifacts --pattern "all_reduce_perf"
+
+set -euo pipefail
+
+ARTIFACT_DIR="${ARTIFACT_DIR:-./artifacts}"
+PATTERN="${PATTERN:-NCCL}"
+EXIT_ON_ERROR=false
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --artifact-dir) ARTIFACT_DIR="$2"; shift 2;;
+    --pattern) PATTERN="$2"; shift 2;;
+    --exit-on-error) EXIT_ON_ERROR=true; shift ;;
+    *) echo "Unknown arg $1"; exit 2;;
+  esac
+done
+
+echo "Scanning artifacts under $ARTIFACT_DIR for NCCL errors or failures"
+grep -R --line-number -E "NCCL|AllReduce|Error|failed|RuntimeError" "$ARTIFACT_DIR" || true
+
+if grep -R -q -E "NCCL fatal|NCCL ERROR|NCCL WARN|MPI_ABORT" "$ARTIFACT_DIR"; then
+  echo "Found NCCL-related errors in artifacts"
+  $EXIT_ON_ERROR && exit 3 || true
+else
+  echo "No obvious NCCL fatal errors found in artifacts"
+fi
+
+echo "Try checking GPU utilization logs (nvidia-smi) and DCGM metrics for throughput."
+exit 0
+
