*** Begin Patch
*** Add File:terraform/mongo_atlas/main.tf
+terraform {
+  required_providers {
+    mongodbatlas = {
+      source  = "mongodb/mongodbatlas"
+      version = "~> 1.4"
+    }
+  }
+}
+
+provider "mongodbatlas" {
+  public_key  = var.atlas_public_key
+  private_key = var.atlas_private_key
+  org_id      = var.atlas_org_id
+}
+
+resource "mongodbatlas_project" "aegis" {
+  name = var.project_name
+}
+
+resource "mongodbatlas_cluster" "aegis_cluster" {
+  project_id   = mongodbatlas_project.aegis.id
+  name         = var.cluster_name
+  provider_name = "AWS"
+  provider_region_name = var.aws_region
+  provider_instance_size_name = var.instance_size
+  provider_backup_enabled = true
+  replication_specs {
+    num_shards = 1
+    regions_config {
+      (var.aws_region) = {
+        electable_nodes = 3
+        priority = 7
+      }
+    }
+  }
+}
+
+resource "mongodbatlas_database_user" "aegis_user" {
+  username   = var.db_user
+  password   = var.db_password
+  project_id = mongodbatlas_project.aegis.id
+  roles {
+    role_name = "readWrite"
+    database_name = "aegis"
+  }
+  labels = {
+    "created-by" = "aegis-terraform"
+  }
+}
+
+output "mongo_connection_string" {
+  value     = "mongodb+srv://${mongodbatlas_database_user.aegis_user.username}:${mongodbatlas_database_user.aegis_user.password}@${mongodbatlas_cluster.aegis_cluster.name}.mongodb.net/aegis?retryWrites=true&w=majority"
+  sensitive = true
+}
+
*** End Patch
*** Begin Patch
*** Add File:terraform/mongo_atlas/variables.tf
+variable "atlas_public_key" { type = string }
+variable "atlas_private_key" { type = string, sensitive = true }
+variable "atlas_org_id" { type = string }
+variable "project_name" { type = string, default = "aegis-mongo-project" }
+variable "cluster_name" { type = string, default = "aegis-cluster" }
+variable "db_user" { type = string, default = "aegis_user" }
+variable "db_password" { type = string, default = "REPLACE_WITH_STRONG_PASSWORD", sensitive = true }
+variable "aws_region" { type = string, default = "us-west-2" }
+variable "instance_size" { type = string, default = "M10" }
+
*** End Patch
*** Begin Patch
*** Add File:terraform/couchbase_capella/README.md
+# Couchbase Capella (managed) provisioning notes
+
+This folder contains a placeholder for provisioning Couchbase Capella via API/terraform.
+
+Notes:
+- Couchbase Capella has an API and may be provisioned via provider plugins (check vendor docs). This patch provides instructions and a placeholder where you can plug-in Capella provisioning (tenant, cluster, org) and capture credentials/connection strings as outputs.
+- If you prefer self-managed Couchbase Autonomous Operator, use the manifests in couchbase/operator and couchbase/cluster.
+
+Operator: create API credentials in Capella, then add a Terraform module or script to call the Capella API to create a cluster and buckets. Capture the cluster connection string and admin credentials and store them in Kubernetes Secrets.
+
*** End Patch
*** Begin Patch
*** Add File:couchbase/operator/INSTALL.md
+# Couchbase Autonomous Operator - Install notes
+
+This patch includes the CouchbaseCluster manifest (couchbase/cluster/couchbasecluster.yaml) and a Secret template. Use the official operator install docs:
+https://docs.couchbase.com/operator/current/installation.html
+
+Quick install:
+- kubectl create ns couchbase
+- Install CRDs and Operator using vendor docs or Helm
+- Apply couchbase/secret-couchbase.yaml then couchbase/cluster/couchbasecluster.yaml
+
*** End Patch
*** Begin Patch
*** Add File:couchbase/cluster/couchbasecluster.yaml
+apiVersion: couchbase.com/v2
+kind: CouchbaseCluster
+metadata:
+  name: aegis-cb-cluster
+  namespace: couchbase
+spec:
+  version: "7.2.0"
+  servers:
+    - size: 3
+      services:
+        - data
+        - query
+        - index
+  buckets:
+    - name: artifacts
+      memoryQuota: 256
+      replicas: 1
+      evictionPolicy: fullEviction
+    - name: sessions
+      memoryQuota: 128
+      replicas: 1
+  users:
+    - username: "cb_admin"
+      displayName: "aegis cb admin"
+      password: "REPLACE_COUCHBASE_PASSWORD"
+      roles:
+        - admin
+
*** End Patch
*** Begin Patch
*** Add File:couchbase/secret-couchbase.yaml
+apiVersion: v1
+kind: Secret
+metadata:
+  name: couchbase-credentials
+  namespace: couchbase
+type: Opaque
+stringData:
+  COUCHBASE_USER: "cb_admin"
+  COUCHBASE_PASSWORD: "REPLACE_COUCHBASE_PASSWORD"
+
*** End Patch
*** Begin Patch
*** Add File:k8s/mongodb/secret-mongodb.yaml
+apiVersion: v1
+kind: Secret
+metadata:
+  name: mongodb-connection
+  namespace: aegis
+type: Opaque
+stringData:
+  MONGO_URI: "mongodb+srv://<user>:<pass>@<cluster>.mongodb.net/aegis?retryWrites=true&w=majority"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/ingest/mongo_to_couchbase.py
+#!/usr/bin/env python3
+"""
+MongoDB -> Couchbase change stream consumer (deployment-ready)
+Env:
+  MONGO_URI, MONGO_DB, MONGO_COLLECTION
+  COUCHBASE_HOST, COUCHBASE_USER, COUCHBASE_PASSWORD, COUCHBASE_BUCKET
+"""
+import os, time, json
+from pymongo import MongoClient
+from pymongo.errors import PyMongoError
+from couchbase.cluster import Cluster, ClusterOptions
+from couchbase.auth import PasswordAuthenticator
+from couchbase.exceptions import CouchbaseException
+
+MONGO_URI = os.environ.get("MONGO_URI", "mongodb://localhost:27017")
+MONGO_DB = os.environ.get("MONGO_DB", "aegis")
+MONGO_COLLECTION = os.environ.get("MONGO_COLLECTION", "artifacts")
+
+CB_HOST = os.environ.get("COUCHBASE_HOST", "couchbase.cluster.local")
+CB_USER = os.environ.get("COUCHBASE_USER", "cb_admin")
+CB_PASS = os.environ.get("COUCHBASE_PASSWORD", "REPLACE_COUCHBASE_PASSWORD")
+CB_BUCKET = os.environ.get("COUCHBASE_BUCKET", "artifacts")
+
+def connect_mongo():
+    client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
+    client.admin.command('ping')
+    return client
+
+def connect_couchbase():
+    cluster = Cluster(f"couchbase://{CB_HOST}", ClusterOptions(PasswordAuthenticator(CB_USER, CB_PASS)))
+    bucket = cluster.bucket(CB_BUCKET)
+    coll = bucket.default_collection()
+    return coll
+
+def process_change(coll_cb, change):
+    try:
+        doc = change.get("fullDocument")
+        if not doc:
+            return
+        docid = str(doc.get("_id"))
+        payload = json.loads(json.dumps(doc, default=str))
+        coll_cb.upsert(docid, payload)
+        print("Upserted to Couchbase id=", docid)
+    except CouchbaseException as e:
+        print("Couchbase upsert error:", e)
+
+def main():
+    while True:
+        try:
+            mg = connect_mongo()
+            db = mg[MONGO_DB]
+            coll = db[MONGO_COLLECTION]
+            cb_coll = connect_couchbase()
+            print("Connected to MongoDB and Couchbase; starting change stream.")
+            with coll.watch(full_document='updateLookup') as stream:
+                for change in stream:
+                    process_change(cb_coll, change)
+        except PyMongoError as e:
+            print("Mongo error:", e)
+            time.sleep(5)
+        except Exception as e:
+            print("Unexpected error:", e)
+            time.sleep(5)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:docker/consumer/Dockerfile
+FROM python:3.10-slim
+WORKDIR /app
+COPY scripts/ingest/mongo_to_couchbase.py /app/mongo_to_couchbase.py
+RUN pip install pymongo couchbase
+CMD ["python","/app/mongo_to_couchbase.py"]
+
*** End Patch
*** Begin Patch
*** Add File:k8s/consumer/deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: mongo-to-couchbase
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: mongo-to-couchbase
+  template:
+    metadata:
+      labels:
+        app: mongo-to-couchbase
+    spec:
+      containers:
+        - name: consumer
+          image: registry.example.com/aegis/mongo-to-couchbase:latest
+          env:
+            - name: MONGO_URI
+              valueFrom:
+                secretKeyRef:
+                  name: mongodb-connection
+                  key: MONGO_URI
+            - name: COUCHBASE_HOST
+              value: "couchbase.couchbase.svc.cluster.local"
+            - name: COUCHBASE_USER
+              valueFrom:
+                secretKeyRef:
+                  name: couchbase-credentials
+                  key: COUCHBASE_USER
+            - name: COUCHBASE_PASSWORD
+              valueFrom:
+                secretKeyRef:
+                  name: couchbase-credentials
+                  key: COUCHBASE_PASSWORD
+          resources:
+            requests:
+              cpu: 100m
+              memory: 200Mi
+            limits:
+              cpu: 500m
+              memory: 512Mi
+
*** End Patch
*** Begin Patch
*** Add File:k8s/kafka/README.md
+# Kafka (Strimzi) & Debezium integration notes
+
+This repository includes connector configs used by Kafka Connect (below). For production you can deploy Strimzi operator or a managed Kafka (MSK/Aiven/Confluent). The recommended patterns:
+- Strimzi operator (k8s) + Kafka cluster (if you want self-managed).
+- Debezium MongoDB Connector (Kafka Connect) as source when using Atlas Change Streams (requires Atlas connector or Debezium source).
+- Kafka Connect Couchbase Sink connector to write to Couchbase from Kafka (3rd party connector).
+
+This patch provides connector JSON templates in connectors/ for you to adapt and apply to your Kafka Connect cluster.
+
*** End Patch
*** Begin Patch
*** Add File:connectors/mongodb-source.json
+{
+  "name": "mongo-source-aegis",
+  "config": {
+    "connector.class": "com.mongodb.kafka.connect.MongoSourceConnector",
+    "tasks.max": "1",
+    "connection.uri": "${MONGO_URI}", 
+    "database": "aegis",
+    "collection": "artifacts",
+    "copy.existing": "true",
+    "publish.full.document.only": "true",
+    "topic.prefix": "mongo.aegis."
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:connectors/couchbase-sink.json
+{
+  "name": "couchbase-sink-aegis",
+  "config": {
+    "connector.class": "com.couchbase.connect.kafka.CouchbaseSinkConnector",
+    "tasks.max": "1",
+    "topics": "mongo.aegis.artifacts",
+    "couchbase.seed_nodes": "couchbase.couchbase.svc.cluster.local:8091",
+    "couchbase.bucket": "artifacts",
+    "couchbase.username": "${CB_USER}",
+    "couchbase.password": "${CB_PASS}",
+    "couchbase.kv.timeout": "10s",
+    "couchbase.document.id.strategy": "com.couchbase.connect.kafka.processor.id.ByTopicDocumentIdProcessor"
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:k8s/connect/kafka-connect-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: kafka-connect
+  namespace: aegis
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: kafka-connect
+  template:
+    metadata:
+      labels:
+        app: kafka-connect
+    spec:
+      containers:
+        - name: connect
+          image: debezium/connect:2.2
+          env:
+            - name: BOOTSTRAP_SERVERS
+              value: "kafka:9092"
+            - name: GROUP_ID
+              value: "connect-aegis"
+          ports:
+            - containerPort: 8083
+          readinessProbe:
+            httpGet:
+              path: /connectors
+              port: 8083
+            initialDelaySeconds: 10
+            periodSeconds: 10
+
*** End Patch
*** Begin Patch
*** Add File:docs/INTEGRATION_RUNBOOK.md
+# Aegis: MongoDB (primary) + Couchbase (specialized) + Kafka (optional) Integration Runbook
+
+This runbook explains how to install and wire the three integration patterns so you can choose the approach that fits your scale and operational model.
+
+Deployment options (all included in repo):
+- Managed-first (recommended): MongoDB Atlas (Terraform) + Couchbase Capella (managed) OR Couchbase Operator (self-managed) + optional managed Kafka (MSK).
+- Self-managed: MongoDB Operator (not provided here) + Couchbase Autonomous Operator (k8s) + Strimzi (k8s) + Debezium + Kafka Connect.
+- Hybrid: Managed Atlas + self-managed Couchbase operator + Kafka streaming.
+
+Quickstart (recommended managed path)
+1. MongoDB Atlas (Terraform)
+   - cd terraform/mongo_atlas
+   - export ATLAS creds (atlas_public_key, atlas_private_key, atlas_org_id) via TF variables or environment
+   - terraform init && terraform apply -var="db_password=<strong>" -var="aws_region=us-west-2"
+   - copy output mongo_connection_string and create k8s secret: kubectl create secret generic mongodb-connection --from-literal=MONGO_URI='<conn>' -n aegis
+
+2. Couchbase Capella (managed) - operator / Capella
+   - If using Capella: follow provider / API to provision (place credentials in k8s secret)
+   - If using Autonomous Operator (self-managed): install operator and apply couchbase/secret-couchbase.yaml and couchbase/cluster/couchbasecluster.yaml
+
+3. Deploy consumer
+   - Build & push docker/consumer image to registry
+   - kubectl apply -f k8s/consumer/deployment.yaml (edit image)
+
+4A. Direct consumer flow (small scale)
+   - Consumer watches MongoDB change streams and upserts to Couchbase.
+   - Pros: simple, low-latency for cache population.
+   - Deploy consumer and verify logs.
+
+4B. Kafka-mediated flow (recommended for scale)
+   - Install Kafka (MSK or Strimzi)
+   - Deploy Kafka Connect (k8s/connect/kafka-connect-deployment.yaml)
+   - POST connectors using provided JSON (connectors/mongodb-source.json and connectors/couchbase-sink.json) to Kafka Connect REST API
+   - Pros: decoupled, durable, re-playable, better scaling.
+
+5. Monitoring & Backup
+   - Deploy monitoring exporters: monitoring/mongo_exporter and monitoring/couchbase_exporter
+   - Configure Atlas backups or use scripts/db/backup_mongo_to_s3.sh for on-demand exports (ensure network access)
+   - For Couchbase, follow operator or Capella backup guidance and export to EVIDENCE_BUCKET for long-term retention.
+
+6. Security
+   - Use VPC peering / private endpoints for Atlas
+   - Use TLS everywhere (MongoDB Atlas enforces TLS)
+   - Store connection strings in Kubernetes Secrets & GitHub secrets
+   - Limit access using NetworkPolicy for couchbase and k8s services
+
+7. Testing
+   - CI writes artifact metadata to MongoDB (see .github/workflows/ci_write_metadata.yml)
+   - Verify consumer upserts to Couchbase (query bucket)
+   - Introduce a failure (consumer down), then restart it and confirm catch-up via change streams or via Kafka topic replay
+   - Run DB backup & restore drills and record evidence in EVIDENCE_BUCKET
+
+Notes and caveats
+- Keep MongoDB as source of truth. Do not write authoritative updates directly to Couchbase unless explicitly configured.
+- Monitor change stream lag and consumer health. Use Kafka if you require durability and re-playability.
+- This patch includes templates and examples; operator must provision credentials and tune sizing for production.
+
*** End Patch
*** End Patch
