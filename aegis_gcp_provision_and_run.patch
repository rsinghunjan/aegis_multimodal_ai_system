*** Begin Patch
*** Add File: infra/gcp/terraform_apply.sh
+#!/usr/bin/env bash
+#
+# Bootstrap Terraform for GCP infra and apply it.
+# Usage:
+#   PROJECT=my-proj GCS_BUCKET=my-bucket ./infra/gcp/terraform_apply.sh
+set -euo pipefail
+
+HERE="$(cd "$(dirname "$0")" && pwd)"
+TF_DIR="$HERE"
+
+PROJECT="${PROJECT:-}"
+GCS_BUCKET="${GCS_BUCKET:-}"
+REGION="${REGION:-us-central1}"
+ZONE="${ZONE:-us-central1-b}"
+
+if [ -z "$PROJECT" ] || [ -z "$GCS_BUCKET" ]; then
+  echo "Usage: PROJECT=<project> GCS_BUCKET=<bucket> [$0]" >&2
+  exit 2
+fi
+
+echo "Initializing Terraform in $TF_DIR"
+cd "$TF_DIR"
+terraform init -input=false
+
+ARGS=(
+  -var "project=${PROJECT}"
+  -var "gcs_bucket=${GCS_BUCKET}"
+  -var "region=${REGION}"
+  -var "zone=${ZONE}"
+)
+
+echo "Planning Terraform apply..."
+terraform plan -input=false -out=tfplan "${ARGS[@]}"
+
+echo "Applying Terraform plan..."
+terraform apply -input=false tfplan
+
+echo "Terraform apply complete. Fetching outputs..."
+terraform output -json
+
+echo "You can now run scripts/gcp_wi_bind.sh to map k8s SA -> GCP SA and push images."
+
*** End Patch
*** Begin Patch
*** Add File: scripts/gcp_full_provision_and_run.sh
+#!/usr/bin/env bash
+#
+# End-to-end helper to provision GCP infra (via terraform helper), create Workload Identity binding,
+# build & push trainer image to Artifact Registry, deploy minimal k8s manifests and submit example Argo TPU workflow.
+#
+# Usage:
+#   PROJECT=my-project GCS_BUCKET=my-bucket ./scripts/gcp_full_provision_and_run.sh
+#
+# Requirements:
+#  - gcloud authenticated as a user with permission to create infra OR GCP_SA_KEY env (for CI)
+#  - kubectl configured to talk to the new GKE cluster (the Terraform outputs include cluster name; you must run gcloud container clusters get-credentials)
+set -euo pipefail
+
+REPO_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
+
+PROJECT="${PROJECT:-}"
+GCS_BUCKET="${GCS_BUCKET:-}"
+REGION="${REGION:-us-central1}"
+ZONE="${ZONE:-us-central1-b}"
+ARTIFACT_REPO="${ARTIFACT_REPO:-aegis-repo}"
+IMAGE_TAG="${IMAGE_TAG:-latest}"
+K8S_NAMESPACE="${K8S_NAMESPACE:-aegis}"
+
+if [ -z "$PROJECT" ] || [ -z "$GCS_BUCKET" ]; then
+  echo "Set PROJECT and GCS_BUCKET env vars. Example:"
+  echo "PROJECT=my-proj GCS_BUCKET=my-bucket $0"
+  exit 2
+fi
+
+echo "1) Ensure required APIs and a GCP SA exist (optional step included)"
+if [ ! -x "./scripts/gcp_enable_and_setup.sh" ]; then
+  echo "Missing scripts/gcp_enable_and_setup.sh; ensure it exists." >&2
+else
+  PROJECT="$PROJECT" REGION="$REGION" ZONE="$ZONE" ./scripts/gcp_enable_and_setup.sh
+fi
+
+echo "2) Run Terraform apply to provision infra (GKE, Artifact Registry, GCS bucket, SA)"
+PROJECT="$PROJECT" GCS_BUCKET="$GCS_BUCKET" REGION="$REGION" ZONE="$ZONE" ./infra/gcp/terraform_apply.sh
+
+echo "3) Fetch Terraform outputs and configure kubectl"
+cd infra/gcp
+CLUSTER_NAME=$(terraform output -raw gke_cluster_name 2>/dev/null || true)
+if [ -n "$CLUSTER_NAME" ]; then
+  echo "Getting GKE credentials for cluster: $CLUSTER_NAME"
+  gcloud container clusters get-credentials "$CLUSTER_NAME" --zone "$ZONE" --project "$PROJECT"
+else
+  echo "Cluster name not found in terraform output; ensure terraform_apply completed successfully."
+fi
+cd - >/dev/null
+
+echo "4) Map Workload Identity: create k8s SA and bind to GCP SA"
+TRAINER_SA_EMAIL=$(terraform output -raw trainer_sa_email 2>/dev/null || true)
+if [ -z "$TRAINER_SA_EMAIL" ]; then
+  echo "Trainer SA email not found in terraform output; please supply GCP SA email via GCP_SA_EMAIL env var or check terraform output." >&2
+  TRAINER_SA_EMAIL="${GCP_SA_EMAIL:-}"
+fi
+if [ -z "$TRAINER_SA_EMAIL" ]; then
+  echo "GCP SA email required for Workload Identity mapping." >&2
+  exit 3
+fi
+
+PROJECT="$PROJECT" NAMESPACE="$K8S_NAMESPACE" K8S_SA="aegis-trainer" GCP_SA_EMAIL="$TRAINER_SA_EMAIL" ./scripts/gcp_wi_bind.sh
+
+echo "5) Build & push trainer image to Artifact Registry"
+# Ensure helper exists
+if [ ! -x "./scripts/push_image_crosscloud.sh" ]; then
+  echo "Missing scripts/push_image_crosscloud.sh; ensure present in repo." >&2
+else
+  CLOUD_PROVIDER="gcp" PROJECT="$PROJECT" REPO="$ARTIFACT_REPO" REGION="$REGION" IMAGE="tpu-trainer:${IMAGE_TAG}" DOCKERFILE="tpu/Dockerfile.tpu_trainer" ./scripts/push_image_crosscloud.sh
+fi
+
+echo "6) Deploy minimal k8s manifests (namespace, service accounts, webhook receiver) to cluster"
+kubectl create namespace "$K8S_NAMESPACE" --dry-run=client -o yaml | kubectl apply -f -
+kubectl apply -f k8s/gcp/workload_identity_sa.yaml -n "$K8S_NAMESPACE" || true
+
+echo "7) Submit example Argo workflow that runs ephemeral TPU VM (adjust parameters as needed)"
+# Use storage wrapper to store artifacts in GCS via storage_uri parameter
+ARGO_IMAGE_PARAM="us-docker.pkg.dev/${PROJECT}/${ARTIFACT_REPO}/tpu-trainer:${IMAGE_TAG}"
+STORAGE_URI="gs://${GCS_BUCKET}/model-archives/"
+argo submit argo/workflows/tpu_ephemeral_vm.yaml -p OBJECT_STORE_BUCKET="${GCS_BUCKET}" -n "$K8S_NAMESPACE" || true
+
+echo "8) Verify artifact uploaded and workflow progress"
+echo "Waiting a short while for workflow to start; check Argo UI or use argo list/logs."
+echo "To inspect artifacts:"
+echo "  gsutil ls ${STORAGE_URI}"
+
+echo "Provision+run completed (or initiated). Inspect Argo workflows and GCS for artifacts."
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/gcp_provision_and_run.yml
+name: GCP Provision & Run Aegis (CI)
+
+on:
+  workflow_dispatch:
+
+jobs:
+  provision-run:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Set up gcloud
+        uses: google-github-actions/setup-gcloud@v1
+        with:
+          service_account_key: ${{ secrets.GCP_SA_KEY }}
+          project_id: ${{ secrets.GCP_PROJECT }}
+      - name: Install Terraform
+        uses: hashicorp/setup-terraform@v2
+        with:
+          terraform_version: 1.5.0
+      - name: Apply Terraform and provision infra
+        env:
+          PROJECT: ${{ secrets.GCP_PROJECT }}
+          GCS_BUCKET: ${{ secrets.GCP_BUCKET }}
+          REGION: ${{ inputs.region || 'us-central1' }}
+          ZONE: ${{ inputs.zone || 'us-central1-b' }}
+        run: |
+          chmod +x infra/gcp/terraform_apply.sh
+          infra/gcp/terraform_apply.sh
+      - name: Configure kubectl
+        env:
+          PROJECT: ${{ secrets.GCP_PROJECT }}
+          ZONE: ${{ inputs.zone || 'us-central1-b' }}
+        run: |
+          CLUSTER=$(terraform -chdir=infra/gcp output -raw gke_cluster_name)
+          gcloud container clusters get-credentials "$CLUSTER" --zone "${ZONE}" --project "${PROJECT}"
+      - name: Run provisioning + deploy script
+        env:
+          PROJECT: ${{ secrets.GCP_PROJECT }}
+          GCS_BUCKET: ${{ secrets.GCP_BUCKET }}
+          REGION: ${{ inputs.region || 'us-central1' }}
+          ZONE: ${{ inputs.zone || 'us-central1-b' }}
+        run: |
+          chmod +x scripts/gcp_full_provision_and_run.sh
+          ./scripts/gcp_full_provision_and_run.sh
+
*** End Patch
*** Begin Patch
*** Add File: scripts/verify_gcp_run.sh
+#!/usr/bin/env bash
+#
+# Verify that the Argo TPU ephemeral workflow produced an artifact in GCS and that the GKE cluster is reachable.
+# Usage:
+#   PROJECT=my-project GCS_BUCKET=my-bucket ./scripts/verify_gcp_run.sh
+set -euo pipefail
+
+PROJECT="${PROJECT:-}"
+GCS_BUCKET="${GCS_BUCKET:-}"
+NAMESPACE="${NAMESPACE:-aegis}"
+
+if [ -z "$PROJECT" ] || [ -z "$GCS_BUCKET" ]; then
+  echo "Set PROJECT and GCS_BUCKET env variables" >&2
+  exit 2
+fi
+
+echo "Checking GKE cluster access (kubectl get nodes)"
+kubectl get nodes -o wide
+
+echo "Listing Argo workflows in namespace ${NAMESPACE}"
+argo list -n "${NAMESPACE}" --sort-by=.status.startedAt || true
+
+echo "Searching for artifacts in gs://${GCS_BUCKET}/model-archives/"
+gsutil ls "gs://${GCS_BUCKET}/model-archives/" || echo "No artifacts found yet (workflows may still be running)."
+
+echo "If artifacts exist, validate packaging/attestation steps uploaded attestation.json and sbom files alongside artifact tar.gz"
+gsutil ls "gs://${GCS_BUCKET}/model-archives/**.attestation.json" || echo "No attestation files found (packaging may not have run)."
+
*** End Patch
*** Begin Patch
*** Add File: docs/GCP_PROVISION_RUN.md
+````markdown
+name=docs/GCP_PROVISION_RUN.md
+
+# Provision & Run Aegis on GCP — step-by-step
+
+This document explains how to run the provisioning and example training workflow on GCP using the scripts and CI added to the repo.
+
+Prerequisites
+- gcloud SDK installed and authenticated with a user that can create resources in the target GCP project (or use CI with GCP_SA_KEY secret).
+- kubectl installed
+- Terraform installed (if running locally)
+- GitHub repo secrets (for CI): GCP_SA_KEY, GCP_PROJECT, GCP_BUCKET
+
+Quick local run (developer machine)
+1. Enable APIs and create initial service account (optional):
+   PROJECT=my-project REGION=us-central1 ZONE=us-central1-b ./scripts/gcp_enable_and_setup.sh
+
+2. Provision infra with Terraform:
+   PROJECT=my-project GCS_BUCKET=my-aegis-bucket REGION=us-central1 ZONE=us-central1-b ./infra/gcp/terraform_apply.sh
+
+3. Configure kubectl:
+   CLUSTER=$(terraform -chdir=infra/gcp output -raw gke_cluster_name)
+   gcloud container clusters get-credentials "$CLUSTER" --zone "us-central1-b" --project "$PROJECT"
+
+4. Bind Workload Identity:
+   PROJECT=my-project NAMESPACE=aegis K8S_SA=aegis-trainer GCP_SA_EMAIL=aegis-trainer@${PROJECT}.iam.gserviceaccount.com ./scripts/gcp_wi_bind.sh
+
+5. Push trainer image to Artifact Registry:
+   PROJECT=my-project REPO=aegis-repo REGION=us-central1 IMAGE=tpu-trainer:latest DOCKERFILE=tpu/Dockerfile.tpu_trainer ./scripts/push_image_crosscloud.sh
+
+6. Submit an Argo workflow (ephemeral TPU VM example):
+   argo submit argo/workflows/tpu_ephemeral_vm.yaml -p OBJECT_STORE_BUCKET=${GCS_BUCKET} -n aegis
+
+7. Verify:
+   ./scripts/verify_gcp_run.sh PROJECT=my-project GCS_BUCKET=${GCS_BUCKET}
+
+CI run via GitHub Action
+- Go to Actions → GCP Provision & Run Aegis → Run workflow (ensure repo secrets set).
+
+Notes & troubleshooting
+- Terraform may create resources that take a few minutes to become ready; wait for cluster to be provisioned before running gcloud container clusters get-credentials.
+- TPU VMs use alpha APIs; ensure your gcloud SDK supports alpha TPU commands or adapt the Argo ephemeral workflow to use a separate controller that provisions TPUs.
+- For production, prefer ephemeral TPU VMs or a dedicated TPU node pool with proper quota and cost controls.
+
+Security notes
+- Use Workload Identity (recommended) instead of mounting JSON keys.
+- Remove local JSON keys when no longer needed:
+  rm ./aegis-trainer-sa-key.json
+
+````

*** End Patch
*** End Patch
