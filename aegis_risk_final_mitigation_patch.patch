*** Begin Patch
*** Add File:ops/hsm/VENDOR_HSM_ROTATION_RUNBOOK.md
+# HSM Vendor Rotation & Validation Runbook (Aegis)
+
+Purpose
+- Provide operators with a tested, repeatable procedure to rotate HSM signing keys, validate the rotation, and produce signed evidence for audits.
+
+Scope
+- Applies to any HSM used for signing artifacts (models, MCPs, manifests). Vendor-specific CLI commands must be added to the rotation script before running in production.
+
+Prerequisites
+- Operator access to HSM vendor CLI on a bastion or container (e.g., yubihsmctl, utimaco-cli, nshield-cli).
+- Vault and Kubernetes credentials with rights to push evidence to EVIDENCE_BUCKET.
+- The rotation wrapper script ops/hsm/vendor_rotation_integration.sh updated with vendor commands.
+- The validation suite ops/hsm/vendor_validation_suite.py available in repo.
+
+Runbook Steps (staging)
+1. Prepare
+   - Notify stakeholders of maintenance window and expected impact.
+   - Ensure the current key is present and usage metrics are healthy (ops/hsm/hsm_healthcheck.py).
+   - Back up HSM configuration as per vendor instructions.
+
+2. Dry-run vendor rotation (no commit)
+   - On bastion/container with vendor CLI installed:
+       bash ops/hsm/vendor_rotation_integration.sh
+   - Confirm script executed and logged to /tmp/hsm_rotation/.
+
+3. Execute rotation (staging)
+   - Replace the placeholder commands in ops/hsm/vendor_rotation_integration.sh with vendor-specific rotation commands.
+   - Run the Kubernetes job:
+       kubectl apply -f ops/hsm/k8s/hsm-rotation-job.yaml -n aegis
+   - Wait for job completion and fetch logs:
+       kubectl logs job/hsm-rotation-run -n aegis
+
+4. Validate rotation
+   - Run validation suite:
+       python3 ops/hsm/vendor_validation_suite.py --runs 20
+   - Confirm sign success rate, latency p50/p95 meet thresholds in ops/hsm_vendor_validation_*.json.
+   - Check /tmp/hsm_health.json for fallback usage.
+
+5. Acceptance criteria (staging)
+   - Sign success rate >= 99% across runs.
+   - Latency p95 < configured threshold (e.g., 2.0s) or baseline agreed with vendor.
+   - No unexplained fallback events; any fallback must be logged and explained.
+   - Validation JSON uploaded to EVIDENCE_BUCKET.
+
+6. Promote to production (if staging passes)
+   - Schedule maintenance window and repeat steps 2–5 in prod environment.
+   - Coordinate with legal/compliance for evidence collection.
+
+7. Post-rotation tasks
+   - Update key references (if key labels changed) in signing configs.
+   - Run smoke sign flows in CI to validate end-to-end signing for MCPs.
+   - Record rotation in audit logs and run ops/hsm/hsm_fallback_audit.py to push record to Rekor if configured.
+
+Notes & vendor integration
+- This runbook intentionally excludes vendor CLI specifics. Operators MUST add and test vendor commands in a secure environment and ensure keys and credentials are not leaked.
+- See ops/hsm/DEPLOY_HSM_VENDOR_INSTRUCTIONS.md for vendor-specific guidance and example commands.
+
*** End Patch
*** Begin Patch
*** Add File:ops/hsm/vendor_rotation_test.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# End-to-end test harness to exercise HSM rotation & validation in a controlled environment.
+# WARNING: vendor rotation commands are placeholders. Replace before using on real HSM.
+#
+OUT_DIR=${OUT_DIR:-/tmp/hsm_rotation_test}
+mkdir -p "$OUT_DIR"
+
+echo "Running HSM rotation smoke test (dry-run) at $(date -u)" > "$OUT_DIR/run.log"
+echo "1) Healthcheck (pre-rotation)" >> "$OUT_DIR/run.log"
+python3 ops/hsm/hsm_healthcheck.py --json >> "$OUT_DIR/run.log" 2>&1 || true
+
+echo "2) Vendor rotation wrapper (dry)" >> "$OUT_DIR/run.log"
+bash -x ops/hsm/vendor_rotation_integration.sh >> "$OUT_DIR/run.log" 2>&1 || true
+
+echo "3) Run validation suite" >> "$OUT_DIR/run.log"
+python3 ops/hsm/vendor_validation_suite.py --runs 10 >> "$OUT_DIR/run.log" 2>&1 || true
+
+echo "4) Healthcheck (post-rotation)" >> "$OUT_DIR/run.log"
+python3 ops/hsm/hsm_healthcheck.py --json >> "$OUT_DIR/run.log" 2>&1 || true
+
+echo "Test run complete. Logs in $OUT_DIR"
+if [ -n "${EVIDENCE_BUCKET:-}" ]; then
+  echo "Uploading logs to evidence bucket $EVIDENCE_BUCKET"
+  aws s3 cp "$OUT_DIR/run.log" "s3://${EVIDENCE_BUCKET}/hsm_rotation_tests/$(basename $OUT_DIR)_run.log" || true
+fi
+
*** End Patch
*** Begin Patch
*** Add File:helm/feast/values-ha-redis-streaming.yaml
+# Feast values tuned for HA + RedisCluster + Streaming guarantees (example)
+global:
+  modelArtifactBucket: "your-prod-bucket"
+image:
+  repository: registry.example.com/aegis/feast
+  tag: v1.0.0
+offlineStore:
+  s3:
+    bucket: "your-prod-bucket"
+    prefix: feast/offline
+onlineStore:
+  type: redis
+  redis:
+    host: redis-cluster-headless.aegis.svc
+    port: 6379
+    use_sentinel: false
+streaming:
+  enabled: true
+  kafka:
+    bootstrap: aegis-kafka-bootstrap:9092
+job:
+  resources:
+    requests:
+      cpu: "1"
+      memory: "2Gi"
+    limits:
+      cpu: "4"
+      memory: "8Gi"
+replicas: 3
+prometheus:
+  enabled: true
+  serviceMonitor:
+    enabled: true
+    interval: "15s"
+hpa:
+  enabled: true
+  minReplicas: 2
+  maxReplicas: 10
+
*** End Patch
*** Begin Patch
*** Add File:redis/rediscluster_pdb_servicemonitor.yaml
+apiVersion: policy/v1
+kind: PodDisruptionBudget
+metadata:
+  name: redis-cluster-pdb
+  namespace: aegis
+spec:
+  minAvailable: 2
+  selector:
+    matchLabels:
+      app.kubernetes.io/name: redis
+
+---
+apiVersion: monitoring.coreos.com/v1
+kind: ServiceMonitor
+metadata:
+  name: redis-cluster-servicemonitor
+  namespace: aegis
+spec:
+  selector:
+    matchLabels:
+      app.kubernetes.io/name: redis
+  endpoints:
+    - port: metrics
+      interval: 15s
+      honorLabels: true
+
*** End Patch
*** Begin Patch
*** Add File:observability/slo/feast_lookup_slo.yaml
+apiVersion: reliability.kubearmor.io/v1alpha1
+kind: ServiceLevelObjective
+metadata:
+  name: feast-online-lookup-p95
+  namespace: aegis
+spec:
+  service: feast-online
+  objective: 0.99
+  window: 30d
+  slo_type: latency
+  target:
+    metric: feast_online_lookup_p95
+    threshold_ms: 50
+
+---
+# Prometheus alert for SLO breach (example)
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: feast-slo-alerts
+  namespace: aegis
+spec:
+  groups:
+    - name: feast-slo
+      rules:
+        - alert: FeastLookupSLOBreached
+          expr: feast_online_lookup_p95 > 0.05
+          for: 5m
+          labels:
+            severity: critical
+          annotations:
+            summary: "Feast lookup P95 SLO breached"
+            description: "P95 for online lookup exceeded target for more than 5 minutes."
+
*** End Patch
*** Begin Patch
*** Add File:argo/feast_slo_validation_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: feast-slo-validation-
+  namespace: aegis
+spec:
+  entrypoint: feast-slo-validate
+  templates:
+    - name: feast-slo-validate
+      steps:
+        - - name: run-bench
+            template: run-redis-bench
+        - - name: evaluate
+            template: evaluate
+
+    - name: run-redis-bench
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install redis && python3 benchmarks/redis_latency_bench.py --host redis-headless.aegis.svc --port 6379 --duration 60 --qps 200 --output /tmp/redis_bench.json && cat /tmp/redis_bench.json
+
+    - name: evaluate
+      script:
+        image: python:3.10-slim
+        command: [python3]
+        source: |
+          import json,sys
+          try:
+              j=json.load(open('/tmp/redis_bench.json'))
+              p95=j.get('p95_ms',None)
+              print("Observed p95",p95)
+              if p95 is None:
+                  print("No p95 found, fail")
+                  sys.exit(2)
+              if float(p95) > 50.0:
+                  print("P95 too high - fail")
+                  sys.exit(3)
+              print("SLO met")
+          except Exception as e:
+              print("Error evaluating bench:",e)
+              sys.exit(4)
+
*** End Patch
*** Begin Patch
*** Add File:federation/secure_agg_integration/README.md
+# Federated Secure Aggregation & DP Audit Integration
+
+Overview
+- This folder contains scaffolding to replace the federation fallback with a vetted multi-party secure-aggregation library (CrypTen) and produce DP accounting report using Opacus.
+
+Files provided
+- crypten_orchestrator.py : launches local multi-party CrypTen worker processes for testing.
+- crypten_worker.py : simple CrypTen worker stub.
+- privacy/accountant_demo.py : demo to compute epsilon for a training run using Opacus.
+- argo/federation_privacy_audit_workflow.yaml : Argo workflow to run secure aggregation demo and produce audit artifacts.
+
+Notes
+- Production multi-party secure aggregation with CrypTen requires a coordinator and proper network/transport setup for parties. The included orchestrator is a local demo; extend to multi-host orchestration using Kubernetes Jobs or a scheduler.
+- DP accounting (Opacus) requires replicating training steps and logging noise/batch parameters to compute epsilon; the demo is a starting point.
+
*** End Patch
*** Begin Patch
*** Add File:federation/secure_agg_integration/privacy/accountant_demo.py
+#!/usr/bin/env python3
+"""
+Demo for DP accountant using Opacus.
+Computes epsilon for a simple training loop configuration and prints the privacy budget.
+"""
+import math
+try:
+    from opacus.accountants.analysis.rdp import compute_rdp, get_privacy_spent
+except Exception:
+    print("Please install opacus to run the privacy accountant demo (pip install opacus)")
+    raise
+
+def compute_epsilon(noise_multiplier, sample_rate, steps, delta=1e-5):
+    orders = [1 + x/10. for x in range(1, 100)]
+    rdp = compute_rdp(q=sample_rate, noise_multiplier=noise_multiplier, steps=steps, orders=orders)
+    eps, opt_order = get_privacy_spent(orders, rdp, target_delta=delta)
+    return eps, opt_order
+
+if __name__ == "__main__":
+    # Example params (tune for your jobs)
+    noise = 1.1
+    batch_size = 256
+    dataset_size = 100000
+    epochs = 3
+    steps = (dataset_size // batch_size) * epochs
+    sample_rate = batch_size / dataset_size
+    eps, order = compute_epsilon(noise, sample_rate, steps)
+    print(f"DP accountant demo -> eps={eps:.3f} at order {order} (noise={noise}, sample_rate={sample_rate:.6f}, steps={steps})")
+
*** End Patch
*** Begin Patch
*** Add File:argo/federation_privacy_audit_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: federation-privacy-audit-
+  namespace: aegis
+spec:
+  entrypoint: privacy-audit
+  templates:
+    - name: privacy-audit
+      steps:
+        - - name: run-crypten-demo
+            template: crypten-demo
+        - - name: dp-accountant
+            template: dp-accountant
+
+    - name: crypten-demo
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install crypten torch && python3 federation/secure_agg_integration/crypten_orchestrator.py || true
+
+    - name: dp-accountant
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install opacus && python3 federation/secure_agg_integration/privacy/accountant_demo.py
+
*** End Patch
*** Begin Patch
*** Add File:ops/erasure/discover_and_erase_all.py
+#!/usr/bin/env python3
+"""
+Discover and erase artifacts across known backup locations (S3 / MinIO / local) and produce a signed manifest for legal.
+
+Usage:
+  python3 ops/erasure/discover_and_erase_all.py --bucket my-bucket --prefixes 'feast/,mcp/,models/' --dry-run
+
+Notes:
+ - Destructive: run with --dry-run first.
+ - Signed manifest uses production.policy.signing.sign_with_retry if available.
+"""
+import argparse, boto3, json, os, time
+
+def list_s3_objects(s3, bucket, prefix, max_items=10000):
+    out=[]
+    kwargs={"Bucket":bucket,"Prefix":prefix}
+    while True:
+        resp = s3.list_objects_v2(**kwargs)
+        for o in resp.get("Contents",[]):
+            out.append(o["Key"])
+            if len(out) >= max_items:
+                return out
+        if not resp.get("IsTruncated"):
+            break
+        kwargs["ContinuationToken"]=resp.get("NextContinuationToken")
+    return out
+
+def delete_s3_objects(s3, bucket, keys):
+    # Delete in batches of 1000
+    deleted=[]
+    for i in range(0,len(keys),1000):
+        chunk=keys[i:i+1000]
+        objs=[{"Key":k} for k in chunk]
+        resp=s3.delete_objects(Bucket=bucket, Delete={"Objects":objs})
+        deleted.extend([d.get("Key") for d in resp.get("Deleted",[])])
+    return deleted
+
+def sign_manifest(manifest):
+    try:
+        from production.policy.signing.sign_with_retry import sign_payload
+        sig, meta = sign_payload(json.dumps(manifest).encode(), None)
+        manifest['signature'] = sig
+        manifest['signed_by'] = meta.get('keylabel', meta.get('method'))
+    except Exception as e:
+        manifest['signature'] = ''
+        manifest['signed_by'] = ''
+        manifest['signing_error'] = str(e)
+    return manifest
+
+def main():
+    p=argparse.ArgumentParser()
+    p.add_argument("--bucket", required=True)
+    p.add_argument("--prefixes", default="feast/,mcp/,models/")
+    p.add_argument("--dry-run", action="store_true")
+    p.add_argument("--out", default="/tmp/erasure_master_manifest.json")
+    args=p.parse_args()
+
+    s3=boto3.client("s3")
+    report={"bucket": args.bucket, "time": time.time(), "prefixes": {}}
+    for pref in args.prefixes.split(","):
+        pref=pref.strip()
+        if not pref:
+            continue
+        print("Listing",pref)
+        keys=list_s3_objects(s3, args.bucket, pref)
+        report['prefixes'][pref] = {"count": len(keys), "sample": keys[:50]}
+        if not args.dry_run and keys:
+            print("Deleting",len(keys),"objects under",pref)
+            deleted = delete_s3_objects(s3, args.bucket, keys)
+            report['prefixes'][pref]['deleted_count'] = len(deleted)
+    # sign manifest
+    signed = sign_manifest(report)
+    with open(args.out,"w") as f:
+        json.dump(signed, f, indent=2)
+    print("Wrote manifest to", args.out)
+    # upload manifest to evidence location
+    evidence_bucket=os.environ.get("EVIDENCE_BUCKET","")
+    if evidence_bucket:
+        key=f"evidence/erasure/manifest_{int(time.time())}.json"
+        s3.put_object(Bucket=evidence_bucket, Key=key, Body=json.dumps(signed).encode())
+        print("Uploaded manifest to s3://%s/%s" % (evidence_bucket, key))
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:argo/erasure_discovery_and_erase.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-erasure-
+  namespace: aegis
+spec:
+  entrypoint: erasure
+  templates:
+    - name: erasure
+      steps:
+        - - name: discover
+            template: discover
+        - - name: erase
+            template: erase
+
+    - name: discover
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install boto3 && python3 ops/erasure/discover_and_erase_all.py --bucket ${MODEL_ARTIFACT_BUCKET:-your-bucket} --prefixes "feast/,mcp/,models/" --dry-run --out /tmp/erasure_discovery.json && cat /tmp/erasure_discovery.json
+
+    - name: erase
+      container:
+        image: python:3.10-slim
+        command: [sh,-c]
+        args:
+          - pip install boto3 && python3 ops/erasure/discover_and_erase_all.py --bucket ${MODEL_ARTIFACT_BUCKET:-your-bucket} --prefixes "feast/,mcp/,models/" --out /tmp/erasure_manifest.json && cat /tmp/erasure_manifest.json
+
*** End Patch
*** Begin Patch
*** Add File:compliance/EXTERNAL_AUDIT_PLAYBOOK.md
+# External Compliance Audit Playbook (SOC2 / HIPAA / ISO)
+
+Purpose
+- Provide a repeatable sequence to prepare, run and evidence an external audit around Aegis.
+
+Pre-audit checklist
+1. Inventory systems & subprocessors (complete list in compliance/DPA_Documentation_TEMPLATE.md).
+2. Run evidence bundle assembly:
+   - python3 compliance/assemble_audit_bundle.py
+   - Ensure EVIDENCE_BUCKET contains the latest bundle.
+3. Ensure HSM validation report exists (ops/hsm/vendor_validation_suite.py output) and is included.
+4. Ensure DSR/erasure manifests for recent DSRs are present and signed.
+5. Run security and privacy self-assessments (include DP accountant reports).
+
+Audit steps
+1. Kick off external auditor engagement (legal coordinates).
+2. Provide auditors with evidence bundle download link and a README mapping artifacts to controls.
+3. Run live demos for:
+   - Model signing (HSM path)
+   - E2E pipeline (ingest → train → sign → deploy)
+   - DSR: discover+erase flow for a sample dataset and show signed erasure manifest
+   - Telemetry cost control: show relabeling rules and cardinality audit logs
+4. Capture auditor requests and remediate within agreed timeline.
+
+Post-audit
+1. Implement remediation actions and produce a follow-up evidence package.
+2. Schedule periodic internal audits (quarterly).
+
*** End Patch
*** Begin Patch
*** Add File:compliance/audit_issue_template.md
+---
+name: "External Audit Request"
+about: "Create an issue to coordinate external audit evidence and remediation"
+title: "[Audit] {{audit_type}} - {{date}}"
+labels: ["audit","compliance"]
+assignees: []
+body: |
+### Audit Type
+- Type: {{audit_type}} (SOC2/HIPAA/ISO)
+
+### Contacts
+- Legal: @legal-team
+- Security: @security-team
+- Engineering: @infra-team
+
+### Evidence to provide (checklist)
+- [ ] EVIDENCE bundle (path: s3://{{EVIDENCE_BUCKET}}/…)
+- [ ] HSM vendor validation report (ops/hsm/)
+- [ ] DSR/erasure manifests and logs (ops/erasure/)
+- [ ] GE reports for production pipelines
+- [ ] Prometheus & SLO dashboards
+- [ ] Gatekeeper policies & recent audit logs
+
+### Desired audit window
+- Start: {{start_date}}
+- End: {{end_date}}
+
+### Notes
+Add any constraints and special access needed for auditors.
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/audit_bundle_and_notify.yml
+name: Build audit bundle and notify legal
+on:
+  workflow_dispatch:
+
+jobs:
+  assemble:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Install deps
+        run: pip install boto3
+      - name: Assemble audit bundle
+        run: |
+          python3 compliance/assemble_audit_bundle.py
+      - name: Upload bundle artifact
+        uses: actions/upload-artifact@v4
+        with:
+          name: audit-bundle
+          path: /tmp/aegis_audit_bundle_*.tar.gz
+
+  notify:
+    runs-on: ubuntu-latest
+    needs: assemble
+    steps:
+      - name: Notify legal (placeholder)
+        run: |
+          echo "Notify legal and compliance team with link to artifact in workflow run."
+          # Placeholder: replace with real notification e.g., slack webhook or email integration
+
*** End Patch
*** End Patch
