*** Begin Patch
*** Add File:deploy/vault/auto_init_rotate_advanced.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Advanced Vault bootstrap + rotation helper.
+# - Initializes Vault (if needed) with 5 key shares, archives init bundle to S3 (object-lock compatible bucket).
+# - Stores root token and an "automation token" into AWS Secrets Manager.
+# - Enables Kubernetes auth, PKI, transit, and file audit device.
+# - Creates a rotation record signer (cosign via KMS) and uploads rotation proofs to EVIDENCE_BUCKET.
+#
+# Required env:
+#   VAULT_ADDR, EVIDENCE_BUCKET, KMS_ARN, AWS_REGION
+
+: "${VAULT_ADDR:?VAULT_ADDR required}"
+: "${EVIDENCE_BUCKET:?EVIDENCE_BUCKET required}"
+: "${KMS_ARN:?KMS_ARN required}"
+: "${AWS_REGION:?AWS_REGION required}"
+
+echo "Waiting for Vault..."
+until curl -sSf --insecure "${VAULT_ADDR}/v1/sys/health" >/dev/null 2>&1; do sleep 3; done
+
+if vault status -format=json | jq -e '.initialized' >/dev/null 2>&1; then
+  echo "Vault already initialized"
+else
+  echo "Initializing Vault..."
+  vault operator init -key-shares=5 -key-threshold=3 -format=json > /tmp/vault-init.json
+  ROOT_TOKEN=$(jq -r '.root_token' /tmp/vault-init.json)
+  # Archive init bundle to S3 (assumes EVIDENCE_BUCKET has object lock or governance)
+  aws s3 cp /tmp/vault-init.json "s3://${EVIDENCE_BUCKET}/vault-init/vault-init-$(date -u +%Y%m%dT%H%M%SZ).json" --sse aws:kms --sse-kms-key-id "${KMS_ARN}"
+  # Store root in Secrets Manager (operator must handle root lifecycle: retrieve offline & rotate)
+  if aws secretsmanager describe-secret --secret-id aegis/vault/root-token --region ${AWS_REGION} >/dev/null 2>&1; then
+    aws secretsmanager put-secret-value --secret-id aegis/vault/root-token --secret-string "${ROOT_TOKEN}" --region ${AWS_REGION}
+  else
+    aws secretsmanager create-secret --name aegis/vault/root-token --secret-string "${ROOT_TOKEN}" --region ${AWS_REGION}
+  fi
+  # generate an automation token (policy-based) and store in secrets manager
+  export VAULT_TOKEN="${ROOT_TOKEN}"
+  vault auth enable kubernetes || true
+  vault secrets enable -path=pki pki || true
+  vault secrets enable transit || true
+  vault write -f transit/keys/aegis-signing || true
+  cat > /tmp/signing-proxy.hcl <<'HCL'
+path "transit/sign/aegis-signing" {
+  capabilities = ["create","read"]
+}
+path "pki/issue/ci-client" {
+  capabilities = ["create","read"]
+}
+HCL
+  vault policy write signing-proxy /tmp/signing-proxy.hcl || true
+  AUTOMATION_TOKEN=$(vault token create -policy="signing-proxy" -format=json | jq -r .auth.client_token)
+  if aws secretsmanager describe-secret --secret-id aegis/vault/automation-token --region ${AWS_REGION} >/dev/null 2>&1; then
+    aws secretsmanager put-secret-value --secret-id aegis/vault/automation-token --secret-string "${AUTOMATION_TOKEN}" --region ${AWS_REGION}
+  else
+    aws secretsmanager create-secret --name aegis/vault/automation-token --secret-string "${AUTOMATION_TOKEN}" --region ${AWS_REGION}
+  fi
+  # enable file audit device; ensure PVC mounted to /vault/logs in Vault helm values
+  vault audit enable file file_path=/vault/logs/audit.log || true
+fi
+
+echo "Signing & uploading rotation record"
+ROT_RECORD="/tmp/vault-rotation-record-$(date -u +%Y%m%dT%H%M%SZ).txt"
+echo "rotation: $(date -u --iso-8601=seconds)" > ${ROT_RECORD}
+if command -v cosign >/dev/null && [ -n "${KMS_ARN}" ]; then
+  cosign sign --key "awskms://${KMS_ARN}" ${ROT_RECORD} || true
+fi
+aws s3 cp ${ROT_RECORD} "s3://${EVIDENCE_BUCKET}/vault-rotations/$(basename ${ROT_RECORD})" --sse aws:kms --sse-kms-key-id "${KMS_ARN}" || true
+
+echo "Vault bootstrap and rotation record created. Ensure operator rotates root offline according to policy."
+
*** End Patch
*** Begin Patch
*** Add File:deploy/vault/rotate_automation_cronjob.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: vault-rotate-automation-token
+  namespace: vault
+spec:
+  schedule: "0 2 * * 0" # weekly; tune for your policy
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          serviceAccountName: vault-operator
+          containers:
+            - name: rotate-token
+              image: hashicorp/vault:1.14.0
+              env:
+                - name: VAULT_ADDR
+                  value: "https://vault.vault.svc:8200"
+                - name: VAULT_TOKEN
+                  valueFrom:
+                    secretKeyRef:
+                      name: vault-root-token
+                      key: token
+                - name: EVIDENCE_BUCKET
+                  valueFrom:
+                    secretKeyRef:
+                      name: aegis-config
+                      key: EVIDENCE_BUCKET
+                - name: COSIGN_KMS_KEY_ARN
+                  valueFrom:
+                    secretKeyRef:
+                      name: aegis-config
+                      key: COSIGN_KMS_KEY_ARN
+              command: ["/bin/sh","-c"]
+              args:
+                - |
+                  set -e
+                  NEW_TOKEN=$(vault token create -policy="signing-proxy" -format=json | jq -r .auth.client_token)
+                  TS=$(date -u +%Y%m%dT%H%M%SZ)
+                  echo "${NEW_TOKEN}" > /tmp/new-token-${TS}.txt
+                  if [ -n "${COSIGN_KMS_KEY_ARN:-}" ]; then cosign sign --key "awskms://${COSIGN_KMS_KEY_ARN}" /tmp/new-token-${TS}.txt || true; fi
+                  aws s3 cp /tmp/new-token-${TS}.txt s3://${EVIDENCE_BUCKET}/vault-automation-rotations/ || true
+                  # update Secrets Manager or operator will pick up via automation
+          restartPolicy: OnFailure
+
*** End Patch
*** Begin Patch
*** Add File:deploy/rekor/test_failover_and_restore.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Test Rekor RDS endpoint connectivity, perform a small test write/read and perform a restore check into a temp DB.
+# Requires: PGPASSWORD or env creds and aws cli
+
+: "${REKOR_DB_HOST:-REPLACE}"
+: "${REKOR_DB_USER:-REPLACE}"
+: "${REKOR_DB_PASS:-REPLACE}"
+: "${EVIDENCE_BUCKET:-REPLACE}"
+
+export PGPASSWORD="${REKOR_DB_PASS}"
+TMPFILE="/tmp/rekor_test_$(date -u +%s).sql"
+echo "create table if not exists rekor_test (id serial primary key, msg text, created timestamptz default now());" > ${TMPFILE}
+echo "insert into rekor_test (msg) values ('rekor test $(date -u)');" >> ${TMPFILE}
+psql -h "${REKOR_DB_HOST}" -U "${REKOR_DB_USER}" -d "rekordb" -f ${TMPFILE}
+echo "Inserted test row into Rekor DB"
+# Dump to file and upload signed backup
+OUT="/tmp/rekor_test_dump_$(date -u +%Y%m%dT%H%M%SZ).dump"
+pg_dump -h "${REKOR_DB_HOST}" -U "${REKOR_DB_USER}" -d "rekordb" -F c -f "${OUT}"
+if command -v cosign >/dev/null && [ -n "${COSIGN_KMS_KEY_ARN:-}" ]; then
+  cosign sign --key "awskms://${COSIGN_KMS_KEY_ARN}" "${OUT}" || true
+fi
+aws s3 cp "${OUT}" "s3://${EVIDENCE_BUCKET}/rekor-backups/$(basename ${OUT})" --sse aws:kms || true
+echo "Uploaded signed backup to s3://${EVIDENCE_BUCKET}/rekor-backups/"
+
+echo "Restore test: creating temp DB and attempting pg_restore (requires privileges, may be disabled in prod)"
+RESTORE_DB="rekor_test_restore_$(date -u +%s)"
+createdb -h "${REKOR_DB_HOST}" -U "${REKOR_DB_USER}" "${RESTORE_DB}" || true
+pg_restore -h "${REKOR_DB_HOST}" -U "${REKOR_DB_USER}" -d "${RESTORE_DB}" "${OUT}" || true
+echo "Restore attempted to DB ${RESTORE_DB}; operator should validate contents."
+
*** End Patch
*** Begin Patch
*** Add File:scripts/evidence/train_with_evidence.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Wrapper to run a training job then create and sign evidence automatically.
+# Usage: ./train_with_evidence.sh --cmd "python train.py --out out/model" --manifest out/manifest.json
+
+MANIFEST=""
+CMD=""
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --cmd) CMD="$2"; shift 2 ;;
+    --manifest) MANIFEST="$2"; shift 2 ;;
+    *) echo "Unknown $1"; exit 2 ;;
+  esac
+done
+
+if [ -z "$CMD" ]; then echo "Missing --cmd"; exit 2; fi
+${CMD}
+if [ -z "$MANIFEST" ]; then echo "No manifest provided; attempting to auto-detect out/manifest.json"; MANIFEST="out/manifest.json"; fi
+EVIDENCE_OUT="/tmp/evidence-$(date -u +%Y%m%dT%H%M%SZ).tgz"
+python3 scripts/evidence/attach_and_sign.py --manifest "${MANIFEST}" --sbom out/sbom.spdx.json --logs out/train.log --out "${EVIDENCE_OUT}"
+echo "Evidence created at ${EVIDENCE_OUT}"
+
*** End Patch
*** Begin Patch
*** Add File:scripts/evidence/inference_with_evidence.py
+#!/usr/bin/env python3
+"""
+Small wrapper for inference calls that records inputs/outputs (redacted), signs the trace and uploads to evidence bucket.
+Example usage inside model-serving code or as a middleware.
+"""
+import os, json, time, base64, hashlib, subprocess, tempfile
+
+EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET")
+COSIGN_KMS = os.environ.get("COSIGN_KMS_KEY_ARN")
+
+def redact(text):
+    # import simple redactor if available (presidio)
+    try:
+        from presidio_analyzer import AnalyzerEngine
+        from presidio_anonymizer import AnonymizerEngine, AnonymizerRequest
+        analyzer = AnalyzerEngine()
+        anonymizer = AnonymizerEngine()
+        results = analyzer.analyze(text=text, language='en', return_decision_process=False)
+        if not results:
+            return text
+        anonymize_request = AnonymizerRequest()
+        anonymize_request.text = text
+        anonymize_request.entities = [{'start': r.start, 'end': r.end, 'entity_type': r.entity_type, 'anonymizer_config': {'type': 'replace', 'replace_value': '[REDACTED]'}} for r in results]
+        return anonymizer.anonymize(anonymize_request).text
+    except Exception:
+        # fallback: simple regex redaction
+        import re
+        s = re.sub(r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}', '[REDACTED_EMAIL]', text)
+        s = re.sub(r'\+?\d[\d\-\s]{7,}\d', '[REDACTED_PHONE]', s)
+        if len(s) > 1000:
+            return s[:500] + "...[REDACTED]"
+        return s
+
+def record_inference(model_name, request_obj, response_obj):
+    ts = time.time()
+    trace = {"model": model_name, "time": ts, "request": {"redacted": redact(json.dumps(request_obj))}, "response": {"redacted": redact(json.dumps(response_obj))}}
+    tmpd = tempfile.mkdtemp()
+    trace_file = os.path.join(tmpd, "trace.json")
+    with open(trace_file, "w") as f:
+        json.dump(trace, f)
+    tar = os.path.join(tmpd, "evidence.tgz")
+    subprocess.run(["tar","czf",tar,"-C",tmpd,"trace.json"], check=False)
+    # sign and upload
+    if COSIGN_KMS:
+        subprocess.run(["cosign","sign","--key",f"awskms://{COSIGN_KMS}","--output-signature",tar+".sig",tar], check=False)
+    if EVIDENCE_BUCKET:
+        subprocess.run(["aws","s3","cp",tar,f"s3://{EVIDENCE_BUCKET}/inference/"], check=False)
+    return trace
+
+if __name__=="__main__":
+    import sys
+    # simple test invocation: inference_with_evidence.py model '{"q":"hi"}' '{"a":"hello"}'
+    model = sys.argv[1]
+    req = json.loads(sys.argv[2])
+    res = json.loads(sys.argv[3])
+    t = record_inference(model, req, res)
+    print("Recorded trace:", t)
+
*** End Patch
*** Begin Patch
*** Add File:gatekeeper/constraints/require_evidence_annotation_template.yaml
+apiVersion: templates.gatekeeper.sh/v1beta1
+kind: ConstraintTemplate
+metadata:
+  name: require_evidence_annotation
+spec:
+  crd:
+    spec:
+      names:
+        kind: RequireEvidenceAnnotation
+  targets:
+    - target: admission.k8s.gatekeeper.sh
+      rego: |
+        package require_evidence_annotation
+
+        violation[{"msg": msg}] {
+          input.review.object.metadata.annotations["aegis.evidence"] != "true"
+          msg := "Deployment/Job must include annotation aegis.evidence=true with evidence S3 path after promotion/creation"
+        }
+
+---
+apiVersion: constraints.gatekeeper.sh/v1beta1
+kind: RequireEvidenceAnnotation
+metadata:
+  name: require-evidence-annotation
+spec:
+  enforcementAction: dryrun
+
+# Note: initially dryrun. Review audit events and then set enforcementAction to "deny".
+
*** End Patch
*** Begin Patch
*** Add File:infra/seldon/prod_rag_seldon.yaml
+apiVersion: machinelearning.seldon.io/v1
+kind: SeldonDeployment
+metadata:
+  name: rag-prod
+  namespace: aegis
+spec:
+  protocol: seldon
+  predictors:
+    - name: rag-predictor
+      replicas: 2
+      componentSpecs:
+        - spec:
+            containers:
+              - name: rag-server
+                image: registry.example.com/aegis/rag-triton-adapter:latest
+                resources:
+                  limits:
+                    nvidia.com/gpu: 1
+                  requests:
+                    cpu: 2000m
+                    memory: 8Gi
+      graph:
+        name: rag-triton
+        implementation: TRITON_SERVER
+        modelUri: "s3://models/rag_reader"
+
+---
+# Flagger canary will integrate; create Service for ingress metrics and canary checks
+
*** End Patch
*** Begin Patch
*** Add File:infra/triton/keda_scaledobject.yaml
+apiVersion: keda.sh/v1alpha1
+kind: ScaledObject
+metadata:
+  name: triton-scaledobject
+  namespace: aegis
+spec:
+  scaleTargetRef:
+    apiVersion: apps/v1
+    kind: Deployment
+    name: triton
+  minReplicaCount: 1
+  maxReplicaCount: 5
+  triggers:
+    - type: prometheus
+      metadata:
+        serverAddress: http://prometheus.monitoring.svc:9090
+        metricName: triton_gpu_utilization
+        threshold: "60"
+        query: avg_over_time(triton_gpu_utilization[2m])
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/slo/prometheus_slo_rules.yaml
+groups:
+  - name: aegis-slos
+    rules:
+      - alert: InferenceLatencySLOBreached
+        expr: histogram_quantile(0.95, sum(rate(model_inference_latency_seconds_bucket[5m])) by (le)) > 1.0
+        for: 5m
+        labels:
+          severity: page
+        annotations:
+          summary: "95th percentile inference latency > 1s"
+
+      - alert: ModelErrorRateSLOBreached
+        expr: increase(model_inference_errors_total[5m]) / increase(model_inference_requests_total[5m]) > 0.01
+        for: 5m
+        labels:
+          severity: ticket
+        annotations:
+          summary: "Model error rate > 1% (slo breach)"
+
*** End Patch
*** Begin Patch
*** Add File:security/presidio/integration_middleware.py
+#!/usr/bin/env python3
+"""
+Presidio-based redaction middleware for model-serving FastAPI or Flask apps.
+Call redact_text() with incoming user text to detect and anonymize PII before storage.
+"""
+from presidio_analyzer import AnalyzerEngine
+from presidio_anonymizer import AnonymizerEngine, AnonymizerRequest
+
+analyzer = AnalyzerEngine()
+anonymizer = AnonymizerEngine()
+
+def redact_text(text: str) -> str:
+    if not text:
+        return text
+    results = analyzer.analyze(text=text, language='en', return_decision_process=False)
+    if not results:
+        return text
+    anonymize_request = AnonymizerRequest()
+    anonymize_request.text = text
+    anonymize_request.entities = [
+        {'start': r.start, 'end': r.end, 'entity_type': r.entity_type, 'anonymizer_config': {'type': 'replace', 'replace_value': '[REDACTED]'}}
+        for r in results
+    ]
+    return anonymizer.anonymize(anonymize_request).text
+
*** End Patch
*** Begin Patch
*** Add File:argo/adversarial/langgraph_adversarial_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: langgraph-adversarial-
+  namespace: aegis
+spec:
+  entrypoint: adversarial-run
+  templates:
+    - name: adversarial-run
+      steps:
+        - - name: gen-prompts
+            template: gen-prompts
+        - - name: run-tests
+            template: run-tests
+        - - name: bundle-evidence
+            template: bundle-evidence
+
+    - name: gen-prompts
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install || true; python3 ml/sim/adversarial_generator.py --count 50 --out /tmp/adv.json; cat /tmp/adv.json
+      outputs:
+        artifacts:
+          - name: adv
+            path: /tmp/adv.json
+
+    - name: run-tests
+      inputs:
+        artifacts:
+          - name: adv
+            path: /tmp/adv.json
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - pip install requests || true; python3 - <<PY
+import json, requests, os
+adv = json.load(open('/tmp/adv.json'))
+out=[]
+for p in adv:
+    try:
+        r = requests.post('http://langgraph.langgraph.svc:8080/run/simple_graph', json={'input':{'question':p['prompt']}}, timeout=20)
+        out.append({'prompt':p,'resp':r.json()})
+    except Exception as e:
+        out.append({'prompt':p,'error':str(e)})
+open('/tmp/adv_results.json','w').write(json.dumps(out))
+print('wrote /tmp/adv_results.json')
+PY
+      outputs:
+        artifacts:
+          - name: adv-results
+            path: /tmp/adv_results.json
+
+    - name: bundle-evidence
+      inputs:
+        artifacts:
+          - name: adv-results
+            path: /tmp/adv_results.json
+      container:
+        image: python:3.10-slim
+        command: [sh, -c]
+        args:
+          - python3 scripts/evidence/attach_and_sign.py --manifest langgraph/config/graph-example.json --logs /tmp/adv_results.json --out /tmp/adv_evidence.tgz || true; ls -l /tmp/adv_evidence.tgz
+      outputs:
+        artifacts:
+          - name: evidence
+            path: /tmp/adv_evidence.tgz
+
*** End Patch
*** Begin Patch
*** Add File:ops/token_budget/enforce_client.py
+#!/usr/bin/env python3
+"""
+Small HF client wrapper that checks token budget before performing a request.
+Use this in your model runners or LangGraph runtime at the call site before invoking HF APIs.
+"""
+import os, requests, json
+
+TOKEN_BUDGET_URL = os.environ.get("TOKEN_BUDGET_URL","http://token-budget.aegis.svc:9200")
+
+def check_and_consume(team:str, tokens:int) -> bool:
+    # check
+    r = requests.post(f"{TOKEN_BUDGET_URL}/check", json={"team":team,"tokens":tokens}, timeout=5)
+    if r.status_code != 200:
+        return False
+    j = r.json()
+    if not j.get("allowed", False):
+        return False
+    # consume
+    rc = requests.post(f"{TOKEN_BUDGET_URL}/consume", json={"team":team,"tokens":tokens}, timeout=5)
+    return rc.status_code == 200
+
+def call_hf_with_budget(team, tokens, hf_call_fn, *args, **kwargs):
+    if not check_and_consume(team, tokens):
+        raise RuntimeError("Token budget exceeded for team " + team)
+    return hf_call_fn(*args, **kwargs)
+
*** End Patch
*** Begin Patch
*** Add File:docs/PROD_SECRETS_ROTATION_AND_EVIDENCE_POLICY.md
+# Production Secrets, Rotation & Evidence Policy (Aegis)
+
+This document summarizes the automation and policies implemented by the patch:
+
+Vault & PKI rotation
+- Vault auto-init script: deploy/vault/auto_init_rotate_advanced.sh — initializes Vault, archives init bundle to EVIDENCE_BUCKET, stores root & automation tokens in AWS Secrets Manager, enables PKI & transit and audit device.
+- Rotation cronjob: deploy/vault/rotate_automation_cronjob.yaml — rotates automation tokens weekly and archives rotation proof signed with COSIGN KMS.
+- Operators must maintain root unseal ceremony offline and rotate root per org policy.
+
+Rekor durability
+- Backup & restore test: deploy/rekor/test_failover_and_restore.sh — performs test insert, pg_dump, signs backup, uploads to EVIDENCE_BUCKET and tests restore into temp DB.
+- Weekly credential rotation cronjob provided; operator must sequence DB password change during maintenance window.
+
+Evidence completeness
+- Training wrapper: scripts/evidence/train_with_evidence.sh — runs training command and produces signed evidence using attach_and_sign.py.
+- Inference wrapper: scripts/evidence/inference_with_evidence.py — redacts PII, bundles trace and uploads signed evidence to EVIDENCE_BUCKET.
+- Gatekeeper constraint template require_evidence_annotation_template.yaml (dry-run) to start auditing deployments/pods lacking evidence annotation.
+
+Serving scale & SLOs
+- Seldon and Triton prod manifests provided (infra/seldon/prod_rag_seldon.yaml, infra/triton/keda_scaledobject.yaml, infra/triton/tuned_deployment.yaml).
+- Prometheus SLO alerting rules in monitoring/slo/prometheus_slo_rules.yaml.
+
+Privacy & Safety
+- Presidio integration middleware for robust PII detection (security/presidio/integration_middleware.py).
+- Adversarial test Argo workflow (argo/adversarial/langgraph_adversarial_workflow.yaml) for automated adversarial campaigning and evidence bundling.
+- Safety monitor thresholds should be tuned; use Gatekeeper audits and Argo test evidence to iterate.
+
+Cost control
+- token-budget service exists; client enforcement wrapper added ops/token_budget/enforce_client.py. Integrate checks in model runtimes (LangGraph / HF clients).
+
+Apply notes
+- Secret values (KMS ARNs, EVIDENCE_BUCKET, COSIGN_KMS_KEY_ARN, DB creds) must be injected securely using Vault/Secrets Manager and GitOps pipelines.
+- Validate all new cronjobs & workflows in staging first. Flip Gatekeeper enforcement from dry-run to deny only after audit review.
+
*** End Patch
*** End Patch
