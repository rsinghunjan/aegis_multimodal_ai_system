*** Begin Patch
*** Add File:ops/robotics/ros2_adapter/requirements.txt
+rclpy==2.9.0
+opencv-python-headless==4.7.0.72
+onnxruntime==1.15.1
+requests==2.31.0
+numpy==1.26.0
+Pillow==9.5.0
+
*** End Patch
*** Begin Patch
*** Add File:ops/robotics/ros2_adapter/onnx_inference_node.py
+#!/usr/bin/env python3
+"""
+ROS2 adapter node that subscribes to a camera image topic, runs ONNXRuntime inference,
+publishes detections on a topic, and emits telemetry to the Aegis telemetry collector.
+
+Usage: (on a ROS2 device or container)
+  pip install -r ops/robotics/ros2_adapter/requirements.txt
+  ros2 run <package> onnx_inference_node.py   # or run this script directly in a ROS2 environment
+
+Notes:
+- Topic names are configurable via environment variables.
+- Model path should point to an ONNX model on the device (optimized for TensorRT/ONNXRuntime).
+- Sends a small telemetry JSON to the telemetry collector URL for each frame.
+"""
+import os
+import sys
+import json
+import time
+import cv2
+import numpy as np
+import requests
+
+# ROS2 imports (rclpy)
+try:
+    import rclpy
+    from rclpy.node import Node
+    from sensor_msgs.msg import Image
+    from std_msgs.msg import String
+    from cv_bridge import CvBridge
+except Exception as e:
+    print("ROS2 packages not available in this environment; this script must run in ROS2 runtime.", file=sys.stderr)
+    raise
+
+try:
+    import onnxruntime as ort
+except Exception:
+    ort = None
+
+TELEMETRY_URL = os.environ.get("TELEMETRY_URL", "http://telemetry-collector:9102/")
+CAMERA_TOPIC = os.environ.get("CAMERA_TOPIC", "/camera/image_raw")
+DETECTIONS_TOPIC = os.environ.get("DETECTIONS_TOPIC", "/perception/detections")
+MODEL_PATH = os.environ.get("ONNX_MODEL_PATH", "/models/model.onnx")
+INFERENCE_INTERVAL = float(os.environ.get("INFERENCE_INTERVAL", "0.05"))  # seconds between frames (throttle)
+
+class ONNXInferenceNode(Node):
+    def __init__(self):
+        super().__init__('aegis_onnx_inference_node')
+        self.bridge = CvBridge()
+        self.subscription = self.create_subscription(Image, CAMERA_TOPIC, self.image_callback, 10)
+        self.pub = self.create_publisher(String, DETECTIONS_TOPIC, 10)
+        self.last_infer = 0.0
+        self.session = None
+        self.input_name = None
+        self.load_model(MODEL_PATH)
+        self.get_logger().info(f"ONNX inference node started. Subscribed to {CAMERA_TOPIC}")
+
+    def load_model(self, path):
+        if not ort:
+            self.get_logger().error("onnxruntime not installed")
+            raise RuntimeError("onnxruntime missing")
+        if not os.path.exists(path):
+            self.get_logger().error(f"ONNX model not found at {path}")
+            # Node keeps running; operators should ensure model is staged
+            return
+        self.session = ort.InferenceSession(path, providers=['CUDAExecutionProvider','CPUExecutionProvider'])
+        meta = self.session.get_inputs()
+        if meta:
+            self.input_name = meta[0].name
+        self.get_logger().info(f"Loaded ONNX model {path}; input={self.input_name}")
+
+    def image_callback(self, msg):
+        now = time.time()
+        if now - self.last_infer < INFERENCE_INTERVAL:
+            return
+        self.last_infer = now
+        try:
+            cv_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
+        except Exception as e:
+            self.get_logger().error(f"cv_bridge error: {e}")
+            return
+        # Preprocess to model input (example: resize to 640x480, normalize)
+        img = cv2.resize(cv_img, (640, 480))
+        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
+        # HWC -> NCHW
+        inp = np.transpose(img_rgb, (2,0,1)).astype(np.float32)[None, ...]
+        detections = []
+        if self.session and self.input_name:
+            try:
+                out = self.session.run(None, {self.input_name: inp})
+                # For generic models, produce a placeholder detection result
+                detections = self.parse_output(out)
+            except Exception as e:
+                self.get_logger().error(f"Inference failed: {e}")
+        else:
+            # placeholder no-model output (for dev)
+            detections = [{"label":"nop-model","score":0.0}]
+        # Publish detections as JSON on topic
+        payload = json.dumps({"ts": int(now), "detections": detections})
+        self.pub.publish(String(data=payload))
+        # Send small telemetry record
+        self.emit_telemetry(len(detections), latency_s=0.0, tokens=None)
+        self.get_logger().debug(f"Published {len(detections)} detections")
+
+    def parse_output(self, outputs):
+        # Basic parser: convert whatever outputs into label/score list.
+        # Operators should replace with model-specific parsing (boxes, scores, classes).
+        results = []
+        try:
+            for o in outputs:
+                # flatten small outputs
+                arr = np.array(o).ravel().tolist()
+                results.append({"name":"out_chunk","values_sample": arr[:5]})
+        except Exception:
+            pass
+        return results
+
+    def emit_telemetry(self, num_detections:int, latency_s:float, tokens:int=None):
+        try:
+            data = {
+                "ts": int(time.time()),
+                "node": os.uname().nodename,
+                "model": os.path.basename(MODEL_PATH),
+                "detections": num_detections,
+                "latency_s": latency_s
+            }
+            # best-effort post
+            if TELEMETRY_URL:
+                requests.post(TELEMETRY_URL.rstrip('/') + "/collect", json=data, timeout=1)
+        except Exception:
+            pass
+
+def main(args=None):
+    rclpy.init(args=args)
+    node = ONNXInferenceNode()
+    try:
+        rclpy.spin(node)
+    except KeyboardInterrupt:
+        pass
+    node.destroy_node()
+    rclpy.shutdown()
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/robotics/carla/requirements.txt
+carla==0.9.13
+opencv-python-headless==4.7.0.72
+boto3==1.28.0
+numpy==1.26.0
+
*** End Patch
*** Begin Patch
*** Add File:ops/robotics/carla/run_carla_capture.py
+#!/usr/bin/env python3
+"""
+Run a simple CARLA scenario, capture camera frames and metadata, and write artifacts to local disk or S3.
+
+This script is designed to run inside an Argo container in the cloud for synthetic data generation.
+It performs:
+ - connects to CARLA server (assumes CARLA is reachable at CARLA_HOST:CARLA_PORT)
+ - spawns a vehicle and camera sensor
+ - records N frames and writes images + metadata to /tmp/carla_output
+ - optionally uploads to S3 if FEATURESTORE_S3 is configured
+"""
+import os
+import sys
+import time
+import json
+import uuid
+import argparse
+from pathlib import Path
+
+try:
+    import carla
+except Exception:
+    carla = None
+
+try:
+    import boto3
+except Exception:
+    boto3 = None
+
+import cv2
+import numpy as np
+
+OUT_DIR = "/tmp/carla_output"
+CARLA_HOST = os.environ.get("CARLA_HOST", "localhost")
+CARLA_PORT = int(os.environ.get("CARLA_PORT", "2000"))
+FEATURESTORE_S3 = os.environ.get("FEATURESTORE_S3", "")
+BUCKET_PREFIX = os.environ.get("FEATURESTORE_S3_PREFIX", "featurestore/carla")
+CAPTURE_FRAMES = int(os.environ.get("CARLA_CAPTURE_FRAMES", "50"))
+
+def ensure_dir(p):
+    Path(p).mkdir(parents=True, exist_ok=True)
+
+def connect_client():
+    if not carla:
+        print("carla package not installed; exiting", file=sys.stderr)
+        sys.exit(2)
+    client = carla.Client(CARLA_HOST, CARLA_PORT)
+    client.set_timeout(10.0)
+    return client
+
+def run_capture(frames=50):
+    client = connect_client()
+    world = client.get_world()
+    bp_lib = world.get_blueprint_library()
+    vehicle_bp = bp_lib.filter("vehicle.*")[0]
+    cam_bp = bp_lib.find('sensor.camera.rgb')
+    # configure camera
+    cam_bp.set_attribute('image_size_x', '800')
+    cam_bp.set_attribute('image_size_y', '600')
+    cam_bp.set_attribute('fov', '90')
+    spawn_points = world.get_map().get_spawn_points()
+    vehicle = None
+    camera = None
+    ensure_dir(OUT_DIR)
+    try:
+        vehicle = world.spawn_actor(vehicle_bp, spawn_points[0])
+        cam_transform = carla.Transform(carla.Location(x=1.5, z=2.4))
+        camera = world.spawn_actor(cam_bp, cam_transform, attach_to=vehicle)
+        frame_id = 0
+        def _on_image(image):
+            nonlocal frame_id
+            array = np.frombuffer(image.raw_data, dtype=np.uint8)
+            array = array.reshape((image.height, image.width, 4))[:,:,:3]
+            fname = os.path.join(OUT_DIR, f"frame-{frame_id:05d}.jpg")
+            cv2.imwrite(fname, array)
+            meta = {"ts": image.timestamp, "frame": frame_id, "width": image.width, "height": image.height}
+            with open(os.path.join(OUT_DIR, f"frame-{frame_id:05d}.json"), "w") as fh:
+                json.dump(meta, fh)
+            frame_id += 1
+        camera.listen(_on_image)
+        # let simulation run
+        t0 = time.time()
+        while frame_id < frames and time.time() - t0 < frames * 0.5 + 30:
+            time.sleep(0.1)
+        camera.stop()
+    finally:
+        if camera:
+            camera.destroy()
+        if vehicle:
+            vehicle.destroy()
+
+def upload_to_s3():
+    if not boto3 or not FEATURESTORE_S3:
+        print("S3 upload disabled or boto3 not present")
+        return
+    s3 = boto3.client("s3")
+    for f in os.listdir(OUT_DIR):
+        key = f"{BUCKET_PREFIX}/{uuid.uuid4().hex}/{f}"
+        s3.upload_file(os.path.join(OUT_DIR, f), FEATURESTORE_S3, key)
+        print("uploaded", key)
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("--frames", type=int, default=CAPTURE_FRAMES)
+    args = parser.parse_args()
+    print("Running CARLA capture", args)
+    run_capture(args.frames)
+    upload_to_s3()
+    print("CARLA capture complete; artifacts in", OUT_DIR)
+
*** End Patch
*** Begin Patch
*** Add File:ops/robotics/carla/argo_carla_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-carla-
+spec:
+  entrypoint: run-carla
+  templates:
+    - name: run-carla
+      steps:
+        - - name: carla-capture
+            template: carla-capture
+        - - name: ingest
+            template: ingest
+    - name: carla-capture
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - |
+            set -e
+            pip install --no-cache-dir -r ops/robotics/carla/requirements.txt
+            python ops/robotics/carla/run_carla_capture.py --frames 100
+      # If CARLA server is remote, ensure network access; otherwise run CARLA server as a separate container/Job
+    - name: ingest
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - |
+            set -e
+            pip install --no-cache-dir boto3 pyarrow
+            # This placeholder could call a featurestore ingest helper that packages generated artifacts into Parquet
+            echo "Ingest placeholder: copy /tmp/carla_output to featurestore or S3"
+            ls -la /tmp/carla_output || true
+  # volumes and serviceAccount may be added for S3 credentials and larger workloads
+
*** End Patch
*** Begin Patch
*** Add File:k8s/edge/jetson/Dockerfile.jetson
+# Jetson / edge inference runtime (ARM64)
+# Build on a JetPack/Ubuntu base compatible with NVIDIA Jetson devices.
+# Operators: build image on device or use NVIDIA build tools.
+FROM nvcr.io/nvidia/l4t-base:r35.2.1
+ENV DEBIAN_FRONTEND=noninteractive
+RUN apt-get update && apt-get install -y --no-install-recommends \
+    python3-pip python3-opencv libopencv-dev ca-certificates wget \
+    && rm -rf /var/lib/apt/lists/*
+RUN python3 -m pip install --upgrade pip
+RUN pip3 install --no-cache-dir \
+    onnxruntime==1.15.1 \
+    opencv-python-headless==4.7.0.72 \
+    numpy==1.26.0 \
+    requests==2.31.0 \
+    Pillow==9.5.0
+# Copy ROS2 adapter and supporting scripts
+WORKDIR /opt/aegis
+COPY ops/robotics/ros2_adapter /opt/aegis/ros2_adapter
+# The container expects to run in a device with CUDA drivers and tensorRT installed by JetPack
+ENV TELEMETRY_URL="http://telemetry-collector:9102/"
+ENV CAMERA_TOPIC="/camera/image_raw"
+ENV DETECTIONS_TOPIC="/perception/detections"
+ENTRYPOINT ["python3","/opt/aegis/ros2_adapter/onnx_inference_node.py"]
+
*** End Patch
*** Begin Patch
*** Add File:k8s/edge/jetson/daemonset.yaml
+apiVersion: apps/v1
+kind: DaemonSet
+metadata:
+  name: aegis-edge-inference
+  namespace: aegis-edge
+spec:
+  selector:
+    matchLabels:
+      app: aegis-edge-inference
+  template:
+    metadata:
+      labels:
+        app: aegis-edge-inference
+    spec:
+      serviceAccountName: edge-inference-sa
+      runtimeClassName: aegis-sandbox-rc
+      tolerations:
+        - key: "nvidia.com/gpu"
+          operator: "Exists"
+          effect: "NoSchedule"
+      containers:
+        - name: edge-inference
+          image: REPLACE_WITH_JETSON_IMAGE
+          resources:
+            limits:
+              nvidia.com/gpu: 1
+            requests:
+              cpu: "500m"
+              memory: "512Mi"
+          env:
+            - name: TELEMETRY_URL
+              value: "http://telemetry-collector:9102/"
+            - name: CAMERA_TOPIC
+              value: "/camera/image_raw"
+            - name: DETECTIONS_TOPIC
+              value: "/perception/detections"
+          volumeMounts:
+            - name: dev
+              mountPath: /dev
+      volumes:
+        - name: dev
+          hostPath:
+            path: /dev
+            type: Directory
+---
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: edge-inference-sa
+  namespace: aegis-edge
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name: edge-inference-role
+  namespace: aegis-edge
+rules:
+  - apiGroups: [""]
+    resources: ["pods","secrets"]
+    verbs: ["get","list"]
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: RoleBinding
+metadata:
+  name: edge-inference-rb
+  namespace: aegis-edge
+roleRef:
+  apiGroup: rbac.authorization.k8s.io
+  kind: Role
+  name: edge-inference-role
+subjects:
+  - kind: ServiceAccount
+    name: edge-inference-sa
+    namespace: aegis-edge
+
*** End Patch
*** Begin Patch
*** Add File:ops/robotics/ota/ota_canary.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# OTA canary script for edge fleet:
+# - Downloads artifact (tar.gz) from a registry or S3 URL
+# - Verifies cosign signature using COSIGN_KMS_ARN and Rekor evidence (REKOR_URL)
+# - If verification passes, publishes artifact to a per-edge local path and optionally restarts the edge inference pod
+#
+# Usage:
+#   OTA_ARTIFACT_URL=s3://bucket/path/model.tar.gz COSIGN_SIG_URL=s3://bucket/path/model.tar.gz.sig ./ops/robotics/ota/ota_canary.sh
+#
+ARTIFACT_URL=${ARTIFACT_URL:-}
+SIG_URL=${SIG_URL:-}
+TMP_DIR=${TMP_DIR:-/tmp/ota}
+RESTART_POD=${RESTART_POD:-edge-inference}   # name of pod or label to restart
+NAMESPACE=${NAMESPACE:-aegis-edge}
+COSIGN_KMS_ARN=${COSIGN_KMS_ARN:-}
+REKOR_URL=${REKOR_URL:-}
+
+if [ -z "${ARTIFACT_URL}" ] || [ -z "${SIG_URL}" ]; then
+  echo "Set ARTIFACT_URL and SIG_URL"
+  exit 2
+fi
+
+mkdir -p "${TMP_DIR}"
+ART_NAME="${TMP_DIR}/artifact.tgz"
+SIG_PATH="${TMP_DIR}/artifact.sig"
+
+echo "[ota] Fetching artifact ${ARTIFACT_URL}"
+if [[ "${ARTIFACT_URL}" == s3://* ]]; then
+  aws s3 cp "${ARTIFACT_URL}" "${ART_NAME}"
+else
+  curl -sSL -o "${ART_NAME}" "${ARTIFACT_URL}"
+fi
+
+echo "[ota] Fetching signature ${SIG_URL}"
+if [[ "${SIG_URL}" == s3://* ]]; then
+  aws s3 cp "${SIG_URL}" "${SIG_PATH}" || true
+else
+  curl -sSL -o "${SIG_PATH}" "${SIG_URL}" || true
+fi
+
+if [ ! -f "${SIG_PATH}" ]; then
+  echo "[ota] Signature file not found; aborting"
+  exit 3
+fi
+
+if [ -z "${COSIGN_KMS_ARN}" ]; then
+  echo "[ota] COSIGN_KMS_ARN not set; aborting verification"
+  exit 4
+fi
+
+if [ -n "${REKOR_URL}" ]; then
+  export REKOR_URL
+fi
+
+echo "[ota] Verifying signature with cosign (KMS)"
+COSIGN_EXPERIMENTAL=1 cosign verify-blob --key "k8s://${COSIGN_KMS_ARN}" --signature "${SIG_PATH}" "${ART_NAME}"
+
+if [ $? -ne 0 ]; then
+  echo "[ota] cosign verify failed; aborting"
+  exit 5
+fi
+
+echo "[ota] Verified artifact. Extracting to /opt/aegis/artifacts/current"
+mkdir -p /opt/aegis/artifacts
+tar -xzf "${ART_NAME}" -C /opt/aegis/artifacts
+echo "[ota] Installed artifact files:"
+ls -la /opt/aegis/artifacts
+
+# optional: restart pod(s) to pick up new artifact via rolling restart
+if [ -n "${RESTART_POD}" ]; then
+  echo "[ota] Restarting edge pods (label or name): ${RESTART_POD}"
+  # if user provided label selector, use that; otherwise treat as pod name
+  if kubectl -n "${NAMESPACE}" get pods -l "app=${RESTART_POD}" >/dev/null 2>&1; then
+    kubectl -n "${NAMESPACE}" rollout restart daemonset aegis-edge-inference || true
+  else
+    kubectl -n "${NAMESPACE}" delete pod -l "app=aegis-edge-inference" --ignore-not-found || true
+  fi
+fi
+
+echo "[ota] OTA canary deploy complete and verified."
+
*** End Patch
*** Begin Patch
*** Add File:docs/runbooks/robotics_onboarding.md
+# Aegis Robotics & AV Onboarding Runbook (MVP)
+
+This runbook walks through the minimal steps to deploy the ROS2 adapter, CARLA data generation pipeline and Jetson edge runtime, and perform an OTA canary in staging.
+
+Prereqs:
+- Kubernetes cluster with edge nodes (or dev hosts)
+- CARLA server reachable by capture job (or run CARLA locally)
+- AWS/GCP credentials for S3 and DLP integration
+- cosign installed on operator machine for verification
+- GitHub repo secrets set (COSIGN_KMS_ARN, REKOR_URL, MODEL_REGISTRY_S3)
+
+1) Deploy telemetry collector & featurestore ingestion if not running
+- Follow ops/telemetry/collector.py to run telemetry collector as a Deployment
+- Ensure TELEMETRY_URL is reachable from edge devices
+
+2) Deploy Jetson edge DaemonSet (staging)
+- kubectl create ns aegis-edge || true
+- kubectl apply -f k8s/edge/jetson/daemonset.yaml
+- Update image in manifest to built Jetson image (or use local device image)
+
+3) Test ROS2 adapter locally on a device
+- Build the Jetson image or install deps
+- Run: python3 ops/robotics/ros2_adapter/onnx_inference_node.py
+- Ensure it connects to camera topic and posts telemetry
+
+4) Run CARLA capture via Argo (staging)
+- Ensure CARLA server accessible
+- kubectl -n argo apply -f ops/robotics/carla/argo_carla_workflow.yaml
+- Inspect artifacts in /tmp/carla_output or S3 bucket
+
+5) Build training image & run a distributed training Argo job
+- docker build -t ghcr.io/yourorg/aegis-train:prod -f docker/training/Dockerfile.prod .
+- Push image and update Argo training workflow manifest to reference it
+- kubectl -n argo apply -f ops/training/argo_dist_train_checkpointed.yaml
+
+6) OTA canary test (single edge device)
+- Prepare a signed artifact tar.gz and signature (.sig) (use cosign sign-blob with KMS)
+- Place ARTIFACT_URL and SIG_URL accessible (S3 recommended)
+- On edge device run:
+  ARTIFACT_URL=s3://.../model.tgz SIG_URL=s3://.../model.tgz.sig COSIGN_KMS_ARN=arn:... NAMESPACE=aegis-edge ./ops/robotics/ota/ota_canary.sh
+- Verify artifact loads and edge process restarts and reports telemetry
+
+7) Run DLP & red-team tuning
+- Place red-team corpus files under ops/tests/redteam_corpus
+- Run ops/dlp/redteam_tune.py and ops/dlp/production_tune_and_run.py to scan corpus and check Macie/GCP DLP integration
+
+8) Validate drift thresholds and calibrate
+- Place baseline samples under /var/lib/aegis/baseline_samples/<model>.txt
+- Run ops/drift/calibrate_thresholds.py to produce thresholds
+- Start ops/drift/production_drift_detector.py with DRIFT_MODELS set
+
+9) Run full red-team & chaos suite
+- ./ops/tests/full_redteam_and_chaos.sh
+- Review results and adjust seccomp/AppArmor / Gatekeeper rules as needed
+
+10) Iterate
+- Tune thresholds, retrain pipelines, canary windows, and automation_policy per findings
+
+Safety note:
+- Do not allow any edge OTA that controls actuators without validated HIL testing and sign-off.
+- Use signed artifacts and Rekor audit trails for every OTA deployment.
+
*** End Patch
*** End Patch
