*** Begin Patch
*** Add File:k8s/grafana/autonomy_dashboard_provision.yaml
+apiVersion: 1
+providers:
+  - name: 'aegis-autonomy'
+    orgId: 1
+    folder: 'Aegis'
+    type: file
+    disableDeletion: false
+    options:
+      path: /var/lib/grafana/dashboards/aegis
+
*** End Patch
*** Begin Patch
*** Add File:ops/autonomy/grafana_autonomy_dashboard_full.json
+{
+  "annotations": {
+    "list": [
+      {
+        "builtIn": 1,
+        "datasource": "-- Grafana --",
+        "enable": true,
+        "hide": true,
+        "iconColor": "rgba(0, 211, 255, 1)",
+        "name": "Annotations & Alerts",
+        "type": "dashboard"
+      }
+    ]
+  },
+  "editable": true,
+  "gnetId": null,
+  "graphTooltip": 0,
+  "id": null,
+  "iteration": 1610000000000,
+  "links": [],
+  "panels": [
+    {
+      "datasource": null,
+      "fieldConfig": {
+        "defaults": {},
+        "overrides": []
+      },
+      "gridPos": {
+        "h": 6,
+        "w": 12,
+        "x": 0,
+        "y": 0
+      },
+      "id": 2,
+      "options": {
+        "colorMode": "value",
+        "graphMode": "area",
+        "justifyMode": "auto",
+        "orientation": "auto",
+        "reduceOptions": {
+          "calcs": [
+            "mean"
+          ],
+          "fields": "",
+          "values": false
+        },
+        "textMode": "auto"
+      },
+      "pluginVersion": "8.0.0",
+      "targets": [
+        {
+          "expr": "aegis_autonomy_percent",
+          "format": "time_series",
+          "interval": "",
+          "legendFormat": "",
+          "refId": "A"
+        }
+      ],
+      "title": "Aegis Autonomy %",
+      "type": "stat"
+    },
+    {
+      "datasource": null,
+      "fieldConfig": {
+        "defaults": {},
+        "overrides": []
+      },
+      "gridPos": {
+        "h": 6,
+        "w": 6,
+        "x": 0,
+        "y": 6
+      },
+      "id": 3,
+      "options": {},
+      "targets": [
+        {
+          "expr": "aegis_ns_high_autonomy",
+          "refId": "A"
+        }
+      ],
+      "title": "Namespaces at High Autonomy",
+      "type": "stat"
+    },
+    {
+      "datasource": null,
+      "fieldConfig": {
+        "defaults": {},
+        "overrides": []
+      },
+      "gridPos": {
+        "h": 6,
+        "w": 6,
+        "x": 6,
+        "y": 6
+      },
+      "id": 4,
+      "options": {},
+      "targets": [
+        {
+          "expr": "aegis_recent_attestations",
+          "refId": "A"
+        }
+      ],
+      "title": "Recent Attestations (24h)",
+      "type": "stat"
+    },
+    {
+      "datasource": null,
+      "fieldConfig": {
+        "defaults": {},
+        "overrides": []
+      },
+      "gridPos": {
+        "h": 6,
+        "w": 6,
+        "x": 0,
+        "y": 12
+      },
+      "id": 5,
+      "options": {},
+      "targets": [
+        {
+          "expr": "aegis_pending_promotions",
+          "refId": "A"
+        }
+      ],
+      "title": "Pending Promotions",
+      "type": "stat"
+    },
+    {
+      "datasource": null,
+      "fieldConfig": {
+        "defaults": {},
+        "overrides": []
+      },
+      "gridPos": {
+        "h": 6,
+        "w": 6,
+        "x": 6,
+        "y": 12
+      },
+      "id": 6,
+      "options": {},
+      "targets": [
+        {
+          "expr": "aegis_circuit_open",
+          "refId": "A"
+        }
+      ],
+      "title": "Circuit Open (1=open)",
+      "type": "stat"
+    }
+  ],
+  "schemaVersion": 27,
+  "style": "dark",
+  "tags": [
+    "aegis",
+    "autonomy"
+  ],
+  "time": {
+    "from": "now-6h",
+    "to": "now"
+  },
+  "timepicker": {},
+  "timezone": "",
+  "title": "Aegis Autonomy Overview",
+  "uid": "aegis-autonomy-overview",
+  "version": 1
+}
+
*** End Patch
*** Begin Patch
*** Add File:k8s/autonomy/autonomy_exporter_service_monitor.yaml
+apiVersion: monitoring.coreos.com/v1
+kind: ServiceMonitor
+metadata:
+  name: aegis-autonomy-exporter-sm
+  namespace: monitoring
+  labels:
+    release: prometheus
+spec:
+  selector:
+    matchLabels:
+      app: aegis-autonomy-exporter
+  namespaceSelector:
+    matchNames:
+      - aegis-system
+  endpoints:
+    - port: metrics
+      interval: 30s
+      path: /metrics
+
*** End Patch
*** Begin Patch
*** Add File:ops/compliance/esign_adapter.py
+#!/usr/bin/env python3
+"""
+E-sign integration adapter (blueprint).
+
+This module demonstrates a safe pattern for requesting a legal e-signature from a provider
+(DocuSign, Adobe Sign) and receiving a webhook callback to record a legal signoff.
+
+Design:
+ - POST /request-signature to start a request (creates local record and calls provider API)
+ - Provider will call /callback when signer completes; callback verifies provider signature/HMAC and records signoff via signoff_manager
+ - The provider-specific bits are abstracted; operator must configure provider API credentials and callback verification secret.
+
+This is a non-production blueprint: operators must adapt to the chosen provider API and secure keys.
+"""
+import os
+import json
+import requests
+from flask import Flask, request, jsonify
+from ops.compliance.signoff_manager import record_signoff
+
+app = Flask(__name__)
+
+PROVIDER_API = os.environ.get("ESIGN_API_URL", "")
+PROVIDER_KEY = os.environ.get("ESIGN_API_KEY", "")
+CALLBACK_SECRET = os.environ.get("ESIGN_CALLBACK_SECRET", "")
+
+@app.route("/request-signature", methods=["POST"])
+def request_signature():
+    body = request.json or {}
+    doc_ref = body.get("doc_ref")
+    signer_email = body.get("signer_email")
+    business_key = body.get("signoff_key")  # e.g., legal:policy-123:artifact-456
+    if not (doc_ref and signer_email and business_key):
+        return jsonify({"ok": False, "error": "doc_ref, signer_email and signoff_key required"}), 400
+    # create local placeholder record (could be stored in DB; here we just echo)
+    req_payload = {
+        "document": doc_ref,
+        "signer": {"email": signer_email},
+        "callback_url": os.environ.get("ESIGN_CALLBACK_URL", "https://your-ingress/aegis-esign/callback"),
+        "business_key": business_key
+    }
+    # call provider (placeholder)
+    if PROVIDER_API:
+        headers = {"Authorization": f"Bearer {PROVIDER_KEY}", "Content-Type": "application/json"}
+        r = requests.post(PROVIDER_API + "/envelopes", headers=headers, json=req_payload, timeout=10)
+        r.raise_for_status()
+        resp = r.json()
+        return jsonify({"ok": True, "provider_resp": resp})
+    else:
+        # simulate provider acceptance and return an id
+        return jsonify({"ok": True, "provider_resp": {"id": "simulated-123", "status": "sent"}})
+
+@app.route("/callback", methods=["POST"])
+def provider_callback():
+    # provider posts completion events; verify with shared secret or signature
+    sig = request.headers.get("X-Provider-Signature", "")
+    payload = request.get_data()
+    # simple HMAC verification if provided
+    import hmac, hashlib
+    if CALLBACK_SECRET:
+        mac = hmac.new(CALLBACK_SECRET.encode(), payload, hashlib.sha256).hexdigest()
+        if not hmac.compare_digest(mac, sig):
+            return jsonify({"ok": False, "error": "invalid signature"}), 401
+    data = request.json or {}
+    business_key = data.get("business_key")
+    signer = data.get("signer", {}).get("email")
+    doc_ref = data.get("document")
+    status = data.get("status")
+    signature_blob = data.get("signature")  # Base64 or URL to signed PDF
+    # record via signoff_manager with key business_key
+    if status == "completed" and business_key:
+        rec = record_signoff(business_key, signer or "esign-provider", doc_ref or "provider-doc", comment="e-sign completed", signature=signature_blob)
+        return jsonify({"ok": True, "record": rec})
+    return jsonify({"ok": False, "error": "not completed or missing business key"}), 400
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", "8095")))
+
*** End Patch
*** Begin Patch
*** Add File:k8s/compliance/esign_adapter_deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-esign-adapter
+  namespace: aegis-system
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-esign-adapter
+  template:
+    metadata:
+      labels:
+        app: aegis-esign-adapter
+    spec:
+      containers:
+        - name: esign
+          image: python:3.11-slim
+          command: ["sh","-c","pip install flask requests && python /opt/aegis/esign_adapter.py"]
+          env:
+            - name: ESIGN_API_URL
+              value: ""
+            - name: ESIGN_API_KEY
+              valueFrom:
+                secretKeyRef:
+                  name: esign-secrets
+                  key: api_key
+            - name: ESIGN_CALLBACK_SECRET
+              valueFrom:
+                secretKeyRef:
+                  name: esign-secrets
+                  key: callback_secret
+          volumeMounts:
+            - name: code
+              mountPath: /opt/aegis
+      volumes:
+        - name: code
+          hostPath:
+            path: ./ops/compliance
+            type: Directory
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-esign-adapter
+  namespace: aegis-system
+spec:
+  selector:
+    app: aegis-esign-adapter
+  ports:
+    - port: 8095
+      targetPort: 8095
+
*** End Patch
*** Begin Patch
*** Add File:ops/chaos/chaos_validation_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-chaos-validate-
+spec:
+  entrypoint: chaos-validate
+  templates:
+    - name: chaos-validate
+      steps:
+        - - name: delete-milvus-pod
+            template: delete-milvus
+        - - name: run-milvus-failover-test
+            template: milvus-failover
+        - - name: run-dcgm-attribution
+            template: dcgm-attrib
+        - - name: run-rlhf-bench
+            template: rlhf-bench
+        - - name: simulate-circuit-trip
+            template: circuit-trip
+        - - name: restore-circuit
+            template: restore-circuit
+
+    - name: delete-milvus
+      container:
+        image: bitnami/kubectl:latest
+        command: [sh, -c]
+        args:
+          - |
+            set -e
+            POD=$(kubectl -n milvus get pods -l app.kubernetes.io/instance=milvus -o jsonpath='{.items[0].metadata.name}' || true)
+            if [ -n "$POD" ]; then
+              kubectl -n milvus delete pod "$POD" --grace-period=0 --force || true
+              echo "deleted pod $POD"
+            else
+              echo "no milvus pod found"
+            fi
+
+    - name: milvus-failover
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - pip install requests && python /opt/aegis/milvus/failover_test.sh || true
+      volumeMounts:
+        - name: code
+          mountPath: /opt/aegis
+
+    - name: dcgm-attrib
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - pip install requests && python /opt/aegis/carbon/run_attribution_experiment.sh || true
+      volumeMounts:
+        - name: code
+          mountPath: /opt/aegis
+
+    - name: rlhf-bench
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - pip install requests && python /opt/aegis/generative/rlhf/rlhf_benchmark_suite.py --bench-file /data/rlhf_bench.jsonl --out /tmp/rlhf_report.json || true
+      volumeMounts:
+        - name: data
+          mountPath: /data
+        - name: code
+          mountPath: /opt/aegis
+
+    - name: circuit-trip
+      container:
+        image: bitnami/kubectl:latest
+        command: [sh, -c]
+        args:
+          - |
+            kubectl -n kube-system create configmap aegis-autonomy-circuit --from-literal=state=open --dry-run=client -o yaml | kubectl apply -f -
+            echo "circuit set to open"
+
+    - name: restore-circuit
+      container:
+        image: bitnami/kubectl:latest
+        command: [sh, -c]
+        args:
+          - |
+            sleep 30
+            kubectl -n kube-system create configmap aegis-autonomy-circuit --from-literal=state=closed --dry-run=client -o yaml | kubectl apply -f -
+            echo "circuit restored to closed"
+
+  volumes:
+    - name: code
+      hostPath:
+        path: ./ops
+        type: Directory
+    - name: data
+      persistentVolumeClaim:
+        claimName: rlhf-data-pvc
+
*** End Patch
*** Begin Patch
*** Add File:docs/runbooks/chaos_and_autonomy_validation.md
+# Chaos & Autonomy Validation Runbook
+
+Purpose
+-------
+Use the Argo chaos validation workflow to validate autonomy safety by injecting faults, running attribution experiments, RLHF benchmarks and ensuring circuit-breaker and invariants protect the system.
+
+Prereqs
+--------
+- Argo (workflows) installed and reachable.
+- Kubernetes access with kubectl configured.
+- Ops repo checked out on a runner where Argo has access to templates (or push manifests to cluster).
+- Required PVCs (rlhf-data-pvc), buckets and secrets in place.
+
+Run the chaos validation
+-----------------------
+1. Submit the workflow:
+   kubectl -n argo apply -f ops/chaos/chaos_validation_workflow.yaml
+   argo submit -n argo -f ops/chaos/chaos_validation_workflow.yaml
+
+2. Monitor steps:
+   argo watch <workflow-name>
+   argo logs -w <workflow-name> -c main
+
+What it does
+------------
+- Deletes a Milvus pod to validate failover and p95 targets.
+- Runs the Milvus failover test (ops/milvus/failover_test.sh).
+- Runs the DCGM attribution experiment (ops/carbon/run_attribution_experiment.sh).
+- Runs the RLHF bench suite and writes a report.
+- Simulates a circuit breaker trip and then restores it; ensures the controller respects circuit state.
+
+Acceptance criteria
+-------------------
+- Milvus recovers and search p95 within target after failover.
+- DCGM attribution MAE within threshold versus Prometheus mapping for representative jobs.
+- RLHF bench passes thresholds (hallucination & latency). If RLHF fails, workflow suspends (or reports failure).
+- Circuit-breaker trip prevents auto-promote actions during the open window (no pending promotions completed).
+
+Next steps on failures
+----------------------
+- Investigate logs in /var/log/<component> or kubectl logs for failing pods.
+- Inspect attestations and audit records in /var/lib/aegis/auto_promote_audit.
+- If circuit opened unexpectedly, inspect Prometheus metrics for anomalies and adjust thresholds or roll back recent promotions.
+
*** End Patch
*** End Patch
