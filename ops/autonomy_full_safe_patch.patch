*** Begin Patch
*** Add File:ops/autonomy/autonomy_manager.py
+#!/usr/bin/env python3
+"""
+Autonomy Level Manager
+
+Stores and retrieves per-namespace autonomy levels in a ConfigMap:
+  aegis-autonomy-level (namespace: kube-system)
+
+Levels:
+  none        - no autonomous actions allowed
+  supervised  - automation allowed for low-risk ops only
+  supervised-plus - medium risk with attestations
+  autonomous  - highest level; requires signed attestations and strong metrics
+
+This is an operator tool (CLI) used by humans and by controllers to read the policy.
+"""
+import os
+import sys
+import json
+from kubernetes import client, config
+
+CM_NAME = "aegis-autonomy-level"
+CM_NS = "kube-system"
+
+def load_k8s():
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    return client.CoreV1Api()
+
+def get_levels():
+    core = load_k8s()
+    try:
+        cm = core.read_namespaced_config_map(CM_NAME, CM_NS)
+        data = cm.data or {}
+    except client.exceptions.ApiException:
+        data = {}
+    return data
+
+def set_level(namespace, level):
+    core = load_k8s()
+    try:
+        cm = core.read_namespaced_config_map(CM_NAME, CM_NS)
+        cm.data = cm.data or {}
+        cm.data[namespace] = level
+        core.replace_namespaced_config_map(CM_NAME, CM_NS, cm)
+    except client.exceptions.ApiException:
+        body = client.V1ConfigMap(metadata=client.V1ObjectMeta(name=CM_NAME), data={namespace: level})
+        core.create_namespaced_config_map(CM_NS, body)
+
+def delete_level(namespace):
+    core = load_k8s()
+    try:
+        cm = core.read_namespaced_config_map(CM_NAME, CM_NS)
+        if namespace in (cm.data or {}):
+            del cm.data[namespace]
+            core.replace_namespaced_config_map(CM_NAME, CM_NS, cm)
+    except Exception:
+        pass
+
+def cli():
+    if len(sys.argv) < 2:
+        print("usage: autonomy_manager.py get|set|list|delete [namespace] [level]")
+        sys.exit(2)
+    cmd = sys.argv[1]
+    if cmd == "get":
+        ns = sys.argv[2]
+        levels = get_levels()
+        print(levels.get(ns, "none"))
+    elif cmd == "set":
+        ns = sys.argv[2]; lvl = sys.argv[3]
+        set_level(ns, lvl)
+        print("set", ns, lvl)
+    elif cmd == "list":
+        print(json.dumps(get_levels(), indent=2))
+    elif cmd == "delete":
+        ns = sys.argv[2]
+        delete_level(ns)
+        print("deleted", ns)
+
+if __name__ == "__main__":
+    cli()
+
*** End Patch
*** Begin Patch
*** Add File:ops/autonomy/hil_attestor.py
+#!/usr/bin/env python3
+"""
+HIL Attestor:
+
+ - Collects HIL test results (logs/artifacts)
+ - Runs a basic verifier (scriptable checks)
+ - Produces a signed attestation JSON (cosign-compatible stub)
+ - Stores attestation as a Kubernetes Secret and optionally uploads artifact to S3
+
+This script intentionally requires operator invocation (or Argo job) to create attestations;
+controllers must require attestations before acting.
+"""
+import os
+import sys
+import json
+import subprocess
+import tempfile
+from datetime import datetime
+try:
+    from kubernetes import client, config
+    config.load_incluster_config()
+except Exception:
+    try:
+        config.load_kube_config()
+    except Exception:
+        client = None
+
+ATT_DIR = os.environ.get("HIL_DIR", "/var/lib/aegis/hil")
+S3_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
+ATTEST_SECRET = os.environ.get("ATTEST_SECRET", "aegis-hil-attest")
+
+def run_checks(artifacts_dir):
+    # Placeholder: operator can extend with domain-specific checks.
+    # We run a simple presence/exit-code checks.
+    results = {"passed": True, "checks": []}
+    # e.g., look for files test_summary.json with {"status": "ok"}
+    sfile = os.path.join(artifacts_dir, "test_summary.json")
+    if os.path.exists(sfile):
+        try:
+            with open(sfile) as fh:
+                data = json.load(fh)
+            ok = data.get("status") == "ok"
+            results["checks"].append({"file": sfile, "ok": ok})
+            results["passed"] = results["passed"] and ok
+        except Exception as e:
+            results["checks"].append({"file": sfile, "error": str(e)})
+            results["passed"] = False
+    else:
+        results["checks"].append({"file": sfile, "ok": False, "reason":"missing"})
+        results["passed"] = False
+    return results
+
+def sign_attestation(attest_path, key_ref=None):
+    # Try to sign using cosign if present (operator must configure cosign)
+    if not shutil.which("cosign"):
+        # produce unsigned attestation but mark as unsigned
+        return {"signed": False, "path": attest_path}
+    cmd = ["cosign", "sign-blob", "-key", key_ref or os.environ.get("COSIGN_KEY",""), attest_path]
+    try:
+        out = subprocess.check_output(cmd, stderr=subprocess.STDOUT)
+        return {"signed": True, "cosign_output": out.decode()}
+    except Exception as e:
+        return {"signed": False, "error": str(e)}
+
+def store_attestation_k8s(name, ns, attestation_json):
+    if client is None:
+        return False
+    core = client.CoreV1Api()
+    body = client.V1Secret(metadata=client.V1ObjectMeta(name=name, namespace=ns), string_data={"attestation.json": json.dumps(attestation_json)})
+    try:
+        core.create_namespaced_secret(ns, body)
+    except client.exceptions.ApiException:
+        core.replace_namespaced_secret(name, ns, body)
+    return True
+
+def upload_to_s3(path, key):
+    try:
+        import boto3
+        s3 = boto3.client("s3")
+        s3.upload_file(path, S3_BUCKET, key)
+        return True
+    except Exception as e:
+        return False
+
+def cli():
+    import argparse, shutil
+    p = argparse.ArgumentParser()
+    p.add_argument("--artifacts", default=ATT_DIR)
+    p.add_argument("--name", required=True, help="attestation id/name")
+    p.add_argument("--namespace", default="aegis-system")
+    p.add_argument("--upload-s3", action="store_true")
+    args = p.parse_args()
+    artifacts = args.artifacts
+    checks = run_checks(artifacts)
+    attest = {"id": args.name, "ts": datetime.utcnow().isoformat()+"Z", "checks": checks}
+    # write attestation file
+    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".json")
+    tmp.write(json.dumps(attest).encode())
+    tmp.close()
+    # sign (best-effort)
+    signed = {"signed": False}
+    try:
+        signed = sign_attestation(tmp.name)
+    except Exception:
+        signed = {"signed": False}
+    attest["signature"] = signed
+    # store in k8s secret
+    stored = store_attestation_k8s(args.name, args.namespace, attest)
+    if args.upload_s3 and S3_BUCKET:
+        upload_to_s3(tmp.name, f"hil/{args.name}.json")
+    print(json.dumps({"attestation": attest, "stored": stored}))
+
+if __name__ == "__main__":
+    cli()
+
*** End Patch
*** Begin Patch
*** Add File:ops/autonomy/attestation_service.py
+#!/usr/bin/env python3
+"""
+Attestation verification service (HTTP)
+
+ - Exposes /verify/<attestation_id> which returns whether attestation exists and if signature verified.
+ - Uses Kubernetes Secrets (attestation stored by hil_attestor) or S3 as fallback.
+ - Signature verification uses cosign verify-blob if available; otherwise returns unsigned status.
+"""
+from flask import Flask, jsonify
+import os, json, subprocess
+try:
+    from kubernetes import client, config
+    config.load_incluster_config()
+    core = client.CoreV1Api()
+except Exception:
+    core = None
+
+ATTEST_SECRET_PREFIX = os.environ.get("ATTEST_SECRET_PREFIX","aegis-hil-attest")
+S3_BUCKET = os.environ.get("EVIDENCE_BUCKET","")
+
+app = Flask(__name__)
+
+def get_attestation_from_k8s(name, ns="aegis-system"):
+    if core is None:
+        return None
+    try:
+        s = core.read_namespaced_secret(name, ns)
+        data = s.string_data or {k: v.decode() for k,v in (s.data or {}).items()}
+        raw = data.get("attestation.json") or (s.data.get("attestation.json") if s.data else None)
+        if isinstance(raw, bytes):
+            raw = raw.decode()
+        return json.loads(raw) if raw else None
+    except Exception:
+        return None
+
+def verify_signature(attest_path):
+    # best-effort use cosign to verify; operators should configure cosign public key
+    if not shutil.which("cosign"):
+        return {"verified": False, "reason": "cosign_missing"}
+    cmd = ["cosign", "verify-blob", "-key", os.environ.get("COSIGN_PUB",""), "-signature", attest_path + ".sig", attest_path]
+    try:
+        out = subprocess.check_output(cmd, stderr=subprocess.STDOUT)
+        return {"verified": True, "output": out.decode()}
+    except Exception as e:
+        return {"verified": False, "error": str(e)}
+
+@app.route("/verify/<attest_id>", methods=["GET"])
+def verify(attest_id):
+    # try k8s secret
+    att = get_attestation_from_k8s(attest_id)
+    if not att and S3_BUCKET:
+        # fallback: not implemented - call to S3 could be added
+        pass
+    if not att:
+        return jsonify({"found": False}), 404
+    # check signature presence (best-effort)
+    sig = att.get("signature", {})
+    verified = sig.get("signed", False)
+    return jsonify({"found": True, "attestation": att, "verified": verified})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT","8088")))
+
*** End Patch
*** Begin Patch
*** Add File:ops/autonomy/historical_success_service.py
+#!/usr/bin/env python3
+"""
+Historical Success Scoring Service
+
+ - Loads a trained model from VERIFIER_MODEL_OUT (joblib pickle)
+ - Exposes a /score endpoint to score a plan (JSON)
+ - Exposes a /train endpoint (POST) to trigger training using existing audit logs (calls ops/agentic/train_historical_success.py)
+"""
+from flask import Flask, request, jsonify
+import os, joblib, threading, subprocess, json
+
+MODEL_PATH = os.environ.get("VERIFIER_MODEL_OUT", "/var/lib/aegis/verifier/model.pkl")
+AUDIT_DIR = os.environ.get("AGENT_AUDIT_DIR", "/var/lib/aegis/agent_audit")
+
+app = Flask(__name__)
+model = None
+
+def load_model():
+    global model
+    try:
+        model = joblib.load(MODEL_PATH)
+    except Exception:
+        model = None
+
+@app.route("/score", methods=["POST"])
+def score():
+    data = request.json or {}
+    plan = data.get("plan", [])
+    # naive featurize (should match training featurize)
+    steps = len(plan)
+    kubectl = sum(1 for s in plan if s.get("tool")=="kubectl" or "kubectl" in s.get("params",{}).get("cmd",""))
+    feat = [[steps, kubectl]]
+    if model:
+        prob = float(model.predict_proba(feat)[0][1])
+    else:
+        prob = 0.5
+    return jsonify({"score": prob})
+
+@app.route("/train", methods=["POST"])
+def train():
+    # spawn a background job to train
+    def do_training():
+        subprocess.run(["python", "ops/agentic/train_historical_success.py"], check=False)
+        load_model()
+    threading.Thread(target=do_training).start()
+    return jsonify({"started": True})
+
+if __name__ == "__main__":
+    load_model()
+    app.run(host="0.0.0.0", port=int(os.environ.get("PORT","8090")))
+
*** End Patch
*** Begin Patch
*** Add File:ops/autonomy/circuit_breaker.py
+#!/usr/bin/env python3
+"""
+Simple circuit-breaker monitor:
+ - Queries Prometheus for anomaly metrics (operator-configurable)
+ - Sets ConfigMap aegis-autonomy-circuit in kube-system with state "open" (tripped) or "closed"
+ - Controllers should consult this ConfigMap and refuse autonomous actions when open
+"""
+import os
+import time
+import json
+import requests
+from kubernetes import client, config
+
+CM_NAME = "aegis-autonomy-circuit"
+CM_NS = "kube-system"
+PROM_URL = os.environ.get("PROM_URL", "http://prometheus:9090")
+ANOMALY_QUERY = os.environ.get("ANOMALY_QUERY", 'sum(rate(http_request_errors_total[1m]))')
+POLL_S = int(os.environ.get("CIRCUIT_POLL_S", "15"))
+
+def set_state(state):
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    core = client.CoreV1Api()
+    body = client.V1ConfigMap(metadata=client.V1ObjectMeta(name=CM_NAME), data={"state": state})
+    try:
+        core.replace_namespaced_config_map(CM_NAME, CM_NS, body)
+    except client.exceptions.ApiException:
+        try:
+            core.create_namespaced_config_map(CM_NS, body)
+        except Exception:
+            pass
+
+def query_prom(q):
+    try:
+        r = requests.get(f"{PROM_URL}/api/v1/query", params={"query": q}, timeout=5)
+        r.raise_for_status()
+        data = r.json().get("data",{}).get("result",[])
+        if not data:
+            return 0.0
+        return float(data[0].get("value",[0,0])[1])
+    except Exception:
+        return 0.0
+
+def main():
+    while True:
+        val = query_prom(ANOMALY_QUERY)
+        # trip threshold (operator-tunable)
+        if val > float(os.environ.get("CIRCUIT_TRIP_THRESHOLD","1.0")):
+            set_state("open")
+        else:
+            set_state("closed")
+        time.sleep(POLL_S)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/autonomy/invariants_runtime.py
+#!/usr/bin/env python3
+"""
+Runtime invariants & guarded executor
+
+Provides check_plan(plan) and guarded execute wrapper that consults:
+ - invariants (ops/agentic/invariants.json)
+ - circuit-breaker ConfigMap
+ - autonomy level for the target namespace
+
+The execute_tool function will refuse to run if any guard fails.
+"""
+import os, json, re, subprocess
+from kubernetes import client, config
+
+INVAR_FILE = os.environ.get("AGENT_INVARIANTS", "ops/agentic/invariants.json")
+CM_AUTONOMY = ("aegis-autonomy-level", "kube-system")
+CM_CIRCUIT = ("aegis-autonomy-circuit", "kube-system")
+
+def load_invariants():
+    if os.path.exists(INVAR_FILE):
+        with open(INVAR_FILE) as fh:
+            return json.load(fh)
+    return {"forbid": [], "require": []}
+
+def check_plan(plan):
+    inv = load_invariants()
+    violations=[]
+    for step in plan:
+        cmd = step.get("params",{}).get("cmd","") or step.get("cmd","")
+        for rule in inv.get("forbid", []):
+            if rule.get("type")=="substring" and rule.get("value") in cmd:
+                violations.append({"rule": rule, "cmd": cmd})
+            if rule.get("type")=="regex" and re.search(rule.get("value"), cmd):
+                violations.append({"rule": rule, "cmd": cmd})
+    return violations
+
+def get_configmap(name, ns):
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    core = client.CoreV1Api()
+    try:
+        cm = core.read_namespaced_config_map(name, ns)
+        return cm.data or {}
+    except Exception:
+        return {}
+
+def execute_tool(step, namespace="default", require_autonomy_level="supervised"):
+    # Validate invariants
+    violations = check_plan([step])
+    if violations:
+        return {"ok": False, "reason": "invariants", "violations": violations}
+    # check circuit breaker
+    circ = get_configmap(CM_CIRCUIT[0], CM_CIRCUIT[1]).get("state","closed")
+    if circ == "open":
+        return {"ok": False, "reason": "circuit_open"}
+    # check autonomy level for namespace
+    levels = get_configmap(CM_AUTONOMY[0], CM_AUTONOMY[1])
+    ns_level = levels.get(namespace, "none")
+    order = ["none","supervised","supervised-plus","autonomous"]
+    if order.index(ns_level) < order.index(require_autonomy_level):
+        return {"ok": False, "reason": "insufficient_autonomy_level", "level": ns_level}
+    # if all good, execute in sandbox (call sandbox_executor)
+    try:
+        cmd = step.get("params",{}).get("cmd","")
+        p = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=int(os.environ.get("SANDBOX_TIMEOUT", "60")))
+        return {"ok": True, "rc": p.returncode, "stdout": p.stdout, "stderr": p.stderr}
+    except Exception as e:
+        return {"ok": False, "reason": str(e)}
+
+def get_configmap(name, ns):
+    try:
+        config.load_incluster_config()
+    except Exception:
+        try:
+            config.load_kube_config()
+        except Exception:
+            return {}
+    core = client.CoreV1Api()
+    try:
+        cm = core.read_namespaced_config_map(name, ns)
+        return cm.data or {}
+    except Exception:
+        return {}
+
+if __name__=="__main__":
+    print("invariants_runtime loaded")
+
*** End Patch
*** Begin Patch
*** Add File:ops/autonomy/auto_promote_controller.py
+#!/usr/bin/env python3
+"""
+Metrics-driven Auto-Promote Controller (safe)
+
+Watches for Argo Workflows (or a promotion queue) with label aegis/auto-promote=pending.
+For each candidate, it requires:
+ - namespace autonomy level >= required
+ - attestation present and verified
+ - historical-success score >= threshold
+ - recent metrics (Prometheus) within thresholds
+ - circuit-breaker closed
+ - cooldown window elapsed
+
+On success: performs promotion action (kubectl apply or helm upgrade) and records an audit entry
+that includes the attestation id and model artifact reference.
+
+This controller is intentionally conservative and requires signed attestations and metrics.
+"""
+import os
+import time
+import json
+import subprocess
+import requests
+from kubernetes import client, config
+
+PROM_URL = os.environ.get("PROM_URL","http://prometheus:9090")
+ATT_SERVICE = os.environ.get("ATTESTATION_SERVICE","http://aegis-attest:8088")
+HIST_SERVICE = os.environ.get("HIST_SERVICE","http://aegis-hist:8090")
+NAMESPACE = os.environ.get("ARGO_NS","argo")
+POLL_S = int(os.environ.get("AUTO_PROMOTE_POLL_S","30"))
+SCORE_THRESH = float(os.environ.get("HIST_SCORE_THRESH","0.75"))
+COOLDOWN_S = int(os.environ.get("PROMOTE_COOLDOWN_S","3600"))
+AUDIT_DIR = os.environ.get("AUTOMATION_AUDIT_DIR","/var/lib/aegis/auto_promote_audit")
+
+def load_k8s():
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    return client.CustomObjectsApi(), client.CoreV1Api()
+
+def list_candidates():
+    api, core = load_k8s()
+    try:
+        res = api.list_namespaced_custom_object(group="argoproj.io", version="v1alpha1", namespace=NAMESPACE, plural="workflows")
+        items = res.get("items", [])
+        # find those labeled aegis/auto-promote=pending
+        return [w for w in items if w.get("metadata",{}).get("labels",{}).get("aegis/auto-promote")=="pending"]
+    except Exception:
+        return []
+
+def get_autonomy_level(namespace):
+    core = load_k8s()[1]
+    try:
+        cm = core.read_namespaced_config_map("aegis-autonomy-level","kube-system")
+        return (cm.data or {}).get(namespace, "none")
+    except Exception:
+        return "none"
+
+def verify_attestation(attest_id):
+    try:
+        r = requests.get(f"{ATT_SERVICE}/verify/{attest_id}", timeout=10)
+        if r.status_code == 200:
+            j = r.json()
+            return j.get("verified", False) or j.get("attestation",{}).get("signature",{}).get("signed",False)
+    except Exception:
+        return False
+    return False
+
+def score_plan(plan):
+    try:
+        r = requests.post(f"{HIST_SERVICE}/score", json={"plan": plan}, timeout=5)
+        r.raise_for_status()
+        return float(r.json().get("score",0.5))
+    except Exception:
+        return 0.5
+
+def metrics_ok(expr, threshold):
+    try:
+        r = requests.get(f"{PROM_URL}/api/v1/query", params={"query": expr}, timeout=5)
+        r.raise_for_status()
+        res = r.json().get("data",{}).get("result",[])
+        if not res:
+            return True
+        val = float(res[0].get("value",[0,0])[1])
+        return val <= float(threshold)
+    except Exception:
+        return False
+
+def promote_workflow(wf):
+    # read promotion annotation for artifact path or manifest
+    meta = wf.get("metadata",{})
+    ann = meta.get("annotations",{})
+    manifest = ann.get("aegis.promote.manifest")
+    helm_release = ann.get("aegis.promote.helm_release")
+    try:
+        if manifest:
+            subprocess.check_call(["kubectl","apply","-f", manifest])
+        elif helm_release and ann.get("aegis.promote.helm_chart"):
+            chart = ann.get("aegis.promote.helm_chart")
+            subprocess.check_call(["helm","upgrade", "--install", helm_release, chart])
+        else:
+            return False, "no promotion target"
+        return True, "promoted"
+    except Exception as e:
+        return False, str(e)
+
+def audit_record(wf_name, details):
+    os.makedirs(AUDIT_DIR, exist_ok=True)
+    fname = os.path.join(AUDIT_DIR, f"promote_audit_{int(time.time())}.json")
+    rec = {"wf": wf_name, "ts": int(time.time()), "details": details}
+    with open(fname,"w") as fh:
+        json.dump(rec, fh)
+    return fname
+
+def main_loop():
+    while True:
+        candidates = list_candidates()
+        for wf in candidates:
+            name = wf.get("metadata",{}).get("name")
+            ns = wf.get("metadata",{}).get("namespace","default")
+            print("considering", name)
+            level = get_autonomy_level(ns)
+            if level == "none":
+                print("autonomy level none; skipping", name); continue
+            ann = wf.get("metadata",{}).get("annotations",{})
+            attest_id = ann.get("aegis.hil.attestation")
+            if not attest_id:
+                print("no attestation; skipping", name); continue
+            if not verify_attestation(attest_id):
+                print("attestation not verified; skipping", name); continue
+            plan = wf.get("spec",{})
+            score = score_plan(plan)
+            if score < SCORE_THRESH:
+                print("historical success too low", score); continue
+            # check simple metric (example: latency)
+            latency_ok = metrics_ok(os.environ.get("PROM_LATENCY_QUERY","histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))"), os.environ.get("PROM_LATENCY_THRESH","0.5"))
+            if not latency_ok:
+                print("latency bad; skipping")
+                continue
+            # check circuit breaker
+            core = load_k8s()[1]
+            try:
+                cm = core.read_namespaced_config_map("aegis-autonomy-circuit","kube-system")
+                if (cm.data or {}).get("state","closed") == "open":
+                    print("circuit open; skipping")
+                    continue
+            except Exception:
+                pass
+            # check cooldown file
+            last_promo_file = os.path.join(AUDIT_DIR, f"last_promo_{ns}.txt")
+            if os.path.exists(last_promo_file):
+                last = os.path.getmtime(last_promo_file)
+                if time.time() - last < COOLDOWN_S:
+                    print("cooldown active; skipping")
+                    continue
+            ok, reason = promote_workflow(wf)
+            details = {"promoted": ok, "reason": reason, "attestation": attest_id, "score": score}
+            audit_path = audit_record(name, details)
+            with open(last_promo_file,"w") as fh:
+                fh.write(str(time.time()))
+            print("audit", audit_path)
+        time.sleep(POLL_S)
+
+if __name__ == "__main__":
+    main_loop()
+
*** End Patch
*** Begin Patch
*** Add File:k8s/autonomy/auto_promote-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-auto-promote
+  namespace: aegis-system
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-auto-promote
+  template:
+    metadata:
+      labels:
+        app: aegis-auto-promote
+    spec:
+      containers:
+        - name: auto-promote
+          image: python:3.11-slim
+          command: ["sh","-c","pip install requests kubernetes boto3 && python /opt/aegis/auto_promote_controller.py"]
+          env:
+            - name: PROM_URL
+              value: "http://prometheus:9090"
+            - name: ATT_SERVICE
+              value: "http://aegis-attest.aegis-system.svc.cluster.local:8088"
+            - name: HIST_SERVICE
+              value: "http://aegis-hist.aegis-system.svc.cluster.local:8090"
+          volumeMounts:
+            - name: code
+              mountPath: /opt/aegis
+      volumes:
+        - name: code
+          hostPath:
+            path: ./ops/autonomy
+            type: Directory
+
*** End Patch
*** Begin Patch
*** Add File:k8s/autonomy/services-deploy.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-attestation
+  namespace: aegis-system
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-attestation
+  template:
+    metadata:
+      labels:
+        app: aegis-attestation
+    spec:
+      containers:
+        - name: attest
+          image: python:3.11-slim
+          command: ["sh","-c","pip install flask kubernetes boto3 && python /opt/aegis/attestation_service.py"]
+          volumeMounts:
+            - name: code
+              mountPath: /opt/aegis
+      volumes:
+        - name: code
+          hostPath:
+            path: ./ops/autonomy
+            type: Directory
+---
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-hist
+  namespace: aegis-system
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-hist
+  template:
+    metadata:
+      labels:
+        app: aegis-hist
+    spec:
+      containers:
+        - name: hist
+          image: python:3.11-slim
+          command: ["sh","-c","pip install flask joblib scikit-learn && python /opt/aegis/historical_success_service.py"]
+          volumeMounts:
+            - name: code
+              mountPath: /opt/aegis
+      volumes:
+        - name: code
+          hostPath:
+            path: ./ops/autonomy
+            type: Directory
+---
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-circuit
+  namespace: aegis-system
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-circuit
+  template:
+    metadata:
+      labels:
+        app: aegis-circuit
+    spec:
+      containers:
+        - name: circuit
+          image: python:3.11-slim
+          command: ["sh","-c","pip install requests kubernetes && python /opt/aegis/circuit_breaker.py"]
+          volumeMounts:
+            - name: code
+              mountPath: /opt/aegis
+      volumes:
+        - name: code
+          hostPath:
+            path: ./ops/autonomy
+            type: Directory
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/auto_promote_pipeline.yml
+name: Auto Promote Pipeline (safe)
+
+on:
+  workflow_dispatch:
+    inputs:
+      workflow_name:
+        description: 'Argo workflow name to consider promoting'
+        required: true
+      attest_id:
+        description: 'HIL attestation id'
+        required: true
+
+jobs:
+  validate-and-queue:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+      - name: Run staging validation
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG }}
+        run: |
+          python ops/validation/stage_validation_runner.py
+      - name: Add label to workflow to mark pending promotion
+        env:
+          KUBECONFIG: ${{ secrets.KUBECONFIG }}
+        run: |
+          kubectl -n argo label workflow ${ { github.event.inputs.workflow_name } } aegis/auto-promote=pending --overwrite || true
+          kubectl -n argo annotate workflow ${ { github.event.inputs.workflow_name } } aegis.hil.attestation=${ { github.event.inputs.attest_id } } --overwrite
+      - name: Request manual approval
+        uses: actions/manual-approval@v1
+        with:
+          github-token: ${{ secrets.GITHUB_TOKEN }}
+
*** End Patch
*** Begin Patch
*** Add File:docs/runbooks/autonomy_increase_playbook.md
+# Autonomy Increase Playbook (safe path to higher autonomy)
+
+Overview
+--------
+This playbook describes the safe sequence to raise autonomy for a namespace or workload.
+
+Steps
+1) Prepare HIL attestations
+   - Run HIL tests and create attestations using ops/autonomy/hil_attestor.py --name <id> --artifacts /path/to/artifacts
+   - Verify via attestation service: curl http://aegis-attest:8088/verify/<id>
+
+2) Ensure historical-success model trained
+   - Trigger training: curl -X POST http://aegis-hist:8090/train
+   - Confirm model exists at VERIFIER_MODEL_OUT and scores acceptable on sample plans.
+
+3) Set autonomy level for namespace
+   - ops/autonomy/autonomy_manager.py set <namespace> supervised-plus
+
+4) Run staging validation
+   - python ops/validation/stage_validation_runner.py
+
+5) Use GitHub action to enqueue promote and request approval
+   - Use .github/workflows/auto_promote_pipeline.yml dispatch with workflow_name + attest_id
+
+6) Monitor
+   - Circuit breaker will trip on anomalies (aegis-autonomy-circuit ConfigMap)
+   - Audit records stored in AUTOMATION_AUDIT_DIR
+
+Rollback
+--------
+ - Flip autonomy level to "none" via autonomy_manager
+ - Delete pending labels on workflows and run rollback_playbook if necessary
+
*** End Patch
*** End Patch
