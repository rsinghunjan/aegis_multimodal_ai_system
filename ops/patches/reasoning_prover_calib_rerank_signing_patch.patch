*** Begin Patch
*** Add File:ops/formal/targeted_prover_z3.py
+#!/usr/bin/env python3
+"""
+Targeted prover using Z3.
+ - Scans SMT-LIB stubs produced by invariant_authoring_tool and attempts to discharge them with Z3.
+ - Writes a proof certificate (JSON) per invariant to VERIFIER_LOG_DIR and returns structured result.
+ - Produces artifacts that invariant_coverage reporter and proof_certifier can use.
+"""
+import os
+import subprocess
+import json
+from datetime import datetime
+
+SMT_DIR = os.environ.get("INVARIANT_SMT_DIR", "/tmp/invariant_smt")
+VERIF_LOG_DIR = os.environ.get("VERIFIER_LOG_DIR", "/tmp/verifier_logs")
+Z3_BIN = os.environ.get("Z3_BIN", "z3")  # must be on PATH or override
+
+os.makedirs(VERIF_LOG_DIR, exist_ok=True)
+
+def prove_smt(smt_path, timeout_s=30):
+    name = os.path.splitext(os.path.basename(smt_path))[0]
+    outpath = os.path.join(VERIF_LOG_DIR, f"{name}.proof.json")
+    result = {"id": name, "smt": smt_path, "proved": False, "error": None, "ts": datetime.utcnow().isoformat()+"Z"}
+    try:
+        # call z3 with proof output; using (proof) options might vary by version
+        # We'll ask for proof and use timeout.
+        proc = subprocess.Popen([Z3_BIN, "-smt2", smt_path, f"-T:{int(timeout_s)}"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+        out, err = proc.communicate(timeout=timeout_s+5)
+        stdout = out.decode(errors="ignore")
+        stderr = err.decode(errors="ignore")
+        result["stdout"] = stdout[:10000]
+        result["stderr"] = stderr[:10000]
+        code = proc.returncode
+        # heuristics: Z3 prints "unsat" when proof of safety property (negated conjecture) succeeded.
+        if "unsat" in stdout.lower() or "unsat" in stderr.lower():
+            result["proved"] = True
+        else:
+            result["proved"] = False
+        # write proof artifact
+        json.dump(result, open(outpath, "w"), indent=2)
+    except subprocess.TimeoutExpired:
+        result["error"] = "timeout"
+        json.dump(result, open(outpath, "w"), indent=2)
+    except Exception as e:
+        result["error"] = str(e)
+        json.dump(result, open(outpath, "w"), indent=2)
+    return result
+
+def prove_all(timeout_s=30):
+    res = []
+    if not os.path.exists(SMT_DIR):
+        return res
+    for fn in os.listdir(SMT_DIR):
+        if not fn.endswith(".smt2"):
+            continue
+        path = os.path.join(SMT_DIR, fn)
+        r = prove_smt(path, timeout_s=timeout_s)
+        res.append(r)
+    return res
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--timeout", type=int, default=30)
+    args = p.parse_args()
+    print(json.dumps(prove_all(timeout_s=args.timeout), indent=2))
+
*** End Patch
*** Begin Patch
*** Add File:ops/formal/prover_orchestrator.py
+#!/usr/bin/env python3
+"""
+Orchestrator to attempt proving invariants from registry and update registry with results.
+ - Reads INVARIANT_REGISTRY_PATH, finds SMT stubs in INVARIANT_SMT_DIR, runs targeted_prover_z3, and annotates registry entries.
+ - Produces a summary report.
+"""
+import os
+import json
+from datetime import datetime
+from ops.formal.targeted_prover_z3 import prove_all, VERIF_LOG_DIR
+
+REGISTRY = os.environ.get("INVARIANT_REGISTRY_PATH", "ops/formal/invariant_registry.json")
+SMT_DIR = os.environ.get("INVARIANT_SMT_DIR", "/tmp/invariant_smt")
+OUT_SUMMARY = os.environ.get("PROVER_SUMMARY_OUT", "/tmp/prover_summary.json")
+
+def load_registry():
+    if os.path.exists(REGISTRY):
+        return json.load(open(REGISTRY))
+    return {}
+
+def save_registry(r):
+    open(REGISTRY, "w").write(json.dumps(r, indent=2))
+
+def run_and_annotate():
+    registry = load_registry()
+    results = prove_all()
+    # annotate registry by id
+    for r in results:
+        inv_id = r["id"]
+        rec = registry.get(inv_id, {})
+        rec["last_prover_result"] = {"proved": bool(r.get("proved")), "ts": datetime.utcnow().isoformat()+"Z", "proof_artifact": os.path.join(VERIF_LOG_DIR, f"{inv_id}.proof.json")}
+        registry[inv_id] = rec
+    save_registry(registry)
+    summary = {"ts": datetime.utcnow().isoformat()+"Z", "results": results}
+    open(OUT_SUMMARY, "w").write(json.dumps(summary, indent=2))
+    return summary
+
+if __name__ == "__main__":
+    print(json.dumps(run_and_annotate(), indent=2))
+
*** End Patch
*** Begin Patch
*** Add File:ops/carbon/calibration_collector.py
+#!/usr/bin/env python3
+"""
+Calibration collector and aggregator.
+ - Scans NODE_POWER_DIR for per-node JSONL samples produced by node_power_exporter.
+ - Aggregates samples by instance_type tag (from node meta or job meta provided) and computes avg watts and standard deviation.
+ - Updates CARBON_CALIB_PATH with aggregated per-instance calibration and uncertainty estimate.
+"""
+import os
+import json
+import math
+from collections import defaultdict
+from datetime import datetime
+
+NODE_POWER_DIR = os.environ.get("NODE_POWER_DIR", "/tmp/node_power")
+CALIB_OUT = os.environ.get("CARBON_CALIB_PATH", "/etc/aegis/carbon_calibration.json")
+NODE_META_DIR = os.environ.get("AEGIS_JOB_DIR", "/tmp/aegis_jobs")  # source for job meta -> instance mapping
+
+def aggregate():
+    # collect per-node samples
+    agg = defaultdict(list)
+    if not os.path.exists(NODE_POWER_DIR):
+        print("no node power dir", NODE_POWER_DIR)
+        return {}
+    for fn in os.listdir(NODE_POWER_DIR):
+        if not fn.endswith(".jsonl"):
+            continue
+        node = fn.replace("node_power_","").replace(".jsonl","")
+        path = os.path.join(NODE_POWER_DIR, fn)
+        try:
+            with open(path) as fh:
+                for line in fh:
+                    s = json.loads(line)
+                    # try to attach instance type: best-effort from job meta file per node
+                    instance_type = s.get("instance_type") or "generic"
+                    # if node meta available in AEGIS_JOB_DIR, attempt to read
+                    agg[instance_type].append({"host_w": s.get("host_watts") or 0.0, "gpu_w": s.get("gpu_watts") or 0.0})
+        except Exception:
+            continue
+    # compute stats
+    calib = {}
+    for inst, samples in agg.items():
+        host_vals = [s["host_w"] for s in samples]
+        gpu_vals = [s["gpu_w"] for s in samples]
+        def stats(vals):
+            if not vals:
+                return {"count":0,"mean":0.0,"std":0.0}
+            n = len(vals)
+            mean = sum(vals)/n
+            var = sum((x-mean)**2 for x in vals)/n
+            return {"count": n, "mean": mean, "std": math.sqrt(var)}
+        h = stats(host_vals)
+        g = stats(gpu_vals)
+        # uncertainty: combined relative std
+        rel_unc = max(0.0, min(1.0, (h["std"]/max(1e-6,h["mean"]) if h["mean"] else 1.0 + g["std"]/max(1e-6,g["mean"]) if g["mean"] else 1.0) / 2.0))
+        calib[inst] = {"host": h, "gpu": g, "uncertainty_pct": rel_unc, "samples": sum(1 for _ in samples)}
+    os.makedirs(os.path.dirname(CALIB_OUT), exist_ok=True)
+    open(CALIB_OUT, "w").write(json.dumps({"ts": datetime.utcnow().isoformat()+"Z", "calibration": calib}, indent=2))
+    print("Wrote calibration DB to", CALIB_OUT)
+    return calib
+
+if __name__ == "__main__":
+    aggregate()
+
*** End Patch
*** Begin Patch
*** Add File:k8s/jobs/calibration_job.yaml
+apiVersion: batch/v1
+kind: Job
+metadata:
+  name: aegis-calibration
+  namespace: aegis-retriever
+spec:
+  template:
+    metadata:
+      name: aegis-calibration
+    spec:
+      nodeSelector:
+        dedicated: calibration
+      tolerations:
+        - operator: "Exists"
+      containers:
+        - name: calibration
+          image: aegis/carbon-tools:latest
+          command: ["python", "ops/carbon/calibration_runner.py", "--instance", "calib-instance", "--node", "$(NODE_NAME)"]
+          env:
+            - name: NODE_NAME
+              valueFrom:
+                fieldRef:
+                  fieldPath: spec.nodeName
+      restartPolicy: Never
+  backoffLimit: 0
+
*** End Patch
*** Begin Patch
*** Add File:ops/retrieval/cross_encoder.py
+#!/usr/bin/env python3
+"""
+Cross-encoder reranker wrapper using sentence-transformers if available.
+ - Fallbacks to simple overlap scoring when model not available.
+ - Provides a cross_encoder_fn(query, text)->score in [0,1] suitable for ops/retrieval/reranker.py
+"""
+import os
+try:
+    from sentence_transformers import CrossEncoder
+except Exception:
+    CrossEncoder = None
+import math
+
+MODEL = os.environ.get("CROSS_ENCODER_MODEL", "cross-encoder/ms-marco-MiniLM-L-6-v2")
+_model = None
+
+def load_model():
+    global _model
+    if _model is None and CrossEncoder:
+        try:
+            _model = CrossEncoder(MODEL)
+        except Exception:
+            _model = None
+    return _model
+
+def cross_encoder_fn(query: str, text: str) -> float:
+    m = load_model()
+    if m:
+        try:
+            score = m.predict([(query, text)])[0]
+            # normalize if model outputs arbitrary scores (ms-marco variant returns 0..1)
+            return float(score)
+        except Exception:
+            pass
+    # fallback: simple token overlap
+    qset = set(query.lower().split())
+    tset = set(text.lower().split())
+    if not qset:
+        return 0.0
+    overlap = len(qset.intersection(tset))
+    union = len(qset.union(tset))
+    return overlap / union if union else 0.0
+
+if __name__ == "__main__":
+    print(cross_encoder_fn("what is braking distance", "braking distance increases roughly with the square of speed"))
+
*** End Patch
*** Begin Patch
*** Add File:ops/causal/dowhy_adapter.py
+#!/usr/bin/env python3
+"""
+DoWhy adapter for causal estimation and counterfactual reasoning.
+ - Uses dowhy if available, otherwise falls back to the lightweight SCM in causal_reasoner.py
+ - Exposes estimate_effect and simple_counterfactual APIs
+"""
+import os
+import json
+try:
+    import dowhy
+    from dowhy import CausalModel
+    DOWHY_AVAILABLE = True
+except Exception:
+    DOWHY_AVAILABLE = False
+from ops.causal.causal_reasoner import SCM, counterfactual_query
+
+def estimate_effect_dowhy(data_df, treatment, outcome, common_causes):
+    if not DOWHY_AVAILABLE:
+        raise RuntimeError("dowhy not available")
+    model = CausalModel(data=data_df, treatment=treatment, outcome=outcome, common_causes=common_causes)
+    identified_estimand = model.identify_effect()
+    estimate = model.estimate_effect(identified_estimand, method_name="backdoor.linear_regression")
+    return estimate.value
+
+def counterfactual(model_name, factual: dict, intervention: dict):
+    if DOWHY_AVAILABLE:
+        # advanced flows would build DataFrame and model; for now delegate to SCM fallback
+        return counterfactual_query(model_name, factual, intervention)
+    else:
+        return counterfactual_query(model_name, factual, intervention)
+
+if __name__ == "__main__":
+    print("DoWhy adapter available:", DOWHY_AVAILABLE)
+
*** End Patch
*** Begin Patch
*** Add File:ops/verifier/proof_certifier.py
+#!/usr/bin/env python3
+"""
+Proof certifier and composer.
+ - Aggregates Z3 proof artifacts produced under VERIFIER_LOG_DIR and composes a certificate JSON.
+ - Optionally signs the certificate using ops/evidence/sign_evidence.py (stub HSM or PEM signing).
+"""
+import os
+import json
+from datetime import datetime
+import subprocess
+
+VERIF_LOG_DIR = os.environ.get("VERIFIER_LOG_DIR", "/tmp/verifier_logs")
+CERT_OUT = os.environ.get("PROOF_CERT_OUT", "/tmp/proof_certificate.json")
+SIGN_TOOL = os.environ.get("EVIDENCE_SIGN_TOOL", "python ops/evidence/sign_evidence.py")
+
+def collect_proofs():
+    cert = {"ts": datetime.utcnow().isoformat()+"Z", "proofs": []}
+    if not os.path.exists(VERIF_LOG_DIR):
+        return cert
+    for fn in os.listdir(VERIF_LOG_DIR):
+        if not fn.endswith(".proof.json"):
+            continue
+        try:
+            j = json.load(open(os.path.join(VERIF_LOG_DIR, fn)))
+            cert["proofs"].append(j)
+        except Exception:
+            continue
+    return cert
+
+def write_and_sign():
+    cert = collect_proofs()
+    open(CERT_OUT, "w").write(json.dumps(cert, indent=2))
+    # optionally sign
+    sign = os.environ.get("EVIDENCE_SIGN", "false").lower() in ("1","true")
+    if sign:
+        try:
+            subprocess.check_call(SIGN_TOOL.split() + [CERT_OUT])
+        except Exception:
+            pass
+    return CERT_OUT
+
+if __name__ == "__main__":
+    print("wrote", write_and_sign())
+
*** End Patch
*** Begin Patch
*** Add File:ops/evidence/sign_evidence.py
+#!/usr/bin/env python3
+"""
+Sign an evidence artifact using a PEM private key (or HSM stub).
+ - Usage: python ops/evidence/sign_evidence.py /path/to/archive.zip
+ - If EVIDENCE_PRIVATE_KEY env var points to a file path, we use it; otherwise this is a no-op stub.
+ - Writes <artifact>.sig alongside the artifact.
+"""
+import os
+import sys
+import base64
+from datetime import datetime
+try:
+    from cryptography.hazmat.primitives import hashes
+    from cryptography.hazmat.primitives.asymmetric import padding
+    from cryptography.hazmat.primitives import serialization
+except Exception:
+    # cryptography not available -> fallback to simple HMAC-like stub (not secure)
+    hashes = None
+
+KEY_PATH_ENV = "EVIDENCE_PRIVATE_KEY"
+
+def sign_with_pem(artifact_path, key_path):
+    with open(artifact_path, "rb") as f:
+        data = f.read()
+    with open(key_path, "rb") as kf:
+        key = serialization.load_pem_private_key(kf.read(), password=None)
+    sig = key.sign(data, padding.PKCS1v15(), hashes.SHA256())
+    out = artifact_path + ".sig"
+    open(out, "wb").write(sig)
+    print("Wrote signature", out)
+    return out
+
+def stub_sign(artifact_path):
+    # write a simple signature file with timestamp and sha-like placeholder
+    out = artifact_path + ".sig"
+    open(out, "w").write(f"stub-signed:{os.environ.get('USER','ops')}@{datetime.utcnow().isoformat()}\\n")
+    print("Wrote stub signature", out)
+    return out
+
+def main():
+    if len(sys.argv) < 2:
+        print("usage: sign_evidence.py <artifact>")
+        sys.exit(2)
+    artifact = sys.argv[1]
+    key_path = os.environ.get(KEY_PATH_ENV, "")
+    if key_path and os.path.exists(key_path) and hashes:
+        sign_with_pem(artifact, key_path)
+    else:
+        stub_sign(artifact)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/infra/submit_job_enforced.sh
+#!/usr/bin/env bash
+set -euo pipefail
+MANIFEST="$1"
+# Run the carbon-aware submitter (which enforces schedule/placement policies) before applying
+python ops/carbon/submit_job_carbon_aware.py --manifest "$MANIFEST" --auto-opt || true
+# After submission attempt, apply the manifest to ensure kubectl state (submit_job_carbon_aware may have patched)
+kubectl apply -f "$MANIFEST"
+echo "Submitted manifest $MANIFEST via carbon-aware wrapper"
+
*** End Patch
*** Begin Patch
*** Update File:ops/evidence/evidence_packager.py
@@
 def package(model_name, model_artifact, verification_evidence, provenance, metadata):
     os.makedirs(OUT_DIR, exist_ok=True)
     out_path = os.path.join(OUT_DIR, f"{model_name}_evidence_{int(time.time())}.zip")
     with zipfile.ZipFile(out_path, "w", zipfile.ZIP_DEFLATED) as z:
@@
     # stub signing
-    sig_path = out_path + ".sig"
-    open(sig_path, "w").write("signed-by:ops@aegis\n")
-    return out_path, sig_path
+    sig_path = out_path + ".sig"
+    # try to sign with EVIDENCE_SIGN_TOOL or python signing helper
+    sign = os.environ.get("EVIDENCE_SIGN", "false").lower() in ("1","true")
+    if sign:
+        # call sign_evidence.py if present
+        try:
+            import subprocess
+            subprocess.check_call(["python", "ops/evidence/sign_evidence.py", out_path])
+            sig_path = out_path + ".sig"
+        except Exception:
+            # fallback stub
+            open(sig_path, "w").write("signed-by:ops@aegis\\n")
+    else:
+        open(sig_path, "w").write("signed-by:ops@aegis\\n")
+    return out_path, sig_path
*** End Patch
*** End Patch
