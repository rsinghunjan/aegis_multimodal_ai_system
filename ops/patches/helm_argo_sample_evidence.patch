*** Begin Patch
*** Add File:charts/node-power-exporter/Chart.yaml
+apiVersion: v2
+name: node-power-exporter
+description: A DaemonSet chart to deploy node_power_exporter across the cluster
+type: application
+version: 0.1.0
+appVersion: "1.0"
+
*** End Patch
*** Begin Patch
*** Add File:charts/node-power-exporter/values.yaml
+replicaCount: 1
+image:
+  repository: aegis/node-power-exporter
+  tag: latest
+  pullPolicy: IfNotPresent
+nodeSelector: {}
+tolerations:
+- operator: "Exists"
+resources: {}
+service:
+  enabled: true
+  port: 9203
+serviceMonitor:
+  enabled: true
+  interval: 15s
+  path: /metrics
+
*** End Patch
*** Begin Patch
*** Add File:charts/node-power-exporter/templates/daemonset.yaml
+apiVersion: apps/v1
+kind: DaemonSet
+metadata:
+  name: {{ include "node-power-exporter.fullname" . | default "node-power-exporter" }}
+  labels:
+    app: node-power-exporter
+spec:
+  selector:
+    matchLabels:
+      app: node-power-exporter
+  template:
+    metadata:
+      labels:
+        app: node-power-exporter
+    spec:
+      hostPID: true
+      tolerations:
+{{ toYaml .Values.tolerations | indent 6 }}
+      containers:
+        - name: node-power-exporter
+          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
+          imagePullPolicy: {{ .Values.image.pullPolicy }}
+          env:
+            - name: NODE_POWER_INTERVAL_S
+              value: "15"
+            - name: NODE_POWER_DIR
+              value: "/var/lib/aegis/node_power"
+          volumeMounts:
+            - name: lib
+              mountPath: /var/lib/aegis
+          ports:
+            - containerPort: 9202
+              name: metrics
+      volumes:
+        - name: lib
+          hostPath:
+            path: /var/lib/aegis
+            type: DirectoryOrCreate
+
*** End Patch
*** Begin Patch
*** Add File:charts/node-power-exporter/templates/service.yaml
+{{- if .Values.service.enabled }}
+apiVersion: v1
+kind: Service
+metadata:
+  name: node-power-exporter
+  namespace: {{ .Release.Namespace }}
+  labels:
+    app: node-power-exporter
+  annotations:
+    prometheus.io/scrape: "true"
+    prometheus.io/port: "{{ .Values.service.port }}"
+    prometheus.io/path: "/metrics"
+spec:
+  selector:
+    app: node-power-exporter
+  ports:
+    - name: metrics
+      port: {{ .Values.service.port }}
+      targetPort: 9202
+{{- end }}
+
*** End Patch
*** Begin Patch
*** Add File:charts/node-power-exporter/templates/servicemonitor.yaml
+{{- if .Values.serviceMonitor.enabled }}
+apiVersion: monitoring.coreos.com/v1
+kind: ServiceMonitor
+metadata:
+  name: node-power-monitor
+  namespace: {{ .Release.Namespace }}
+spec:
+  selector:
+    matchLabels:
+      app: node-power-exporter
+  namespaceSelector:
+    matchNames:
+      - {{ .Release.Namespace }}
+  endpoints:
+    - port: metrics
+      interval: {{ .Values.serviceMonitor.interval }}
+      path: {{ .Values.serviceMonitor.path }}
+{{- end }}
+
*** End Patch
*** Begin Patch
*** Add File:charts/node-power-exporter/README.md
+# Node Power Exporter Helm Chart
+
+Deploys node_power_exporter DaemonSet, Service and ServiceMonitor for Prometheus scraping.
+
+Usage:
+
+- Install:
+  helm upgrade --install node-power-exporter charts/node-power-exporter -n aegis-retriever --create-namespace
+
+- Verify:
+  kubectl get ds -n aegis-retriever -l app=node-power-exporter
+  kubectl get svc -n aegis-retriever node-power-exporter
+
*** End Patch
*** Begin Patch
*** Add File:k8s/argo/workflows/model_safety_example.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: model-safety-example-
+  namespace: aegis-retriever
+spec:
+  entrypoint: safety-example
+  templates:
+    - name: safety-example
+      inputs:
+        parameters:
+          - name: model-name
+            value: "toy-model"
+          - name: model-dir
+            value: "models/toy-model"
+          - name: artifact
+            value: "models/toy-model/artifact.txt"
+          - name: tests
+            value: "models/toy-model/tests"
+          - name: invariants
+            value: ""
+      steps:
+        - - name: run-sil
+            template: sil-run
+            arguments:
+              parameters:
+                - name: model-dir
+                  value: "{{inputs.parameters.model-dir}}"
+                - name: tests
+                  value: "{{inputs.parameters.tests}}"
+        - - name: run-verification
+            template: verification
+            arguments:
+              parameters:
+                - name: model
+                  value: "{{inputs.parameters.model-name}}"
+                - name: artifact
+                  value: "{{inputs.parameters.artifact}}"
+                - name: tests
+                  value: "{{inputs.parameters.tests}}"
+        - - name: run-hil
+            template: hil-run
+            when: "{{inputs.parameters.invariants}} != ''"
+            arguments:
+              parameters:
+                - name: artifact
+                  value: "{{inputs.parameters.artifact}}"
+        - - name: package-evidence
+            template: package-evidence
+            arguments:
+              parameters:
+                - name: model
+                  value: "{{inputs.parameters.model-name}}"
+                - name: artifact
+                  value: "{{inputs.parameters.artifact}}"
+        - - name: promote
+            template: promote
+            arguments:
+              parameters:
+                - name: model
+                  value: "{{inputs.parameters.model-name}}"
+                - name: model-dir
+                  value: "{{inputs.parameters.model-dir}}"
+                - name: artifact
+                  value: "{{inputs.parameters.artifact}}"
+                - name: tests
+                  value: "{{inputs.parameters.tests}}"
+
+    - name: sil-run
+      inputs:
+        parameters:
+          - name: model-dir
+          - name: tests
+      container:
+        image: python:3.11-slim
+        command: ["/bin/sh", "-c"]
+        args:
+          - |
+            pip install --no-cache-dir -q -r requirements.txt 2>/dev/null || true
+            python ops/simulation/run_sil.py --model-dir "{{inputs.parameters.model-dir}}" --tests "{{inputs.parameters.tests}}"
+
+    - name: verification
+      inputs:
+        parameters:
+          - name: model
+          - name: artifact
+          - name: tests
+      container:
+        image: python:3.11-slim
+        command: ["/bin/sh", "-c"]
+        args:
+          - |
+            pip install --no-cache-dir requests 2>/dev/null || true
+            python ops/safety/verification_service.py --model "{{inputs.parameters.model}}" --artifact "{{inputs.parameters.artifact}}" --tests "{{inputs.parameters.tests}}"
+
+    - name: hil-run
+      inputs:
+        parameters:
+          - name: artifact
+      container:
+        image: python:3.11-slim
+        command: ["/bin/sh", "-c"]
+        args:
+          - |
+            python ops/hil/run_hil.py --artifact "{{inputs.parameters.artifact}}"
+
+    - name: package-evidence
+      inputs:
+        parameters:
+          - name: model
+          - name: artifact
+      container:
+        image: python:3.11-slim
+        command: ["/bin/sh", "-c"]
+        args:
+          - |
+            python ops/example/generate_sample_evidence.py --model "{{inputs.parameters.model}}" --artifact "{{inputs.parameters.artifact}}"
+
+    - name: promote
+      inputs:
+        parameters:
+          - name: model
+          - name: model-dir
+          - name: artifact
+          - name: tests
+      container:
+        image: python:3.11-slim
+        command: ["/bin/sh", "-c"]
+        args:
+          - |
+            pip install --no-cache-dir requests 2>/dev/null || true
+            python ops/ci/promote_to_safety.py --model "{{inputs.parameters.model}}" --model-dir "{{inputs.parameters.model-dir}}" --artifact "{{inputs.parameters.artifact}}" --tests "{{inputs.parameters.tests}}" --safety-registry "/artifacts/safety-registry"
+
*** End Patch
*** Begin Patch
*** Add File:models/toy-model/metadata.json
+{
+  "model_name": "toy-model",
+  "owner": "alice@example.com",
+  "approver": "safety@example.com",
+  "git_commit": "deadbeef1234567890",
+  "dataset_snapshot": "s3://aegis-data/datasets/toy-ds/snap-2026-01-01",
+  "training_config": {
+    "epochs": 3,
+    "batch_size": 32,
+    "seed": 42
+  },
+  "tests": "models/toy-model/tests",
+  "release_id": "toy-0.1",
+  "instance_type": "g4dn.xlarge",
+  "region": "us-west-2"
+}
+
*** End Patch
*** Begin Patch
*** Add File:models/toy-model/artifact.txt
+This is a placeholder for toy-model artifact.
+In production this would be a model weights file (e.g., .pt, .onnx).
+
*** End Patch
*** Begin Patch
*** Add File:models/toy-model/tests/test_01.json
+{
+  "name": "basic_prediction_check",
+  "description": "Ensure model loads and produces deterministic output for a fixed seed",
+  "input": [1,2,3],
+  "expected_output": [1,0,1]
+}
+
*** End Patch
*** Begin Patch
*** Add File:ops/simulation/run_sil.py
+#!/usr/bin/env python3
+"""
+Simple SIL runner for toy examples.
+ - Loads the artifact (placeholder) and test files then writes a SIL log.
+"""
+import argparse
+import json
+import os
+from datetime import datetime
+
+def run(model_dir, tests_path):
+    os.makedirs("/tmp/sil_logs", exist_ok=True)
+    # Read tests (support directory or single file)
+    tests = []
+    if os.path.isdir(tests_path):
+        for fn in os.listdir(tests_path):
+            if fn.endswith(".json"):
+                tests.append(json.load(open(os.path.join(tests_path, fn))))
+    elif os.path.exists(tests_path):
+        tests = [json.load(open(tests_path))]
+    results = []
+    for t in tests:
+        # trivial deterministic "pass" for demo
+        results.append({"test": t.get("name"), "status": "pass"})
+    out = {"ts": datetime.utcnow().isoformat()+"Z", "model_dir": model_dir, "results": results}
+    path = f"/tmp/sil_logs/sil_{os.path.basename(model_dir)}_{int(datetime.utcnow().timestamp())}.json"
+    with open(path, "w") as fh:
+        json.dump(out, fh, indent=2)
+    print("Wrote SIL log to", path)
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--model-dir", required=True)
+    p.add_argument("--tests", required=True)
+    args = p.parse_args()
+    run(args.model_dir, args.tests)
+
*** End Patch
*** Begin Patch
*** Add File:ops/hil/run_hil.py
+#!/usr/bin/env python3
+"""
+Simple HIL runner stub for demo purposes.
+ - Writes a short log indicating HIL passed.
+"""
+import argparse
+import os
+import json
+from datetime import datetime
+
+def run(artifact):
+    os.makedirs("/tmp/hil_logs", exist_ok=True)
+    out = {"ts": datetime.utcnow().isoformat()+"Z", "artifact": artifact, "status": "pass", "notes": "HIL stub succeeded"}
+    path = f"/tmp/hil_logs/hil_{os.path.basename(artifact)}_{int(datetime.utcnow().timestamp())}.json"
+    with open(path, "w") as fh:
+        json.dump(out, fh, indent=2)
+    print("Wrote HIL log to", path)
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--artifact", required=True)
+    args = p.parse_args()
+    run(args.artifact)
+
*** End Patch
*** Begin Patch
*** Add File:ops/example/generate_sample_evidence.py
+#!/usr/bin/env python3
+"""
+Generate sample verification evidence and call evidence_packager to create a safety evidence zip for the toy model.
+"""
+import argparse
+import os
+import json
+from ops.evidence.evidence_packager import package
+
+def main(model, artifact):
+    # produce a fake verification result
+    verification = {"model": model, "verdict": "pass", "details": "toy verification passed", "ts": "2026-01-09T00:00:00Z"}
+    ver_path = f"/tmp/verification_{model}.json"
+    with open(ver_path, "w") as fh:
+        json.dump(verification, fh, indent=2)
+    # minimal provenance and metadata
+    prov = {"git_commit": "deadbeef123", "dataset_snapshot": "s3://aegis-data/toy"}
+    metadata = {"owner": "alice@example.com", "approver": "safety@example.com", "promoted_at": None}
+    out, sig = package(model, artifact, ver_path, prov, metadata)
+    print("Created evidence:", out, "signature:", sig)
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--model", required=True)
+    p.add_argument("--artifact", required=True)
+    args = p.parse_args()
+    main(args.model, args.artifact)
+
*** End Patch
*** Begin Patch
*** Add File:README.safety_integration.md
+Safety Integration: Deploy Helm, Run Argo Example, Generate Sample Evidence
+-----------------------------------------------------------------------
+
+1) Deploy node-power-exporter Helm chart
+ - helm upgrade --install node-power-exporter charts/node-power-exporter -n aegis-retriever --create-namespace
+ - kubectl get ds -n aegis-retriever -l app=node-power-exporter
+ - Ensure Prometheus ServiceMonitor is discovered
+
+2) Run the Argo example workflow (requires Argo installed)
+ - kubectl apply -f k8s/argo/workflows/model_safety_example.yaml
+ - Start the workflow (example):
+   argo submit -n aegis-retriever -p model-name=toy-model -p model-dir=models/toy-model -p artifact=models/toy-model/artifact.txt -p tests=models/toy-model/tests k8s/argo/workflows/model_safety_example.yaml
+ - Watch logs:
+   argo logs -n aegis-retriever @latest
+
+3) Generate sample evidence locally (without Argo)
+ - python ops/example/generate_sample_evidence.py --model toy-model --artifact models/toy-model/artifact.txt
+ - Evidence zip will be produced under /tmp/safety_evidence
+
+Notes
+ - The SIL/HIL/verification steps here are simple stubs for demonstration. Replace them with your real runners when available.
+ - Ensure job instrumentation (job_wrapper_improved) and node_power_exporter are rolled out in CI and cluster to get full telemetry and carbon accounting.
+
*** End Patch
*** End Patch
