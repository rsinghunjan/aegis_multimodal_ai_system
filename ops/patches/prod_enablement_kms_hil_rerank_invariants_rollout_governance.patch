*** Begin Patch
*** Add File:ops/evidence/kms_vault_ci_helpers.py
+#!/usr/bin/env python3
+"""
+Helpers for CI to validate KMS or Vault signing configuration.
+ - Validate AWS KMS key exists and key policy allows Sign/GetPublicKey (best-effort)
+ - Validate Vault Transit key reachable and can sign (best-effort)
+ - Intended to be run in CI as a quick smoke test prior to enabling signing workflows
+
+Environment:
+ - For AWS: AWS_REGION, AWS_KMS_KEY_ID and AWS credentials in env (or role)
+ - For Vault: VAULT_ADDR, VAULT_TOKEN, VAULT_TRANSIT_KEY
+"""
+import os
+import sys
+import json
+
+def check_aws_kms():
+    try:
+        import boto3
+    except Exception:
+        return {"ok": False, "error": "boto3 not installed"}
+    key_id = os.environ.get("AWS_KMS_KEY_ID")
+    region = os.environ.get("AWS_REGION")
+    if not key_id:
+        return {"ok": False, "error": "AWS_KMS_KEY_ID not set"}
+    try:
+        client = boto3.client("kms", region_name=region)
+        resp = client.describe_key(KeyId=key_id)
+        key_state = resp["KeyMetadata"]["KeyState"]
+        pub = client.get_public_key(KeyId=key_id)
+        return {"ok": True, "key_state": key_state, "has_public_key": "PublicKey" in pub}
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+def check_vault_transit():
+    import requests
+    addr = os.environ.get("VAULT_ADDR")
+    token = os.environ.get("VAULT_TOKEN")
+    key = os.environ.get("VAULT_TRANSIT_KEY")
+    if not addr or not token or not key:
+        return {"ok": False, "error": "VAULT_ADDR/VAULT_TOKEN/VAULT_TRANSIT_KEY not set"}
+    try:
+        url = addr.rstrip("/") + "/v1/sys/health"
+        r = requests.get(url, timeout=5)
+        if r.status_code not in (200, 429):
+            return {"ok": False, "error": f"vault health {r.status_code}"}
+        # try sign a sample payload (not real sensitive)
+        sample = {"input": "c2FtcGxl"}  # "sample" base64
+        sign_url = addr.rstrip("/") + f"/v1/transit/sign/{key}"
+        h = {"X-Vault-Token": token}
+        r2 = requests.post(sign_url, json=sample, headers=h, timeout=10)
+        if r2.status_code != 200:
+            return {"ok": False, "error": f"sign failed {r2.status_code} {r2.text}"}
+        return {"ok": True}
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+def main():
+    backend = os.environ.get("EVIDENCE_SIGN_BACKEND", "stub").lower()
+    if backend == "aws":
+        print(json.dumps(check_aws_kms(), indent=2))
+    elif backend == "vault":
+        print(json.dumps(check_vault_transit(), indent=2))
+    else:
+        print(json.dumps({"ok": True, "info": "stub backend or pem selected - no remote checks performed"}, indent=2))
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/kms_vault_ci_validation.yml
+name: KMS / Vault CI Validation (signing smoke test)
+on:
+  workflow_dispatch:
+
+jobs:
+  validate-signing:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+      - name: Install deps
+        run: |
+          python -m pip install --upgrade pip
+          pip install boto3 requests
+      - name: Run signing backend checks
+        env:
+          EVIDENCE_SIGN_BACKEND: ${{ secrets.EVIDENCE_SIGN_BACKEND }}
+          AWS_KMS_KEY_ID: ${{ secrets.AWS_KMS_KEY_ID }}
+          AWS_REGION: ${{ secrets.AWS_REGION }}
+          VAULT_ADDR: ${{ secrets.VAULT_ADDR }}
+          VAULT_TOKEN: ${{ secrets.VAULT_TOKEN }}
+          VAULT_TRANSIT_KEY: ${{ secrets.VAULT_TRANSIT_KEY }}
+        run: |
+          python ops/evidence/kms_vault_ci_helpers.py
+
*** End Patch
*** Begin Patch
*** Add File:ops/hil/run_hil.py
+#!/usr/bin/env python3
+"""
+HIL runner integration
+ - Integrates with a HIL rack or HIL runner service via REST API
+ - Supports deterministic replay, firmware checks and produces signed logs and artifact hashes
+
+Environment:
+ - HIL_RUNNER_URL: base URL of HIL orchestration service (e.g. https://hil.example.org)
+ - HIL_API_TOKEN: bearer token for HIL runner
+ - HIL_REPLAY_DIR: directory for replay inputs
+
+If HIL_RUNNER_URL is not set, falls back to local stub behavior but still writes deterministic logs.
+"""
+import os
+import json
+import time
+import hashlib
+from datetime import datetime
+
+HIL_RUNNER_URL = os.environ.get("HIL_RUNNER_URL", "")
+HIL_API_TOKEN = os.environ.get("HIL_API_TOKEN", "")
+HIL_REPLAY_DIR = os.environ.get("HIL_REPLAY_DIR", "/tmp/hil_replay")
+LOG_DIR = os.environ.get("HIL_LOG_DIR", "/tmp/hil_logs")
+
+os.makedirs(LOG_DIR, exist_ok=True)
+os.makedirs(HIL_REPLAY_DIR, exist_ok=True)
+
+def sha256_file(path):
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        for chunk in iter(lambda: f.read(8192), b""):
+            h.update(chunk)
+    return h.hexdigest()
+
+def run_local_stub(artifact, seed=None, firmware_version=None, replay_input=None):
+    """
+    Produce deterministic HIL-like log locally. Useful for dev until HIL runner is available.
+    """
+    ts = int(time.time())
+    out = {
+        "artifact": artifact,
+        "seed": seed,
+        "firmware_version": firmware_version,
+        "replay_input": replay_input,
+        "status": "pass",
+        "notes": "local-stub-run",
+        "ts": datetime.utcnow().isoformat()+"Z"
+    }
+    out_path = os.path.join(LOG_DIR, f"hil_{os.path.basename(artifact)}_{ts}.json")
+    with open(out_path, "w") as fh:
+        json.dump(out, fh, indent=2)
+    # create a deterministic "device log" file to hash
+    dev_log = os.path.join(LOG_DIR, f"hil_device_{ts}.log")
+    with open(dev_log, "w") as fh:
+        fh.write(json.dumps(out))
+    return out_path, dev_log
+
+def call_hil_runner(artifact, seed=None, firmware_version=None, replay_input=None, timeout=600):
+    import requests
+    if not HIL_RUNNER_URL:
+        return run_local_stub(artifact, seed=seed, firmware_version=firmware_version, replay_input=replay_input)
+    url = HIL_RUNNER_URL.rstrip("/") + "/api/v1/run"
+    headers = {"Authorization": f"Bearer {HIL_API_TOKEN}"} if HIL_API_TOKEN else {}
+    payload = {
+        "artifact": artifact,
+        "seed": seed,
+        "firmware_version": firmware_version,
+        "replay_input": replay_input
+    }
+    r = requests.post(url, json=payload, headers=headers, timeout=10)
+    r.raise_for_status()
+    job = r.json()
+    job_id = job.get("job_id")
+    # poll status
+    status_url = HIL_RUNNER_URL.rstrip("/") + f"/api/v1/status/{job_id}"
+    start = time.time()
+    while True:
+        r2 = requests.get(status_url, headers=headers, timeout=10)
+        r2.raise_for_status()
+        j = r2.json()
+        if j.get("state") in ("succeeded","failed","error"):
+            # assume runner provides artifact/log path or base64 content
+            logs = j.get("logs", {})
+            ts = int(time.time())
+            out_path = os.path.join(LOG_DIR, f"hil_{artifact.replace('/','_')}_{job_id}_{ts}.json")
+            with open(out_path, "w") as fh:
+                json.dump(j, fh, indent=2)
+            # write device log if present
+            dev_log_path = None
+            if "device_log" in j:
+                dev_log_path = os.path.join(LOG_DIR, f"hil_device_{job_id}_{ts}.log")
+                with open(dev_log_path, "w") as fh:
+                    fh.write(j["device_log"])
+            return out_path, dev_log_path
+        if time.time() - start > timeout:
+            raise TimeoutError("HIL run timed out")
+        time.sleep(5)
+
+def run(artifact, seed=None, firmware_version=None, replay_input=None):
+    out_json, dev_log = call_hil_runner(artifact, seed=seed, firmware_version=firmware_version, replay_input=replay_input)
+    # compute hashes
+    dev_hash = sha256_file(dev_log) if dev_log and os.path.exists(dev_log) else None
+    return {"hil_log": out_json, "device_log": dev_log, "device_log_sha256": dev_hash}
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--artifact", required=True)
+    p.add_argument("--seed", default=None)
+    p.add_argument("--firmware", default=None)
+    p.add_argument("--replay", default=None)
+    args = p.parse_args()
+    print(json.dumps(run(args.artifact, args.seed, args.firmware, args.replay), indent=2))
+
*** End Patch
*** Begin Patch
*** Add File:k8s/argo/workflows/hil_run_template.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: hil-run-
+  namespace: aegis-retriever
+spec:
+  entrypoint: hil-run
+  templates:
+    - name: hil-run
+      inputs:
+        parameters:
+          - name: artifact
+          - name: seed
+          - name: firmware
+          - name: replay
+      container:
+        image: aegis/hil-runner:latest
+        command: ["/bin/sh", "-c"]
+        args:
+          - |
+            python ops/hil/run_hil.py --artifact "{{inputs.parameters.artifact}}" --seed "{{inputs.parameters.seed}}" --firmware "{{inputs.parameters.firmware}}" --replay "{{inputs.parameters.replay}}"
+
*** End Patch
*** Begin Patch
*** Add File:ops/formal/register_invariant.py
+#!/usr/bin/env python3
+"""
+Register an existing SMT file into the invariant registry.
+ - Validates the SMT file exists and writes an entry to ops/formal/invariant_registry.json
+ - Example: python ops/formal/register_invariant.py --id my_inv --smt ops/formal/smt_examples/my_inv.smt2 --tactic interval --desc "desc"
+"""
+import os
+import json
+from datetime import datetime
+
+REG = os.environ.get("INVARIANT_REGISTRY_PATH", "ops/formal/invariant_registry.json")
+
+def load_registry():
+    if os.path.exists(REG):
+        return json.load(open(REG))
+    return {}
+
+def save_registry(r):
+    open(REG, "w").write(json.dumps(r, indent=2))
+
+def register(inv_id, smt_path, tactic="interval", desc=""):
+    if not os.path.exists(smt_path):
+        raise RuntimeError("smt_path does not exist: " + smt_path)
+    r = load_registry()
+    r[inv_id] = {"id": inv_id, "smt": smt_path, "tactic": tactic, "description": desc, "created_at": datetime.utcnow().isoformat()+"Z"}
+    save_registry(r)
+    return r[inv_id]
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--id", required=True)
+    p.add_argument("--smt", required=True)
+    p.add_argument("--tactic", default="interval")
+    p.add_argument("--desc", default="")
+    args = p.parse_args()
+    print("Registering", args.id)
+    print(register(args.id, args.smt, args.tactic, args.desc))
+
*** End Patch
*** Begin Patch
*** Add File:ops/formal/invariant_validator.py
+#!/usr/bin/env python3
+"""
+Validate that registered invariants in invariant_registry.json reference real SMT files,
+have a tactic and are parseable by a simple lint (look for basic SMT-LIB tokens).
+"""
+import os
+import json
+import re
+
+REG = os.environ.get("INVARIANT_REGISTRY_PATH", "ops/formal/invariant_registry.json")
+
+def lint_smt(path):
+    if not os.path.exists(path):
+        return False, "missing"
+    txt = open(path).read(2000)
+    # naive check
+    if "(set-logic" not in txt.lower() and "(declare-fun" not in txt.lower():
+        return False, "no-smt-tokens"
+    return True, ""
+
+def validate():
+    if not os.path.exists(REG):
+        return {"ok": False, "error": "registry missing"}
+    r = json.load(open(REG))
+    issues = {}
+    for k,v in r.items():
+        smt = v.get("smt")
+        tactic = v.get("tactic")
+        if not smt:
+            issues[k] = "missing smt path"
+            continue
+        ok,msg = lint_smt(smt)
+        if not ok:
+            issues[k] = msg
+        if not tactic:
+            issues.setdefault(k, "missing tactic")
+    return {"ok": len(issues)==0, "issues": issues}
+
+if __name__ == "__main__":
+    import sys
+    print(json.dumps(validate(), indent=2))
+    sys.exit(0 if validate().get("ok") else 2)
+
*** End Patch
*** Begin Patch
*** Add File:ops/retrieval/train_reranker.py
+#!/usr/bin/env python3
+"""
+Train a cross-encoder reranker using sentence-transformers' CrossEncoder.
+ - Expects training data as JSONL with fields:
+     {"query":"...", "pos":"positive passage", "neg":"negative passage"}
+ - Produces a saved CrossEncoder model directory for deployment.
+
+Usage:
+  python ops/retrieval/train_reranker.py --train data/train.jsonl --out /tmp/reranker_model --model cross-encoder/ms-marco-MiniLM-L-6-v2
+"""
+import argparse
+import json
+import os
+from sentence_transformers import CrossEncoder, InputExample
+from torch.utils.data import DataLoader
+
+def load_examples(path):
+    examples = []
+    with open(path) as fh:
+        for l in fh:
+            j = json.loads(l)
+            q = j["query"]
+            pos = j["pos"]
+            neg = j.get("neg")
+            # Create InputExample with label 1 for positive pair and 0 for negative
+            examples.append(InputExample(texts=[q, pos], label=1.0))
+            if neg:
+                examples.append(InputExample(texts=[q, neg], label=0.0))
+    return examples
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--train", required=True)
+    p.add_argument("--out", required=True)
+    p.add_argument("--model", default="cross-encoder/ms-marco-MiniLM-L-6-v2")
+    p.add_argument("--epochs", type=int, default=1)
+    p.add_argument("--batch", type=int, default=16)
+    args = p.parse_args()
+
+    examples = load_examples(args.train)
+    model = CrossEncoder(args.model)
+    train_dataloader = DataLoader(examples, shuffle=True, batch_size=args.batch)
+    model.fit(train_dataloader=train_dataloader, epochs=args.epochs, output_path=args.out)
+    print("Saved reranker to", args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/retrieval/reranker_service.py
+#!/usr/bin/env python3
+"""
+Lightweight reranker scoring service
+ - Loads a CrossEncoder model (local path or HF model name) and exposes a simple HTTP API POST /score
+ - Request JSON: {"query":"...","candidates":["text1","text2",...]}
+ - Response: [{"text":"...","score": float}, ...] ordered by score desc
+
+Environment:
+ - RERANKER_MODEL_PATH: path or HF model id (default: cross-encoder/ms-marco-MiniLM-L-6-v2)
+ - PORT: default 8080
+"""
+import os
+import json
+from flask import Flask, request, jsonify
+try:
+    from sentence_transformers import CrossEncoder
+except Exception:
+    CrossEncoder = None
+
+MODEL = os.environ.get("RERANKER_MODEL_PATH", "cross-encoder/ms-marco-MiniLM-L-6-v2")
+PORT = int(os.environ.get("PORT", "8080"))
+
+app = Flask(__name__)
+_model = None
+
+def load_model():
+    global _model
+    if _model is None:
+        if CrossEncoder:
+            _model = CrossEncoder(MODEL)
+        else:
+            _model = None
+    return _model
+
+@app.route("/score", methods=["POST"])
+def score():
+    body = request.get_json() or {}
+    q = body.get("query","")
+    cands = body.get("candidates", [])
+    m = load_model()
+    out = []
+    if m:
+        pairs = [(q, c) for c in cands]
+        scores = m.predict(pairs)
+        for c,s in zip(cands, scores):
+            out.append({"text": c, "score": float(s)})
+    else:
+        # fallback simple overlap
+        qset = set(q.split())
+        for c in cands:
+            tset = set(c.split())
+            score = len(qset.intersection(tset)) / (len(qset.union(tset)) or 1)
+            out.append({"text": c, "score": score})
+    out.sort(key=lambda x: x["score"], reverse=True)
+    return jsonify(out)
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=PORT)
+
*** End Patch
*** Begin Patch
*** Add File:ops/infra/rollout_helper.py
+#!/usr/bin/env python3
+"""
+Rollout helper to deploy node-power-exporter Helm chart cluster-wide and to patch job templates to include job_wrapper_improved.
+ - Accepts a list of kubeconfig files or contexts and applies helm upgrade on each.
+ - Searches a repo path for job definitions and ensures they call job_wrapper_improved.py (best-effort patch).
+
+Usage:
+  python ops/infra/rollout_helper.py --kubeconfigs kube1.yaml,kube2.yaml --helm-release node-power-exporter --chart charts/node-power-exporter
+"""
+import os
+import subprocess
+import argparse
+from glob import glob
+
+def helm_upgrade(kubeconfig, release, chart, namespace="aegis-retriever", extra_args=""):
+    env = os.environ.copy()
+    env["KUBECONFIG"] = kubeconfig
+    cmd = f"helm upgrade --install {release} {chart} -n {namespace} --create-namespace {extra_args}"
+    print("Running:", cmd, "KUBECONFIG=", kubeconfig)
+    subprocess.check_call(cmd, shell=True, env=env)
+
+def enforce_job_wrapper(repo_root="."):
+    # best-effort: find job YAMLs under k8s/ and add a comment if wrapper not present
+    patched = []
+    for fn in glob(os.path.join(repo_root, "**/*.yaml"), recursive=True):
+        if "job" in fn.lower() or "workflow" in fn.lower():
+            txt = open(fn).read()
+            if "job_wrapper_improved.py" not in txt:
+                # insert a comment at top to remind operator to add wrapper
+                with open(fn, "w") as fh:
+                    fh.write("# TODO: ensure heavy jobs use job_wrapper_improved.py wrapper for telemetry and evidence\n" + txt)
+                patched.append(fn)
+    return patched
+
+def main():
+    p = argparse.ArgumentParser()
+    p.add_argument("--kubeconfigs", default="")
+    p.add_argument("--helm-release", default="node-power-exporter")
+    p.add_argument("--chart", default="charts/node-power-exporter")
+    p.add_argument("--repo-root", default=".")
+    args = p.parse_args()
+    kcs = args.kubeconfigs.split(",") if args.kubeconfigs else []
+    for k in kcs:
+        helm_upgrade(k, args.helm_release, args.chart)
+    patched = enforce_job_wrapper(args.repo_root)
+    print("Patched job manifests (added TODO comments) count:", len(patched))
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/ci/enforce_deploy_gate.py
+#!/usr/bin/env python3
+"""
+CI script to enforce that any deployment to safety namespaces includes approved evidence metadata.
+ - Checks Kubernetes manifests in a PR or branch and ensures deployments to namespace 'safety-*' include an annotation:
+     metadata.annotations["aegis/safety-evidence"] = "<evidence-zip-path-or-s3-uri>"
+ - Fails with non-zero exit if missing.
+
+Usage (CI): python ops/ci/enforce_deploy_gate.py --manifests k8s/production/*.yaml
+"""
+import os
+import sys
+import yaml
+from glob import glob
+
+def check_manifest(path):
+    try:
+        docs = list(yaml.safe_load_all(open(path)))
+    except Exception:
+        return False, "not_yaml"
+    for d in docs:
+        if not isinstance(d, dict):
+            continue
+        kind = d.get("kind","")
+        meta = d.get("metadata", {})
+        ns = meta.get("namespace","default")
+        if ns.startswith("safety-"):
+            ann = meta.get("annotations", {})
+            if not ann or not ann.get("aegis/safety-evidence"):
+                return False, f"missing evidence annotation in {path}"
+    return True, ""
+
+def main():
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--manifests", default="k8s/**/*.yaml")
+    args = p.parse_args()
+    files = glob(args.manifests, recursive=True)
+    issues = []
+    for f in files:
+        ok, msg = check_manifest(f)
+        if not ok:
+            issues.append({"file": f, "reason": msg})
+    if issues:
+        print("Deploy gate failed for following manifests:")
+        for i in issues:
+            print(i)
+        sys.exit(2)
+    print("Deploy gate checks passed.")
+    sys.exit(0)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:docs/safety_governance.md
+Safety Governance & SOC Playbook (short)
+======================================
+
+Purpose
+-------
+Define roles, responsibilities, release signoff, incident response and audit retention policies for safety-certified artifacts.
+
+Roles
+- Safety Owner: accountable for the safety case and invariants. Approves promotions to safety registry.
+- Verification Engineer: authors invariants, runs provers, triages verification failures.
+- Release Approver: final signoff for safety release (may be Safety Owner or a committee).
+- Incident Commander: leads incident handling for runtime safety events.
+- SOC/Operations: runs pipelines, monitors, and safety_controller operations.
+
+Release signoff process
+1. Research → Safety Candidate
+   - Model prepared with metadata.json including owner, approver, dataset_snapshot, tests.
+   - Run promotion pipeline: SIL → verification → HIL → prover attempts → evidence bundle.
+2. Evidence review
+   - Verification Engineer attaches provenance.json, verification outputs, prover artifacts and HIL logs.
+   - Safety Owner reviews evidence and signs off in CI (approve workflow dispatch or set approver field).
+3. Promote
+   - On signoff CI moves artifact into safety registry and produces signed evidence bundle. Deployments to safety namespaces only allowed from safety registry artifacts with aegis/safety-evidence annotation.
+
+Incident response (runtime invariant violation)
+1. monitor_agent detects violation → posts to safety_controller (quiesce/fail_closed).
+2. Safety Controller records event and optionally quiesces deployment.
+3. Incident Commander notified; triage begins:
+   - Pull evidence bundle, prover logs, HIL/SIL traces, monitor logs.
+   - Run replay in SIL with same seed where possible.
+4. Containment & rollback: if unsafe, rollback to previous safety artifact and block further promotions until root cause identified.
+5. Postmortem: document timeline, root cause, corrective actions and update invariants/tests.
+
+Audit & retention
+- Evidence bundles and signatures retained for a minimum of 7 years (or per regulation).
+- Proof artifacts, prover logs and HIL logs stored in immutable object store (S3 with object lock or equivalent).
+- Public keys and signing metadata published with each release to allow external verifiers to check signatures.
+
+Change management
+- All changes to invariants or safety-critical code require:
+  - A documented change request
+  - Safety Owner review
+  - Regression SIL/HIL run and evidence bundle produced prior to merge
+
+Periodic audit & drills
+- Quarterly internal audit: run E2E pipeline on a random safety artifact and verify reproducibility.
+- Annual third-party review: share evidence bundles, keys (public) and reproduction instructions with external auditor.
+
*** End Patch
*** End Patch
