*** Begin Patch
*** Add File:ops/hsm/auditor_checklist.md
+# Live CloudHSM Auditor Session Checklist
+
+Purpose: checklist for operators to run during an external HSM auditor session. Record answers and artifacts using auditor_evidence_recorder.py.
+
+Before auditor arrives
+- Ensure CloudHSM cluster(s) are healthy and reachable.
+- Ensure HSM signer service is running and reachable from control plane.
+- Place sample blob at: ops/hsm/audit_sample.bin
+- Ensure EVIDENCE_BUCKET env var is set for upload.
+- Prepare video recording system and obtain URL placeholder.
+
+During session (operator)
+1. Key ceremony (manual) â€” record start/end timestamps, attendee names.
+2. Live sign test:
+   - Run: python ops/hsm/live_auditor_session_orchestrator.py --sample ops/hsm/audit_sample.bin --kms-key-id <key-id> --cluster-id <cluster-id> --notes "ceremony"
+   - Save auditor_report.json and upload.
+3. Demonstrate CloudTrail entries for KMS/CloudHSM operations (show logs).
+4. Produce and upload HSM bundle (index.json present).
+5. Obtain auditor written acceptance (scan or URL).
+
+After session
+- Run auditor_evidence_recorder.py to persist session metadata and video link in ConfigMap.
+- Tag the release/signoff with the auditor signoff ID and attach to release bundle.
+
+Retention
+- Keep evidence bundles and video links for the project retention period and include in release artifact.
+
*** End Patch
*** Begin Patch
*** Add File:ops/hsm/auditor_video_uploader.py
+#!/usr/bin/env python3
+"""
+Upload/record a link to the auditor session recording and attach to signoff entry.
+"""
+import os
+import json
+from kubernetes import client, config
+
+SIGNOFF_CM = os.environ.get("AUDIT_SIGNOFF_CM", "aegis-auditor-signoffs")
+SIGNOFF_NS = os.environ.get("AUDIT_SIGNOFF_NS", "kube-system")
+
+def k8s_client():
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    return client.CoreV1Api()
+
+def attach_video(signoff_id, video_url):
+    core = k8s_client()
+    cm = core.read_namespaced_config_map(SIGNOFF_CM, SIGNOFF_NS)
+    data = cm.data or {}
+    if signoff_id not in data:
+        raise RuntimeError("signoff id not found")
+    entry = json.loads(data[signoff_id])
+    entry["video_link"] = video_url
+    data[signoff_id] = json.dumps(entry)
+    body = client.V1ConfigMap(metadata=client.V1ObjectMeta(name=SIGNOFF_CM), data=data)
+    core.replace_namespaced_config_map(SIGNOFF_CM, SIGNOFF_NS, body)
+    return entry
+
+if __name__=="__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--id", required=True)
+    p.add_argument("--url", required=True)
+    args = p.parse_args()
+    print(attach_video(args.id, args.url))
+
*** End Patch
*** Begin Patch
*** Add File:ops/formal/inventory_invariants.py
+#!/usr/bin/env python3
+"""
+Inventory candidate invariants from code & config heuristics.
+
+ - Scans ops/ for uses of common safety-related variables and creates an invariants skeleton
+ - Helps drive the formal inventory step for Safety/Verification to finalize SMT templates
+"""
+import os
+import re
+import json
+
+ROOT = os.environ.get("REPO_ROOT","./")
+OUT = os.environ.get("INVARIANTS_OUT","ops/formal/invariants_discovered.json")
+
+VARS = ["lateral_accel","long_decel","speed","planner_ms","obstacle_dist","position","controller_gain"]
+
+def scan():
+    found = {}
+    for root,_,files in os.walk(os.path.join(ROOT,"ops")):
+        for f in files:
+            if f.endswith(".py") or f.endswith(".json"):
+                p = os.path.join(root,f)
+                try:
+                    txt = open(p, errors="ignore").read()
+                except Exception:
+                    continue
+                for v in VARS:
+                    if re.search(r"\b"+re.escape(v)+r"\b", txt):
+                        found.setdefault(v, []).append(p)
+    # emit skeleton invariants
+    inv = {}
+    for v,locs in found.items():
+        inv[v] = {"type": "numeric_limit", "variable": v, "op":"le", "value": 0.0, "sources": locs}
+    with open(OUT,"w") as fh:
+        json.dump(inv, fh, indent=2)
+    print("Wrote invariants skeleton to", OUT)
+    return OUT
+
+if __name__=="__main__":
+    scan()
+
*** End Patch
*** Begin Patch
*** Add File:ops/formal/auto_smt_generator.py
+#!/usr/bin/env python3
+"""
+Generate simple Z3 checks from invariants JSON (skeleton) and write per-invariant files for review.
+"""
+import json
+import os
+
+IN = os.environ.get("INVARIANTS_IN","ops/formal/invariants_discovered.json")
+OUT_DIR = os.environ.get("INVARIANTS_SMT_DIR","/tmp/invariants_smt")
+
+TEMPLATE = '''from z3 import Real, Solver, Not, sat
+
+{var}=Real('{var}')
+s = Solver()
+s.add(Not({var} {op} {val}))
+res = s.check()
+print("invariant", "{name}", "status:", res)
+'''
+
+def generate():
+    os.makedirs(OUT_DIR, exist_ok=True)
+    inv = json.load(open(IN))
+    for name, spec in inv.items():
+        var = spec.get("variable", name)
+        op = spec.get("op","le")
+        val = spec.get("value", 0)
+        code = TEMPLATE.format(var=var, op=op, val=val, name=name)
+        path = os.path.join(OUT_DIR, f"{name}.py")
+        with open(path,"w") as fh:
+            fh.write(code)
+    print("Generated SMT stubs at", OUT_DIR)
+    return OUT_DIR
+
+if __name__=="__main__":
+    generate()
+
*** End Patch
*** Begin Patch
*** Add File:ops/validation/asg_tuner_improved.py
+#!/usr/bin/env python3
+"""
+Improved ASG/Nodepool tuner: runs iterative tuning and writes locked config when SLOs stable.
+"""
+import time
+import json
+import os
+from datetime import datetime
+
+LOCK_FILE = os.environ.get("ASG_LOCK_FILE","/tmp/asg_locked_config.json")
+SLO_P95 = float(os.environ.get("TARGET_P95_SEC","5.0"))
+PROM_URL = os.environ.get("PROM_URL","http://prometheus:9090")
+
+def sample_p95(metric="aegis_quantum_sim_p95_latency"):
+    import requests
+    try:
+        r = requests.get(f"{PROM_URL}/api/v1/query", params={"query": metric}, timeout=5)
+        r.raise_for_status()
+        data = r.json().get("data",{}).get("result",[])
+        return float(data[0]["value"][1]) if data else None
+    except Exception:
+        return None
+
+def tune(loop_seconds=30, max_steps=6):
+    # naive stepper: increase desired by 10% until p95 < SLO or max steps
+    desired = int(os.environ.get("GPU_MIN","1"))
+    for step in range(max_steps):
+        print(f"Tuner step {step+1}, desired={desired}")
+        # apply desired via ConfigMap (or external API)
+        cfg = {"desired": desired, "ts": datetime.utcnow().isoformat()+"Z"}
+        with open("/tmp/asg_desired.json","w") as fh:
+            json.dump(cfg, fh)
+        time.sleep(loop_seconds)
+        p95 = sample_p95()
+        print("observed p95:", p95)
+        if p95 is not None and p95 <= SLO_P95:
+            print("SLO met; locking config")
+            with open(LOCK_FILE,"w") as fh:
+                json.dump({"desired": desired, "locked_at": datetime.utcnow().isoformat()+"Z"}, fh)
+            return True
+        desired = int(desired * 1.2) + 1
+    print("Tuning failed to meet SLO after steps")
+    return False
+
+if __name__=="__main__":
+    tune()
+
*** End Patch
*** Begin Patch
*** Add File:ops/providers/adapters_test_suite.py
+#!/usr/bin/env python3
+"""
+Run provider adapter sandbox tests end-to-end and aggregate results.
+"""
+import json
+from datetime import datetime
+from ops.providers.braket_adapter_hardened import BraketHardened
+from ops.providers.ibmq_adapter_hardened import IBMQHardened
+
+OUT = "/tmp/provider_adapter_sandbox_report.json"
+
+def test_braket():
+    b = BraketHardened(sandbox=True)
+    try:
+        res = b.submit_task("arn:aws:braket:::device/mock", "s3://mock/out", {"circuit":"h"}, shots=100)
+        status = b.get_task_status(res.get("quantumTaskArn"))
+        return {"ok": True, "res": res, "status": status}
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+def test_ibmq():
+    i = IBMQHardened(sandbox=True)
+    try:
+        res = i.submit_job("ibmq_qasm_simulator", {"circuit":"h"}, shots=100)
+        status = i.get_status(res.get("job_id"))
+        return {"ok": True, "res": res, "status": status}
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+def run_all():
+    out = {"ts": datetime.utcnow().isoformat()+"Z", "braket": test_braket(), "ibmq": test_ibmq()}
+    with open(OUT,"w") as fh:
+        json.dump(out, fh, indent=2)
+    print("Wrote", OUT)
+    return OUT
+
+if __name__=="__main__":
+    run_all()
+
*** End Patch
*** Begin Patch
*** Add File:ops/ota/device_verifier_harden.py
+#!/usr/bin/env python3
+"""
+Hardened device verification client:
+ - Verifies manifest + signature using cosign public key or HSM verify endpoint
+ - Verifies device state (bootloader/hardware attest) via vendor SDK when available (placeholder)
+"""
+import os
+import subprocess
+import requests
+import json
+
+COSIGN_PUB = os.environ.get("COSIGN_PUB","")
+HSM_VERIFY = os.environ.get("HSM_VERIFY_URL","")
+
+def verify_with_cosign(manifest_path, sig_path, pubkey):
+    cmd = ["cosign","verify-blob","-key",pubkey, manifest_path]
+    try:
+        subprocess.check_call(cmd)
+        return True
+    except Exception:
+        return False
+
+def verify_with_hsm(manifest_path, signature_hex):
+    if not HSM_VERIFY:
+        return False
+    r = requests.post(HSM_VERIFY + "/v1/verify", json={"manifest": open(manifest_path).read(), "signature": signature_hex}, timeout=10)
+    return r.json().get("ok", False)
+
+def verify(manifest_path, signature_hex):
+    if COSIGN_PUB:
+        sigfile = manifest_path + ".sig"
+        open(sigfile,"wb").write(bytes.fromhex(signature_hex))
+        ok = verify_with_cosign(manifest_path, sigfile, COSIGN_PUB)
+        if ok:
+            return True
+    # fallback HSM verify
+    return verify_with_hsm(manifest_path, signature_hex)
+
+if __name__=="__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--manifest", required=True)
+    p.add_argument("--sig", required=True)
+    args = p.parse_args()
+    print("verify ok:", verify(args.manifest, args.sig))
+
*** End Patch
*** Begin Patch
*** Add File:ops/sandbox/seccomp_triage.py
+#!/usr/bin/env python3
+"""
+Parse seccomp matrix results and generate remediation suggestions.
+Input: /tmp/seccomp_matrix_results.csv produced by seccomp matrix CI.
+Output: /tmp/seccomp_triage.json with failures and suggested actions.
+"""
+import csv
+import json
+from collections import defaultdict
+
+IN = "/tmp/seccomp_matrix_results.csv"
+OUT = "/tmp/seccomp_triage.json"
+
+def triage():
+    issues = defaultdict(list)
+    try:
+        with open(IN) as fh:
+            rdr = csv.DictReader(fh)
+            for r in rdr:
+                if r.get("ok","False").lower() not in ("true","1","yes"):
+                    issues[r.get("image")].append(r.get("output"))
+    except Exception:
+        pass
+    suggestions = {}
+    for img, outs in issues.items():
+        suggestions[img] = {"failures": outs, "suggestion": "Review syscalls emitted by image; reduce dependencies; create finer-grained seccomp profile or run in Wasm sandbox."}
+    with open(OUT,"w") as fh:
+        json.dump(suggestions, fh, indent=2)
+    print("Wrote triage to", OUT)
+    return OUT
+
+if __name__=="__main__":
+    triage()
+
*** End Patch
*** Begin Patch
*** Add File:ops/edge/device_profile_registry.py
+#!/usr/bin/env python3
+"""
+Device profile registry: maintain device hardware profiles and preferred model variant mapping.
+"""
+import os
+import json
+REG = "/tmp/device_profile_registry.json"
+
+def ensure():
+    if not os.path.exists(REG):
+        default = {
+            "device-A": {"cpu":"arm64","gpu":"none","mem_mb":2048,"preferred_model":"model-small"},
+            "device-B": {"cpu":"amd64","gpu":"nvidia-tx2","mem_mb":8192,"preferred_model":"model-int8"}
+        }
+        with open(REG,"w") as fh:
+            json.dump(default, fh, indent=2)
+    return REG
+
+def get_profile(device_id):
+    ensure()
+    data = json.load(open(REG))
+    return data.get(device_id)
+
+def register_profile(device_id, profile):
+    ensure()
+    data = json.load(open(REG))
+    data[device_id] = profile
+    with open(REG,"w") as fh:
+        json.dump(data, fh, indent=2)
+    return profile
+
+if __name__=="__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--get")
+    p.add_argument("--register", help="json")
+    args = p.parse_args()
+    if args.get:
+        print(get_profile(args.get))
+    if args.register:
+        print(register_profile(args.register, json.loads(args.register)))
+
*** End Patch
*** Begin Patch
*** Add File:ops/security/ci_sbom_and_scan.py
+#!/usr/bin/env python3
+"""
+CI enforcement script: generate SBOM and run secrets scan. Exit non-zero on failure.
+"""
+import subprocess
+import json
+import sys
+from ops.security.sbom_generator import sbom_from_requirements
+from ops.security.secrets_audit import scan as secrets_scan
+
+def main():
+    sbom = sbom_from_requirements()
+    findings = secrets_scan()
+    if findings:
+        print("Secrets found:", findings)
+        sys.exit(2)
+    print("SBOM generated:", sbom)
+    return 0
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/remediation_ci.yml
+name: Remediation CI Checks
+on:
+  workflow_dispatch:
+  pull_request:
+    types: [opened, synchronize]
+
+jobs:
+  seccomp-matrix:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run Seccomp Matrix (fast)
+        run: |
+          python ops/sandbox/seccomp_matrix_test.py
+      - name: Triager
+        run: |
+          python ops/sandbox/seccomp_triage.py || true
+      - name: Upload results
+        uses: actions/upload-artifact@v4
+        with:
+          name: seccomp-results
+          path: /tmp/seccomp_matrix_results.csv
+
+  providers-sandbox:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Run provider sandbox tests
+        run: |
+          python ops/providers/adapters_test_suite.py
+      - name: Upload report
+        uses: actions/upload-artifact@v4
+        with:
+          name: provider-sandbox-report
+          path: /tmp/provider_adapter_sandbox_report.json
+
+  sbom-secrets:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: SBOM + Secrets scan
+        run: |
+          python ops/security/ci_sbom_and_scan.py
+
*** End Patch
*** Begin Patch
*** Add File:k8s/argo/remediation_full_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-remediation-full-
+spec:
+  entrypoint: remediation-full
+  templates:
+    - name: remediation-full
+      steps:
+        - - name: auditor-session
+            template: auditor-session
+        - - name: fullscale-validation
+            template: fullscale
+        - - name: provider-sandbox
+            template: provider-sandbox
+        - - name: finance-rehearsal
+            template: finance
+        - - name: calibrate-hardware
+            template: calibration
+        - - name: seccomp-ci
+            template: seccomp
+        - - name: sbom-scan
+            template: sbom
+        - - name: package-release
+            template: package
+
+    - name: auditor-session
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - pip install boto3 requests || true
+            python /opt/aegis/ops/hsm/live_auditor_session_orchestrator.py --sample /opt/aegis/ops/hsm/audit_sample.bin || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: fullscale
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - pip install requests || true
+            python /opt/aegis/ops/validation/fullscale_validation_runner.py || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: provider-sandbox
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - pip install boto3 || true
+            python /opt/aegis/ops/providers/adapters_test_suite.py || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: finance
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - pip install google-cloud-bigquery azure-identity azure-mgmt-consumption || true
+            python /opt/aegis/ops/finance/reconcile_signoff_workflow.py || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: calibration
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - pip install numpy || true
+            python /opt/aegis/ops/quantum/hardware_calibration_ci.py --backend sim || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: seccomp
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - python /opt/aegis/ops/sandbox/seccomp_matrix_test.py || true
+            python /opt/aegis/ops/sandbox/seccomp_triage.py || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: sbom
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - python /opt/aegis/ops/security/sbom_generator.py --req requirements.txt || true
+            python /opt/aegis/ops/security/secrets_audit.py || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: package
+      container:
+        image: python:3.11-slim
+        command: [sh,-c]
+        args:
+          - python /opt/aegis/ops/release/run_release_and_signoff.py --manifest /opt/aegis/ops/quantum/sample_manifest.json || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+  volumes:
+    - name: code
+      hostPath:
+        path: ./ops
+        type: Directory
+
*** End Patch
*** End Patch
