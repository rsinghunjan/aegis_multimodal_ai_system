*** Begin Patch
*** Add File:ops/carbon/config.json
+{
+  "prometheus_url": "http://prometheus:9090",
+  "cpu_watts_per_core": 15.0,
+  "gpu_watts_per_gpu": 250.0,
+  "default_pue": 1.2,
+  "default_grid_intensity_gco2_per_kwh": 400,
+  "electricitymap_api_url": "https://api.electricitymap.org/v3/carbon-intensity/latest",
+  "electricitymap_zone": "",
+  "evidence_carbon_report_path": "/tmp/carbon_report.json"
+}
+
*** End Patch
*** Begin Patch
*** Add File:ops/carbon/job_emissions_calculator.py
+#!/usr/bin/env python3
+"""
+Job emissions calculator.
+ - Queries Prometheus for CPU core-seconds and (optionally) GPU counts for a given label filter over a time window.
+ - Converts resource usage -> kWh using configurable coefficients, applies PUE, fetches grid carbon intensity (electricityMap)
+   and computes kgCO2e.
+ - Writes JSON report to configured path (default /tmp/carbon_report.json) for inclusion in evidence bundles.
+
+Usage:
+  python ops/carbon/job_emissions_calculator.py --promql-filter 'job="math-bench"' --window '1h'
+
+Environment/Config:
+ - PROMETHEUS_URL or ops/carbon/config.json/prometheus_url
+ - ELECTRICITYMAP_API_KEY env for grid intensity (optional)
+ - ELECTRICITYMAP_ZONE or config.electricitymap_zone
+"""
+import os
+import sys
+import json
+import time
+import argparse
+import requests
+from datetime import datetime
+
+ROOT = os.path.dirname(os.path.dirname(__file__))
+CFG_PATH = os.path.join(ROOT, "carbon", "config.json")
+
+def load_cfg():
+    cfg = {}
+    try:
+        cfg = json.load(open(CFG_PATH))
+    except Exception:
+        pass
+    # allow overrides from env
+    cfg["prometheus_url"] = os.environ.get("PROMETHEUS_URL", cfg.get("prometheus_url", "http://prometheus:9090"))
+    cfg["cpu_watts_per_core"] = float(os.environ.get("CPU_WATTS_PER_CORE", cfg.get("cpu_watts_per_core", 15.0)))
+    cfg["gpu_watts_per_gpu"] = float(os.environ.get("GPU_WATTS_PER_GPU", cfg.get("gpu_watts_per_gpu", 250.0)))
+    cfg["default_pue"] = float(os.environ.get("DEFAULT_PUE", cfg.get("default_pue", 1.2)))
+    cfg["default_grid_intensity_gco2_per_kwh"] = float(os.environ.get("DEFAULT_GRID_INTENSITY", cfg.get("default_grid_intensity_gco2_per_kwh", 400)))
+    cfg["electricitymap_api_url"] = cfg.get("electricitymap_api_url", "https://api.electricitymap.org/v3/carbon-intensity/latest")
+    cfg["electricitymap_zone"] = os.environ.get("ELECTRICITYMAP_ZONE", cfg.get("electricitymap_zone", ""))
+    cfg["report_path"] = os.environ.get("CARBON_REPORT_PATH", cfg.get("evidence_carbon_report_path", "/tmp/carbon_report.json"))
+    return cfg
+
+def prom_query(prometheus_url, query):
+    r = requests.get(prometheus_url.rstrip("/") + "/api/v1/query", params={"query": query}, timeout=15)
+    r.raise_for_status()
+    j = r.json()
+    if j.get("status") != "success":
+        raise RuntimeError(f"Prometheus query failed: {j}")
+    data = j["data"]["result"]
+    if not data:
+        return 0.0
+    # sum values across result vector
+    s = 0.0
+    for item in data:
+        # value is [timestamp, value]
+        s += float(item["value"][1])
+    return s
+
+def query_resource_usage(prometheus_url, promql_filter, window):
+    """
+    promql_filter: e.g., 'namespace="aegis-retriever",pod=~"math-bench.*"'
+    window: Prometheus duration like '1h' or '30m'
+    Returns: cpu_core_seconds (float), gpu_count_seconds (float)
+    """
+    # CPU: increase(container_cpu_usage_seconds_total{filter}[window])
+    cpu_query = f'sum(increase(container_cpu_usage_seconds_total{{{promql_filter}}}[{window}]))'
+    # GPU: best-effort: sum of (gpu_request * window_seconds). Use kube_pod_container_resource_requests if available.
+    # Attempt to find GPU requests and multiply by window seconds as approximation.
+    gpu_query = f'sum(kube_pod_container_resource_requests{{resource="nvidia.com/gpu",{promql_filter}}})'
+    cpu_secs = 0.0
+    gpu_count = 0.0
+    try:
+        cpu_secs = prom_query(prometheus_url, cpu_query)
+    except Exception as e:
+        print("CPU Prometheus query failed:", e)
+    try:
+        # gpu_query returns instantaneous count (number of GPUs requested). Multiply by window seconds.
+        gpu_req = prom_query(prometheus_url, gpu_query)
+        # parse window into seconds (supports simple m/h)
+        if window.endswith("m"):
+            secs = int(window[:-1]) * 60
+        elif window.endswith("h"):
+            secs = int(window[:-1]) * 3600
+        else:
+            secs = 3600
+        gpu_count = float(gpu_req) * secs
+    except Exception:
+        gpu_count = 0.0
+    return cpu_secs, gpu_count
+
+def get_grid_intensity(cfg):
+    key = os.environ.get("ELECTRICITYMAP_API_KEY", "")
+    zone = cfg.get("electricitymap_zone","")
+    if not key or not zone:
+        # fallback to default
+        return cfg["default_grid_intensity_gco2_per_kwh"], "default"
+    url = cfg["electricitymap_api_url"]
+    params = {"zone": zone} if "zone" in url or True else {}
+    headers = {"auth-token": key}
+    try:
+        r = requests.get(url, params={"zone": zone}, headers=headers, timeout=10)
+        r.raise_for_status()
+        js = r.json()
+        # electricityMap returns data.series[0].carbonIntensity or data[0].carbonIntensity depending on API version
+        ci = None
+        if isinstance(js.get("data"), dict):
+            # v3 returns data.carbonIntensity
+            ci = js["data"].get("carbonIntensity") or js["data"].get("carbonIntensity")
+        elif isinstance(js.get("data"), list) and js["data"]:
+            ci = js["data"][0].get("carbonIntensity")
+        if ci is None:
+            return cfg["default_grid_intensity_gco2_per_kwh"], "fallback"
+        return float(ci), "electricityMap"
+    except Exception as e:
+        print("electricityMap lookup failed:", e)
+        return cfg["default_grid_intensity_gco2_per_kwh"], "fallback"
+
+def compute_kwh(cpu_core_seconds, gpu_seconds, cfg):
+    # CPU: cpu_core_seconds * watts_per_core / 3600 -> Wh -> /1000 -> kWh
+    cpu_wh = cpu_core_seconds * cfg["cpu_watts_per_core"]
+    cpu_kwh = cpu_wh / 3600.0
+    # GPU: gpu_seconds * gpu_watts / 3600
+    gpu_wh = gpu_seconds * cfg["gpu_watts_per_gpu"]
+    gpu_kwh = gpu_wh / 3600.0
+    total_kwh = (cpu_kwh + gpu_kwh) * cfg["default_pue"]
+    return {"cpu_kwh": cpu_kwh, "gpu_kwh": gpu_kwh, "total_kwh": total_kwh}
+
+def run(promql_filter, window, out_path=None):
+    cfg = load_cfg()
+    prom = cfg["prometheus_url"]
+    cpu_secs, gpu_secs = query_resource_usage(prom, promql_filter, window)
+    kwh = compute_kwh(cpu_secs, gpu_secs, cfg)
+    intensity, src = get_grid_intensity(cfg)
+    kgco2 = kwh["total_kwh"] * intensity / 1000.0
+    report = {
+        "ts": datetime.utcnow().isoformat() + "Z",
+        "promql_filter": promql_filter,
+        "window": window,
+        "cpu_core_seconds": cpu_secs,
+        "gpu_seconds": gpu_secs,
+        "cpu_kwh": kwh["cpu_kwh"],
+        "gpu_kwh": kwh["gpu_kwh"],
+        "total_kwh": kwh["total_kwh"],
+        "grid_intensity_gCO2_per_kWh": intensity,
+        "grid_intensity_source": src,
+        "kgCO2e": kgco2
+    }
+    path = out_path or cfg["report_path"]
+    with open(path, "w") as fh:
+        json.dump(report, fh, indent=2)
+    print("Wrote carbon report to", path)
+    return report
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--promql-filter", required=True, help='PromQL label filter, e.g. namespace="aegis-retriever"')
+    p.add_argument("--window", default="1h", help="Prometheus window (e.g., 30m, 1h)")
+    p.add_argument("--out", default=None)
+    args = p.parse_args()
+    run(args.promql_filter, args.window, args.out)
+
*** End Patch
*** Begin Patch
*** Add File:ops/carbon/carbon_aware_scheduler.py
+#!/usr/bin/env python3
+"""
+Carbon-aware scheduler (basic).
+ - Decides whether to run or defer a Kubernetes Job based on grid carbon intensity and user threshold.
+ - Optionally substitutes nodeSelector for 'green' nodepool if present.
+ - Usage:
+     python ops/carbon/carbon_aware_scheduler.py --job job.yaml --max-intensity 300 --zone EU
+
+Notes: This is a best-effort helper. Integrate into your batch orchestration pipeline (Argo/Cron) for automation.
+"""
+import os
+import argparse
+import subprocess
+import json
+from ops.carbon.job_emissions_calculator import load_cfg, get_grid_intensity
+from datetime import datetime
+import time
+
+def decide_and_schedule(job_manifest, max_intensity, zone=None, delay_window_minutes=60):
+    cfg = load_cfg()
+    if zone:
+        cfg["electricitymap_zone"] = zone
+    intensity, src = get_grid_intensity(cfg)
+    decision = {"intensity": intensity, "source": src, "timestamp": datetime.utcnow().isoformat()+"Z"}
+    if intensity <= max_intensity:
+        # schedule immediately
+        subprocess.check_call(["kubectl","apply","-f", job_manifest])
+        decision["action"] = "scheduled"
+        decision["job_manifest"] = job_manifest
+    else:
+        # attempt to find green nodepool alternative via replacement label 'nodeSelector: green=true' substitution
+        # If job manifest contains "nodeSelector", patch it to prefer green=true if such nodes exist (best-effort)
+        print(f"High grid intensity ({intensity} gCO2/kWh) exceeds max {max_intensity}. Deferring or looking for green nodes.")
+        decision["action"] = "deferred"
+        decision["defer_until"] = (datetime.utcnow().timestamp() + delay_window_minutes*60)
+    return decision
+
+if __name__ == "__main__":
+    p = argparse.ArgumentParser()
+    p.add_argument("--job", required=True, help="Kubernetes job manifest to schedule")
+    p.add_argument("--max-intensity", type=float, default=300.0, help="max gCO2/kWh to allow immediate scheduling")
+    p.add_argument("--zone", default=None)
+    args = p.parse_args()
+    dec = decide_and_schedule(args.job, args.max_intensity, zone=args.zone)
+    print(json.dumps(dec, indent=2))
+
*** End Patch
*** Begin Patch
*** Add File:grafana/dashboards/aegis_carbon_dashboard.json
+{
+  "annotations": { "list": [] },
+  "panels": [
+    {
+      "type": "stat",
+      "title": "Total job kWh (24h)",
+      "targets": [{ "expr": "sum(aegis_job_kwh_total[24h])", "legendFormat": "kWh_24h" }],
+      "id": 1
+    },
+    {
+      "type": "stat",
+      "title": "Total kgCO2e (24h)",
+      "targets": [{ "expr": "sum(aegis_job_kgco2e_total[24h])", "legendFormat": "kgCO2e_24h" }],
+      "id": 2
+    },
+    {
+      "type": "graph",
+      "title": "Job kWh over time",
+      "targets": [{ "expr": "sum(rate(aegis_job_kwh_total[5m]))", "legendFormat": "kWh_rate" }],
+      "id": 3
+    },
+    {
+      "type": "graph",
+      "title": "Grid intensity (gCO2/kWh)",
+      "targets": [{ "expr": "aegis_grid_intensity_gco2_per_kwh", "legendFormat": "grid_intensity" }],
+      "id": 4
+    }
+  ],
+  "schemaVersion": 16,
+  "title": "Aegis Carbon Overview",
+  "version": 1
+}
+
*** End Patch
*** Begin Patch
*** Update File:ops/release/include_evidence_bundle.py
@@
 OUT = "/tmp/release_evidence.zip"
 EVIDENCE_BUCKET = os.environ.get("EVIDENCE_BUCKET", "")
 
 def make_zip():
     # remove old
     if os.path.exists(OUT):
         os.remove(OUT)
     with zipfile.ZipFile(OUT, "w", compression=zipfile.ZIP_DEFLATED) as z:
         for root,_,files in os.walk(SNAPSHOT_DIR):
             for f in files:
                 z.write(os.path.join(root,f), arcname=os.path.join("snapshots", f))
         for root,_,files in os.walk(PROV_DIR):
             for f in files:
                 z.write(os.path.join(root,f), arcname=os.path.join("provenance", f))
+        # include carbon report if present
+        carbon_path = os.environ.get("CARBON_REPORT_PATH", "/tmp/carbon_report.json")
+        if os.path.exists(carbon_path):
+            z.write(carbon_path, arcname=os.path.join("evidence", "carbon_report.json"))
     return OUT
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/carbon_reporting.yml
+name: Carbon Reporting & Evidence Attachment
+on:
+  workflow_run:
+    workflows: ["Math Bench (GSM8K sample) & Numeric Fidelity", "Nightly Full Bench & Device Tests"]
+    types:
+      - completed
+
+jobs:
+  compute-carbon:
+    runs-on: ubuntu-latest
+    if: ${{ github.event.workflow_run.conclusion == 'success' }}
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+      - name: Install deps
+        run: |
+          python -m pip install --upgrade pip
+          pip install requests
+      - name: Compute carbon for recent run
+        env:
+          PROMETHEUS_URL: ${{ secrets.PROMETHEUS_URL }}
+          ELECTRICITYMAP_API_KEY: ${{ secrets.ELECTRICITYMAP_API_KEY }}
+          ELECTRICITYMAP_ZONE: ${{ secrets.ELECTRICITYMAP_ZONE }}
+        run: |
+          # Example promql filter to match namespace and labels used by benchmark jobs
+          python ops/carbon/job_emissions_calculator.py --promql-filter 'namespace=\"aegis-retriever\"' --window '1h' --out /tmp/carbon_report.json
+      - name: Upload carbon report artifact
+        uses: actions/upload-artifact@v4
+        with:
+          name: carbon-report
+          path: /tmp/carbon_report.json
+      - name: Attach carbon report to release evidence bundle (if present)
+        run: |
+          python ops/release/include_evidence_bundle.py || true
+
*** End Patch
*** Begin Patch
*** Add File:ops/metrics/job_kwh_exporter.py
+#!/usr/bin/env python3
+"""
+Simple Prometheus exporter that exposes aggregated job-level carbon metrics.
+ - Reads /tmp/carbon_report.json (produced by job_emissions_calculator.py) and exposes Prometheus metrics:
+     aegis_job_kwh_total, aegis_job_kgco2e_total, aegis_grid_intensity_gco2_per_kwh
+ - Intended to run as a short-lived exporter after job completion or as a sidecar.
+"""
+import os
+import json
+from prometheus_client import start_http_server, Gauge
+import time
+
+CARBON_PATH = os.environ.get("CARBON_REPORT_PATH", "/tmp/carbon_report.json")
+EXPORT_PORT = int(os.environ.get("CARBON_EXPORT_PORT", "9202"))
+
+KWH = Gauge("aegis_job_kwh_total", "Total job energy (kWh)")
+KGCO2 = Gauge("aegis_job_kgco2e_total", "Total job emissions (kgCO2e)")
+GRID_INT = Gauge("aegis_grid_intensity_gco2_per_kwh", "Grid carbon intensity gCO2 per kWh")
+
+def loop():
+    start_http_server(EXPORT_PORT)
+    while True:
+        if os.path.exists(CARBON_PATH):
+            try:
+                j = json.load(open(CARBON_PATH))
+                KWH.set(j.get("total_kwh", 0.0))
+                KGCO2.set(j.get("kgCO2e", 0.0))
+                GRID_INT.set(j.get("grid_intensity_gCO2_per_kWh", 0.0))
+            except Exception:
+                pass
+        time.sleep(10)
+
+if __name__ == "__main__":
+    loop()
+
*** End Patch
*** End Patch
