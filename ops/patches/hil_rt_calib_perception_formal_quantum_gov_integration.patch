*** Begin Patch
*** Add File:ops/hil/provision_hil_rack.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Provision a HIL rack and run an integrated smoke test:
+#  - Register rack in registry
+#  - Create replay lock for manifest
+#  - Snapshot firmware (pre)
+#  - Submit run via run_hil_integrated.py
+#  - Run deterministic verification on returned artifacts
+#  - Sign provenance if EVIDENCE_SIGN_BACKEND configured
+#
+# Usage:
+#   ./provision_hil_rack.sh --name rack1 --adapter ops.hil.vendor_impl_example.ExampleVendor --manifest ci/hil/test_manifest.json --firmware-cmd "vendortool --dump /dev/ecu0"
+
+usage() {
+  echo "Usage: $0 --name NAME --adapter ADAPTER_PY --manifest MANIFEST --firmware-cmd CMD"
+  exit 2
+}
+
+NAME=""
+ADAPTER=""
+MANIFEST=""
+FW_CMD=""
+
+while [[ $# -gt 0 ]]; do
+  case "$1" in
+    --name) NAME="$2"; shift 2;;
+    --adapter) ADAPTER="$2"; shift 2;;
+    --manifest) MANIFEST="$2"; shift 2;;
+    --firmware-cmd) FW_CMD="$2"; shift 2;;
+    *) echo "Unknown arg $1"; usage;;
+  esac
+done
+
+[ -n "$NAME" ] || usage
+[ -n "$ADAPTER" ] || usage
+[ -n "$MANIFEST" ] || usage
+
+echo "[1/6] Registering HIL rack $NAME"
+python3 - <<PY
+from ops.hil.hil_provisioning import register_rack, health_check
+print(register_rack("$NAME","$ADAPTER"))
+ok, info = health_check("$ADAPTER")
+print("health:", ok, info)
+PY
+
+echo "[2/6] Creating replay lock"
+LOCK=$(python3 - <<PY
+from ops.hil.hil_provisioning import create_replay_lock
+print(create_replay_lock("$MANIFEST"))
+PY
+)
+echo "Lock created: $LOCK"
+
+echo "[3/6] Running integrated HIL (this may take minutes)"
+RES=$(python3 - <<PY
+from ops.hil.run_hil_integrated import run_integrated
+res = run_integrated("$ADAPTER", "$MANIFEST", lock_path="$LOCK", firmware_dump_cmd="$FW_CMD", sig_prov=True)
+print(res)
+PY
+)
+echo "Run result: $RES"
+
+# try to locate replay meta and hil log from common locations
+REPLAY_META="/tmp/hil_replay/ros_replay_metadata.json"
+HIL_LOG="/tmp/hil_artifacts/hil_log.json"
+
+if [[ -f "$REPLAY_META" && -f "$HIL_LOG" ]]; then
+  echo "[4/6] Running deterministic verification"
+  python3 - <<PY
+from ops.hil.deterministic_verifier import produce_report
+out, sig = produce_report("$REPLAY_META", "$HIL_LOG", "/tmp/hil_artifacts", out_path="/tmp/determinism_report.json", tolerance_ms=10.0)
+print("determinism report:", out, "sig:", sig)
+PY
+else
+  echo "[4/6] Replay meta or hil log not found: skipping deterministic_verifier"
+fi
+
+echo "[5/6] Uploading artifacts & marking provenance (if configured)"
+# In production this step would upload to artifact store; here we just list files
+ls -lah /tmp/hil_artifacts || true
+
+echo "[6/6] Done"
+
*** End Patch
*** Begin Patch
*** Add File:k8s/deployments/hil-runner-deployment.yaml
+apiVersion: v1
+kind: Namespace
+metadata:
+  name: aegis-hil
+---
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-hil-runner
+  namespace: aegis-hil
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-hil-runner
+  template:
+    metadata:
+      labels:
+        app: aegis-hil-runner
+    spec:
+      containers:
+        - name: hil-runner
+          image: ${HIL_RUNNER_IMAGE:-aegis/hil-runner:latest}
+          imagePullPolicy: IfNotPresent
+          ports:
+            - containerPort: 5002
+          env:
+            - name: HIL_SERVER_DIR
+              value: /var/lib/aegis/hil_server
+            - name: PORT
+              value: "5002"
+          volumeMounts:
+            - name: hil-data
+              mountPath: /var/lib/aegis/hil_server
+      volumes:
+        - name: hil-data
+          hostPath:
+            path: /var/lib/aegis/hil_server
+            type: DirectoryOrCreate
+
*** End Patch
*** Begin Patch
*** Add File:ops/rt/prometheus_wcet_reporter.py
+#!/usr/bin/env python3
+"""
+WCET reporter:
+ - Reads /tmp/wcet_report.json (generated by ops/rt/wcet_analyzer.py)
+ - Extracts p95/p99/worst and pushes to Prometheus Pushgateway if configured (PUSHGATEWAY_URL)
+ - Otherwise writes a prometheus text file to /tmp/wcet_latency.prom
+"""
+import os
+import json
+import time
+import requests
+
+WCET_PATH = os.environ.get("WCET_REPORT_PATH", "/tmp/wcet_report.json")
+PUSHGATEWAY = os.environ.get("PUSHGATEWAY_URL", "")
+METRIC_NAME_PREFIX = os.environ.get("METRIC_PREFIX", "aegis_control_loop_latency_seconds")
+OUT_PROM = os.environ.get("WCET_PROM_OUT", "/tmp/wcet_latency.prom")
+
+def format_prom(p95, p99, worst):
+    ts = int(time.time())
+    lines = [
+        f"# HELP {METRIC_NAME_PREFIX}_p95 P95 latency seconds",
+        f"# TYPE {METRIC_NAME_PREFIX}_p95 gauge",
+        f"{METRIC_NAME_PREFIX}_p95 {p95} {ts}",
+        f"# HELP {METRIC_NAME_PREFIX}_p99 P99 latency seconds",
+        f"# TYPE {METRIC_NAME_PREFIX}_p99 gauge",
+        f"{METRIC_NAME_PREFIX}_p99 {p99} {ts}",
+        f"# HELP {METRIC_NAME_PREFIX}_worst Worst-case latency seconds",
+        f"# TYPE {METRIC_NAME_PREFIX}_worst gauge",
+        f"{METRIC_NAME_PREFIX}_worst {worst} {ts}",
+    ]
+    return "\n".join(lines)
+
+def push_to_pushgateway(job, body):
+    if not PUSHGATEWAY:
+        return False
+    url = f"{PUSHGATEWAY}/metrics/job/{job}"
+    try:
+        resp = requests.post(url, data=body, timeout=5)
+        resp.raise_for_status()
+        return True
+    except Exception:
+        return False
+
+def main():
+    if not os.path.exists(WCET_PATH):
+        raise SystemExit(f"Missing wcet report at {WCET_PATH}")
+    j = json.load(open(WCET_PATH))
+    p95 = j.get("p95") or j.get("p95_latency") or j.get("p95_ms", 0.0)
+    p99 = j.get("p99") or j.get("p99_latency") or j.get("p99_ms", 0.0)
+    worst = j.get("max") or j.get("worst") or j.get("max_ms", 0.0)
+    # if units are ms, convert heuristically if >1
+    if p95 and p95 > 10:
+        p95 = float(p95)/1000.0
+    if p99 and p99 > 10:
+        p99 = float(p99)/1000.0
+    if worst and worst > 10:
+        worst = float(worst)/1000.0
+    prom = format_prom(p95, p99, worst)
+    if PUSHGATEWAY:
+        ok = push_to_pushgateway("wcet_report", prom)
+        if ok:
+            print("Pushed to pushgateway")
+            return
+    open(OUT_PROM, "w").write(prom)
+    print("Wrote prom file", OUT_PROM)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/perception/auto_promote_detector.py
+#!/usr/bin/env python3
+"""
+Automatic detector promotion helper:
+ - Verifies evaluation_summary.json is present and signed
+ - Runs perception_promotion_gate.py to validate thresholds
+ - Registers the model in model_registry and attaches provenance pointing to signed evaluation
+ - Calls enforce_release_board.py to ensure governance checks pass
+"""
+import os
+import json
+import subprocess
+
+MODEL_REG = os.environ.get("MODEL_REGISTRY_PATH", "ops/models/model_registry.json")
+
+def run_promotion(eval_summary_path, model_path, model_name, version="0.0.1"):
+    # 1) ensure signed
+    if not os.path.exists(eval_summary_path):
+        raise SystemExit("Missing evaluation summary")
+    if not os.path.exists(eval_summary_path + ".sig"):
+        raise SystemExit("Evaluation summary not signed")
+    # 2) run promotion gate
+    subprocess.check_call(["python","ops/perception/perception_promotion_gate.py"])
+    # 3) register model
+    prov = {"evidence_bundle": eval_summary_path, "evidence_sig": eval_summary_path + ".sig"}
+    subprocess.check_call(["python","ops/models/register_models.py","--name",model_name,"--kind","detector","--endpoint",model_path,"--version",version])
+    # append provenance to registry
+    reg = json.load(open(MODEL_REG))
+    if model_name in reg:
+        reg[model_name]["provenance"] = prov
+        json.dump(reg, open(MODEL_REG,"w"), indent=2)
+    # 4) enforce release board (best-effort; will fail CI if roles missing)
+    subprocess.check_call(["python","ops/governance/enforce_release_board.py", model_name])
+    print("Promotion complete for", model_name)
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--eval", required=True)
+    p.add_argument("--model-path", required=True)
+    p.add_argument("--model-name", required=True)
+    p.add_argument("--version", default="0.0.1")
+    args = p.parse_args()
+    run_promotion(args.eval, args.model_path, args.model_name, args.version)
+
*** End Patch
*** Begin Patch
*** Add File:ops/formal/compose_proofs.py
+#!/usr/bin/env python3
+"""
+Compose proof artifacts into a single composition manifest for auditing.
+ - Reads VERIFIER_LOG_DIR for *.proof.json
+ - Aggregates results into COMPOSE_OUT
+ - Marks overall status (all_proved True/False)
+"""
+import os
+import json
+from glob import glob
+
+VERIF_LOG_DIR = os.environ.get("VERIF_LOG_DIR", "/tmp/verifier_logs")
+COMPOSE_OUT = os.environ.get("COMPOSE_OUT", "/tmp/composed_certificate.json")
+
+def main():
+    artifacts = []
+    all_proved = True
+    for fn in glob(os.path.join(VERIF_LOG_DIR, "*.proof.json")):
+        try:
+            j = json.load(open(fn))
+        except Exception:
+            continue
+        artifacts.append({"file": fn, "result": j})
+        if not j.get("proved", False):
+            all_proved = False
+    out = {"ts": __import__("datetime").datetime.utcnow().isoformat()+"Z", "all_proved": all_proved, "artifacts": artifacts}
+    with open(COMPOSE_OUT, "w") as fh:
+        json.dump(out, fh, indent=2)
+    print("Wrote composed certificate to", COMPOSE_OUT, "all_proved:", all_proved)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/infra/emissions_webhook.py
+#!/usr/bin/env python3
+"""
+Mutating Admission Webhook (skeleton) for emissions-aware placement.
+ - Receives AdmissionReview JSON on /mutate
+ - If pod has annotation aegis/emissions_advisory=true, call emission_scheduler_advisor.recommend to get nodeSelector
+ - Returns a JSON patch to add nodeSelector to pod.spec.template.spec.nodeSelector
+ - NOTE: This is a demo skeleton. Production requires TLS, proper K8s webhook registration, retries and auth.
+"""
+import os
+import json
+from flask import Flask, request, jsonify
+from ops.carbon.emission_scheduler_advisor import recommend
+
+app = Flask(__name__)
+
+@app.route("/mutate", methods=["POST"])
+def mutate():
+    req = request.get_json()
+    try:
+        review = req
+        uid = review["request"]["uid"]
+        obj = review["request"]["object"]
+        meta = obj.get("metadata", {})
+        annotations = meta.get("annotations", {})
+        # only act if advisory present
+        if annotations.get("aegis/emissions_advisory","false").lower() not in ("1","true","yes"):
+            return jsonify({"response":{"uid":uid,"allowed":True}})
+        # derive candidates from annotation or default
+        candidates = [{"instance_type":"generic","node_label_selector":{"aegis/low_emissions":"true"}}]
+        duration = float(annotations.get("aegis/expected_duration_s","3600"))
+        rec = recommend(candidates, duration)
+        chosen = rec.get("chosen")
+        if not chosen:
+            return jsonify({"response":{"uid":uid,"allowed":True}})
+        selector = chosen["candidate"].get("node_label_selector", {})
+        # construct patch to add nodeSelector
+        patch = []
+        # if path exists, replace; else add
+        path = "/spec/nodeSelector"
+        # set nodeSelector
+        value = selector
+        patch.append({"op":"add","path":path,"value":value})
+        resp = {"response": {"uid": uid, "allowed": True, "patchType": "JSONPatch", "patch": (json.dumps(patch)).encode("utf-8").decode("utf-8")}}
+        return jsonify(resp)
+    except Exception as e:
+        return jsonify({"response":{"allowed":False,"status":{"message":str(e)}}})
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=int(os.environ.get("WEBHOOK_PORT","8443")))
+
*** End Patch
*** Begin Patch
*** Add File:k8s/webhooks/emissions_webhook_deployment.yaml
+apiVersion: v1
+kind: Namespace
+metadata:
+  name: aegis-webhook
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: aegis-emissions-webhook
+  namespace: aegis-webhook
+spec:
+  ports:
+    - port: 8443
+      targetPort: 8443
+  selector:
+    app: aegis-emissions-webhook
+---
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-emissions-webhook
+  namespace: aegis-webhook
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-emissions-webhook
+  template:
+    metadata:
+      labels:
+        app: aegis-emissions-webhook
+    spec:
+      containers:
+        - name: webhook
+          image: ${EMISSIONS_WEBHOOK_IMAGE:-aegis/emissions-webhook:latest}
+          imagePullPolicy: IfNotPresent
+          ports:
+            - containerPort: 8443
+          env:
+            - name: REDIS_URL
+              value: ""
+
*** End Patch
*** Begin Patch
*** Add File:ops/quantum/qpu_worker_setup.md
+QPU Worker & Billing â€” Setup notes
+---------------------------------
+This document describes how to start the QPU job queue worker and ensure IAM/billing checks are in place.
+
+1) Ensure you have Redis (optional) or rely on file-based queue for demo.
+2) Configure env:
+   export REDIS_URL=redis://redis:6379
+   export QPU_FALLBACK_TO_SIMULATOR=true
+   export MAX_QPU_JOB_COST_USD=50.0
+   export QPU_ACCOUNT_MONTHLY_LIMIT_USD=1000.0
+
+3) Validate IAM:
+   python ops/quantum/iam_validator.py
+
+4) Start worker:
+   python ops/quantum/qpu_job_queue.py
+
+5) Submit jobs via redis or append to /tmp/qpu_job_queue.jsonl
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/hil_validation_and_promotion.yml
+name: HIL Validation and Promotion Pipeline
+on:
+  workflow_dispatch:
+
+jobs:
+  hil-validate:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+      - name: Install deps
+        run: |
+          python -m pip install --upgrade pip
+          pip install requests
+      - name: Run HIL provisioning script (demo)
+        env:
+          HIL_VENDOR_ADAPTER: ${{ secrets.HIL_VENDOR_ADAPTER }}
+          HIL_VENDOR_URL: ${{ secrets.HIL_VENDOR_URL }}
+          HIL_VENDOR_TOKEN: ${{ secrets.HIL_VENDOR_TOKEN }}
+          EVIDENCE_SIGN_BACKEND: ${{ secrets.EVIDENCE_SIGN_BACKEND }}
+        run: |
+          chmod +x ops/hil/provision_hil_rack.sh
+          ./ops/hil/provision_hil_rack.sh --name ci-rack --adapter "${HIL_VENDOR_ADAPTER}" --manifest "${{ secrets.HIL_TEST_MANIFEST }}" --firmware-cmd "${{ secrets.HIL_FW_DUMP_CMD }}" || true
+      - name: Run deterministic verifier if present
+        run: |
+          if [ -f /tmp/determinism_report.json ]; then
+            cat /tmp/determinism_report.json
+          fi
+      - name: Run perception promotion & governance promotion
+        run: |
+          python ops/perception/perception_promotion_gate.py || true
+          python ops/governance/enforce_release_board.py example-model || true
+
*** End Patch
*** End Patch
