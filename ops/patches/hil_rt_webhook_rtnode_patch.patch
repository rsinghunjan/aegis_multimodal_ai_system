*** Begin Patch
*** Add File:ops/hil/playbook/README.md
+HIL End-to-End Playbook
+=======================
+
+Purpose
+-------
+This playbook contains templates and a convenience script to:
+ - register and provision a HIL rack,
+ - lock replay inputs,
+ - snapshot firmware,
+ - run an integrated HIL job via vendor adapter,
+ - run deterministic verification on artifacts,
+ - sign provenance/evidence, and
+ - (optionally) trigger promotion gates.
+
+Files
+-----
+ - vendor_manifest_template.yaml — vendor manifest template for HIL runs
+ - example_replay_manifest.json  — example replay manifest for CI/dev
+ - hil_end_to_end.py              — orchestrates the full flow
+ - .github/workflows/hil_end_to_end.yml — demo CI that runs the end-to-end flow
+
+Quick start (local/demo)
+------------------------
+1. Ensure vendor adapter is configured or use the example adapter:
+     export HIL_VENDOR_ADAPTER=ops.hil.vendor_impl_example.ExampleVendor
+
+2. Prepare an example manifest (see example_replay_manifest.json).
+
+3. Run the end-to-end script:
+     python ops/hil/hil_end_to_end.py --adapter "$HIL_VENDOR_ADAPTER" --manifest ops/hil/playbook/example_replay_manifest.json --firmware-cmd "vendortool --dump /dev/ecu0" --register-name demo-rack
+
+Notes
+-----
+ - In production, point adapter to a real vendor implementation and provide credentials via env.
+ - The script will attempt to sign artifacts if EVIDENCE_SIGN_BACKEND is configured.
+
*** End Patch
*** Begin Patch
*** Add File:ops/hil/playbook/vendor_manifest_template.yaml
+---
+# Example vendor manifest template for HIL orchestration.
+# Adapt fields to your vendor's API and the ops/hil/vendor_adapter expectations.
+manifest:
+  id: "example_manifest_{{ timestamp }}"
+  description: "HIL replay manifest for scenario X"
+  bag: "s3://example-bucket/rosbags/example.bag"
+  seed: 42
+  start_time: "2026-01-01T00:00:00Z"
+  topics:
+    - "/camera/image_raw"
+    - "/lidar/points"
+    - "/control/cmd"
+  checksums:
+    bag: "<sha256-of-bag>"
+  expected_env:
+    firmware_version: "v1.2.3"
+  vendor:
+    rack_id: "<rack identifier>"
+    slot: 1
+
*** End Patch
*** Begin Patch
*** Add File:ops/hil/playbook/example_replay_manifest.json
+{
+  "id": "example_manifest_001",
+  "description": "Demo scenario replay manifest",
+  "bag": "data/hil/example.bag",
+  "seed": 1337,
+  "start_time": "2026-01-01T00:00:00Z",
+  "topics": ["/camera/image_raw", "/control/cmd"],
+  "checksums": {
+    "data/hil/example.bag": "REPLACE_WITH_SHA256"
+  },
+  "expected_env": {
+    "firmware_version": "demo-fw-1.0"
+  }
+}
+
*** End Patch
*** Begin Patch
*** Add File:ops/hil/hil_end_to_end.py
+#!/usr/bin/env python3
+"""
+HIL end-to-end orchestrator (demo)
+ - Registers HIL rack (optional)
+ - Creates replay lock
+ - Snapshots firmware (pre)
+ - Runs integrated HIL job via run_hil_integrated.py
+ - Runs deterministic verifier and signs resulting provenance
+ - Optionally triggers promotion helpers (placeholder)
+"""
+import os
+import json
+import subprocess
+from datetime import datetime
+from ops.hil.hil_provisioning import register_rack, create_replay_lock, health_check
+from ops.hil.run_hil_integrated import run_integrated
+from ops.hil.deterministic_verifier import produce_report
+
+def sign_if_available(path):
+    if os.environ.get("EVIDENCE_SIGN_BACKEND"):
+        try:
+            subprocess.check_call(["python", "ops/evidence/sign_with_kms_or_vault.py", path])
+            return path + ".sig"
+        except Exception:
+            return None
+    return None
+
+def main(adapter, manifest, firmware_cmd=None, register_name=None):
+    print("Adapter:", adapter)
+    if register_name:
+        print("Registering rack:", register_name)
+        reg = register_rack(register_name, adapter)
+        print("Registered:", reg)
+    ok, info = health_check(adapter)
+    print("Health:", ok, info)
+    print("Creating replay lock for manifest:", manifest)
+    lock = create_replay_lock(manifest)
+    print("Lock:", lock)
+    print("Running integrated HIL (this may take some time)...")
+    res = run_integrated(adapter, manifest, lock_path=lock, firmware_dump_cmd=firmware_cmd, sig_prov=False)
+    print("HIL run result:", res.get("result"))
+    # try locate replay meta and hil log
+    replay_meta = os.environ.get("HIL_REPLAY_META", "/tmp/hil_replay/ros_replay_metadata.json")
+    hil_log = None
+    artifacts = res.get("result", {}).get("artifacts", []) or []
+    for a in artifacts:
+        if a.endswith("hil_log.json") or "hil_log" in os.path.basename(a):
+            hil_log = a
+            break
+    # fallback default paths
+    if os.path.exists(replay_meta) and hil_log and os.path.exists(hil_log):
+        print("Running deterministic verification")
+        report_path, sig = produce_report(replay_meta, hil_log, os.path.dirname(hil_log), out_path="/tmp/determinism_report.json")
+        print("Determinism report:", report_path, "sig:", sig)
+        if not sig:
+            sig = sign_if_available(report_path)
+            print("Signed:", sig)
+    else:
+        print("Replay meta or hil log not found; verification skipped. artifacts:", artifacts)
+    # Optionally: call promotion helper or mark evidence ready
+    print("HIL end-to-end complete")
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--adapter", required=True)
+    p.add_argument("--manifest", required=True)
+    p.add_argument("--firmware-cmd", default=None)
+    p.add_argument("--register-name", default=None)
+    args = p.parse_args()
+    main(args.adapter, args.manifest, firmware_cmd=args.firmware_cmd, register_name=args.register_name)
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/hil_end_to_end.yml
+name: HIL End-to-End (demo)
+on:
+  workflow_dispatch:
+
+jobs:
+  hil-e2e:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+      - name: Install deps
+        run: |
+          python -m pip install --upgrade pip
+          pip install requests
+      - name: Run HIL end-to-end script (demo)
+        env:
+          HIL_VENDOR_ADAPTER: ${{ secrets.HIL_VENDOR_ADAPTER }}
+          HIL_VENDOR_URL: ${{ secrets.HIL_VENDOR_URL }}
+          HIL_VENDOR_TOKEN: ${{ secrets.HIL_VENDOR_TOKEN }}
+          EVIDENCE_SIGN_BACKEND: ${{ secrets.EVIDENCE_SIGN_BACKEND }}
+        run: |
+          python ops/hil/hil_end_to_end.py --adapter "${HIL_VENDOR_ADAPTER}" --manifest ops/hil/playbook/example_replay_manifest.json --firmware-cmd "${{ secrets.HIL_FW_DUMP_CMD }}" --register-name "ci-demo-rack" || true
+
*** End Patch
*** Begin Patch
*** Add File:k8s/webhooks/gen_certs.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Generate self-signed cert/key for webhook service and create k8s TLS secret.
+# Usage: ./gen_certs.sh --service <svc> --namespace <ns> --secret <secretname>
+
+SERVICE=${1:-aegis-emissions-webhook}
+NAMESPACE=${2:-aegis-webhook}
+SECRET=${3:-aegis-emissions-webhook-tls}
+
+# generate private key and cert
+openssl req -x509 -newkey rsa:2048 -nodes -keyout webhook.key -out webhook.crt -subj "/CN=${SERVICE}.${NAMESPACE}.svc"
+
+# create TLS secret in cluster
+kubectl create secret tls ${SECRET} -n ${NAMESPACE} --cert=webhook.crt --key=webhook.key --dry-run=client -o yaml > emissions-webhook-tls-secret.yaml
+echo "Wrote emissions-webhook-tls-secret.yaml. Apply with kubectl apply -f emissions-webhook-tls-secret.yaml"
+
+# extract CA bundle for MutatingWebhookConfiguration
+CA_BUNDLE=$(cat webhook.crt | base64 | tr -d '\n')
+echo "Base64 CA bundle (copy into mutatingwebhookconfiguration caBundle field):"
+echo "${CA_BUNDLE}"
+
*** End Patch
*** Begin Patch
*** Add File:k8s/webhooks/mutatingwebhookconfiguration.yaml
+apiVersion: admissionregistration.k8s.io/v1
+kind: MutatingWebhookConfiguration
+metadata:
+  name: aegis-emissions-webhook
+webhooks:
+  - name: emissions.aegis.local
+    clientConfig:
+      service:
+        name: aegis-emissions-webhook
+        namespace: aegis-webhook
+        path: "/mutate"
+      # IMPORTANT: replace caBundle with base64 of webhook TLS cert (generated by gen_certs.sh)
+      caBundle: "<REPLACE_WITH_BASE64_CA_CERT>"
+    admissionReviewVersions: ["v1","v1beta1"]
+    sideEffects: None
+    timeoutSeconds: 10
+    rules:
+      - apiGroups: [""]
+        apiVersions: ["v1"]
+        operations: ["CREATE"]
+        resources: ["pods"]
+        scope: "Namespaced"
+
*** End Patch
*** Begin Patch
*** Add File:k8s/webhooks/emissions-webhook-tls-secret.yaml
+apiVersion: v1
+kind: Secret
+metadata:
+  name: aegis-emissions-webhook-tls
+  namespace: aegis-webhook
+type: kubernetes.io/tls
+data:
+  tls.crt: "<BASE64_CRT_GOES_HERE>"
+  tls.key: "<BASE64_KEY_GOES_HERE>"
+
*** End Patch
*** Begin Patch
*** Add File:k8s/webhooks/README.md
+Webhook TLS & MutatingWebhookConfiguration
+-----------------------------------------
+
+1. Generate cert and secret manifest:
+   ./k8s/webhooks/gen_certs.sh aegis-emissions-webhook aegis-webhook aegis-emissions-webhook-tls
+
+2. Apply the TLS secret:
+   kubectl apply -f k8s/webhooks/emissions-webhook-tls-secret.yaml
+
+3. Patch caBundle in k8s/webhooks/mutatingwebhookconfiguration.yaml with the base64 CA printed by gen_certs.sh.
+
+4. Apply webhook and service/deployment:
+   kubectl apply -f k8s/webhooks/mutatingwebhookconfiguration.yaml
+   kubectl apply -f k8s/webhooks/emissions-webhook-deployment.yaml
+
+Notes:
+ - Production must secure TLS properly (use cert-manager or enterprise PKI) and configure readiness/liveness checks.
+ - The webhook skeleton (ops/infra/emissions_webhook.py) must be reachable by the kube-apiserver (service + DNS).
+
*** End Patch
*** Begin Patch
*** Add File:ops/rt/rollout_rt_image.sh
+#!/usr/bin/env bash
+set -euo pipefail
+#
+# Build and roll out RT node helper + label nodes as RT-capable
+# Usage:
+#   ./rollout_rt_image.sh --image <registry>/aegis-rt-node:tag --node-selector "node-role.kubernetes.io/vehicle=true" --label aegis/rt=true
+
+IMAGE=""
+NODE_SELECTOR=""
+LABEL_KV="aegis/rt=true"
+
+while [[ $# -gt 0 ]]; do
+  case $1 in
+    --image) IMAGE="$2"; shift 2;;
+    --node-selector) NODE_SELECTOR="$2"; shift 2;;
+    --label) LABEL_KV="$2"; shift 2;;
+    *) echo "Unknown $1"; exit 2;;
+  esac
+done
+
+[ -n "$IMAGE" ] || { echo "Provide --image"; exit 2; }
+
+echo "[1/3] Building or pulling image: $IMAGE (CI recommended to push image prior to running)"
+echo "[2/3] Labeling matching nodes"
+if [ -n "$NODE_SELECTOR" ]; then
+  nodes=$(kubectl get nodes -l "${NODE_SELECTOR}" -o name --no-headers)
+else
+  # fallback: label nodes with names containing 'vehicle' or with GPUs
+  nodes=$(kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}' | grep -E "vehicle|gpu" || true)
+fi
+for n in $nodes; do
+  if [ -z "$n" ]; then continue; fi
+  echo "Labeling node $n with $LABEL_KV"
+  kubectl label "$n" "$LABEL_KV" --overwrite || true
+done
+
+echo "[3/3] Deploying RT node agent via helm (charts/rt-node)"
+helm upgrade --install aegis-rt-node charts/rt-node --set image="$IMAGE"
+
+echo "Rollout initiated; check daemonset pods and node labels."
+
*** End Patch
*** Begin Patch
*** Add File:charts/rt-node/Chart.yaml
+apiVersion: v2
+name: aegis-rt-node
+description: DaemonSet to validate RT kernel presence and expose status
+type: application
+version: 0.1.0
+appVersion: "0.1.0"
+
*** End Patch
*** Begin Patch
*** Add File:charts/rt-node/values.yaml
+image:
+  repository: aegis/rt-node-agent
+  tag: latest
+  pullPolicy: IfNotPresent
+
+tolerations: []
+
*** End Patch
*** Begin Patch
*** Add File:charts/rt-node/templates/daemonset.yaml
+apiVersion: apps/v1
+kind: DaemonSet
+metadata:
+  name: aegis-rt-node-agent
+  labels:
+    app: aegis-rt-node-agent
+spec:
+  selector:
+    matchLabels:
+      app: aegis-rt-node-agent
+  template:
+    metadata:
+      labels:
+        app: aegis-rt-node-agent
+    spec:
+      hostPID: true
+      containers:
+        - name: rt-checker
+          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
+          imagePullPolicy: "{{ .Values.image.pullPolicy }}"
+          securityContext:
+            privileged: true
+          command: ["/bin/sh", "-c"]
+          args:
+            - |
+              /opt/rt-agent/check_rt_kernel.sh || true
+              sleep 3600
+          volumeMounts:
+            - name: proc
+              mountPath: /proc
+      volumes:
+        - name: proc
+          hostPath:
+            path: /proc
+            type: ""
+
*** End Patch
*** Begin Patch
*** Add File:ops/rt/check_rt_kernel.sh
+#!/usr/bin/env bash
+# Simple RT kernel check script; runs on node as privileged container.
+set -euo pipefail
+LOG_DIR=/var/log/aegis
+mkdir -p "${LOG_DIR}"
+KVER=$(uname -v 2>/dev/null || true)
+OUT=${LOG_DIR}/rt_check_$(hostname).log
+echo "kernel_version: $(uname -r)" > "$OUT"
+echo "kernel_version_verbose: $KVER" >> "$OUT"
+if uname -a | grep -qi PREEMPT; then
+  echo "rt_present: true" >> "$OUT"
+else
+  # heuristic: check if 'PREEMPT_RT' string appears in version or config
+  if grep -qi PREEMPT /proc/version 2>/dev/null; then
+    echo "rt_present: true" >> "$OUT"
+  else
+    echo "rt_present: false" >> "$OUT"
+  fi
+fi
+echo "wrote $OUT"
+
*** End Patch
*** Begin Patch
*** Add File:.github/workflows/wcet_compliance.yml
+name: WCET Compliance Pipeline
+on:
+  workflow_dispatch:
+
+jobs:
+  wcet:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v4
+      - name: Setup Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+      - name: Install deps
+        run: |
+          python -m pip install --upgrade pip
+      - name: Run WCET campaign (example)
+        run: |
+          # Provide a campaign file ops/rt/wcet_campaign.json in repo listing control binaries (demo)
+          if [ -f ops/rt/wcet_campaign.json ]; then
+            python ops/rt/wcet_campaign_runner.py --campaign ops/rt/wcet_campaign.json --samples 200 || true
+          else
+            echo "No campaign file found; skipping"
+          fi
+      - name: Enforce P99 annotations on safety deployments
+        run: python ops/ci/check_rt_p99.py
+
*** End Patch
*** End Patch
