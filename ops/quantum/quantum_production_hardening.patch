*** Begin Patch
*** Add File:ops/signing/hsm_integration.py
+#!/usr/bin/env python3
+"""
+HSM integration helper (PKCS#11 / CloudHSM / vendor-agnostic skeleton)
+
+Provides:
+ - sign_with_hsm(data, key_label): attempts to sign using an HSM via PKCS#11 (PyKCS11)
+ - fallback: calls local PQC signing (pyOQS) if HSM unavailable
+
+Operator: install and configure your PKCS#11 provider library and set PKCS11_MODULE env var.
+This file is a safe skeleton â€” vendors will require adapting slot/key handling and RBAC.
+"""
+import os
+import tempfile
+import json
+import hashlib
+
+try:
+    import PyKCS11
+except Exception:
+    PyKCS11 = None
+
+try:
+    import oqs
+except Exception:
+    oqs = None
+
+PKCS11_MODULE = os.environ.get("PKCS11_MODULE","/usr/lib/your-pkcs11.so")
+PKCS11_PIN = os.environ.get("PKCS11_PIN","")
+
+def sign_with_hsm(data: bytes, key_label: str):
+    """
+    Attempt to sign using PKCS#11 HSM. Returns dict with {'ok':bool,'signature':hex,'meta':...}
+    """
+    if PyKCS11 is None:
+        return {"ok": False, "error": "pykcs11_missing"}
+    try:
+        lib = PyKCS11.PyKCS11Lib()
+        lib.load(PKCS11_MODULE)
+        slots = lib.getSlotList(tokenPresent=True)
+        if not slots:
+            return {"ok": False, "error": "no_hsm_slots"}
+        slot = slots[0]
+        session = lib.openSession(slot)
+        if PKCS11_PIN:
+            session.login(PKCS11_PIN)
+        # This is vendor-specific: find key by label
+        objs = session.findObjects([(PyKCS11.CKA_LABEL, key_label)])
+        if not objs:
+            return {"ok": False, "error": "key_not_found"}
+        key = objs[0]
+        # Use SHA256 RSA/ECDSA sign depending on key type; this is illustrative
+        digest = hashlib.sha256(data).digest()
+        mech = PyKCS11.Mechanism(PyKCS11.CKM_SHA256_RSA_PKCS, None)
+        sig = bytes(session.sign(key, digest, mech))
+        if PKCS11_PIN:
+            session.logout()
+        session.closeSession()
+        return {"ok": True, "signature": sig.hex(), "algo": "hsm-pkcs11", "key_label": key_label}
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+def sign_with_pqc_local(data: bytes, alg="Dilithium2"):
+    """
+    Local PQC signing fallback using pyOQS. Returns dict.
+    """
+    if oqs is None:
+        return {"ok": False, "error": "pyOQS_missing"}
+    try:
+        with oqs.Signature(alg) as signer:
+            pub, priv = signer.generate_keypair()
+            sig = signer.sign(data, priv)
+            return {"ok": True, "signature": sig.hex(), "public": pub.hex(), "alg": alg}
+    except Exception as e:
+        return {"ok": False, "error": str(e)}
+
+if __name__ == "__main__":
+    import argparse, sys
+    p = argparse.ArgumentParser()
+    p.add_argument("--key-label", required=False, default="aegis-cosign")
+    p.add_argument("--file", required=True)
+    args = p.parse_args()
+    data = open(args.file, "rb").read()
+    res = sign_with_hsm(data, args.key_label)
+    if not res.get("ok"):
+        print("HSM sign failed, fallback to local PQC:", res.get("error"))
+        res = sign_with_pqc_local(data)
+    print(json.dumps(res, indent=2))
+
*** End Patch
*** Begin Patch
*** Add File:ops/signing/hsm_rotation.py
+#!/usr/bin/env python3
+"""
+HSM / PQC key rotation orchestration skeleton
+
+ - Creates a new PQC keypair (via pyOQS or vendor API)
+ - Stores public key in ConfigMap and private key in a sealed secret (operator must seal)
+ - Marks previous key alias as retiring and optionally schedules OBJ deletion in HSM (vendor-specific)
+"""
+import os
+import json
+from datetime import datetime
+try:
+    import oqs
+except Exception:
+    oqs = None
+from kubernetes import client, config
+
+CM_NAME = "aegis-pqc-keys"
+CM_NS = "kube-system"
+SECRET_PREFIX = "aegis-pqc-"
+
+def generate_pqc(alg="Dilithium2"):
+    if oqs is None:
+        raise RuntimeError("pyOQS not available")
+    with oqs.Signature(alg) as signer:
+        pub, priv = signer.generate_keypair()
+    return pub.hex(), priv.hex()
+
+def store_k8s(pub_hex, priv_hex, alias):
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    core = client.CoreV1Api()
+    # private -> secret (operator to seal/ensure encryption)
+    sec_name = f"{SECRET_PREFIX}{alias}-priv"
+    sec = client.V1Secret(metadata=client.V1ObjectMeta(name=sec_name, namespace=CM_NS), string_data={"private": priv_hex})
+    try:
+        core.create_namespaced_secret(CM_NS, sec)
+    except Exception:
+        core.replace_namespaced_secret(sec_name, CM_NS, sec)
+    # public -> configmap
+    try:
+        cm = core.read_namespaced_config_map(CM_NAME, CM_NS)
+        data = cm.data or {}
+    except Exception:
+        data = {}
+    data[alias] = pub_hex
+    body = client.V1ConfigMap(metadata=client.V1ObjectMeta(name=CM_NAME), data=data)
+    try:
+        core.replace_namespaced_config_map(CM_NAME, CM_NS, body)
+    except Exception:
+        core.create_namespaced_config_map(CM_NS, body)
+    return sec_name
+
+def main():
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--alias", required=True)
+    p.add_argument("--alg", default="Dilithium2")
+    args = p.parse_args()
+    pub, priv = generate_pqc(args.alg)
+    sec = store_k8s(pub, priv, args.alias)
+    print("generated and stored keys alias=", args.alias, "secret=", sec)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/quantum/simulator_benchmark.py
+#!/usr/bin/env python3
+"""
+Simulator benchmark runner
+
+ - Runs a configurable number of simulation workers (locally or via cluster) and measures latency/throughput
+ - Emits a JSON report and writes a Prometheus textfile metrics for collection
+"""
+import time
+import json
+import os
+from datetime import datetime
+from concurrent.futures import ThreadPoolExecutor
+
+def run_sim_task(shots=1024):
+    # lightweight run using qiskit Aer if available; fallback to sleep to simulate load
+    try:
+        from qiskit import QuantumCircuit
+        from qiskit_aer import AerSimulator
+        qc = QuantumCircuit(2,2)
+        qc.h(0); qc.cx(0,1); qc.measure([0,1],[0,1])
+        sim = AerSimulator()
+        t0 = time.time()
+        qobj = sim.run(qc, shots=shots).result()
+        latency = time.time() - t0
+        return {"ok": True, "latency": latency}
+    except Exception:
+        t0 = time.time(); time.sleep(0.1)
+        return {"ok": True, "latency": time.time()-t0}
+
+def main():
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--workers", type=int, default=8)
+    p.add_argument("--shots", type=int, default=1024)
+    p.add_argument("--out", default="/tmp/sim_bench.json")
+    p.add_argument("--metricdir", default="/var/lib/node_exporter/textfile_collector")
+    args = p.parse_args()
+    results=[]
+    with ThreadPoolExecutor(max_workers=args.workers) as ex:
+        futures = [ex.submit(run_sim_task, args.shots) for _ in range(args.workers)]
+        for f in futures:
+            results.append(f.result())
+    latencies = [r["latency"] for r in results if r.get("ok")]
+    p95 = sorted(latencies)[int(0.95*len(latencies))-1] if latencies else 0
+    report = {"workers": args.workers, "shots": args.shots, "p95_latency": p95, "samples": len(latencies), "ts": datetime.utcnow().isoformat()+"Z"}
+    os.makedirs(os.path.dirname(args.out), exist_ok=True)
+    with open(args.out, "w") as fh:
+        json.dump(report, fh, indent=2)
+    # write simple prometheus textfile
+    try:
+        os.makedirs(args.metricdir, exist_ok=True)
+        nm = os.path.join(args.metricdir, f"quantum_sim_bench.prom")
+        with open(nm, "w") as fh:
+            fh.write(f'aegis_quantum_sim_p95_latency {p95}\n')
+            fh.write(f'aegis_quantum_sim_workers {args.workers}\n')
+    except Exception:
+        pass
+    print("wrote", args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/generative/rlhf/rlhf_perf_runner.py
+#!/usr/bin/env python3
+"""
+Distributed RLHF perf runner skeleton
+
+ - Launches scaled training jobs (placeholder for torchrun/accelerate)
+ - Measures epoch time, GPU utilization (if available) and writes a perf report
+ - Intended to be executed by Argo workflows and used in autoscaler tuning
+"""
+import os, time, json
+from datetime import datetime
+
+def run_dummy_training(nodes=1, gpus_per_node=8, epochs=3):
+    # placeholder: simulate epoch runtimes and utilization
+    stats=[]
+    for e in range(epochs):
+        t0 = time.time()
+        # simulate some compute
+        time.sleep(1 + 0.1 * nodes * gpus_per_node)
+        epoch_time = time.time() - t0
+        stats.append({"epoch": e+1, "epoch_time_s": epoch_time, "nodes": nodes, "gpus_per_node": gpus_per_node})
+    return stats
+
+def main():
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--nodes", type=int, default=1)
+    p.add_argument("--gpus", type=int, default=8)
+    p.add_argument("--out", default="/tmp/rlhf_perf.json")
+    args = p.parse_args()
+    stats = run_dummy_training(args.nodes, args.gpus)
+    report = {"nodes": args.nodes, "gpus_per_node": args.gpus, "stats": stats, "ts": datetime.utcnow().isoformat()+"Z"}
+    with open(args.out, "w") as fh:
+        json.dump(report, fh, indent=2)
+    print("wrote", args.out)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/providers/provider_hardening.py
+#!/usr/bin/env python3
+"""
+Provider hardening utilities
+
+ - Robust submission wrapper with retry/exponential backoff and quota handling
+ - Emits structured logs and basic Prometheus textfile metrics for provider auth/billing failures
+ - Billing API stub (operator to implement provider-specific billing retrieval)
+"""
+import time
+import json
+import os
+import random
+from datetime import datetime
+
+def exponential_backoff(func, tries=5, base=1.0, factor=2.0, max_wait=60, *args, **kwargs):
+    attempt = 0
+    while attempt < tries:
+        try:
+            return {"ok": True, "result": func(*args, **kwargs)}
+        except Exception as e:
+            attempt += 1
+            wait = min(max_wait, base * (factor ** (attempt-1)) + random.random())
+            print(f"provider attempt {attempt} failed: {e}; sleeping {wait}s")
+            time.sleep(wait)
+    return {"ok": False, "error": "exhausted_retries"}
+
+def submit_with_quota_check(submit_fn, quota_fn, *args, **kwargs):
+    """
+    submit_fn: callable to submit job
+    quota_fn: callable that returns (allowed:boolean, remaining:int)
+    """
+    allowed, remaining = quota_fn()
+    if not allowed:
+        return {"ok": False, "error": "quota_exceeded"}
+    res = exponential_backoff(submit_fn, *args, **kwargs)
+    if not res.get("ok"):
+        # emit provider auth failure metric
+        try:
+            metricdir = "/var/lib/node_exporter/textfile_collector"
+            os.makedirs(metricdir, exist_ok=True)
+            with open(os.path.join(metricdir, "provider_auth_fail.prom"), "w") as fh:
+                fh.write(f'aegis_quantum_provider_auth_failures_total{{provider="unknown"}} 1\n')
+        except Exception:
+            pass
+    return res
+
+def fetch_provider_billing_stub(provider, start_ts, end_ts):
+    """
+    Placeholder: operator should implement provider billing API calls.
+    Returns total cost in USD for the period.
+    """
+    # Example: call AWS Cost Explorer, GCP Billing, or Azure Cost APIs
+    return {"provider": provider, "cost_usd": 0.0, "period": {"start": start_ts, "end": end_ts}}
+
+if __name__ == "__main__":
+    print("provider hardening utils")
+
*** End Patch
*** Begin Patch
*** Add File:ops/compliance/seal_secret.py
+#!/usr/bin/env python3
+"""
+Seal Kubernetes secret using kubeseal (if available) or create sealed placeholder
+
+ - Reads a plaintext secret manifest and calls kubeseal to produce a sealed secret
+ - If kubeseal is unavailable, the script prints instructions for operator
+"""
+import os
+import subprocess
+import sys
+
+def seal(input_file, output_file):
+    if not shutil.which("kubeseal"):
+        print("kubeseal not installed; please run: kubeseal --format=yaml < secret.yaml > sealedsecret.yaml")
+        return False
+    try:
+        subprocess.check_call(["kubeseal", "--format", "yaml", "-o", output_file, "-f", input_file])
+        return True
+    except Exception as e:
+        print("kubeseal failed:", e)
+        return False
+
+if __name__ == "__main__":
+    import argparse, shutil
+    p = argparse.ArgumentParser()
+    p.add_argument("--in", dest="input", required=True)
+    p.add_argument("--out", dest="out", required=True)
+    args = p.parse_args()
+    ok = seal(args.input, args.out)
+    print("sealed ok:", ok)
+
*** End Patch
*** Begin Patch
*** Add File:ops/audit/attestation_audit_trail.py
+#!/usr/bin/env python3
+"""
+Attestation audit trail writer
+
+ - Appends attestation metadata to a secure append-only audit log in S3 (and local copy)
+ - Ensures every attestation write is atomic and returns an audit record id
+"""
+import os
+import json
+import boto3
+from datetime import datetime
+
+S3_BUCKET = os.environ.get("EVIDENCE_BUCKET","")
+AUDIT_PREFIX = "attest-audit-log/"
+
+def append_audit_record(record):
+    # record is a dict with at least attestation_id, actor, ts, artifact_type
+    ts = datetime.utcnow().isoformat()+"Z"
+    rec = dict(record)
+    rec["ingested_at"] = ts
+    key = AUDIT_PREFIX + f"{rec.get('attestation_id','unknown')}-{int(datetime.utcnow().timestamp())}.json"
+    if S3_BUCKET:
+        s3 = boto3.client("s3")
+        s3.put_object(Bucket=S3_BUCKET, Key=key, Body=json.dumps(rec).encode())
+    # local store for quick lookup as well
+    try:
+        os.makedirs("/var/lib/aegis/attest_audit", exist_ok=True)
+        path = os.path.join("/var/lib/aegis/attest_audit", os.path.basename(key))
+        with open(path, "w") as fh:
+            json.dump(rec, fh, indent=2)
+    except Exception:
+        pass
+    return {"ok": True, "s3_key": f"s3://{S3_BUCKET}/{key}" if S3_BUCKET else None, "local": path}
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--attestation-id", required=True)
+    p.add_argument("--actor", default="system")
+    p.add_argument("--artifact", default="quantum")
+    args = p.parse_args()
+    r = append_audit_record({"attestation_id": args.attestation_id, "actor": args.actor, "artifact": args.artifact})
+    print(r)
+
*** End Patch
*** Begin Patch
*** Add File:ops/monitoring/provider_cost_collector.py
+#!/usr/bin/env python3
+"""
+Provider cost collector
+
+ - Periodically queries provider billing APIs (stubbed) and writes Prometheus textfile metrics
+ - Designed to be extended for AWS Cost Explorer, Azure Billing, GCP Billing
+"""
+import time
+import os
+import json
+from datetime import datetime, timedelta
+
+METRIC_DIR = os.environ.get("METRIC_DIR","/var/lib/node_exporter/textfile_collector")
+
+def fetch_costs(provider, days=1):
+    # Placeholder: implement provider-specific API
+    # Return dict: {"provider":provider, "cost_usd":float}
+    return {"provider": provider, "cost_usd": 0.0}
+
+def write_metric(provider, cost, ts):
+    os.makedirs(METRIC_DIR, exist_ok=True)
+    fn = os.path.join(METRIC_DIR, f"quantum_cost_{provider}.prom")
+    with open(fn, "w") as fh:
+        fh.write(f'aegis_quantum_provider_cost_usd{{provider="{provider}"}} {cost}\n')
+        fh.write(f'aegis_quantum_provider_cost_ts{{provider="{provider}"}} {int(ts)}\n')
+
+def main():
+    providers = os.environ.get("QUANTUM_PROVIDERS","ibmq,braket").split(",")
+    while True:
+        for p in providers:
+            res = fetch_costs(p, days=1)
+            ts = int(time.time())
+            write_metric(p, res.get("cost_usd",0.0), ts)
+        time.sleep(int(os.environ.get("COST_POLL_S","3600")))
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File:ops/policy/machine_policy_activation.py
+#!/usr/bin/env python3
+"""
+Policy activation helper
+
+ - Proposes a policy to be machine_verifiable (writes to proposals configmap)
+ - Checks for legal signoff (via signoff_manager) and activates machine_verifiable when signoff present
+ - Writes audit entry via attestation_audit_trail
+"""
+import os, json
+from kubernetes import client, config
+from ops.compliance.signoff_manager import list_signoffs
+from ops.audit.attestation_audit_trail import append_audit_record
+
+PROPOSAL_CM = ("aegis-policy-proposals","kube-system")
+REG_CM = ("aegis-policy-registry","kube-system")
+
+def load_cm(name, ns):
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    core = client.CoreV1Api()
+    try:
+        cm = core.read_namespaced_config_map(name, ns)
+        return cm.data or {}
+    except Exception:
+        return {}
+
+def write_cm(name, ns, data):
+    core = client.CoreV1Api()
+    body = client.V1ConfigMap(metadata=client.V1ObjectMeta(name=name), data=data)
+    try:
+        core.replace_namespaced_config_map(name, ns, body)
+    except Exception:
+        core.create_namespaced_config_map(ns, body)
+
+def activate_if_signed(policy_id):
+    proposals = load_cm(PROPOSAL_CM[0], PROPOSAL_CM[1])
+    if policy_id not in proposals:
+        return {"ok": False, "error": "no_proposal"}
+    # legal signoff key expected: legal:<policy_id>
+    signoffs = list_signoffs()
+    key = f"legal:{policy_id}"
+    found = any(key in v for v in signoffs.values())
+    if not found:
+        return {"ok": False, "error": "legal_signoff_missing"}
+    # move registry
+    reg = load_cm(REG_CM[0], REG_CM[1])
+    reg[policy_id] = json.dumps({"machine_verifiable": True, "doc_ref": json.loads(proposals[policy_id]).get("doc_ref")})
+    write_cm(REG_CM[0], REG_CM[1], reg)
+    # audit
+    append_audit_record({"attestation_id": f"policy-activate-{policy_id}", "actor": "policy-activation", "artifact": "policy", "note": "activated machine_verifiable"})
+    return {"ok": True}
+
+if __name__ == "__main__":
+    import argparse
+    p = argparse.ArgumentParser()
+    p.add_argument("--policy", required=True)
+    args = p.parse_args()
+    print(activate_if_signed(args.policy))
+
*** End Patch
*** Begin Patch
*** Add File:ops/chaos/scale_and_validation_workflow.yaml
+apiVersion: argoproj.io/v1alpha1
+kind: Workflow
+metadata:
+  generateName: aegis-scale-validate-
+spec:
+  entrypoint: scale-validate
+  templates:
+    - name: scale-validate
+      steps:
+        - - name: sim-bench
+            template: sim-bench
+        - - name: rlhf-perf
+            template: rlhf-perf
+        - - name: attestation-reconcile
+            template: attestation-reconcile
+
+    - name: sim-bench
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - pip install qiskit-aer && python /opt/aegis/ops/quantum/simulator_benchmark.py --workers 16 --shots 2048 --out /tmp/sim_bench.json || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: rlhf-perf
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - pip install torch || true
+            python /opt/aegis/ops/generative/rlhf/rlhf_perf_runner.py --nodes 2 --gpus 8 --out /tmp/rlhf_perf.json || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+    - name: attestation-reconcile
+      container:
+        image: python:3.11-slim
+        command: [sh, -c]
+        args:
+          - pip install boto3 kubernetes oqs || true
+            python /opt/aegis/ops/audit/attestation_reconciler_pqc.py || true
+        volumeMounts:
+          - name: code
+            mountPath: /opt/aegis
+
+  volumes:
+    - name: code
+      hostPath:
+        path: ./ops
+        type: Directory
+
*** End Patch
*** Begin Patch
*** Add File:monitoring/prometheus/quantum_production_promrules.yaml
+apiVersion: monitoring.coreos.com/v1
+kind: PrometheusRule
+metadata:
+  name: aegis-quantum-production
+  namespace: monitoring
+spec:
+  groups:
+    - name: aegis-quantum-production
+      rules:
+        - alert: QuantumProviderCostSpike
+          expr: increase(aegis_quantum_provider_cost_usd[6h]) > (increase(aegis_quantum_expected_cost_usd[6h]) * 1.25)
+          for: 30m
+          labels:
+            severity: page
+          annotations:
+            summary: "Quantum provider cost spike >25% in 6h"
+        - alert: QuantumSimP95LatencyBreach
+          expr: aegis_quantum_sim_p95_latency > 5
+          for: 10m
+          labels:
+            severity: page
+          annotations:
+            summary: "Quantum simulator p95 latency > 5s"
+        - alert: AttestationIntegrityFailure
+          expr: increase(aegis_attestation_failed_verifications_total[1h]) > 0
+          for: 5m
+          labels:
+            severity: page
+          annotations:
+            summary: "Failed attestation verifications detected"
+
*** End Patch
*** Begin Patch
*** Add File:ops/monitoring/kpi_tracker.py
+#!/usr/bin/env python3
+"""
+KPI tracker for quantum production readiness
+
+ - Aggregates simulation & RLHF perf reports, attestation reconciliation results, and provider cost metrics
+ - Writes a summary ConfigMap `aegis-quantum-kpis` in kube-system for dashboards and automation decisions
+"""
+import os, json
+from kubernetes import client, config
+
+CM_NAME = "aegis-quantum-kpis"
+CM_NS = "kube-system"
+
+def load_file(p):
+    try:
+        with open(p) as fh:
+            return json.load(fh)
+    except Exception:
+        return {}
+
+def write_cm(data):
+    try:
+        config.load_incluster_config()
+    except Exception:
+        config.load_kube_config()
+    core = client.CoreV1Api()
+    body = client.V1ConfigMap(metadata=client.V1ObjectMeta(name=CM_NAME), data={k: json.dumps(v) for k,v in data.items()})
+    try:
+        core.replace_namespaced_config_map(CM_NAME, CM_NS, body)
+    except Exception:
+        core.create_namespaced_config_map(CM_NS, body)
+
+def main():
+    sim = load_file("/tmp/sim_bench.json")
+    rlhf = load_file("/tmp/rlhf_perf.json")
+    att = load_file("/tmp/attestation_reconcile.json")
+    data = {"sim_bench": sim, "rlhf_perf": rlhf, "attestation_reconcile": att, "ts": str(__import__("datetime").datetime.utcnow().isoformat()+"Z")}
+    write_cm(data)
+    print("updated kpis")
+
+if __name__=="__main__":
+    main()
+
*** End Patch
*** End Patch
