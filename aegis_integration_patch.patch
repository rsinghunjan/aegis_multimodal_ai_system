*** Begin Patch
*** Add File: k8s/serving/kserve_prod_batched.yaml
+apiVersion: "serving.kserve.io/v1beta1"
+kind: "InferenceService"
+metadata:
+  name: "aegis-model-prod"
+  namespace: "aegis"
+  annotations:
+    autoscaling.knative.dev/target: "100"           # knative concurrency target per pod
+    serving.kserve.io/enable-batcher: "true"        # enable server-side batching if supported
+    serving.kserve.io/request-batch-size: "16"      # batch size hint
+    serving.kserve.io/request-batch-max-delay: "50ms"
+spec:
+  predictor:
+    serviceAccountName: aegis-model-sa
+    timeout: 60s
+    container:
+      image: ghcr.io/yourorg/aegis-model-server:latest
+      name: model-server
+      args:
+        - "--model-store"
+        - "s3://MODEL_BUCKET/model-archives/aegis-model/"
+        - "--max-concurrency=16"
+        - "--enable-batching=true"
+      env:
+        - name: S3_ENDPOINT
+          value: "https://s3.example"
+        - name: S3_BUCKET
+          value: "MODEL_BUCKET"
+      resources:
+        requests:
+          cpu: "500m"
+          memory: "1Gi"
+        limits:
+          cpu: "2000m"
+          memory: "8Gi"
+          nvidia.com/gpu: "1"
+---
+# Minimal ServiceAccount + Role to read secrets (S3 creds) for model server
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: aegis-model-sa
+  namespace: aegis
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: Role
+metadata:
+  name:
î€€
