*** Begin Patch
*** Add File: .github/workflows/edge-ci.yml
+on:
+  push:
+    branches: [ main ]
+  workflow_dispatch:
+
+name: Edge CI - build, convert, attest, multi-arch
+
+env:
+  EDGE_IMAGE: ghcr.io/${{ github.repository_owner }}/aegis-edge:latest
+  # Set MODEL_REGISTRY_URL to point to your model registry service in your CI env
+  MODEL_REGISTRY_URL: https://model-registry.example.com
+
+jobs:
+  convert-and-attest:
+    name: Convert models and attest artifacts
+    runs-on: ubuntu-latest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Set up Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: "3.11"
+
+      - name: Install conversion deps
+        run: |
+          python -m pip install --upgrade pip
+          pip install -r aegis_multimodal_ai_system/requirements.txt || true
+          pip install tensorflow numpy requests || true
+
+      - name: Convert example SavedModel -> TFLite (dynamic quant)
+        run: |
+          mkdir -p artifacts/edge
+          python3 scripts/convert_to_tflite.py \
+            --savedmodel model_registry/example-tf-model/0.1/saved_model \
+            --output artifacts/edge/example-v0.1.tflite \
+            --quantize dynamic
+
+      - name: Package & attest model artifact (requires VAULT_ADDR + VAULT_TOKEN)
+        env:
+          VAULT_ADDR: ${{ secrets.VAULT_ADDR || '' }}
+          VAULT_TOKEN: ${{ secrets.VAULT_TOKEN || '' }}
+          REKOR_URL: ${{ secrets.REKOR_URL || '' }}
+        run: |
+          if [ -z "$VAULT_ADDR" ] || [ -z "$VAULT_TOKEN" ]; then
+            echo "Vault credentials not set; skipping signing (set VAULT_ADDR+VAULT_TOKEN in secrets)"
+            exit 0
+          fi
+          ./scripts/package_and_attest.sh artifacts/edge example-v0.1.tflite.tar.gz
+
+      - name: Upload artifacts for visibility
+        uses: actions/upload-artifact@v4
+        with:
+          name: edge-artifacts
+          path: artifacts/edge/**
+
+  build-multiarch:
+    name: Build & push multi-arch edge images
+    runs-on: ubuntu-latest
+    needs: convert-and-attest
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v4
+
+      - name: Set up QEMU
+        uses: docker/setup-qemu-action@v2
+
+      - name: Set up Docker Buildx
+        uses: docker/setup-buildx-action@v2
+
+      - name: Login to registry
+        uses: docker/login-action@v2
+        with:
+          registry: ghcr.io
+          username: ${{ github.actor }}
+          password: ${{ secrets.GHCR_PAT }}
+
+      - name: Build & push multi-arch image
+        env:
+          IMAGE: ${{ env.EDGE_IMAGE }}
+        run: |
+          ./scripts/build-multiarch.sh "${IMAGE}"
+
+      - name: Annotate image metadata (optional)
+        run: |
+          echo "Built and pushed ${IMAGE}"
+
*** End Patch
*** Begin Patch
*** Add File: Dockerfile.edge
+# Minimal edge runtime image (multi-stage, small)
+FROM python:3.11-slim AS build
+WORKDIR /build
+COPY aegis_multimodal_ai_system/requirements.txt .
+RUN pip wheel -r requirements.txt --wheel-dir /build/wheels
+
+FROM python:3.11-slim AS runtime
+ENV PYTHONUNBUFFERED=1
+# Create non-root user
+RUN useradd -m -u 1000 aegis
+WORKDIR /app
+# Install only wheels (no cache)
+COPY --from=build /build/wheels /wheels
+RUN pip install --no-cache-dir /wheels/* && rm -rf /wheels
+# app code
+COPY . /app
+RUN chown -R aegis:aegis /app
+USER aegis
+EXPOSE 9000 8000
+# Use a small edge agent that handles model load/verification
+CMD ["python", "agent/edge-agent-robust.py"]
+
*** End Patch
*** Begin Patch
*** Add File: Dockerfile.edge.amd64
+# Edge runtime image - amd64 tuned
+ARG BASE=python:3.11-slim
+FROM ${BASE} AS build
+WORKDIR /build
+COPY aegis_multimodal_ai_system/requirements.txt .
+RUN pip wheel -r requirements.txt --wheel-dir /wheels --no-cache-dir
+
+FROM ${BASE}
+ENV PYTHONUNBUFFERED=1
+RUN useradd -m -u 1000 aegis && mkdir -p /models /app
+WORKDIR /app
+COPY --from=build /wheels /wheels
+RUN pip install --no-cache-dir /wheels/* && rm -rf /wheels /root/.cache
+COPY . /app
+RUN chown -R aegis:aegis /app /models
+USER aegis
+EXPOSE 9000 8000
+CMD ["python", "agent/edge-agent-robust.py"]
+
*** End Patch
*** Begin Patch
*** Add File: Dockerfile.edge.arm64
+# Edge runtime image - arm64 tuned (use arm64 base)
+ARG BASE=python:3.11-slim
+FROM --platform=linux/arm64 ${BASE} AS build
+WORKDIR /build
+COPY aegis_multimodal_ai_system/requirements.txt .
+RUN pip wheel -r requirements.txt --wheel-dir /wheels --no-cache-dir
+
+FROM --platform=linux/arm64 ${BASE}
+ENV PYTHONUNBUFFERED=1
+RUN useradd -m -u 1000 aegis && mkdir -p /models /app
+WORKDIR /app
+COPY --from=build /wheels /wheels
+RUN pip install --no-cache-dir /wheels/* && rm -rf /wheels /root/.cache
+COPY . /app
+RUN chown -R aegis:aegis /app /models
+USER aegis
+EXPOSE 9000 8000
+CMD ["python", "agent/edge-agent-robust.py"]
+
*** End Patch
*** Begin Patch
*** Add File: Dockerfile.edge.armv7
+# Edge runtime image - armv7 (32-bit) tuned; smaller deps and fewer wheels may be required
+ARG BASE=python:3.11-slim
+FROM --platform=linux/arm/v7 ${BASE} AS build
+WORKDIR /build
+COPY aegis_multimodal_ai_system/requirements.txt .
+# building wheels for armv7 in CI can be slow. Consider prebuilding in another pipeline.
+RUN pip wheel -r requirements.txt --wheel-dir /wheels --no-cache-dir || true
+
+FROM --platform=linux/arm/v7 ${BASE}
+ENV PYTHONUNBUFFERED=1
+RUN useradd -m -u 1000 aegis && mkdir -p /models /app
+WORKDIR /app
+COPY --from=build /wheels /wheels
+RUN pip install --no-cache-dir /wheels/* || true
+COPY . /app
+RUN chown -R aegis:aegis /app /models
+USER aegis
+EXPOSE 9000 8000
+CMD ["python", "agent/edge-agent-robust.py"]
+
*** End Patch
*** Begin Patch
*** Add File: scripts/convert_to_tflite.py
+#!/usr/bin/env python3
+"""
+Simple helper: convert a SavedModel to a TFLite file with optional int8 quantization.
+Usage:
+  python scripts/convert_to_tflite.py --savedmodel /path/to/savedmodel --output model.tflite --quantize dynamic
+"""
+import argparse
+import os
+
+def convert(saved_model_dir: str, out_path: str, quantize: str | None):
+    try:
+        import tensorflow as tf
+    except Exception as e:
+        raise RuntimeError("TensorFlow is required to run this converter") from e
+
+    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
+    if quantize == "dynamic":
+        converter.optimizations = [tf.lite.Optimize.DEFAULT]
+    elif quantize == "float16":
+        converter.optimizations = [tf.lite.Optimize.DEFAULT]
+        converter.target_spec.supported_types = [tf.float16]
+    tflite_model = converter.convert()
+    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
+    with open(out_path, "wb") as fh:
+        fh.write(tflite_model)
+    print("Wrote", out_path)
+
+def cli():
+    p = argparse.ArgumentParser()
+    p.add_argument("--savedmodel", required=True)
+    p.add_argument("--output", required=True)
+    p.add_argument("--quantize", choices=["dynamic","float16"], default=None)
+    args = p.parse_args()
+    convert(args.savedmodel, args.output, args.quantize)
+
+if __name__ == "__main__":
+    cli()
+
*** End Patch
*** Begin Patch
*** Add File: scripts/convert_and_attest.sh
+#!/usr/bin/env bash
+set -euo pipefail
+# Convert a savedmodel to multiple edge formats, package and sign
+# Usage: ./scripts/convert_and_attest.sh <saved_model_dir> <out_basename>
+SM_DIR="${1:-}"
+OUT_BASENAME="${2:-example}"
+if [ -z "$SM_DIR" ] || [ -z "$OUT_BASENAME" ]; then
+  echo "Usage: $0 <saved_model_dir> <out_basename>"
+  exit 2
+fi
+
+ART_DIR="artifacts/edge/${OUT_BASENAME}"
+mkdir -p "$ART_DIR"
+
+# TFLite dynamic quant
+python3 scripts/convert_to_tflite.py --savedmodel "$SM_DIR" --output "${ART_DIR}/${OUT_BASENAME}.tflite" --quantize dynamic
+
+# (optional) ONNX conversion if savedmodel -> onnx conversion available (placeholder)
+# python3 scripts/convert_to_onnx.py --savedmodel "$SM_DIR" --output "${ART_DIR}/${OUT_BASENAME}.onnx"
+
+# Create deterministic archive and attest using existing packaging script
+tar -C "${ART_DIR}" -czf "${ART_DIR}.tar.gz" -C "${ART_DIR}" .
+if [ -x scripts/package_and_attest.sh ]; then
+  # package_and_attest.sh requires VAULT_ADDR + VAULT_TOKEN in env
+  scripts/package_and_attest.sh "${ART_DIR}" "${ART_DIR}.tar.gz"
+else
+  echo "scripts/package_and_attest.sh not found or not executable; skip signing"
+fi
+
+echo "Converted and (possibly) attested artifacts in ${ART_DIR} and ${ART_DIR}.tar.gz"
+
*** End Patch
*** Begin Patch
*** Add File: scripts/build-multiarch.sh
+#!/usr/bin/env bash
+set -euo pipefail
+IMAGE="${1:-}"
+if [ -z "$IMAGE" ]; then
+  echo "Usage: $0 <image:tag>"
+  exit 2
+fi
+
+# ensure buildx + qemu are prepared externally (CI workflow installs them)
+docker buildx create --name aegis-builder --use || true
+PLATFORMS="linux/amd64,linux/arm64,linux/arm/v7"
+# Use a Dockerfile that selects arch-specific variant by --file or build args
+docker buildx build --platform "$PLATFORMS" \
+  -t "${IMAGE}" \
+  --push \
+  --file Dockerfile.edge .
+echo "Multi-arch build pushed: ${IMAGE}"
+
*** End Patch
*** Begin Patch
*** Add File: agent/edge-agent.py
+#!/usr/bin/env python3
+"""
+Minimal edge agent:
+- loads a TFLite model from MODEL_CACHE_DIR
+- periodically checks registry for signed model updates (simple HTTP poll)
+- verifies signature using local public key (cosign/vault)
+- swaps model file atomically and reloads interpreter
+This is a skeleton you can extend with device identity and robust retry/backoff.
+"""
+import os
+import time
+import requests
+from pathlib import Path
+import logging
+
+MODEL_FILE = Path(os.environ.get("MODEL_CACHE_DIR", "/models")) / "model.tflite"
+REGISTRY = os.environ.get("MODEL_REGISTRY_URL", "http://localhost:8080")
+POLL_SECS = int(os.environ.get("EDGE_POLL_SECS", "60"))
+
+logging.basicConfig(level=logging.INFO)
+interpreter = None
+
+def load_model(path):
+    global interpreter
+    try:
+        import tensorflow as tf
+    except Exception:
+        logging.debug("TensorFlow Lite not available; skipping model load")
+        return
+    if not path.exists():
+        logging.info("No model at %s", path)
+        return
+    try:
+        interpreter = tf.lite.Interpreter(str(path))
+        interpreter.allocate_tensors()
+        logging.info("Loaded TFLite model: %s", path)
+    except Exception as e:
+        logging.exception("Failed to load tflite model: %s", e)
+
+def check_for_update():
+    # Minimal: call registry endpoint /api/v1/models/latest-edge returning JSON with url+sig
+    try:
+        r = requests.get(f"{REGISTRY}/api/v1/models/latest-edge", timeout=10)
+        r.raise_for_status()
+        j = r.json()
+        return j.get("artifact_url"), j.get("signature_url")
+    except Exception as e:
+        logging.debug("registry check failed: %s", e)
+        return None, None
+
+def download_and_verify(url, sigurl, outpath):
+    # Simplified: download and write; signature verification step left for integration with cosign/vault
+    r = requests.get(url, stream=True, timeout=30)
+    r.raise_for_status()
+    tmp = outpath.with_suffix(".tmp")
+    with open(tmp, "wb") as fh:
+        for chunk in r.iter_content(8192):
+            fh.write(chunk)
+    tmp.replace(outpath)
+    logging.info("Downloaded model to %s", outpath)
+    return True
+
+def main_loop():
+    load_model(MODEL_FILE)
+    while True:
+        try:
+            artifact, sig = check_for_update()
+            if artifact:
+                try:
+                    download_and_verify(artifact, sig, MODEL_FILE)
+                    load_model(MODEL_FILE)
+                except Exception:
+                    logging.exception("Failed to download/verify model")
+        except Exception:
+            logging.exception("update loop error")
+        time.sleep(POLL_SECS)
+
+if __name__ == "__main__":
+    main_loop()
+
*** End Patch
*** Begin Patch
*** Add File: agent/edge-agent-robust.py
+#!/usr/bin/env python3
+"""
+Robust edge agent with verification of signed artifacts.
+
+Verification modes:
+ - COSIGN_PUBKEY_PATH + cosign CLI available:
+     Use `cosign verify-blob --key ${COSIGN_PUBKEY_PATH} --signature ${SIG_FILE} ${ARTIFACT}`
+ - VAULT_ADDR + VAULT_TOKEN:
+     Use Vault transit verify endpoint (/v1/transit/verify/<key>) to verify the base64 digest+signature pair
+ - If neither is available, agent will refuse unsigned updates by default (fail-closed).
+
+Environment variables:
+ - MODEL_CACHE_DIR (default /models)
+ - MODEL_REGISTRY_URL (cloud service that returns JSON: {artifact_url, signature_url, digest_b64})
+ - COSIGN_PUBKEY_PATH (optional)
+ - VAULT_ADDR / VAULT_TOKEN (optional)
+ - VAULT_TRANSIT_KEY (default 'aegis-cosign')
+"""
+from __future__ import annotations
+import base64
+import hashlib
+import json
+import logging
+import os
+import shutil
+import subprocess
+import tempfile
+import time
+from pathlib import Path
+from typing import Optional, Tuple
+
+import requests
+
+MODEL_CACHE_DIR = Path(os.environ.get("MODEL_CACHE_DIR", "/models"))
+MODEL_FILE = MODEL_CACHE_DIR / "model.tflite"
+MODEL_REGISTRY = os.environ.get("MODEL_REGISTRY_URL", "http://localhost:8080")
+COSIGN_PUBKEY = os.environ.get("COSIGN_PUBKEY_PATH", "")
+VAULT_ADDR = os.environ.get("VAULT_ADDR", "")
+VAULT_TOKEN = os.environ.get("VAULT_TOKEN", "")
+VAULT_TRANSIT_KEY = os.environ.get("VAULT_TRANSIT_KEY", "aegis-cosign")
+POLL_SECS = int(os.environ.get("EDGE_POLL_SECS", "60"))
+
+logging.basicConfig(level=logging.INFO)
+log = logging.getLogger("edge-agent-robust")
+
+
+def get_latest_artifact_info() -> Optional[dict]:
+    try:
+        r = requests.get(f"{MODEL_REGISTRY}/api/v1/models/latest-edge", timeout=10)
+        r.raise_for_status()
+        return r.json()
+    except Exception as e:
+        log.debug("registry check failed: %s", e)
+        return None
+
+
+def download_url_to(path: Path, url: str, chunk_size=8192) -> None:
+    tmp = path.with_suffix(".tmp")
+    with requests.get(url, stream=True, timeout=30) as r:
+        r.raise_for_status()
+        with open(tmp, "wb") as fh:
+            for chunk in r.iter_content(chunk_size):
+                fh.write(chunk)
+    tmp.replace(path)
+
+
+def compute_sha256_b64(path: Path) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as fh:
+        for chunk in iter(lambda: fh.read(8192), b""):
+            h.update(chunk)
+    return base64.b64encode(h.digest()).decode("ascii")
+
+
+def verify_with_cosign(artifact: Path, sig_b64: str) -> bool:
+    # write signature file in cosign detached format (raw base64)
+    sigfile = artifact.with_suffix(".sig.b64")
+    sigfile.write_text(sig_b64)
+    if not COSIGN_PUBKEY:
+        log.error("COSIGN_PUBKEY_PATH not configured")
+        return False
+    # require cosign CLI
+    try:
+        res = subprocess.run(
+            ["cosign", "verify-blob", "--key", COSIGN_PUBKEY, "--signature", str(sigfile), str(artifact)],
+            stdout=subprocess.PIPE,
+            stderr=subprocess.PIPE,
+            check=False,
+            text=True,
+        )
+        log.debug("cosign stdout: %s", res.stdout)
+        log.debug("cosign stderr: %s", res.stderr)
+        return res.returncode == 0
+    finally:
+        try:
+            sigfile.unlink()
+        except Exception:
+            pass
+
+
+def verify_with_vault(artifact: Path, sig_b64: str, digest_b64: str) -> bool:
+    if not VAULT_ADDR or not VAULT_TOKEN:
+        log.error("VAULT_ADDR/VAULT_TOKEN not configured")
+        return False
+    # Vault transit verify endpoint expects input (base64) and signature (string)
+    url = f"{VAULT_ADDR.rstrip('/')}/v1/transit/verify/{VAULT_TRANSIT_KEY}"
+    payload = {"input": digest_b64, "signature": sig_b64}
+    headers = {"X-Vault-Token": VAULT_TOKEN}
+    try:
+        r = requests.post(url, json=payload, headers=headers, timeout=10)
+        r.raise_for_status()
+        j = r.json()
+        # vault returns data.valid boolean in many setups (depends on transit engine)
+        valid = bool(j.get("data", {}).get("valid", False))
+        log.debug("vault verify response: %s", j)
+        return valid
+    except Exception as e:
+        log.exception("Vault verify failed: %s", e)
+        return False
+
+
+def safe_replace_model(new_model: Path, dest: Path) -> None:
+    dest_tmp = dest.with_suffix(".new")
+    shutil.copy2(new_model, dest_tmp)
+    os.replace(dest_tmp, dest)
+    log.info("Model swapped into place: %s", dest)
+
+
+def reload_hook():
+    # Hook executed after a successful update - override if you need a special reload (e.g., systemctl restart)
+    log.info("Reload hook: no-op (container should hot-reload model or restart strategy will apply)")
+
+
+def process_update(info: dict) -> None:
+    artifact_url = info.get("artifact_url")
+    sig_url = info.get("signature_url")
+    digest_b64 = info.get("digest_b64")  # optional: precomputed digest passed by registry
+    if not artifact_url or not sig_url:
+        log.debug("artifact_url or signature_url missing in registry response")
+        return
+
+    MODEL_CACHE_DIR.mkdir(parents=True, exist_ok=True)
+    tmp_artifact = MODEL_CACHE_DIR / "candidate.artifact"
+    tmp_sig = MODEL_CACHE_DIR / "candidate.sig.json"
+    try:
+        log.info("Downloading artifact from %s", artifact_url)
+        download_url_to(tmp_artifact, artifact_url)
+        log.info("Downloading signature from %s", sig_url)
+        download_url_to(tmp_sig, sig_url)
+        sig_json = json.loads(tmp_sig.read_text())
+        # try to locate common fields (supporting different signing outputs)
+        sig_b64 = (
+            sig_json.get("data", {}).get("signature")
+            or sig_json.get("signature")
+            or sig_json.get("sig")
+            or sig_json.get("signatures", [None])[0]
+        )
+        if not sig_b64:
+            log.error("signature not found in signature JSON")
+            return
+
+        # compute digest if not provided
+        if not digest_b64:
+            digest_b64 = compute_sha256_b64(tmp_artifact)
+            log.debug("Computed artifact digest b64: %s", digest_b64)
+
+        verified = False
+        if COSIGN_PUBKEY:
+            log.info("Attempting cosign verification")
+            verified = verify_with_cosign(tmp_artifact, sig_b64)
+            log.info("cosign verification result: %s", verified)
+        if not verified and VAULT_ADDR and VAULT_TOKEN:
+            log.info("Attempting Vault transit verification")
+            verified = verify_with_vault(tmp_artifact, sig_b64, digest_b64)
+            log.info("vault verification result: %s", verified)
+
+        if not verified:
+            log.error("Artifact verification failed; refusing update")
+            return
+
+        # atomic swap
+        safe_replace_model(tmp_artifact, MODEL_FILE)
+        reload_hook()
+        log.info("Model update complete and verified")
+    except Exception:
+        log.exception("update failed")
+    finally:
+        try:
+            tmp_sig.unlink()
+        except Exception:
+            pass
+
+
+def main_loop():
+    log.info("Starting robust edge agent (policy: fail-closed for unsigned artifacts)")
+    while True:
+        info = get_latest_artifact_info()
+        if info:
+            try:
+                process_update(info)
+            except Exception:
+                log.exception("process_update error")
+        time.sleep(POLL_SECS)
+
+
+if __name__ == "__main__":
+    main_loop()
+
*** End Patch
*** Begin Patch
*** Add File: helm/values.edge.yaml
+# Edge Helm values overlay
+image:
+  repository: ghcr.io/ORG/aegis-edge
+  tag: latest
+  pullPolicy: IfNotPresent
+
+model:
+  registryUrl: "https://model-registry.example.com"
+  cacheDir: /models
+  # Frequency in seconds for agent to poll for updates
+  pollSecs: 60
+
+resources:
+  requests:
+    cpu: "200m"
+    memory: "256Mi"
+  limits:
+    cpu: "1000m"
+    memory: "1Gi"
+
+nodeSelector:
+  "node-role.kubernetes.io/edge": "true"
+
+tolerations:
+  - key: "edge"
+    operator: "Exists"
+    effect: "NoSchedule"
+
+securityContext:
+  runAsUser: 1000
+  runAsGroup: 1000
+  fsGroup: 1000
+
*** End Patch
*** Begin Patch
*** Add File: k8s/edge-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: aegis-edge
+  labels:
+    app: aegis-edge
+spec:
+  replicas: 1
+  selector:
+    matchLabels:
+      app: aegis-edge
+  template:
+    metadata:
+      labels:
+        app: aegis-edge
+    spec:
+      nodeSelector:
+        node-role.kubernetes.io/edge: "true"   # set on edge nodes
+      tolerations:
+      - key: "edge"
+        operator: "Exists"
+        effect: "NoSchedule"
+      containers:
+        - name: aegis-edge
+          image: your-registry/aegis-edge:latest
+          imagePullPolicy: IfNotPresent
+          ports:
+            - containerPort: 9000
+            - containerPort: 8000
+          env:
+            - name: MODEL_CACHE_DIR
+              value: /models
+            - name: MODEL_REGISTRY_URL
+              value: https://model-registry.internal
+          resources:
+            requests:
+              cpu: "200m"
+              memory: "256Mi"
+            limits:
+              cpu: "1000m"
+              memory: "1Gi"
+          volumeMounts:
+            - name: model-cache
+              mountPath: /models
+      volumes:
+        - name: model-cache
+          hostPath:
+            path: /var/lib/aegis/models
+            type: DirectoryOrCreate
+
*** End Patch
*** Begin Patch
*** Add File: k8s/kubeedge/edge-rbac.yaml
+apiVersion: v1
+kind: ServiceAccount
+metadata:
+  name: aegis-edge-controller
+  namespace: aegis
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: aegis-edge-controller-role
+rules:
+  - apiGroups: [""]
+    resources: ["pods","configmaps","secrets"]
+    verbs: ["get","list","watch","update","patch","create"]
+  - apiGroups: ["apps"]
+    resources: ["deployments"]
+    verbs: ["get","list","watch","update","patch"]
+
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRoleBinding
+metadata:
+  name: aegis-edge-controller-binding
+subjects:
+  - kind: ServiceAccount
+    name: aegis-edge-controller
+    namespace: aegis
+roleRef:
+  kind: ClusterRole
+  name: aegis-edge-controller-role
+  apiGroup: rbac.authorization.k8s.io
+
*** End Patch
*** Begin Patch
*** Add File: k8s/kubeedge/ota-cloud-cronjob.yaml
+apiVersion: batch/v1
+kind: CronJob
+metadata:
+  name: aegis-edge-ota-trigger
+  namespace: aegis
+spec:
+  schedule: "*/5 * * * *"  # run every 5 minutes - tune as needed
+  jobTemplate:
+    spec:
+      template:
+        spec:
+          serviceAccountName: aegis-edge-controller
+          restartPolicy: OnFailure
+          containers:
+            - name: ota-trigger
+              image: curlimages/curl:8.2
+              env:
+                - name: MODEL_REGISTRY
+                  value: "https://model-registry.example.com"
+              command:
+                - /bin/sh
+                - -c
+                - |
+                  # Cloud-side "poke" that writes new model metadata into a ConfigMap / triggers KubeEdge sync
+                  # Replace with a real controller or webhook in production.
+                  LATEST=$(curl -fsS ${MODEL_REGISTRY}/api/v1/models/latest-edge || echo "{}")
+                  echo "$LATEST" > /tmp/latest.json
+                  # Create/patch a configmap that edge nodes will watch via KubeEdge; the edgecore will receive the update
+                  kubectl -n aegis create configmap aegis-edge-latest --from-file=latest.json=/tmp/latest.json --dry-run=client -o yaml | kubectl apply -f -
+
*** End Patch
*** Begin Patch
*** Add File: README.edge.md
+# Edge targets & CI - Summary
+
+This new edge support adds:
+- Multi-arch Dockerfiles (amd64/arm64/armv7)
+- CI workflow (.github/workflows/edge-ci.yml) to convert models, attest artifacts, and build multi-arch images
+- Conversion & packaging helpers (scripts/convert_and_attest.sh and scripts/build-multiarch.sh)
+- Robust edge agent (agent/edge-agent-robust.py) that verifies cosign/Vault-signed artifacts
+- Helm values overlay (helm/values.edge.yaml)
+- KubeEdge example with OTA CronJob + RBAC (k8s/kubeedge/*)
+
+Important: secrets & prerequisites
+- CI signing requires VAULT_ADDR + VAULT_TOKEN (set in repo secrets) and optionally REKOR_URL.
+- Edge verification requires either COSIGN_PUBKEY_PATH (container or mounted secret) and cosign CLI in the image OR VAULT_ADDR+VAULT_TOKEN + VAULT_TRANSIT_KEY to call Vault transit verify.
+- For arm builds you must enable QEMU and ensure cross-building in CI.
+
+Next steps I can take (pick one)
+- Open a PR that adds these files to the repo (I can prepare the PR with the exact files).
+- Extend the edge-agent to support TPM-backed device identity and a device bootstrap flow (Vault AppRole or PKI).
+- Add a real cloud controller (Kubernetes Operator) that orchestrates OTA updates and tracks model rollout status.
+
*** End Patch
