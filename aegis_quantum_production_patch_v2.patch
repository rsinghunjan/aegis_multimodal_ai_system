*** Begin Patch
*** Add File: quantum/qpu_provider_ibm.py
+#!/usr/bin/env python3
+"""
+IBM QPU provider integration.
+- Loads IBM credentials from Vault (via secrets.vault_client.get_secret)
+- Submits jobs via qiskit-ibm-runtime (if available) with retries and provenance recording
+- Requires operator approval for real QPU runs (calls Approval Orchestrator or checks a signoff)
+"""
+import os, time, json
+from typing import Dict, Any
+from observability.audit_indexer import write_record
+from rl.checkpoint_manager import upload_checkpoint
+from secrets.vault_client import get_secret
+
+try:
+    from qiskit_ibm_runtime import QiskitRuntimeService, Sampler, Estimator
+    from qiskit import QuantumCircuit
+except Exception:
+    QiskitRuntimeService = None
+    QuantumCircuit = None
+
+APPROVAL_API = os.environ.get("APPROVAL_API", "http://approval-orchestrator.aegis.svc:8207")
+OPERATOR_SIGNOFF_REQUIRED = os.environ.get("QPU_OPERATOR_SIGNOFF", "true").lower() == "true"
+
+def _require_approval(experiment_meta: Dict[str, Any]) -> bool:
+    # Simple hook: if operator signoff required, create approval entry and mark pending
+    if not OPERATOR_SIGNOFF_REQUIRED:
+        return False
+    try:
+        import requests
+        r = requests.post(f"{APPROVAL_API}/submit", json={"plan": {"type":"qpu_run","meta": experiment_meta}, "tenant": experiment_meta.get("tenant","unknown")}, timeout=5)
+        if r.ok:
+            return True
+    except Exception:
+        pass
+    # If we can't create approval, fail-safe: require manual intervention
+    return True
+
+class IBMProvider:
+    def __init__(self, vault_token_path: str = None):
+        self.api_key = get_secret("secret/data/aegis/quantum/ibm", key="api_key") or os.environ.get("IBM_Q_TOKEN")
+        if not self.api_key:
+            raise RuntimeError("IBM API key not configured in Vault or env")
+        if QiskitRuntimeService:
+            self.service = QiskitRuntimeService(channel="ibm_quantum", token=self.api_key)
+        else:
+            self.service = None
+
+    def submit_program(self, program: Dict[str, Any]) -> str:
+        """
+        program: {"qasm": str} or {"qiskit_json": {...}}, "shots": int, "tenant": str, "require_approval": bool}
+        Returns job_id (string) or raises.
+        """
+        meta = {"tenant": program.get("tenant"), "shots": program.get("shots", 1024)}
+        if program.get("require_approval", False) or OPERATOR_SIGNOFF_REQUIRED:
+            # create approval and return pending status until approved
+            _require_approval(meta)
+            # by design, we return a placeholder id that orchestrator will poll
+            jid = f"pending-approval-{int(time.time()*1000)}"
+            write_record("quantum_job_request", {"job_id": jid, "meta": meta, "status": "pending_approval"})
+            return jid
+
+        if self.service is None:
+            raise RuntimeError("Qiskit runtime not installed")
+        qasm = program.get("qasm")
+        qc = None
+        if qasm:
+            qc = QuantumCircuit.from_qasm_str(qasm)
+        else:
+            qc_json = program.get("qiskit_json")
+            if qc_json:
+                qc = QuantumCircuit.from_json(qc_json)
+        if qc is None:
+            raise RuntimeError("No circuit provided")
+
+        sampler = Sampler(session=self.service)
+        job = sampler.run(qc, shots=program.get("shots", 1024))
+        job_id = job.job_id()
+        write_record("quantum_job_submitted", {"job_id": job_id, "tenant": meta.get("tenant"), "backend": "ibm", "shots": meta.get("shots")})
+        return job_id
+
+    def job_status(self, job_id: str) -> Dict[str, Any]:
+        # Simplified status check; operator should extend with real API polling
+        if self.service is None:
+            return {"job_id": job_id, "status": "UNKNOWN"}
+        try:
+            # The qiskit_ibm_runtime Sampler/Estimator job objects have methods; here we attempt to get job via runtime service
+            j = self.service.job(job_id)
+            return {"job_id": job_id, "status": j.status().value, "raw": str(j)}
+        except Exception:
+            return {"job_id": job_id, "status": "UNKNOWN"}
+
*** End Patch
*** Begin Patch
*** Add File: quantum/qpu_provider_braket.py
+#!/usr/bin/env python3
+"""
+Amazon Braket provider integration.
+ - Reads AWS credentials or role from Vault / environment (operators must configure)
+ - Submits tasks using boto3 braket client with careful error handling
+ - Records provenance
+"""
+import os, json, time
+from observability.audit_indexer import write_record
+from secrets.vault_client import get_secret
+
+import boto3
+
+OPERATOR_SIGNOFF_REQUIRED = os.environ.get("QPU_OPERATOR_SIGNOFF", "true").lower() == "true"
+APPROVAL_API = os.environ.get("APPROVAL_API", "http://approval-orchestrator.aegis.svc:8207")
+
+def _require_approval(meta):
+    if not OPERATOR_SIGNOFF_REQUIRED:
+        return False
+    try:
+        import requests
+        r = requests.post(f"{APPROVAL_API}/submit", json={"plan": {"type":"qpu_run","meta": meta}, "tenant": meta.get("tenant","unknown")}, timeout=5)
+        return r.ok
+    except Exception:
+        return True
+
+class BraketProvider:
+    def __init__(self, region=None):
+        self.region = region or os.environ.get("AWS_REGION", "us-east-1")
+        # credentials can be provided via environment, role, or Vault (operator should provide)
+        aws_key = get_secret("secret/data/aegis/quantum/braket", key="aws_access_key_id") or os.environ.get("AWS_ACCESS_KEY_ID")
+        aws_secret = get_secret("secret/data/aegis/quantum/braket", key="aws_secret_access_key") or os.environ.get("AWS_SECRET_ACCESS_KEY")
+        if aws_key and aws_secret:
+            self.client = boto3.client("braket", region_name=self.region, aws_access_key_id=aws_key, aws_secret_access_key=aws_secret)
+        else:
+            self.client = boto3.client("braket", region_name=self.region)
+
+    def submit_task(self, program: dict) -> str:
+        """
+        program should contain keys required by create_quantum_task. This wrapper enforces minimal validation.
+        """
+        meta = {"tenant": program.get("tenant"), "device": program.get("device_arn")}
+        if program.get("require_approval", False):
+            _require_approval(meta)
+            jid = f"pending-approval-{int(time.time()*1000)}"
+            write_record("quantum_job_request", {"job_id": jid, "meta": meta, "status": "pending_approval"})
+            return jid
+        # call create_quantum_task
+        try:
+            resp = self.client.create_quantum_task(**program)
+            arn = resp.get("quantumTaskArn")
+            write_record("quantum_job_submitted", {"job_id": arn, "tenant": meta.get("tenant"), "backend": "braket"})
+            return arn
+        except Exception as e:
+            write_record("quantum_job_submit_error", {"error": str(e), "meta": meta})
+            raise
+
+    def task_status(self, arn: str) -> dict:
+        try:
+            resp = self.client.get_quantum_task(quantumTaskArn=arn)
+            return resp
+        except Exception:
+            return {"arn": arn, "status": "UNKNOWN"}
+
*** End Patch
*** Begin Patch
*** Add File: quantum/job_queue.py
+#!/usr/bin/env python3
+"""
+Quantum Job Queue & Scheduler
+ - Accepts job submissions and persists to SQLite
+ - Uses Redis for a work queue and quota enforcement
+ - Worker processes pick jobs, enforce per-tenant quotas via billing/redis_quota.consume_quota,
+   and dispatch to simulator or real provider adapters
+ - Records provenance and billing entries
+"""
+import os, sqlite3, json, time, threading
+from typing import Dict, Any
+import redis
+from secrets.vault_client import get_secret
+from observability.audit_indexer import write_record
+from billing.redis_quota import consume_quota
+from quantum.qpu_adapter import QPUAdapter
+from quantum.qpu_provider_ibm import IBMProvider
+from quantum.qpu_provider_braket import BraketProvider
+
+DB = os.environ.get("QUANTUM_JOB_DB", "/data/quantum_jobs.sqlite")
+REDIS_URL = os.environ.get("REDIS_URL", "redis://redis:6379/9")
+QUEUE_KEY = os.environ.get("QUANTUM_QUEUE_KEY", "quantum:queue")
+
+redis_client = redis.from_url(REDIS_URL)
+
+def conn():
+    c = sqlite3.connect(DB, check_same_thread=False)
+    c.execute("""CREATE TABLE IF NOT EXISTS jobs (
+        id INTEGER PRIMARY KEY AUTOINCREMENT,
+        job_id TEXT,
+        tenant TEXT,
+        backend TEXT,
+        payload TEXT,
+        status TEXT,
+        created_at INTEGER,
+        updated_at INTEGER
+    )""")
+    c.commit()
+    return c
+
+def enqueue_job(payload: Dict[str, Any]) -> int:
+    c = conn()
+    now = int(time.time())
+    cur = c.cursor()
+    cur.execute("INSERT INTO jobs (job_id,tenant,backend,payload,status,created_at,updated_at) VALUES (?,?,?,?,?,?,?)",
+                (None, payload.get("tenant"), payload.get("backend","simulator"), json.dumps(payload), "queued", now, now))
+    jid = cur.lastrowid
+    c.commit()
+    redis_client.rpush(QUEUE_KEY, jid)
+    write_record("quantum_job_enqueued", {"local_id": jid, "payload": payload})
+    return jid
+
+def worker_loop():
+    sim = QPUAdapter()
+    ibm = None
+    braket = None
+    try:
+        ibm = IBMProvider()
+    except Exception:
+        pass
+    try:
+        braket = BraketProvider()
+    except Exception:
+        pass
+    while True:
+        item = redis_client.blpop(QUEUE_KEY, timeout=5)
+        if not item:
+            time.sleep(1); continue
+        _, raw = item
+        jid = int(raw)
+        c = conn(); cur = c.cursor()
+        cur.execute("SELECT id,payload,tenant,backend FROM jobs WHERE id=?", (jid,))
+        row = cur.fetchone()
+        if not row:
+            continue
+        payload = json.loads(row[1])
+        tenant = row[2] or "default"
+        # estimate cost/tokens: simple runtime estimate; operator must adapt
+        estimated_tokens = int(payload.get("shots", 1024) / 10)
+        allowed, remaining = consume_quota(f"quota:{tenant}", estimated_tokens)
+        if not allowed:
+            cur.execute("UPDATE jobs SET status=?, updated_at=? WHERE id=?", ("throttled", int(time.time()), jid))
+            c.commit()
+            write_record("quantum_job_throttled", {"local_id": jid, "tenant": tenant, "required": estimated_tokens})
+            continue
+        # dispatch to backend
+        backend = payload.get("backend","simulator")
+        try:
+            if backend == "simulator":
+                qpu = sim
+                jobid = qpu.submit_local_sim(payload.get("qasm") or json.dumps(payload.get("qiskit_json")), shots=payload.get("shots",1024))
+            elif backend == "ibm" and ibm:
+                jobid = ibm.submit_program(payload)
+            elif backend == "braket" and braket:
+                jobid = braket.submit_task(payload)
+            else:
+                # fallback to simulator
+                jobid = sim.submit_local_sim(payload.get("qasm") or json.dumps(payload.get("qiskit_json")), shots=payload.get("shots",1024))
+            cur.execute("UPDATE jobs SET job_id=?, status=?, updated_at=? WHERE id=?", (jobid, "submitted", int(time.time()), jid))
+            c.commit()
+            write_record("quantum_job_dispatched", {"local_id": jid, "job_id": jobid, "backend": backend, "tenant": tenant})
+        except Exception as e:
+            cur.execute("UPDATE jobs SET status=?, updated_at=? WHERE id=?", ("failed", int(time.time()), jid))
+            c.commit()
+            write_record("quantum_job_failed", {"local_id": jid, "error": str(e)})
+
+def start_worker_thread():
+    t = threading.Thread(target=worker_loop, daemon=True)
+    t.start()
+    return t
+
+if __name__=="__main__":
+    start_worker_thread()
+    import time
+    while True:
+        time.sleep(10)
+
*** End Patch
*** Begin Patch
*** Add File: k8s/quantum/quantum-job-worker-deployment.yaml
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: quantum-job-worker
+  namespace: aegis
+spec:
+  replicas: 2
+  selector:
+    matchLabels:
+      app: quantum-job-worker
+  template:
+    metadata:
+      labels:
+        app: quantum-job-worker
+    spec:
+      containers:
+        - name: quantum-worker
+          image: aegis/quantum-worker:latest
+          env:
+            - name: REDIS_URL
+              value: "redis://redis:6379/9"
+            - name: QUANTUM_JOB_DB
+              value: "/data/quantum_jobs.sqlite"
+          volumeMounts:
+            - name: data
+              mountPath: /data
+          resources:
+            requests:
+              cpu: "500m"
+              memory: "1Gi"
+            limits:
+              cpu: "1"
+              memory: "2Gi"
+      volumes:
+        - name: data
+          emptyDir: {}
+
+---
+apiVersion: v1
+kind: Service
+metadata:
+  name: quantum-job-worker
+  namespace: aegis
+spec:
+  selector:
+    app: quantum-job-worker
+  ports:
+    - port: 8311
+      targetPort: 8311
+
*** End Patch
*** Begin Patch
*** Add File: quantum/cost_reconciler.py
+#!/usr/bin/env python3
+"""
+Quantum cost reconciler:
+ - pulls job runtime data from providers (where possible)
+ - reconciles estimated costs recorded in quantum/billing.py with provider invoices (operator / S3 store)
+ - raises alerts on discrepancies
+"""
+import os, json, time
+import redis, requests
+from observability.audit_indexer import write_record
+
+REDIS_URL = os.environ.get("REDIS_URL", "redis://redis:6379/9")
+COMPLIANCE_BUCKET = os.environ.get("COMPLIANCE_BUCKET")
+OPERATOR_WEBHOOK = os.environ.get("OPERATOR_NOTIFY_WEBHOOK")
+
+r = redis.from_url(REDIS_URL)
+
+def reconcile_provider(provider_name):
+    # placeholder: implement provider-specific invoice fetch
+    # for now, scan audit records for quantum_job_submitted and aggregate per-tenant estimated runtime
+    # write reconciliation record to compliance bucket via audit_indexer
+    # This function should be extended with real provider billing APIs.
+    rec = {"provider": provider_name, "ts": int(time.time()), "summary": {}}
+    # scan redis or other stores for job metrics
+    # operator: implement provider invoice fetch here
+    write_record("quantum_cost_reconcile", rec)
+    # if anomalies, notify operator
+    if OPERATOR_WEBHOOK:
+        try:
+            requests.post(OPERATOR_WEBHOOK, json={"event":"quantum_reconcile_done","provider": provider_name}, timeout=5)
+        except Exception:
+            pass
+    return rec
+
+if __name__=="__main__":
+    print(reconcile_provider("ibm"))
+
*** End Patch
*** Begin Patch
*** Add File: vault/scripts/configure_quantum_providers.sh
+#!/usr/bin/env bash
+set -euo pipefail
+
+# Configure Vault secret paths for quantum providers. Operators must run with sufficient privileges.
+: "${VAULT_ADDR:?}"
+: "${VAULT_TOKEN:?}"
+
+echo "Creating Vault KV entries for IBM and Braket (operator must set real values)..."
+vault login "${VAULT_TOKEN}" >/dev/null
+
+# Example writes (operator to replace with real secrets)
+vault kv put secret/aegis/quantum/ibm api_key="REPLACE_WITH_REAL"
+vault kv put secret/aegis/quantum/braket aws_access_key_id="REPLACE" aws_secret_access_key="REPLACE"
+
+echo "Configured example quantum provider secrets (replace placeholder values with real tokens via secure process)."
+
*** End Patch
*** Begin Patch
*** Add File: .github/workflows/qpu_run_approval.yml
+name: QPU Run Approval Gate
+on:
+  workflow_dispatch:
+    inputs:
+      job_payload:
+        description: 'JSON payload for QPU run'
+        required: true
+
+jobs:
+  require-approval:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Submit approval request
+        env:
+          APPROVAL_API: ${{ secrets.APPROVAL_API }}
+        run: |
+          echo "${{ github.event.inputs.job_payload }}" > /tmp/job.json
+          curl -s -X POST "${APPROVAL_API}/submit" -H "Content-Type: application/json" -d "{\"plan\": $(cat /tmp/job.json)}"
+          echo "Approval request submitted; operator must approve in approval UI before job will be dispatched to QPU"
+
*** End Patch
*** Begin Patch
*** Add File: compliance/qpu_pen_test_checklist.md
+# QPU Penetration Test Checklist (Operators)
+
+1. Credential handling
+   - Verify IBM and Braket credentials are stored in Vault KV and rotated regularly.
+   - Ensure CI and untrusted namespaces cannot read quantum provider secrets.
+
+2. Network controls
+   - Restrict egress for namespaces that should not access QPU providers.
+   - Ensure operator-signing endpoint only reachable from operator namespace.
+
+3. Job isolation & injection
+   - Test for injection of malicious circuits via job payloads; validate sanitization on orchestrator.
+   - Test job queue replay and idempotency.
+
+4. Billing & accounting
+   - Verify that job runtime metrics map to provider invoices; reconcile discrepancies.
+
+5. Compliance evidence
+   - Ensure each QPU job has an audit record with prompt_id/model/tenant and that artifact evidence (if required) is signed via operator HSM.
+
*** End Patch
*** Begin Patch
*** Add File: quantum/README_provider_integration.md
+# Quantum Provider Integration Guide
+
+1. Vault
+   - Store IBM token at secret/aegis/quantum/ibm: api_key
+   - Store Braket credentials at secret/aegis/quantum/braket: aws_access_key_id, aws_secret_access_key
+
+2. Operator approval
+   - QPU runs that target real hardware require operator approval. The providers' wrappers create an approval entry in Approval Orchestrator.
+   - Operators should approve via the operator UI (Approval Orchestrator) before jobs are dispatched.
+
+3. Job queue
+   - Submit jobs via quantum/job_queue.enqueue_job(payload). Workers pick up and dispatch jobs. Quotas enforced via Redis Lua token bucket.
+   - To run worker: deploy k8s/quantum/quantum-job-worker-deployment.yaml
+
+4. Billing
+   - Quantum job runtime and estimated cost are recorded via quantum/billing and reconciled with quantum/cost_reconciler.py
+
+5. CI
+   - Use .github/workflows/qpu_run_approval.yml to request operator approval when running potential QPU jobs from CI.
+
*** End Patch
*** End Patch
